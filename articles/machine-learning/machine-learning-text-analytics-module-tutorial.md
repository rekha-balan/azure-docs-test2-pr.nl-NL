---
title: Create text analytics models in Azure Machine Learning Studio | Microsoft Docs
description: How to create text analytics models in Azure Machine Learning Studio using modules for text preprocessing, N-grams or feature hashing
services: machine-learning
documentationcenter: ''
author: rastala
manager: jhubbard
editor: ''
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: f5376555602b7a27738d418a2582e767eb1a0f01
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44553137"
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="1dc61-103">Create text analytics models in Azure Machine Learning Studio</span><span class="sxs-lookup"><span data-stu-id="1dc61-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="1dc61-104">You can use Azure Machine Learning to build and operationalize text analytics models.</span><span class="sxs-lookup"><span data-stu-id="1dc61-104">You can use Azure Machine Learning to build and operationalize text analytics models.</span></span> <span data-ttu-id="1dc61-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span><span class="sxs-lookup"><span data-stu-id="1dc61-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="1dc61-106">In a text analytics experiment, you would typically:</span><span class="sxs-lookup"><span data-stu-id="1dc61-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="1dc61-107">Clean and preprocess text dataset</span><span class="sxs-lookup"><span data-stu-id="1dc61-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="1dc61-108">Extract numeric feature vectors from pre-processed text</span><span class="sxs-lookup"><span data-stu-id="1dc61-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="1dc61-109">Train classification or regression model</span><span class="sxs-lookup"><span data-stu-id="1dc61-109">Train classification or regression model</span></span>
4. <span data-ttu-id="1dc61-110">Score and validate the model</span><span class="sxs-lookup"><span data-stu-id="1dc61-110">Score and validate the model</span></span>
5. <span data-ttu-id="1dc61-111">Deploy the model to production</span><span class="sxs-lookup"><span data-stu-id="1dc61-111">Deploy the model to production</span></span>

<span data-ttu-id="1dc61-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span><span class="sxs-lookup"><span data-stu-id="1dc61-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="1dc61-113">The goal is to predict the review score: low (1-2) or high (4-5).</span><span class="sxs-lookup"><span data-stu-id="1dc61-113">The goal is to predict the review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="1dc61-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span><span class="sxs-lookup"><span data-stu-id="1dc61-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="1dc61-115">Predict Book Reviews</span><span class="sxs-lookup"><span data-stu-id="1dc61-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="1dc61-116">Predict Book Reviews - Predictive Experiment</span><span class="sxs-lookup"><span data-stu-id="1dc61-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="1dc61-117">Step 1: Clean and preprocess text dataset</span><span class="sxs-lookup"><span data-stu-id="1dc61-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="1dc61-118">We begin the experiment by dividing the review scores into categorical low and high buckets to formulate the problem as two-class classification.</span><span class="sxs-lookup"><span data-stu-id="1dc61-118">We begin the experiment by dividing the review scores into categorical low and high buckets to formulate the problem as two-class classification.</span></span> <span data-ttu-id="1dc61-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span><span class="sxs-lookup"><span data-stu-id="1dc61-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![Create Label](https://docstestmedia1.blob.core.windows.net/azure-media/articles/machine-learning/media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="1dc61-121">Then, we clean the text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span><span class="sxs-lookup"><span data-stu-id="1dc61-121">Then, we clean the text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="1dc61-122">The cleaning reduces the noise in the dataset, help you find the most important features, and improve the accuracy of the final model.</span><span class="sxs-lookup"><span data-stu-id="1dc61-122">The cleaning reduces the noise in the dataset, help you find the most important features, and improve the accuracy of the final model.</span></span> <span data-ttu-id="1dc61-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span><span class="sxs-lookup"><span data-stu-id="1dc61-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="1dc61-124">We also convert the text to lowercase, lemmatize the words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span><span class="sxs-lookup"><span data-stu-id="1dc61-124">We also convert the text to lowercase, lemmatize the words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![Preprocess Text](https://docstestmedia1.blob.core.windows.net/azure-media/articles/machine-learning/media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="1dc61-126">What if you want to use a custom list of stopwords?</span><span class="sxs-lookup"><span data-stu-id="1dc61-126">What if you want to use a custom list of stopwords?</span></span> <span data-ttu-id="1dc61-127">You can pass it in as optional input.</span><span class="sxs-lookup"><span data-stu-id="1dc61-127">You can pass it in as optional input.</span></span> <span data-ttu-id="1dc61-128">You can also use custom C# syntax regular expression to replace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span><span class="sxs-lookup"><span data-stu-id="1dc61-128">You can also use custom C# syntax regular expression to replace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="1dc61-129">After the preprocessing is complete, we split the data into train and test sets.</span><span class="sxs-lookup"><span data-stu-id="1dc61-129">After the preprocessing is complete, we split the data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="1dc61-130">Step 2: Extract numeric feature vectors from pre-processed text</span><span class="sxs-lookup"><span data-stu-id="1dc61-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="1dc61-131">To build a model for text data, you typically have to convert free-form text into numeric feature vectors.</span><span class="sxs-lookup"><span data-stu-id="1dc61-131">To build a model for text data, you typically have to convert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="1dc61-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module to transform the text data to such format.</span><span class="sxs-lookup"><span data-stu-id="1dc61-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module to transform the text data to such format.</span></span> <span data-ttu-id="1dc61-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span><span class="sxs-lookup"><span data-stu-id="1dc61-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="1dc61-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span><span class="sxs-lookup"><span data-stu-id="1dc61-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="1dc61-135">In this tutorial, we set N-gram size to 2, so our feature vectors include single words and combinations of two subsequent words.</span><span class="sxs-lookup"><span data-stu-id="1dc61-135">In this tutorial, we set N-gram size to 2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![Extract N-grams](https://docstestmedia1.blob.core.windows.net/azure-media/articles/machine-learning/media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="1dc61-137">We apply TF\*IDF (Term Frequency Inverse Document Frequency) weighting to N-gram counts.</span><span class="sxs-lookup"><span data-stu-id="1dc61-137">We apply TF\*IDF (Term Frequency Inverse Document Frequency) weighting to N-gram counts.</span></span> <span data-ttu-id="1dc61-138">This approach adds weight of words that appear frequently in a single record but are rare across the entire dataset.</span><span class="sxs-lookup"><span data-stu-id="1dc61-138">This approach adds weight of words that appear frequently in a single record but are rare across the entire dataset.</span></span> <span data-ttu-id="1dc61-139">Other options include binary, TF, and graph weighing.</span><span class="sxs-lookup"><span data-stu-id="1dc61-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="1dc61-140">Such text features often have high dimensionality.</span><span class="sxs-lookup"><span data-stu-id="1dc61-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="1dc61-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span><span class="sxs-lookup"><span data-stu-id="1dc61-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="1dc61-142">The Extract N-Gram Features module gives you a set of options to reduce the dimensionality.</span><span class="sxs-lookup"><span data-stu-id="1dc61-142">The Extract N-Gram Features module gives you a set of options to reduce the dimensionality.</span></span> <span data-ttu-id="1dc61-143">You can choose to exclude words that are short or long, or too uncommon or too frequent to have significant predictive value.</span><span class="sxs-lookup"><span data-stu-id="1dc61-143">You can choose to exclude words that are short or long, or too uncommon or too frequent to have significant predictive value.</span></span> <span data-ttu-id="1dc61-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span><span class="sxs-lookup"><span data-stu-id="1dc61-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="1dc61-145">Also, you can use feature selection to select only those features that are the most correlated with your prediction target.</span><span class="sxs-lookup"><span data-stu-id="1dc61-145">Also, you can use feature selection to select only those features that are the most correlated with your prediction target.</span></span> <span data-ttu-id="1dc61-146">We use Chi-Squared feature selection to select 1000 features.</span><span class="sxs-lookup"><span data-stu-id="1dc61-146">We use Chi-Squared feature selection to select 1000 features.</span></span> <span data-ttu-id="1dc61-147">You can view the vocabulary of selected words or N-grams by clicking the right output of Extract N-grams module.</span><span class="sxs-lookup"><span data-stu-id="1dc61-147">You can view the vocabulary of selected words or N-grams by clicking the right output of Extract N-grams module.</span></span>

<span data-ttu-id="1dc61-148">As an alternative approach to using Extract N-Gram Features, you can use Feature Hashing module.</span><span class="sxs-lookup"><span data-stu-id="1dc61-148">As an alternative approach to using Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="1dc61-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF\*IDF weighing.</span><span class="sxs-lookup"><span data-stu-id="1dc61-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF\*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="1dc61-150">Step 3: Train classification or regression model</span><span class="sxs-lookup"><span data-stu-id="1dc61-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="1dc61-151">Now the text has been transformed to numeric feature columns.</span><span class="sxs-lookup"><span data-stu-id="1dc61-151">Now the text has been transformed to numeric feature columns.</span></span> <span data-ttu-id="1dc61-152">The dataset still contains string columns from previous stages, so we use Select Columns in Dataset to exclude them.</span><span class="sxs-lookup"><span data-stu-id="1dc61-152">The dataset still contains string columns from previous stages, so we use Select Columns in Dataset to exclude them.</span></span>

<span data-ttu-id="1dc61-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) to predict our target: high or low review score.</span><span class="sxs-lookup"><span data-stu-id="1dc61-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) to predict our target: high or low review score.</span></span> <span data-ttu-id="1dc61-154">At this point, the text analytics problem has been transformed into a regular classification problem.</span><span class="sxs-lookup"><span data-stu-id="1dc61-154">At this point, the text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="1dc61-155">You can use the tools available in Azure Machine Learning to improve the model.</span><span class="sxs-lookup"><span data-stu-id="1dc61-155">You can use the tools available in Azure Machine Learning to improve the model.</span></span> <span data-ttu-id="1dc61-156">For example, you can experiment with different classifiers to find out how accurate results they give, or use hyperparameter tuning to improve the accuracy.</span><span class="sxs-lookup"><span data-stu-id="1dc61-156">For example, you can experiment with different classifiers to find out how accurate results they give, or use hyperparameter tuning to improve the accuracy.</span></span>

![Train and Score](https://docstestmedia1.blob.core.windows.net/azure-media/articles/machine-learning/media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-the-model"></a><span data-ttu-id="1dc61-158">Step 4: Score and validate the model</span><span class="sxs-lookup"><span data-stu-id="1dc61-158">Step 4: Score and validate the model</span></span>
<span data-ttu-id="1dc61-159">How would you validate the trained model?</span><span class="sxs-lookup"><span data-stu-id="1dc61-159">How would you validate the trained model?</span></span> <span data-ttu-id="1dc61-160">We score it against the test dataset and evaluate the accuracy.</span><span class="sxs-lookup"><span data-stu-id="1dc61-160">We score it against the test dataset and evaluate the accuracy.</span></span> <span data-ttu-id="1dc61-161">However, the model learned the vocabulary of N-grams and their weights from the training dataset.</span><span class="sxs-lookup"><span data-stu-id="1dc61-161">However, the model learned the vocabulary of N-grams and their weights from the training dataset.</span></span> <span data-ttu-id="1dc61-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed to creating the vocabulary anew.</span><span class="sxs-lookup"><span data-stu-id="1dc61-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed to creating the vocabulary anew.</span></span> <span data-ttu-id="1dc61-163">Therefore, we add Extract N-Gram Features module to the scoring branch of the experiment, connect the output vocabulary from training branch, and set the vocabulary mode to read-only.</span><span class="sxs-lookup"><span data-stu-id="1dc61-163">Therefore, we add Extract N-Gram Features module to the scoring branch of the experiment, connect the output vocabulary from training branch, and set the vocabulary mode to read-only.</span></span> <span data-ttu-id="1dc61-164">We also disable the filtering of N-grams by frequency by setting the minimum to 1 instance and maximum to 100%, and turn off the feature selection.</span><span class="sxs-lookup"><span data-stu-id="1dc61-164">We also disable the filtering of N-grams by frequency by setting the minimum to 1 instance and maximum to 100%, and turn off the feature selection.</span></span>

<span data-ttu-id="1dc61-165">After the text column in test data has been transformed to numeric feature columns, we exclude the string columns from previous stages like in training branch.</span><span class="sxs-lookup"><span data-stu-id="1dc61-165">After the text column in test data has been transformed to numeric feature columns, we exclude the string columns from previous stages like in training branch.</span></span> <span data-ttu-id="1dc61-166">We then use Score Model module to make predictions and Evaluate Model module to evaluate the accuracy.</span><span class="sxs-lookup"><span data-stu-id="1dc61-166">We then use Score Model module to make predictions and Evaluate Model module to evaluate the accuracy.</span></span>

## <a name="step-5-deploy-the-model-to-production"></a><span data-ttu-id="1dc61-167">Step 5: Deploy the model to production</span><span class="sxs-lookup"><span data-stu-id="1dc61-167">Step 5: Deploy the model to production</span></span>
<span data-ttu-id="1dc61-168">The model is almost ready to be deployed to production.</span><span class="sxs-lookup"><span data-stu-id="1dc61-168">The model is almost ready to be deployed to production.</span></span> <span data-ttu-id="1dc61-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span><span class="sxs-lookup"><span data-stu-id="1dc61-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="1dc61-170">It uses the learned N-gram vocabulary to transform the text to features, and trained logistic regression model to make a prediction from those features.</span><span class="sxs-lookup"><span data-stu-id="1dc61-170">It uses the learned N-gram vocabulary to transform the text to features, and trained logistic regression model to make a prediction from those features.</span></span> 

<span data-ttu-id="1dc61-171">To set up the predictive experiment, we first save the N-gram vocabulary as dataset, and the trained logistic regression model from the training branch of the experiment.</span><span class="sxs-lookup"><span data-stu-id="1dc61-171">To set up the predictive experiment, we first save the N-gram vocabulary as dataset, and the trained logistic regression model from the training branch of the experiment.</span></span> <span data-ttu-id="1dc61-172">Then, we save the experiment using "Save As" to create an experiment graph for predictive experiment.</span><span class="sxs-lookup"><span data-stu-id="1dc61-172">Then, we save the experiment using "Save As" to create an experiment graph for predictive experiment.</span></span> <span data-ttu-id="1dc61-173">We remove the Split Data module and the training branch from the experiment.</span><span class="sxs-lookup"><span data-stu-id="1dc61-173">We remove the Split Data module and the training branch from the experiment.</span></span> <span data-ttu-id="1dc61-174">We then connect the previously saved N-gram vocabulary and model to Extract N-Gram Features and Score Model modules, respectively.</span><span class="sxs-lookup"><span data-stu-id="1dc61-174">We then connect the previously saved N-gram vocabulary and model to Extract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="1dc61-175">We also remove the Evaluate Model module.</span><span class="sxs-lookup"><span data-stu-id="1dc61-175">We also remove the Evaluate Model module.</span></span>

<span data-ttu-id="1dc61-176">We insert Select Columns in Dataset module before Preprocess Text module to remove the label column, and unselect "Append score column to dataset" option in Score Module.</span><span class="sxs-lookup"><span data-stu-id="1dc61-176">We insert Select Columns in Dataset module before Preprocess Text module to remove the label column, and unselect "Append score column to dataset" option in Score Module.</span></span> <span data-ttu-id="1dc61-177">That way, the web service does not request the label it is trying to predict, and does not echo the input features in response.</span><span class="sxs-lookup"><span data-stu-id="1dc61-177">That way, the web service does not request the label it is trying to predict, and does not echo the input features in response.</span></span>

![Predictive Experiment](https://docstestmedia1.blob.core.windows.net/azure-media/articles/machine-learning/media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="1dc61-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span><span class="sxs-lookup"><span data-stu-id="1dc61-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="1dc61-180">Next Steps</span><span class="sxs-lookup"><span data-stu-id="1dc61-180">Next Steps</span></span>
<span data-ttu-id="1dc61-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span><span class="sxs-lookup"><span data-stu-id="1dc61-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>






