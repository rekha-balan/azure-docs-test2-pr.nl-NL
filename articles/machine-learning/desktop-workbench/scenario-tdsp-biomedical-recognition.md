---
title: Biomedical entity recognition - Team Data Science Process - Azure Machine Learning | Microsoft Docs
description: A Team Data Science Process project quickstart that uses deep learning for biomedical entity recognition in Azure Machine Learning Workbench.
services: machine-learning
documentationcenter: ''
author: deguhath
ms.author: deguhath
manager: cgronlun
editor: cgronlun
ms.assetid: ''
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 09/10/2017
ms.openlocfilehash: f6ce43c2d290bacee10e102cc6c382981db9917f
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44866552"
---
# <a name="biomedical-entity-recognition-using-team-data-science-process-tdsp-template"></a><span data-ttu-id="396f9-103">Biomedical entity recognition using Team Data Science Process (TDSP) Template</span><span class="sxs-lookup"><span data-stu-id="396f9-103">Biomedical entity recognition using Team Data Science Process (TDSP) Template</span></span>

<span data-ttu-id="396f9-104">Entity extraction is a subtask of information extraction (also known as [Named-entity recognition (NER)](https://en.wikipedia.org/wiki/Named-entity_recognition), entity chunking, and entity identification).</span><span class="sxs-lookup"><span data-stu-id="396f9-104">Entity extraction is a subtask of information extraction (also known as [Named-entity recognition (NER)](https://en.wikipedia.org/wiki/Named-entity_recognition), entity chunking, and entity identification).</span></span> <span data-ttu-id="396f9-105">The aim of this real-world scenario is to highlight how to use Azure Machine Learning Workbench to solve a complicated Natural Language Processing (NLP) task such as entity extraction from unstructured text:</span><span class="sxs-lookup"><span data-stu-id="396f9-105">The aim of this real-world scenario is to highlight how to use Azure Machine Learning Workbench to solve a complicated Natural Language Processing (NLP) task such as entity extraction from unstructured text:</span></span>

1. <span data-ttu-id="396f9-106">How to train a neural word embeddings model on a text corpus of about 18 million PubMed abstracts using [Spark Word2Vec implementation](https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec).</span><span class="sxs-lookup"><span data-stu-id="396f9-106">How to train a neural word embeddings model on a text corpus of about 18 million PubMed abstracts using [Spark Word2Vec implementation](https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec).</span></span>
2. <span data-ttu-id="396f9-107">How to build a deep Long Short-Term Memory (LSTM) recurrent neural network model for entity extraction on a GPU-enabled Azure Data Science Virtual Machine (GPU DS VM) on Azure.</span><span class="sxs-lookup"><span data-stu-id="396f9-107">How to build a deep Long Short-Term Memory (LSTM) recurrent neural network model for entity extraction on a GPU-enabled Azure Data Science Virtual Machine (GPU DS VM) on Azure.</span></span>
2. <span data-ttu-id="396f9-108">Demonstrate that domain-specific word embeddings model can outperform generic word embeddings models in the entity recognition task.</span><span class="sxs-lookup"><span data-stu-id="396f9-108">Demonstrate that domain-specific word embeddings model can outperform generic word embeddings models in the entity recognition task.</span></span> 
3. <span data-ttu-id="396f9-109">Demonstrate how to train and operationalize deep learning models using Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="396f9-109">Demonstrate how to train and operationalize deep learning models using Azure Machine Learning Workbench.</span></span>

4. <span data-ttu-id="396f9-110">Demonstrate the following capabilities within Azure Machine Learning Workbench:</span><span class="sxs-lookup"><span data-stu-id="396f9-110">Demonstrate the following capabilities within Azure Machine Learning Workbench:</span></span>

    * <span data-ttu-id="396f9-111">Instantiation of [Team Data Science Process (TDSP) structure and templates](how-to-use-tdsp-in-azure-ml.md)</span><span class="sxs-lookup"><span data-stu-id="396f9-111">Instantiation of [Team Data Science Process (TDSP) structure and templates](how-to-use-tdsp-in-azure-ml.md)</span></span>
    * <span data-ttu-id="396f9-112">Automated management of your project dependencies including the download and the installation</span><span class="sxs-lookup"><span data-stu-id="396f9-112">Automated management of your project dependencies including the download and the installation</span></span>
    * <span data-ttu-id="396f9-113">Execution of Python scripts on different compute environments</span><span class="sxs-lookup"><span data-stu-id="396f9-113">Execution of Python scripts on different compute environments</span></span>
    * <span data-ttu-id="396f9-114">Run history tracking for Python scripts</span><span class="sxs-lookup"><span data-stu-id="396f9-114">Run history tracking for Python scripts</span></span>
    * <span data-ttu-id="396f9-115">Execution of jobs on remote Spark compute contexts using HDInsight Spark 2.1 clusters</span><span class="sxs-lookup"><span data-stu-id="396f9-115">Execution of jobs on remote Spark compute contexts using HDInsight Spark 2.1 clusters</span></span>
    * <span data-ttu-id="396f9-116">Execution of jobs in remote GPU VMs on Azure</span><span class="sxs-lookup"><span data-stu-id="396f9-116">Execution of jobs in remote GPU VMs on Azure</span></span>
    * <span data-ttu-id="396f9-117">Easy operationalization of deep learning models as web services on Azure Container Services (ACS)</span><span class="sxs-lookup"><span data-stu-id="396f9-117">Easy operationalization of deep learning models as web services on Azure Container Services (ACS)</span></span>

## <a name="use-case-overview"></a><span data-ttu-id="396f9-118">Use case overview</span><span class="sxs-lookup"><span data-stu-id="396f9-118">Use case overview</span></span>
<span data-ttu-id="396f9-119">Biomedical named entity recognition is a critical step for complex biomedical NLP tasks such as:</span><span class="sxs-lookup"><span data-stu-id="396f9-119">Biomedical named entity recognition is a critical step for complex biomedical NLP tasks such as:</span></span> 
* <span data-ttu-id="396f9-120">Extracting the mentions of named entities such diseases, drugs, chemicals, and symptoms from electronic medical or health records.</span><span class="sxs-lookup"><span data-stu-id="396f9-120">Extracting the mentions of named entities such diseases, drugs, chemicals, and symptoms from electronic medical or health records.</span></span>
* <span data-ttu-id="396f9-121">Drug discovery</span><span class="sxs-lookup"><span data-stu-id="396f9-121">Drug discovery</span></span>
* <span data-ttu-id="396f9-122">Understanding the interactions between different entity types such as drug-drug interaction, drug-disease relationship, and gene-protein relationship.</span><span class="sxs-lookup"><span data-stu-id="396f9-122">Understanding the interactions between different entity types such as drug-drug interaction, drug-disease relationship, and gene-protein relationship.</span></span>

<span data-ttu-id="396f9-123">Our use case scenario focuses on how a large amount of unstructured data corpus such as Medline PubMed abstracts can be analyzed to train a word embedding model.</span><span class="sxs-lookup"><span data-stu-id="396f9-123">Our use case scenario focuses on how a large amount of unstructured data corpus such as Medline PubMed abstracts can be analyzed to train a word embedding model.</span></span> <span data-ttu-id="396f9-124">Then the output embeddings are considered as automatically generated features to train a neural entity extractor.</span><span class="sxs-lookup"><span data-stu-id="396f9-124">Then the output embeddings are considered as automatically generated features to train a neural entity extractor.</span></span>

<span data-ttu-id="396f9-125">Our results show that the biomedical entity extraction model training on the domain-specific word embedding features outperforms the model trained on the generic feature type.</span><span class="sxs-lookup"><span data-stu-id="396f9-125">Our results show that the biomedical entity extraction model training on the domain-specific word embedding features outperforms the model trained on the generic feature type.</span></span> <span data-ttu-id="396f9-126">The domain-specific model can detect 7012 entities correctly (out of 9475) with F1-score of 0.73 compared to 5274 entities with F1-score of 0.61 for the generic model.</span><span class="sxs-lookup"><span data-stu-id="396f9-126">The domain-specific model can detect 7012 entities correctly (out of 9475) with F1-score of 0.73 compared to 5274 entities with F1-score of 0.61 for the generic model.</span></span>

<span data-ttu-id="396f9-127">The following figure shows the architecture that was used to process data and train models.</span><span class="sxs-lookup"><span data-stu-id="396f9-127">The following figure shows the architecture that was used to process data and train models.</span></span>

![Architecture](./media/scenario-tdsp-biomedical-recognition/architecture.png)

## <a name="data-description"></a><span data-ttu-id="396f9-129">Data description</span><span class="sxs-lookup"><span data-stu-id="396f9-129">Data description</span></span>

### <a name="1-word2vec-model-training-data"></a><span data-ttu-id="396f9-130">1. Word2Vec model training data</span><span class="sxs-lookup"><span data-stu-id="396f9-130">1. Word2Vec model training data</span></span>
<span data-ttu-id="396f9-131">We first downloaded the raw MEDLINE abstract data from [MEDLINE](https://www.nlm.nih.gov/pubs/factsheets/medline.html).</span><span class="sxs-lookup"><span data-stu-id="396f9-131">We first downloaded the raw MEDLINE abstract data from [MEDLINE](https://www.nlm.nih.gov/pubs/factsheets/medline.html).</span></span> <span data-ttu-id="396f9-132">The data is publically available in the form of XML files on their [FTP server](https://ftp.ncbi.nlm.nih.gov/pubmed/baseline).</span><span class="sxs-lookup"><span data-stu-id="396f9-132">The data is publically available in the form of XML files on their [FTP server](https://ftp.ncbi.nlm.nih.gov/pubmed/baseline).</span></span> <span data-ttu-id="396f9-133">There are 892 XML files available on the server and each of the XML files has the information of 30,000 articles.</span><span class="sxs-lookup"><span data-stu-id="396f9-133">There are 892 XML files available on the server and each of the XML files has the information of 30,000 articles.</span></span> <span data-ttu-id="396f9-134">More details about the data collection step are provided in the Project Structure section.</span><span class="sxs-lookup"><span data-stu-id="396f9-134">More details about the data collection step are provided in the Project Structure section.</span></span> <span data-ttu-id="396f9-135">The fields present in each file are</span><span class="sxs-lookup"><span data-stu-id="396f9-135">The fields present in each file are</span></span> 
        
        abstract
        affiliation
        authors
        country 
        delete: boolean if False means paper got updated so you might have two XMLs for the same paper.
        file_name   
        issn_linking    
        journal 
        keywords    
        medline_ta: this is abbreviation of the journal nam 
        mesh_terms: list of MeSH terms  
        nlm_unique_id   
        other_id: Other IDs 
        pmc: Pubmed Central ID  
        pmid: Pubmed ID
        pubdate: Publication date
        title

### <a name="2-lstm-model-training-data"></a><span data-ttu-id="396f9-136">2. LSTM model training data</span><span class="sxs-lookup"><span data-stu-id="396f9-136">2. LSTM model training data</span></span>

<span data-ttu-id="396f9-137">The neural entity extraction model has been trained and evaluated on publicly available datasets.</span><span class="sxs-lookup"><span data-stu-id="396f9-137">The neural entity extraction model has been trained and evaluated on publicly available datasets.</span></span> <span data-ttu-id="396f9-138">To obtain a detailed description about these datasets, you could refer to the following sources:</span><span class="sxs-lookup"><span data-stu-id="396f9-138">To obtain a detailed description about these datasets, you could refer to the following sources:</span></span>
 * [<span data-ttu-id="396f9-139">Bio-Entity Recognition Task at BioNLP/NLPBA 2004</span><span class="sxs-lookup"><span data-stu-id="396f9-139">Bio-Entity Recognition Task at BioNLP/NLPBA 2004</span></span>](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html)
 * [<span data-ttu-id="396f9-140">BioCreative V CDR task corpus</span><span class="sxs-lookup"><span data-stu-id="396f9-140">BioCreative V CDR task corpus</span></span>](http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/)
 * [<span data-ttu-id="396f9-141">Semeval 2013 - Task 9.1 (Drug Recognition)</span><span class="sxs-lookup"><span data-stu-id="396f9-141">Semeval 2013 - Task 9.1 (Drug Recognition)</span></span>](https://www.cs.york.ac.uk/semeval-2013/task9/)

## <a name="link-to-the-azure-gallery-github-repository"></a><span data-ttu-id="396f9-142">Link to the Azure gallery GitHub repository</span><span class="sxs-lookup"><span data-stu-id="396f9-142">Link to the Azure gallery GitHub repository</span></span>
<span data-ttu-id="396f9-143">Following is the link to the public GitHub repository of the real-world scenario that contains the code and more detailed description:</span><span class="sxs-lookup"><span data-stu-id="396f9-143">Following is the link to the public GitHub repository of the real-world scenario that contains the code and more detailed description:</span></span> 

[https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction)


## <a name="prerequisites"></a><span data-ttu-id="396f9-144">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="396f9-144">Prerequisites</span></span> 

* <span data-ttu-id="396f9-145">An Azure [subscription](https://azure.microsoft.com/free/)</span><span class="sxs-lookup"><span data-stu-id="396f9-145">An Azure [subscription](https://azure.microsoft.com/free/)</span></span>
* <span data-ttu-id="396f9-146">Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="396f9-146">Azure Machine Learning Workbench.</span></span> <span data-ttu-id="396f9-147">See [installation guide](../service/quickstart-installation.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-147">See [installation guide](../service/quickstart-installation.md).</span></span> <span data-ttu-id="396f9-148">Currently the Azure Machine Learning Workbench can be installed on the following operating systems only:</span><span class="sxs-lookup"><span data-stu-id="396f9-148">Currently the Azure Machine Learning Workbench can be installed on the following operating systems only:</span></span> 
    * <span data-ttu-id="396f9-149">Windows 10 or Windows Server 2016</span><span class="sxs-lookup"><span data-stu-id="396f9-149">Windows 10 or Windows Server 2016</span></span>
    * <span data-ttu-id="396f9-150">macOS Sierra (or newer)</span><span class="sxs-lookup"><span data-stu-id="396f9-150">macOS Sierra (or newer)</span></span>


### <a name="azure-services"></a><span data-ttu-id="396f9-151">Azure services</span><span class="sxs-lookup"><span data-stu-id="396f9-151">Azure services</span></span>
* <span data-ttu-id="396f9-152">[HDInsight Spark cluster](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-jupyter-spark-sql) version Spark 2.1 on Linux (HDI 3.6) for scale-out computation.</span><span class="sxs-lookup"><span data-stu-id="396f9-152">[HDInsight Spark cluster](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-jupyter-spark-sql) version Spark 2.1 on Linux (HDI 3.6) for scale-out computation.</span></span> <span data-ttu-id="396f9-153">To process the full amount of MEDLINE abstracts discussed below, you need the minimum configuration of:</span><span class="sxs-lookup"><span data-stu-id="396f9-153">To process the full amount of MEDLINE abstracts discussed below, you need the minimum configuration of:</span></span> 
    * <span data-ttu-id="396f9-154">Head node: [D13_V2](https://azure.microsoft.com/pricing/details/hdinsight/) size</span><span class="sxs-lookup"><span data-stu-id="396f9-154">Head node: [D13_V2](https://azure.microsoft.com/pricing/details/hdinsight/) size</span></span>
    * <span data-ttu-id="396f9-155">Worker nodes: At least 4 of [D12_V2](https://azure.microsoft.com/pricing/details/hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="396f9-155">Worker nodes: At least 4 of [D12_V2](https://azure.microsoft.com/pricing/details/hdinsight/).</span></span> <span data-ttu-id="396f9-156">In our work, we used 11 worker nodes of D12_V2 size.</span><span class="sxs-lookup"><span data-stu-id="396f9-156">In our work, we used 11 worker nodes of D12_V2 size.</span></span>
* <span data-ttu-id="396f9-157">[NC6 Data Science Virtual Machine (DSVM)](https://docs.microsoft.com/azure/machine-learning/machine-learning-data-science-linux-dsvm-intro) for scale-up computation.</span><span class="sxs-lookup"><span data-stu-id="396f9-157">[NC6 Data Science Virtual Machine (DSVM)](https://docs.microsoft.com/azure/machine-learning/machine-learning-data-science-linux-dsvm-intro) for scale-up computation.</span></span>

### <a name="python-packages"></a><span data-ttu-id="396f9-158">Python packages</span><span class="sxs-lookup"><span data-stu-id="396f9-158">Python packages</span></span>

<span data-ttu-id="396f9-159">All the required dependencies are defined in the aml_config/conda_dependencies.yml file under the scenario project folder.</span><span class="sxs-lookup"><span data-stu-id="396f9-159">All the required dependencies are defined in the aml_config/conda_dependencies.yml file under the scenario project folder.</span></span> <span data-ttu-id="396f9-160">The dependencies defined in this file are automatically provisioned for runs against docker, VM, and HDI cluster targets.</span><span class="sxs-lookup"><span data-stu-id="396f9-160">The dependencies defined in this file are automatically provisioned for runs against docker, VM, and HDI cluster targets.</span></span> <span data-ttu-id="396f9-161">For details about the Conda environment file format, refer to [here](https://conda.io/docs/using/envs.html#create-environment-file-by-hand).</span><span class="sxs-lookup"><span data-stu-id="396f9-161">For details about the Conda environment file format, refer to [here](https://conda.io/docs/using/envs.html#create-environment-file-by-hand).</span></span>

* [<span data-ttu-id="396f9-162">TensorFlow</span><span class="sxs-lookup"><span data-stu-id="396f9-162">TensorFlow</span></span>](https://www.tensorflow.org/install/)
* [<span data-ttu-id="396f9-163">CNTK 2.0</span><span class="sxs-lookup"><span data-stu-id="396f9-163">CNTK 2.0</span></span>](https://docs.microsoft.com/cognitive-toolkit/using-cntk-with-keras)
* [<span data-ttu-id="396f9-164">Keras</span><span class="sxs-lookup"><span data-stu-id="396f9-164">Keras</span></span>](https://keras.io/#installation)
* <span data-ttu-id="396f9-165">NLTK</span><span class="sxs-lookup"><span data-stu-id="396f9-165">NLTK</span></span>
* <span data-ttu-id="396f9-166">Fastparquet</span><span class="sxs-lookup"><span data-stu-id="396f9-166">Fastparquet</span></span>

### <a name="basic-instructions-for-azure-machine-learning-aml-workbench"></a><span data-ttu-id="396f9-167">Basic instructions for Azure Machine Learning (AML) workbench</span><span class="sxs-lookup"><span data-stu-id="396f9-167">Basic instructions for Azure Machine Learning (AML) workbench</span></span>
* [<span data-ttu-id="396f9-168">Overview</span><span class="sxs-lookup"><span data-stu-id="396f9-168">Overview</span></span>](../service/overview-what-is-azure-ml.md)
* [<span data-ttu-id="396f9-169">Installation</span><span class="sxs-lookup"><span data-stu-id="396f9-169">Installation</span></span>](../service/quickstart-installation.md)
* [<span data-ttu-id="396f9-170">Using TDSP</span><span class="sxs-lookup"><span data-stu-id="396f9-170">Using TDSP</span></span>](how-to-use-tdsp-in-azure-ml.md)
* [<span data-ttu-id="396f9-171">How to read and write files</span><span class="sxs-lookup"><span data-stu-id="396f9-171">How to read and write files</span></span>](how-to-read-write-files.md)
* [<span data-ttu-id="396f9-172">How to use Jupyter Notebooks</span><span class="sxs-lookup"><span data-stu-id="396f9-172">How to use Jupyter Notebooks</span></span>](how-to-use-jupyter-notebooks.md)
* [<span data-ttu-id="396f9-173">How to use GPU</span><span class="sxs-lookup"><span data-stu-id="396f9-173">How to use GPU</span></span>](how-to-use-gpu.md)

## <a name="scenario-structure"></a><span data-ttu-id="396f9-174">Scenario structure</span><span class="sxs-lookup"><span data-stu-id="396f9-174">Scenario structure</span></span>
<span data-ttu-id="396f9-175">For the scenario, we use the TDSP project structure and documentation templates (Figure 1), which follows the [TDSP lifecycle](https://github.com/Azure/Microsoft-TDSP/blob/master/Docs/lifecycle-detail.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-175">For the scenario, we use the TDSP project structure and documentation templates (Figure 1), which follows the [TDSP lifecycle](https://github.com/Azure/Microsoft-TDSP/blob/master/Docs/lifecycle-detail.md).</span></span> <span data-ttu-id="396f9-176">Project is created based on instructions provided [here](./how-to-use-tdsp-in-azure-ml.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-176">Project is created based on instructions provided [here](./how-to-use-tdsp-in-azure-ml.md).</span></span>


![Fill in project information](./media/scenario-tdsp-biomedical-recognition/instantiation-3.png) 

<span data-ttu-id="396f9-178">The step-by-step data science workflow is as follows:</span><span class="sxs-lookup"><span data-stu-id="396f9-178">The step-by-step data science workflow is as follows:</span></span>

### <a name="1-data-acquisition-and-understanding"></a><span data-ttu-id="396f9-179">1. Data acquisition and understanding</span><span class="sxs-lookup"><span data-stu-id="396f9-179">1. Data acquisition and understanding</span></span>

<span data-ttu-id="396f9-180">See [Data Acquisition and Understanding](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-180">See [Data Acquisition and Understanding](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md).</span></span>

<span data-ttu-id="396f9-181">The raw MEDLINE corpus has a total of 27 million abstracts where about 10 million articles have an empty abstract field.</span><span class="sxs-lookup"><span data-stu-id="396f9-181">The raw MEDLINE corpus has a total of 27 million abstracts where about 10 million articles have an empty abstract field.</span></span> <span data-ttu-id="396f9-182">Azure HDInsight Spark is used to process big data that cannot be loaded into the memory of a single machine as a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).</span><span class="sxs-lookup"><span data-stu-id="396f9-182">Azure HDInsight Spark is used to process big data that cannot be loaded into the memory of a single machine as a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).</span></span> <span data-ttu-id="396f9-183">First, the data is downloaded into the Spark cluster.</span><span class="sxs-lookup"><span data-stu-id="396f9-183">First, the data is downloaded into the Spark cluster.</span></span> <span data-ttu-id="396f9-184">Then the following steps are executed on the [Spark DataFrame](https://spark.apache.org/docs/latest/sql-programming-guide.html):</span><span class="sxs-lookup"><span data-stu-id="396f9-184">Then the following steps are executed on the [Spark DataFrame](https://spark.apache.org/docs/latest/sql-programming-guide.html):</span></span> 
* <span data-ttu-id="396f9-185">parse the XML files using Medline XML Parser</span><span class="sxs-lookup"><span data-stu-id="396f9-185">parse the XML files using Medline XML Parser</span></span>
* <span data-ttu-id="396f9-186">preprocess the abstract text including sentence splitting, tokenization, and case normalization.</span><span class="sxs-lookup"><span data-stu-id="396f9-186">preprocess the abstract text including sentence splitting, tokenization, and case normalization.</span></span>
* <span data-ttu-id="396f9-187">exclude articles where abstract field is empty or has short text</span><span class="sxs-lookup"><span data-stu-id="396f9-187">exclude articles where abstract field is empty or has short text</span></span> 
* <span data-ttu-id="396f9-188">create the word vocabulary from the training abstracts</span><span class="sxs-lookup"><span data-stu-id="396f9-188">create the word vocabulary from the training abstracts</span></span>
* <span data-ttu-id="396f9-189">train the word embedding neural model.</span><span class="sxs-lookup"><span data-stu-id="396f9-189">train the word embedding neural model.</span></span> <span data-ttu-id="396f9-190">For more information, see [GitHub code link](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md) to get started.</span><span class="sxs-lookup"><span data-stu-id="396f9-190">For more information, see [GitHub code link](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md) to get started.</span></span>


<span data-ttu-id="396f9-191">After parsing XML files, data has the following format:</span><span class="sxs-lookup"><span data-stu-id="396f9-191">After parsing XML files, data has the following format:</span></span> 

![Data Sample](./media/scenario-tdsp-biomedical-recognition/datasample.png)

<span data-ttu-id="396f9-193">The neural entity extraction model has been trained and evaluated on publicly available datasets.</span><span class="sxs-lookup"><span data-stu-id="396f9-193">The neural entity extraction model has been trained and evaluated on publicly available datasets.</span></span> <span data-ttu-id="396f9-194">To obtain a detailed description about these datasets, you could refer to the following sources:</span><span class="sxs-lookup"><span data-stu-id="396f9-194">To obtain a detailed description about these datasets, you could refer to the following sources:</span></span>
 * [<span data-ttu-id="396f9-195">Bio-Entity Recognition Task at BioNLP/NLPBA 2004</span><span class="sxs-lookup"><span data-stu-id="396f9-195">Bio-Entity Recognition Task at BioNLP/NLPBA 2004</span></span>](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html)
 * [<span data-ttu-id="396f9-196">BioCreative V CDR task corpus</span><span class="sxs-lookup"><span data-stu-id="396f9-196">BioCreative V CDR task corpus</span></span>](http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/)
 * [<span data-ttu-id="396f9-197">Semeval 2013 - Task 9.1 (Drug Recognition)</span><span class="sxs-lookup"><span data-stu-id="396f9-197">Semeval 2013 - Task 9.1 (Drug Recognition)</span></span>](https://www.cs.york.ac.uk/semeval-2013/task9/)

### <a name="2-modeling"></a><span data-ttu-id="396f9-198">2. Modeling</span><span class="sxs-lookup"><span data-stu-id="396f9-198">2. Modeling</span></span>

<span data-ttu-id="396f9-199">See [Modeling](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling).</span><span class="sxs-lookup"><span data-stu-id="396f9-199">See [Modeling](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling).</span></span>

<span data-ttu-id="396f9-200">Modeling is the stage where we show how you can use the data downloaded in the previous section for training your own word embedding model and use it for other downstream tasks.</span><span class="sxs-lookup"><span data-stu-id="396f9-200">Modeling is the stage where we show how you can use the data downloaded in the previous section for training your own word embedding model and use it for other downstream tasks.</span></span> <span data-ttu-id="396f9-201">Although we are using the PubMed data, the pipeline to generate the embeddings is generic and can be reused to train word embeddings for any other domain.</span><span class="sxs-lookup"><span data-stu-id="396f9-201">Although we are using the PubMed data, the pipeline to generate the embeddings is generic and can be reused to train word embeddings for any other domain.</span></span> <span data-ttu-id="396f9-202">For embeddings to be an accurate representation of the data, it is essential that the word2vec is trained on a large amount of data.</span><span class="sxs-lookup"><span data-stu-id="396f9-202">For embeddings to be an accurate representation of the data, it is essential that the word2vec is trained on a large amount of data.</span></span>
<span data-ttu-id="396f9-203">Once we have the word embeddings ready, we can train a deep neural network model that uses the learned embeddings to initialize the Embedding layer.</span><span class="sxs-lookup"><span data-stu-id="396f9-203">Once we have the word embeddings ready, we can train a deep neural network model that uses the learned embeddings to initialize the Embedding layer.</span></span> <span data-ttu-id="396f9-204">We mark the embedding layer as non-trainable but that is not mandatory.</span><span class="sxs-lookup"><span data-stu-id="396f9-204">We mark the embedding layer as non-trainable but that is not mandatory.</span></span> <span data-ttu-id="396f9-205">The training of the word embedding model is unsupervised and hence we are able to take advantage of unlabeled texts.</span><span class="sxs-lookup"><span data-stu-id="396f9-205">The training of the word embedding model is unsupervised and hence we are able to take advantage of unlabeled texts.</span></span> <span data-ttu-id="396f9-206">However, the training of the entity recognition model is a supervised learning task and its accuracy depends on the amount and the quality of a manually-annotated data.</span><span class="sxs-lookup"><span data-stu-id="396f9-206">However, the training of the entity recognition model is a supervised learning task and its accuracy depends on the amount and the quality of a manually-annotated data.</span></span> 


#### <a name="21-feature-generation"></a><span data-ttu-id="396f9-207">2.1.</span><span class="sxs-lookup"><span data-stu-id="396f9-207">2.1.</span></span> <span data-ttu-id="396f9-208">Feature generation</span><span class="sxs-lookup"><span data-stu-id="396f9-208">Feature generation</span></span>

<span data-ttu-id="396f9-209">See [Feature generation](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering).</span><span class="sxs-lookup"><span data-stu-id="396f9-209">See [Feature generation](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering).</span></span>

<span data-ttu-id="396f9-210">Word2Vec is the word embedding unsupervised learning algorithm that trains a neural network model from an unlabeled training corpus.</span><span class="sxs-lookup"><span data-stu-id="396f9-210">Word2Vec is the word embedding unsupervised learning algorithm that trains a neural network model from an unlabeled training corpus.</span></span> <span data-ttu-id="396f9-211">It produces a continuous vector for each word in the corpus that represents its semantic information.</span><span class="sxs-lookup"><span data-stu-id="396f9-211">It produces a continuous vector for each word in the corpus that represents its semantic information.</span></span> <span data-ttu-id="396f9-212">These models are simple neural networks with a single hidden layer.</span><span class="sxs-lookup"><span data-stu-id="396f9-212">These models are simple neural networks with a single hidden layer.</span></span> <span data-ttu-id="396f9-213">The word vectors/embeddings are learned by backpropagation and stochastic gradient descent.</span><span class="sxs-lookup"><span data-stu-id="396f9-213">The word vectors/embeddings are learned by backpropagation and stochastic gradient descent.</span></span> <span data-ttu-id="396f9-214">There are two types of word2vec models, namely, the Skip-Gram and the continuous-bag-of-words (check [here](https://arxiv.org/pdf/1301.3781.pdf) for more details).</span><span class="sxs-lookup"><span data-stu-id="396f9-214">There are two types of word2vec models, namely, the Skip-Gram and the continuous-bag-of-words (check [here](https://arxiv.org/pdf/1301.3781.pdf) for more details).</span></span> <span data-ttu-id="396f9-215">Since we are using the MLlib's implementation of the word2vec, which supports the Skip-gram model, we briefly describe it here (image taken from [link](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/)):</span><span class="sxs-lookup"><span data-stu-id="396f9-215">Since we are using the MLlib's implementation of the word2vec, which supports the Skip-gram model, we briefly describe it here (image taken from [link](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/)):</span></span> 

![Skip Gram Model](./media/scenario-tdsp-biomedical-recognition/skip-gram.png)

<span data-ttu-id="396f9-217">The model uses Hierarchical Softmax and Negative sampling to optimize the performance.</span><span class="sxs-lookup"><span data-stu-id="396f9-217">The model uses Hierarchical Softmax and Negative sampling to optimize the performance.</span></span> <span data-ttu-id="396f9-218">Hierarchical SoftMax (H-SoftMax) is an approximation inspired by binary trees.</span><span class="sxs-lookup"><span data-stu-id="396f9-218">Hierarchical SoftMax (H-SoftMax) is an approximation inspired by binary trees.</span></span> <span data-ttu-id="396f9-219">H-SoftMax essentially replaces the flat SoftMax layer with a hierarchical layer that has the words as leaves.</span><span class="sxs-lookup"><span data-stu-id="396f9-219">H-SoftMax essentially replaces the flat SoftMax layer with a hierarchical layer that has the words as leaves.</span></span> <span data-ttu-id="396f9-220">This allows us to decompose calculating the probability of one word into a sequence of probability calculations, which saves us from having to calculate the expensive normalization over all words.</span><span class="sxs-lookup"><span data-stu-id="396f9-220">This allows us to decompose calculating the probability of one word into a sequence of probability calculations, which saves us from having to calculate the expensive normalization over all words.</span></span> <span data-ttu-id="396f9-221">Since a balanced binary tree has a depth of log2(|V|) (V is the Vocabulary), we only need to evaluate at most log2(|V|) nodes to obtain the final probability of a word.</span><span class="sxs-lookup"><span data-stu-id="396f9-221">Since a balanced binary tree has a depth of log2(|V|) (V is the Vocabulary), we only need to evaluate at most log2(|V|) nodes to obtain the final probability of a word.</span></span> <span data-ttu-id="396f9-222">The probability of a word w given its context c is then simply the product of the probabilities of taking right and left turns respectively that lead to its leaf node.</span><span class="sxs-lookup"><span data-stu-id="396f9-222">The probability of a word w given its context c is then simply the product of the probabilities of taking right and left turns respectively that lead to its leaf node.</span></span> <span data-ttu-id="396f9-223">We can build a Huffman Tree based on the frequency of the words in the dataset to ensure that more frequent words get shorter representations.</span><span class="sxs-lookup"><span data-stu-id="396f9-223">We can build a Huffman Tree based on the frequency of the words in the dataset to ensure that more frequent words get shorter representations.</span></span> <span data-ttu-id="396f9-224">For more information, see [this link](http://sebastianruder.com/word-embeddings-softmax/).</span><span class="sxs-lookup"><span data-stu-id="396f9-224">For more information, see [this link](http://sebastianruder.com/word-embeddings-softmax/).</span></span>
<span data-ttu-id="396f9-225">Image taken from [here](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/).</span><span class="sxs-lookup"><span data-stu-id="396f9-225">Image taken from [here](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/).</span></span>

##### <a name="visualization"></a><span data-ttu-id="396f9-226">Visualization</span><span class="sxs-lookup"><span data-stu-id="396f9-226">Visualization</span></span>

<span data-ttu-id="396f9-227">Once we have the word embeddings, we would like to visualize them and see the relationship between semantically similar words.</span><span class="sxs-lookup"><span data-stu-id="396f9-227">Once we have the word embeddings, we would like to visualize them and see the relationship between semantically similar words.</span></span> 

![W2V similarity](./media/scenario-tdsp-biomedical-recognition/w2v-sim.png)

<span data-ttu-id="396f9-229">We have shown two different ways of visualizing the embeddings.</span><span class="sxs-lookup"><span data-stu-id="396f9-229">We have shown two different ways of visualizing the embeddings.</span></span> <span data-ttu-id="396f9-230">The first one uses a PCA to project the high dimensional vector to a 2-D vector space.</span><span class="sxs-lookup"><span data-stu-id="396f9-230">The first one uses a PCA to project the high dimensional vector to a 2-D vector space.</span></span> <span data-ttu-id="396f9-231">This leads to a significant loss of information and the visualization is not as accurate.</span><span class="sxs-lookup"><span data-stu-id="396f9-231">This leads to a significant loss of information and the visualization is not as accurate.</span></span> <span data-ttu-id="396f9-232">The second is to use PCA with [t-SNE](https://distill.pub/2016/misread-tsne/).</span><span class="sxs-lookup"><span data-stu-id="396f9-232">The second is to use PCA with [t-SNE](https://distill.pub/2016/misread-tsne/).</span></span> <span data-ttu-id="396f9-233">t-SNE is a nonlinear dimensionality reduction technique that is well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot.</span><span class="sxs-lookup"><span data-stu-id="396f9-233">t-SNE is a nonlinear dimensionality reduction technique that is well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot.</span></span>  <span data-ttu-id="396f9-234">It models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.</span><span class="sxs-lookup"><span data-stu-id="396f9-234">It models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.</span></span> <span data-ttu-id="396f9-235">It works in two parts.</span><span class="sxs-lookup"><span data-stu-id="396f9-235">It works in two parts.</span></span> <span data-ttu-id="396f9-236">First, it creates a probability distribution over the pairs in the higher dimensional space in a way that similar objects have a high probability of being picked and dissimilar points have  low probability of getting picked.</span><span class="sxs-lookup"><span data-stu-id="396f9-236">First, it creates a probability distribution over the pairs in the higher dimensional space in a way that similar objects have a high probability of being picked and dissimilar points have  low probability of getting picked.</span></span> <span data-ttu-id="396f9-237">Second, it defines a similar probability distribution over the points in a low dimensional map and minimizes the KL Divergence between the two distributions with respect to location of points on the map.</span><span class="sxs-lookup"><span data-stu-id="396f9-237">Second, it defines a similar probability distribution over the points in a low dimensional map and minimizes the KL Divergence between the two distributions with respect to location of points on the map.</span></span> <span data-ttu-id="396f9-238">The location of the points in the low dimension is obtained by minimizing the KL Divergence using Gradient Descent.</span><span class="sxs-lookup"><span data-stu-id="396f9-238">The location of the points in the low dimension is obtained by minimizing the KL Divergence using Gradient Descent.</span></span> <span data-ttu-id="396f9-239">But t-SNE might not be always reliable.</span><span class="sxs-lookup"><span data-stu-id="396f9-239">But t-SNE might not be always reliable.</span></span> <span data-ttu-id="396f9-240">Implementation details can be found [here](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering).</span><span class="sxs-lookup"><span data-stu-id="396f9-240">Implementation details can be found [here](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering).</span></span> 


<span data-ttu-id="396f9-241">As shown in the following figure, the t-SNE visualization provides more separation of word vectors and potential clustering patterns.</span><span class="sxs-lookup"><span data-stu-id="396f9-241">As shown in the following figure, the t-SNE visualization provides more separation of word vectors and potential clustering patterns.</span></span> 


* <span data-ttu-id="396f9-242">Visualization with PCA</span><span class="sxs-lookup"><span data-stu-id="396f9-242">Visualization with PCA</span></span>

![PCA](./media/scenario-tdsp-biomedical-recognition/pca.png)

* <span data-ttu-id="396f9-244">Visualization with t-SNE</span><span class="sxs-lookup"><span data-stu-id="396f9-244">Visualization with t-SNE</span></span>

![t-SNE](./media/scenario-tdsp-biomedical-recognition/tsne.png)

* <span data-ttu-id="396f9-246">Points closest to "Cancer" (they are all subtypes of Cancer)</span><span class="sxs-lookup"><span data-stu-id="396f9-246">Points closest to "Cancer" (they are all subtypes of Cancer)</span></span>

![Points closest to Cancer](./media/scenario-tdsp-biomedical-recognition/nearesttocancer.png)

#### <a name="22-train-the-neural-entity-extractor"></a><span data-ttu-id="396f9-248">2.2.</span><span class="sxs-lookup"><span data-stu-id="396f9-248">2.2.</span></span> <span data-ttu-id="396f9-249">Train the neural entity extractor</span><span class="sxs-lookup"><span data-stu-id="396f9-249">Train the neural entity extractor</span></span>

<span data-ttu-id="396f9-250">See [Train the neural entity extractor](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation/ReadMe.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-250">See [Train the neural entity extractor](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation/ReadMe.md).</span></span>

<span data-ttu-id="396f9-251">The feed-forward neural network architecture suffers from a problem that they treat each input and output as independent of the other inputs and outputs.</span><span class="sxs-lookup"><span data-stu-id="396f9-251">The feed-forward neural network architecture suffers from a problem that they treat each input and output as independent of the other inputs and outputs.</span></span> <span data-ttu-id="396f9-252">This architecture can't model sequence-to-sequence labeling tasks such as machine translation and entity extraction.</span><span class="sxs-lookup"><span data-stu-id="396f9-252">This architecture can't model sequence-to-sequence labeling tasks such as machine translation and entity extraction.</span></span> <span data-ttu-id="396f9-253">Recurrent neural network models overcome this problem as they can pass information computed until now to the next node.</span><span class="sxs-lookup"><span data-stu-id="396f9-253">Recurrent neural network models overcome this problem as they can pass information computed until now to the next node.</span></span> <span data-ttu-id="396f9-254">This property is called having memory in the network since it is able to use the previously computed information as shown in the following figure:</span><span class="sxs-lookup"><span data-stu-id="396f9-254">This property is called having memory in the network since it is able to use the previously computed information as shown in the following figure:</span></span>

![RNN](./media/scenario-tdsp-biomedical-recognition/rnn-expanded.png)

<span data-ttu-id="396f9-256">Vanilla RNNs actually suffer from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) due to which they are not able to utilize all the information they have seen before.</span><span class="sxs-lookup"><span data-stu-id="396f9-256">Vanilla RNNs actually suffer from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) due to which they are not able to utilize all the information they have seen before.</span></span> <span data-ttu-id="396f9-257">The problem becomes evident only when a large amount of context is required to make a prediction.</span><span class="sxs-lookup"><span data-stu-id="396f9-257">The problem becomes evident only when a large amount of context is required to make a prediction.</span></span> <span data-ttu-id="396f9-258">But models like LSTM do not suffer from such a problem, in fact they are designed to remember long-term dependencies.</span><span class="sxs-lookup"><span data-stu-id="396f9-258">But models like LSTM do not suffer from such a problem, in fact they are designed to remember long-term dependencies.</span></span> <span data-ttu-id="396f9-259">Unlike vanilla RNNs that have a single neural network, the LSTMs have the interactions between four neural networks for each cell.</span><span class="sxs-lookup"><span data-stu-id="396f9-259">Unlike vanilla RNNs that have a single neural network, the LSTMs have the interactions between four neural networks for each cell.</span></span> <span data-ttu-id="396f9-260">For a detailed explanation of how LSTM work, refer to [this post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).</span><span class="sxs-lookup"><span data-stu-id="396f9-260">For a detailed explanation of how LSTM work, refer to [this post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).</span></span>

![LSTM Cell](./media/scenario-tdsp-biomedical-recognition/lstm-cell.png)

<span data-ttu-id="396f9-262">Let’s try to put together our own LSTM-based recurrent neural network and try to extract entity types like drug, disease and symptom mentions from PubMed data.</span><span class="sxs-lookup"><span data-stu-id="396f9-262">Let’s try to put together our own LSTM-based recurrent neural network and try to extract entity types like drug, disease and symptom mentions from PubMed data.</span></span> <span data-ttu-id="396f9-263">The first step is to obtain a large amount of labeled data and as you would have guessed, that's not easy!</span><span class="sxs-lookup"><span data-stu-id="396f9-263">The first step is to obtain a large amount of labeled data and as you would have guessed, that's not easy!</span></span> <span data-ttu-id="396f9-264">Most of the medical data contains lot of sensitive information about the person and hence are not publicly available.</span><span class="sxs-lookup"><span data-stu-id="396f9-264">Most of the medical data contains lot of sensitive information about the person and hence are not publicly available.</span></span> <span data-ttu-id="396f9-265">We rely on a combination of two different datasets that are publicly available.</span><span class="sxs-lookup"><span data-stu-id="396f9-265">We rely on a combination of two different datasets that are publicly available.</span></span> <span data-ttu-id="396f9-266">The first dataset is from Semeval 2013 - Task 9.1 (Drug Recognition) and the other is from BioCreative V CDR task.</span><span class="sxs-lookup"><span data-stu-id="396f9-266">The first dataset is from Semeval 2013 - Task 9.1 (Drug Recognition) and the other is from BioCreative V CDR task.</span></span> <span data-ttu-id="396f9-267">We are combining and auto labeling these two datasets so that we can detect both drugs and diseases from medical texts and evaluate our word embeddings.</span><span class="sxs-lookup"><span data-stu-id="396f9-267">We are combining and auto labeling these two datasets so that we can detect both drugs and diseases from medical texts and evaluate our word embeddings.</span></span> <span data-ttu-id="396f9-268">For implementation details, refer to [GitHub code link](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation).</span><span class="sxs-lookup"><span data-stu-id="396f9-268">For implementation details, refer to [GitHub code link](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation).</span></span>

<span data-ttu-id="396f9-269">The model architecture that we have used across all the codes and for comparison is presented below.</span><span class="sxs-lookup"><span data-stu-id="396f9-269">The model architecture that we have used across all the codes and for comparison is presented below.</span></span> <span data-ttu-id="396f9-270">The parameter that changes for different datasets is the maximum sequence length (613 here).</span><span class="sxs-lookup"><span data-stu-id="396f9-270">The parameter that changes for different datasets is the maximum sequence length (613 here).</span></span>

![LSTM model](./media/scenario-tdsp-biomedical-recognition/d-a-d-model.png)

#### <a name="23-model-evaluation"></a><span data-ttu-id="396f9-272">2.3.</span><span class="sxs-lookup"><span data-stu-id="396f9-272">2.3.</span></span> <span data-ttu-id="396f9-273">Model evaluation</span><span class="sxs-lookup"><span data-stu-id="396f9-273">Model evaluation</span></span>
<span data-ttu-id="396f9-274">See [Model evaluation](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/03_model_evaluation/ReadMe.md).</span><span class="sxs-lookup"><span data-stu-id="396f9-274">See [Model evaluation](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/03_model_evaluation/ReadMe.md).</span></span>

<span data-ttu-id="396f9-275">We use the evaluation script from the shared task [Bio-Entity Recognition Task at Bio NLP/NLPBA 2004](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html) to evaluate the precision, recall, and F1 score of the model.</span><span class="sxs-lookup"><span data-stu-id="396f9-275">We use the evaluation script from the shared task [Bio-Entity Recognition Task at Bio NLP/NLPBA 2004](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html) to evaluate the precision, recall, and F1 score of the model.</span></span> 

#### <a name="in-domain-versus-generic-word-embedding-models"></a><span data-ttu-id="396f9-276">In-domain versus generic word embedding models</span><span class="sxs-lookup"><span data-stu-id="396f9-276">In-domain versus generic word embedding models</span></span>

<span data-ttu-id="396f9-277">The following is a comparison between the accuracy of two feature types: (1) word embeddings trained on PubMed abstracts and (2) word embeddings trained on Google News.</span><span class="sxs-lookup"><span data-stu-id="396f9-277">The following is a comparison between the accuracy of two feature types: (1) word embeddings trained on PubMed abstracts and (2) word embeddings trained on Google News.</span></span> <span data-ttu-id="396f9-278">We clearly see that the in-domain model outperforms the generic model.</span><span class="sxs-lookup"><span data-stu-id="396f9-278">We clearly see that the in-domain model outperforms the generic model.</span></span> <span data-ttu-id="396f9-279">Hence having a specific word embedding model rather than using a generic one is much more helpful.</span><span class="sxs-lookup"><span data-stu-id="396f9-279">Hence having a specific word embedding model rather than using a generic one is much more helpful.</span></span> 

* <span data-ttu-id="396f9-280">Task #1: Drugs and Diseases Detection</span><span class="sxs-lookup"><span data-stu-id="396f9-280">Task #1: Drugs and Diseases Detection</span></span>

![Model Comparison 1](./media/scenario-tdsp-biomedical-recognition/mc1.png)

<span data-ttu-id="396f9-282">We perform the evaluation of the word embeddings on other datasets in the similar fashion and see that in-domain model is always better.</span><span class="sxs-lookup"><span data-stu-id="396f9-282">We perform the evaluation of the word embeddings on other datasets in the similar fashion and see that in-domain model is always better.</span></span>

* <span data-ttu-id="396f9-283">Task #2: Proteins, Cell Line, Cell Type, DNA, and RNA Detection</span><span class="sxs-lookup"><span data-stu-id="396f9-283">Task #2: Proteins, Cell Line, Cell Type, DNA, and RNA Detection</span></span>

![Model Comparison 2](./media/scenario-tdsp-biomedical-recognition/mc2.png)

* <span data-ttu-id="396f9-285">Task #3: Chemicals and Diseases Detection</span><span class="sxs-lookup"><span data-stu-id="396f9-285">Task #3: Chemicals and Diseases Detection</span></span>

![Model Comparison 3](./media/scenario-tdsp-biomedical-recognition/mc3.png)

* <span data-ttu-id="396f9-287">Task #4: Drugs Detection</span><span class="sxs-lookup"><span data-stu-id="396f9-287">Task #4: Drugs Detection</span></span>

![Model Comparison 4](./media/scenario-tdsp-biomedical-recognition/mc4.png)

* <span data-ttu-id="396f9-289">Task #5: Genes Detection</span><span class="sxs-lookup"><span data-stu-id="396f9-289">Task #5: Genes Detection</span></span>

![Model Comparison 5](./media/scenario-tdsp-biomedical-recognition/mc5.png)

#### <a name="tensorflow-versus-cntk"></a><span data-ttu-id="396f9-291">TensorFlow versus CNTK</span><span class="sxs-lookup"><span data-stu-id="396f9-291">TensorFlow versus CNTK</span></span>
<span data-ttu-id="396f9-292">All the reported models are trained using Keras with TensorFlow as backend.</span><span class="sxs-lookup"><span data-stu-id="396f9-292">All the reported models are trained using Keras with TensorFlow as backend.</span></span> <span data-ttu-id="396f9-293">Keras with CNTK backend does not support "reverse" at the time this work was done.</span><span class="sxs-lookup"><span data-stu-id="396f9-293">Keras with CNTK backend does not support "reverse" at the time this work was done.</span></span> <span data-ttu-id="396f9-294">Therefore, for the sake of comparison, we have trained a unidirectional LSTM model with the CNTK backend and compared it to a unidirectional LSTM model with TensorFlow backend.</span><span class="sxs-lookup"><span data-stu-id="396f9-294">Therefore, for the sake of comparison, we have trained a unidirectional LSTM model with the CNTK backend and compared it to a unidirectional LSTM model with TensorFlow backend.</span></span> <span data-ttu-id="396f9-295">Install CNTK 2.0 for Keras from [here](https://docs.microsoft.com/cognitive-toolkit/using-cntk-with-keras).</span><span class="sxs-lookup"><span data-stu-id="396f9-295">Install CNTK 2.0 for Keras from [here](https://docs.microsoft.com/cognitive-toolkit/using-cntk-with-keras).</span></span> 

![Model Comparison 6](./media/scenario-tdsp-biomedical-recognition/mc6.png)

<span data-ttu-id="396f9-297">We concluded that CNTK performs as good as Tensorflow both in terms of the training time taken per epoch (60 secs for CNTK and 75 secs for Tensorflow) and the number of test entities detected.</span><span class="sxs-lookup"><span data-stu-id="396f9-297">We concluded that CNTK performs as good as Tensorflow both in terms of the training time taken per epoch (60 secs for CNTK and 75 secs for Tensorflow) and the number of test entities detected.</span></span> <span data-ttu-id="396f9-298">We are using the Unidirectional layers for evaluation.</span><span class="sxs-lookup"><span data-stu-id="396f9-298">We are using the Unidirectional layers for evaluation.</span></span>


### <a name="3-deployment"></a><span data-ttu-id="396f9-299">3. Deployment</span><span class="sxs-lookup"><span data-stu-id="396f9-299">3. Deployment</span></span>

<span data-ttu-id="396f9-300">See [Deployment](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/03_deployment).</span><span class="sxs-lookup"><span data-stu-id="396f9-300">See [Deployment](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/03_deployment).</span></span>

<span data-ttu-id="396f9-301">We deployed a web service on a cluster in the [Azure Container Service (ACS)](https://azure.microsoft.com/services/container-service/).</span><span class="sxs-lookup"><span data-stu-id="396f9-301">We deployed a web service on a cluster in the [Azure Container Service (ACS)](https://azure.microsoft.com/services/container-service/).</span></span> <span data-ttu-id="396f9-302">The operationalization environment provisions Docker and Kubernetes in the cluster to manage the web-service deployment.</span><span class="sxs-lookup"><span data-stu-id="396f9-302">The operationalization environment provisions Docker and Kubernetes in the cluster to manage the web-service deployment.</span></span> <span data-ttu-id="396f9-303">You can find further information about the operationalization process [here](model-management-service-deploy.md ).</span><span class="sxs-lookup"><span data-stu-id="396f9-303">You can find further information about the operationalization process [here](model-management-service-deploy.md ).</span></span>


## <a name="conclusion"></a><span data-ttu-id="396f9-304">Conclusion</span><span class="sxs-lookup"><span data-stu-id="396f9-304">Conclusion</span></span>

<span data-ttu-id="396f9-305">We went over the details of how you could train a word embedding model using Word2Vec algorithm on Spark and then use the extracted embeddings as features to train a deep neural network for entity extraction.</span><span class="sxs-lookup"><span data-stu-id="396f9-305">We went over the details of how you could train a word embedding model using Word2Vec algorithm on Spark and then use the extracted embeddings as features to train a deep neural network for entity extraction.</span></span> <span data-ttu-id="396f9-306">We have applied the training pipeline on the biomedical domain.</span><span class="sxs-lookup"><span data-stu-id="396f9-306">We have applied the training pipeline on the biomedical domain.</span></span> <span data-ttu-id="396f9-307">However, the pipeline is generic enough to be applied to detect custom entity types of any other domain.</span><span class="sxs-lookup"><span data-stu-id="396f9-307">However, the pipeline is generic enough to be applied to detect custom entity types of any other domain.</span></span> <span data-ttu-id="396f9-308">You just need enough data and you can easily adapt the workflow presented here for a different domain.</span><span class="sxs-lookup"><span data-stu-id="396f9-308">You just need enough data and you can easily adapt the workflow presented here for a different domain.</span></span>

## <a name="references"></a><span data-ttu-id="396f9-309">References</span><span class="sxs-lookup"><span data-stu-id="396f9-309">References</span></span>

* <span data-ttu-id="396f9-310">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.</span><span class="sxs-lookup"><span data-stu-id="396f9-310">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.</span></span> <span data-ttu-id="396f9-311">2013a.</span><span class="sxs-lookup"><span data-stu-id="396f9-311">2013a.</span></span> <span data-ttu-id="396f9-312">Efficient estimation of word representations in vector space.</span><span class="sxs-lookup"><span data-stu-id="396f9-312">Efficient estimation of word representations in vector space.</span></span> <span data-ttu-id="396f9-313">In Proceedings of ICLR.</span><span class="sxs-lookup"><span data-stu-id="396f9-313">In Proceedings of ICLR.</span></span>
* <span data-ttu-id="396f9-314">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean.</span><span class="sxs-lookup"><span data-stu-id="396f9-314">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean.</span></span> <span data-ttu-id="396f9-315">2013b.</span><span class="sxs-lookup"><span data-stu-id="396f9-315">2013b.</span></span> <span data-ttu-id="396f9-316">Distributed representations of words and phrases and their compositionality.</span><span class="sxs-lookup"><span data-stu-id="396f9-316">Distributed representations of words and phrases and their compositionality.</span></span> <span data-ttu-id="396f9-317">In Proceedings of NIPS, pages 3111–3119.</span><span class="sxs-lookup"><span data-stu-id="396f9-317">In Proceedings of NIPS, pages 3111–3119.</span></span>
* <span data-ttu-id="396f9-318">Billy Chiu, Gamal Crichton, Anna Korhonen, and Sampo Pyysalo.</span><span class="sxs-lookup"><span data-stu-id="396f9-318">Billy Chiu, Gamal Crichton, Anna Korhonen, and Sampo Pyysalo.</span></span> <span data-ttu-id="396f9-319">2016.</span><span class="sxs-lookup"><span data-stu-id="396f9-319">2016.</span></span> <span data-ttu-id="396f9-320">[How to Train Good Word Embeddings for Biomedical NLP](http://aclweb.org/anthology/W/W16/W16-2922.pdf), In Proceedings of the fifteenth Workshop on Biomedical Natural Language Processing, pages 166–174.</span><span class="sxs-lookup"><span data-stu-id="396f9-320">[How to Train Good Word Embeddings for Biomedical NLP](http://aclweb.org/anthology/W/W16/W16-2922.pdf), In Proceedings of the fifteenth Workshop on Biomedical Natural Language Processing, pages 166–174.</span></span>
* [<span data-ttu-id="396f9-321">Vector Representations of Words</span><span class="sxs-lookup"><span data-stu-id="396f9-321">Vector Representations of Words</span></span>](https://www.tensorflow.org/tutorials/word2vec)
* [<span data-ttu-id="396f9-322">Recurrent Neural Networks</span><span class="sxs-lookup"><span data-stu-id="396f9-322">Recurrent Neural Networks</span></span>](https://www.tensorflow.org/tutorials/recurrent)
* [<span data-ttu-id="396f9-323">Problems encountered with Spark ml Word2Vec</span><span class="sxs-lookup"><span data-stu-id="396f9-323">Problems encountered with Spark ml Word2Vec</span></span>](https://intothedepthsofdataengineering.wordpress.com/2017/06/26/problems-encountered-with-spark-ml-word2vec/)
* [<span data-ttu-id="396f9-324">Spark Word2Vec: lessons learned</span><span class="sxs-lookup"><span data-stu-id="396f9-324">Spark Word2Vec: lessons learned</span></span>](https://intothedepthsofdataengineering.wordpress.com/2017/06/26/spark-word2vec-lessons-learned/)

