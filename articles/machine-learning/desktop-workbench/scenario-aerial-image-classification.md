---
title: Aerial Image Classification  | Microsoft Docs
description: Provides instructions for real world scenario on aerial image classification
author: mawah
ms.author: mawah
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.topic: article
ms.service: machine-learning
ms.component: core
services: machine-learning
ms.workload: data-services
ms.date: 12/13/2017
ms.openlocfilehash: cc436aaaf100c42e5a415d0b131b01901943c907
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44866150"
---
# <a name="aerial-image-classification"></a><span data-ttu-id="bbc92-103">Aerial Image Classification</span><span class="sxs-lookup"><span data-stu-id="bbc92-103">Aerial Image Classification</span></span>

<span data-ttu-id="bbc92-104">This example demonstrates how to use Azure Machine Learning Workbench to coordinate distributed training and operationalization of image classification models.</span><span class="sxs-lookup"><span data-stu-id="bbc92-104">This example demonstrates how to use Azure Machine Learning Workbench to coordinate distributed training and operationalization of image classification models.</span></span> <span data-ttu-id="bbc92-105">We use two approaches for training: (i) refining a deep neural network using an [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/) GPU cluster, and (ii) using the [Microsoft Machine Learning for Apache Spark (MMLSpark)](https://github.com/Azure/mmlspark) package to featurize images using pretrained CNTK models and to train classifiers using the derived features.</span><span class="sxs-lookup"><span data-stu-id="bbc92-105">We use two approaches for training: (i) refining a deep neural network using an [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/) GPU cluster, and (ii) using the [Microsoft Machine Learning for Apache Spark (MMLSpark)](https://github.com/Azure/mmlspark) package to featurize images using pretrained CNTK models and to train classifiers using the derived features.</span></span> <span data-ttu-id="bbc92-106">We then apply the trained models in parallel fashion to large image sets in the cloud using an [Azure HDInsight Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) cluster, allowing us to scale the speed of training and operationalization by adding or removing worker nodes.</span><span class="sxs-lookup"><span data-stu-id="bbc92-106">We then apply the trained models in parallel fashion to large image sets in the cloud using an [Azure HDInsight Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) cluster, allowing us to scale the speed of training and operationalization by adding or removing worker nodes.</span></span>

<span data-ttu-id="bbc92-107">This example highlights two approaches to transfer learning, which leverages pretrained models to avoid the costs of training deep neural networks from scratch.</span><span class="sxs-lookup"><span data-stu-id="bbc92-107">This example highlights two approaches to transfer learning, which leverages pretrained models to avoid the costs of training deep neural networks from scratch.</span></span> <span data-ttu-id="bbc92-108">Retraining a deep neural network typically requires GPU compute, but can lead to greater accuracy when the training set is sufficiently large.</span><span class="sxs-lookup"><span data-stu-id="bbc92-108">Retraining a deep neural network typically requires GPU compute, but can lead to greater accuracy when the training set is sufficiently large.</span></span> <span data-ttu-id="bbc92-109">Training a simple classifier on featurized images does not require GPU compute, is inherently fast and arbitrarily scalable, and fits fewer parameters.</span><span class="sxs-lookup"><span data-stu-id="bbc92-109">Training a simple classifier on featurized images does not require GPU compute, is inherently fast and arbitrarily scalable, and fits fewer parameters.</span></span> <span data-ttu-id="bbc92-110">This method is therefore an excellent choice when few training samples are available -- as is often the case for custom use cases.</span><span class="sxs-lookup"><span data-stu-id="bbc92-110">This method is therefore an excellent choice when few training samples are available -- as is often the case for custom use cases.</span></span> 

<span data-ttu-id="bbc92-111">The Spark cluster used in this example has 40 worker nodes and costs ~$40/hr to operate; the Batch AI cluster resources include eight GPUs and cost ~$10/hr to operate.</span><span class="sxs-lookup"><span data-stu-id="bbc92-111">The Spark cluster used in this example has 40 worker nodes and costs ~$40/hr to operate; the Batch AI cluster resources include eight GPUs and cost ~$10/hr to operate.</span></span> <span data-ttu-id="bbc92-112">Completing this walkthrough takes approximately three hours.</span><span class="sxs-lookup"><span data-stu-id="bbc92-112">Completing this walkthrough takes approximately three hours.</span></span> <span data-ttu-id="bbc92-113">When you are finished, follow the cleanup instructions to remove the resources you have created and stop incurring charges.</span><span class="sxs-lookup"><span data-stu-id="bbc92-113">When you are finished, follow the cleanup instructions to remove the resources you have created and stop incurring charges.</span></span>

## <a name="link-to-the-gallery-github-repository"></a><span data-ttu-id="bbc92-114">Link to the Gallery GitHub repository</span><span class="sxs-lookup"><span data-stu-id="bbc92-114">Link to the Gallery GitHub repository</span></span>

<span data-ttu-id="bbc92-115">The public GitHub repository for this real world scenario contains all materials, including code samples, needed for this example:</span><span class="sxs-lookup"><span data-stu-id="bbc92-115">The public GitHub repository for this real world scenario contains all materials, including code samples, needed for this example:</span></span>

[https://github.com/Azure/MachineLearningSamples-AerialImageClassification](https://github.com/Azure/MachineLearningSamples-AerialImageClassification)

## <a name="use-case-description"></a><span data-ttu-id="bbc92-116">Use case description</span><span class="sxs-lookup"><span data-stu-id="bbc92-116">Use case description</span></span>

<span data-ttu-id="bbc92-117">In this scenario, we train machine learning models to classify the type of land shown in aerial images of 224-meter x 224-meter plots.</span><span class="sxs-lookup"><span data-stu-id="bbc92-117">In this scenario, we train machine learning models to classify the type of land shown in aerial images of 224-meter x 224-meter plots.</span></span> <span data-ttu-id="bbc92-118">Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery.</span><span class="sxs-lookup"><span data-stu-id="bbc92-118">Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery.</span></span> <span data-ttu-id="bbc92-119">We have prepared training and validation image sets based on imagery from the U.S. National Agriculture Imagery Program and land use labels published by the U.S. National Land Cover Database.</span><span class="sxs-lookup"><span data-stu-id="bbc92-119">We have prepared training and validation image sets based on imagery from the U.S. National Agriculture Imagery Program and land use labels published by the U.S. National Land Cover Database.</span></span> <span data-ttu-id="bbc92-120">Example images in each land use class are shown here:</span><span class="sxs-lookup"><span data-stu-id="bbc92-120">Example images in each land use class are shown here:</span></span>

![Example regions for each land use label](media/scenario-aerial-image-classification/example-labels.PNG)

<span data-ttu-id="bbc92-122">After training and validating the classifier model, we will apply it to aerial images spanning Middlesex County, MA -- home of Microsoft's New England Research & Development (NERD) Center -- to demonstrate how these models can be used to study trends in urban development.</span><span class="sxs-lookup"><span data-stu-id="bbc92-122">After training and validating the classifier model, we will apply it to aerial images spanning Middlesex County, MA -- home of Microsoft's New England Research & Development (NERD) Center -- to demonstrate how these models can be used to study trends in urban development.</span></span>

<span data-ttu-id="bbc92-123">To produce an image classifier using transfer learning, data scientists often construct multiple models with a range of methods and select the most performant model.</span><span class="sxs-lookup"><span data-stu-id="bbc92-123">To produce an image classifier using transfer learning, data scientists often construct multiple models with a range of methods and select the most performant model.</span></span> <span data-ttu-id="bbc92-124">Azure Machine Learning Workbench can help data scientists coordinate training across different compute environments, track and compare the performance of multiple models, and apply a chosen model to large datasets on the cloud.</span><span class="sxs-lookup"><span data-stu-id="bbc92-124">Azure Machine Learning Workbench can help data scientists coordinate training across different compute environments, track and compare the performance of multiple models, and apply a chosen model to large datasets on the cloud.</span></span>

## <a name="scenario-structure"></a><span data-ttu-id="bbc92-125">Scenario structure</span><span class="sxs-lookup"><span data-stu-id="bbc92-125">Scenario structure</span></span>

<span data-ttu-id="bbc92-126">In this example, image data and pretrained models are housed in an Azure storage account.</span><span class="sxs-lookup"><span data-stu-id="bbc92-126">In this example, image data and pretrained models are housed in an Azure storage account.</span></span> <span data-ttu-id="bbc92-127">An Azure HDInsight Spark cluster reads these files and constructs an image classification model using MMLSpark.</span><span class="sxs-lookup"><span data-stu-id="bbc92-127">An Azure HDInsight Spark cluster reads these files and constructs an image classification model using MMLSpark.</span></span> <span data-ttu-id="bbc92-128">The trained model and its predictions are then written to the storage account, where they can be analyzed and visualized by a Jupyter notebook running locally.</span><span class="sxs-lookup"><span data-stu-id="bbc92-128">The trained model and its predictions are then written to the storage account, where they can be analyzed and visualized by a Jupyter notebook running locally.</span></span> <span data-ttu-id="bbc92-129">Azure Machine Learning Workbench coordinates remote execution of scripts on the Spark cluster.</span><span class="sxs-lookup"><span data-stu-id="bbc92-129">Azure Machine Learning Workbench coordinates remote execution of scripts on the Spark cluster.</span></span> <span data-ttu-id="bbc92-130">It also tracks accuracy metrics for multiple models trained using different methods, allowing the user to select the most performant model.</span><span class="sxs-lookup"><span data-stu-id="bbc92-130">It also tracks accuracy metrics for multiple models trained using different methods, allowing the user to select the most performant model.</span></span>

![Schematic for the aerial image classification real world scenario](media/scenario-aerial-image-classification/scenario-schematic.PNG)

<span data-ttu-id="bbc92-132">These step-by-step instructions begin by guiding you through the creation and preparation of an Azure storage account and Spark cluster, including data transfer and dependency installation.</span><span class="sxs-lookup"><span data-stu-id="bbc92-132">These step-by-step instructions begin by guiding you through the creation and preparation of an Azure storage account and Spark cluster, including data transfer and dependency installation.</span></span> <span data-ttu-id="bbc92-133">They then describe how to launch training jobs and compare the performance of the resulting models.</span><span class="sxs-lookup"><span data-stu-id="bbc92-133">They then describe how to launch training jobs and compare the performance of the resulting models.</span></span> <span data-ttu-id="bbc92-134">Finally, they illustrate how to apply a chosen model to a large image set on the Spark cluster and analyze the prediction results locally.</span><span class="sxs-lookup"><span data-stu-id="bbc92-134">Finally, they illustrate how to apply a chosen model to a large image set on the Spark cluster and analyze the prediction results locally.</span></span>


## <a name="set-up-the-execution-environment"></a><span data-ttu-id="bbc92-135">Set up the execution environment</span><span class="sxs-lookup"><span data-stu-id="bbc92-135">Set up the execution environment</span></span>

<span data-ttu-id="bbc92-136">The following instructions guide you through the process of setting up execution environment for this example.</span><span class="sxs-lookup"><span data-stu-id="bbc92-136">The following instructions guide you through the process of setting up execution environment for this example.</span></span>

### <a name="prerequisites"></a><span data-ttu-id="bbc92-137">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="bbc92-137">Prerequisites</span></span>
- <span data-ttu-id="bbc92-138">An [Azure account](https://azure.microsoft.com/free/) (free trials are available)</span><span class="sxs-lookup"><span data-stu-id="bbc92-138">An [Azure account](https://azure.microsoft.com/free/) (free trials are available)</span></span>
    - <span data-ttu-id="bbc92-139">You will create an HDInsight Spark cluster with 40 worker nodes (168 cores total).</span><span class="sxs-lookup"><span data-stu-id="bbc92-139">You will create an HDInsight Spark cluster with 40 worker nodes (168 cores total).</span></span> <span data-ttu-id="bbc92-140">Ensure that your account has enough available cores by reviewing the "Usage + quotas" tab for your subscription in Azure portal.</span><span class="sxs-lookup"><span data-stu-id="bbc92-140">Ensure that your account has enough available cores by reviewing the "Usage + quotas" tab for your subscription in Azure portal.</span></span>
       - <span data-ttu-id="bbc92-141">If you have fewer cores available, you may modify the HDInsight cluster template to decrease the number of workers provisioned.</span><span class="sxs-lookup"><span data-stu-id="bbc92-141">If you have fewer cores available, you may modify the HDInsight cluster template to decrease the number of workers provisioned.</span></span> <span data-ttu-id="bbc92-142">Instructions for this appear under the "Create the HDInsight Spark cluster" section.</span><span class="sxs-lookup"><span data-stu-id="bbc92-142">Instructions for this appear under the "Create the HDInsight Spark cluster" section.</span></span>
    - <span data-ttu-id="bbc92-143">This sample creates a Batch AI Training cluster with two NC6 (1 GPU, 6 vCPU) VMs.</span><span class="sxs-lookup"><span data-stu-id="bbc92-143">This sample creates a Batch AI Training cluster with two NC6 (1 GPU, 6 vCPU) VMs.</span></span> <span data-ttu-id="bbc92-144">Ensure that your account has enough available cores in the East US region by reviewing the "Usage + quotas" tab for your subscription in Azure portal.</span><span class="sxs-lookup"><span data-stu-id="bbc92-144">Ensure that your account has enough available cores in the East US region by reviewing the "Usage + quotas" tab for your subscription in Azure portal.</span></span>
- [<span data-ttu-id="bbc92-145">Azure Machine Learning Workbench</span><span class="sxs-lookup"><span data-stu-id="bbc92-145">Azure Machine Learning Workbench</span></span>](../service/overview-what-is-azure-ml.md)
    - <span data-ttu-id="bbc92-146">Follow the [Install and create Quickstart](../service/quickstart-installation.md) to install the Azure Machine Learning Workbench and create Experimentation and Model Management Accounts.</span><span class="sxs-lookup"><span data-stu-id="bbc92-146">Follow the [Install and create Quickstart](../service/quickstart-installation.md) to install the Azure Machine Learning Workbench and create Experimentation and Model Management Accounts.</span></span>
- <span data-ttu-id="bbc92-147">[Batch AI](https://github.com/Azure/BatchAI) Python SDK and Azure CLI</span><span class="sxs-lookup"><span data-stu-id="bbc92-147">[Batch AI](https://github.com/Azure/BatchAI) Python SDK and Azure CLI</span></span>
    - <span data-ttu-id="bbc92-148">Complete the following sections in the [Batch AI Recipes README](https://github.com/Azure/BatchAI/tree/master/recipes):</span><span class="sxs-lookup"><span data-stu-id="bbc92-148">Complete the following sections in the [Batch AI Recipes README](https://github.com/Azure/BatchAI/tree/master/recipes):</span></span>
        - <span data-ttu-id="bbc92-149">"Prerequisites"</span><span class="sxs-lookup"><span data-stu-id="bbc92-149">"Prerequisites"</span></span>
        - <span data-ttu-id="bbc92-150">"Create and get your Azure Active Directory (AAD) application"</span><span class="sxs-lookup"><span data-stu-id="bbc92-150">"Create and get your Azure Active Directory (AAD) application"</span></span>
        - <span data-ttu-id="bbc92-151">"Register BatchAI Resource Providers" (under "Run Recipes Using Azure CLI")</span><span class="sxs-lookup"><span data-stu-id="bbc92-151">"Register BatchAI Resource Providers" (under "Run Recipes Using Azure CLI")</span></span>
        - <span data-ttu-id="bbc92-152">"Install Azure Batch AI Management Client"</span><span class="sxs-lookup"><span data-stu-id="bbc92-152">"Install Azure Batch AI Management Client"</span></span>
        - <span data-ttu-id="bbc92-153">"Install Azure Python SDK"</span><span class="sxs-lookup"><span data-stu-id="bbc92-153">"Install Azure Python SDK"</span></span>
    - <span data-ttu-id="bbc92-154">Record the client ID, secret, and tenant ID of the Azure Active Directory application you are directed to create.</span><span class="sxs-lookup"><span data-stu-id="bbc92-154">Record the client ID, secret, and tenant ID of the Azure Active Directory application you are directed to create.</span></span> <span data-ttu-id="bbc92-155">You will use those credentials later in this tutorial.</span><span class="sxs-lookup"><span data-stu-id="bbc92-155">You will use those credentials later in this tutorial.</span></span>
    - <span data-ttu-id="bbc92-156">As of this writing, Azure Machine Learning Workbench and Azure Batch AI use separate forks of the Azure CLI.</span><span class="sxs-lookup"><span data-stu-id="bbc92-156">As of this writing, Azure Machine Learning Workbench and Azure Batch AI use separate forks of the Azure CLI.</span></span> <span data-ttu-id="bbc92-157">For clarity, we refer to the Workbench's version of the CLI as "a CLI launched from Azure Machine Learning Workbench" and the general-release version (which includes Batch AI) as "Azure CLI."</span><span class="sxs-lookup"><span data-stu-id="bbc92-157">For clarity, we refer to the Workbench's version of the CLI as "a CLI launched from Azure Machine Learning Workbench" and the general-release version (which includes Batch AI) as "Azure CLI."</span></span>
- <span data-ttu-id="bbc92-158">[AzCopy](https://docs.microsoft.com/azure/storage/common/storage-use-azcopy), a free utility for coordinating file transfer between Azure storage accounts</span><span class="sxs-lookup"><span data-stu-id="bbc92-158">[AzCopy](https://docs.microsoft.com/azure/storage/common/storage-use-azcopy), a free utility for coordinating file transfer between Azure storage accounts</span></span>
    - <span data-ttu-id="bbc92-159">Ensure that the folder containing the AzCopy executable is on your system's PATH environment variable.</span><span class="sxs-lookup"><span data-stu-id="bbc92-159">Ensure that the folder containing the AzCopy executable is on your system's PATH environment variable.</span></span> <span data-ttu-id="bbc92-160">(Instructions on modifying environment variables are available [here](https://support.microsoft.com/help/310519/how-to-manage-environment-variables-in-windows-xp).)</span><span class="sxs-lookup"><span data-stu-id="bbc92-160">(Instructions on modifying environment variables are available [here](https://support.microsoft.com/help/310519/how-to-manage-environment-variables-in-windows-xp).)</span></span>
- <span data-ttu-id="bbc92-161">An SSH client; we recommend [PuTTY](http://www.putty.org/).</span><span class="sxs-lookup"><span data-stu-id="bbc92-161">An SSH client; we recommend [PuTTY](http://www.putty.org/).</span></span>

<span data-ttu-id="bbc92-162">This example was tested on a Windows 10 PC; you should be able to run it from any Windows machine, including Azure Data Science Virtual Machines.</span><span class="sxs-lookup"><span data-stu-id="bbc92-162">This example was tested on a Windows 10 PC; you should be able to run it from any Windows machine, including Azure Data Science Virtual Machines.</span></span> <span data-ttu-id="bbc92-163">The Azure CLI was installed from an MSI according to [these instructions](https://github.com/Azure/azure-sdk-for-python/wiki/Contributing-to-the-tests#getting-azure-credentials).</span><span class="sxs-lookup"><span data-stu-id="bbc92-163">The Azure CLI was installed from an MSI according to [these instructions](https://github.com/Azure/azure-sdk-for-python/wiki/Contributing-to-the-tests#getting-azure-credentials).</span></span> <span data-ttu-id="bbc92-164">Minor modifications may be required (for example, changes to filepaths) when running this example on macOS.</span><span class="sxs-lookup"><span data-stu-id="bbc92-164">Minor modifications may be required (for example, changes to filepaths) when running this example on macOS.</span></span>

### <a name="set-up-azure-resources"></a><span data-ttu-id="bbc92-165">Set up Azure resources</span><span class="sxs-lookup"><span data-stu-id="bbc92-165">Set up Azure resources</span></span>

<span data-ttu-id="bbc92-166">This example requires an HDInsight Spark cluster and an Azure storage account to host relevant files.</span><span class="sxs-lookup"><span data-stu-id="bbc92-166">This example requires an HDInsight Spark cluster and an Azure storage account to host relevant files.</span></span> <span data-ttu-id="bbc92-167">Follow these instructions to create these resources in a new Azure resource group:</span><span class="sxs-lookup"><span data-stu-id="bbc92-167">Follow these instructions to create these resources in a new Azure resource group:</span></span>

#### <a name="create-a-new-workbench-project"></a><span data-ttu-id="bbc92-168">Create a new Workbench project</span><span class="sxs-lookup"><span data-stu-id="bbc92-168">Create a new Workbench project</span></span>

<span data-ttu-id="bbc92-169">Create a new project using this example as a template:</span><span class="sxs-lookup"><span data-stu-id="bbc92-169">Create a new project using this example as a template:</span></span>
1.  <span data-ttu-id="bbc92-170">Open Azure Machine Learning Workbench</span><span class="sxs-lookup"><span data-stu-id="bbc92-170">Open Azure Machine Learning Workbench</span></span>
2.  <span data-ttu-id="bbc92-171">On the **Projects** page, click the **+** sign and select **New Project**</span><span class="sxs-lookup"><span data-stu-id="bbc92-171">On the **Projects** page, click the **+** sign and select **New Project**</span></span>
3.  <span data-ttu-id="bbc92-172">In the **Create New Project** pane, fill in the information for your new project</span><span class="sxs-lookup"><span data-stu-id="bbc92-172">In the **Create New Project** pane, fill in the information for your new project</span></span>
4.  <span data-ttu-id="bbc92-173">In the **Search Project Templates** search box, type "Aerial Image Classification" and select the template</span><span class="sxs-lookup"><span data-stu-id="bbc92-173">In the **Search Project Templates** search box, type "Aerial Image Classification" and select the template</span></span>
5.  <span data-ttu-id="bbc92-174">Click **Create**</span><span class="sxs-lookup"><span data-stu-id="bbc92-174">Click **Create**</span></span>
 
#### <a name="create-the-resource-group"></a><span data-ttu-id="bbc92-175">Create the resource group</span><span class="sxs-lookup"><span data-stu-id="bbc92-175">Create the resource group</span></span>

1. <span data-ttu-id="bbc92-176">After loading your project in Azure Machine Learning Workbench, open a Command Line Interface (CLI) by clicking File -> Open Command Prompt.</span><span class="sxs-lookup"><span data-stu-id="bbc92-176">After loading your project in Azure Machine Learning Workbench, open a Command Line Interface (CLI) by clicking File -> Open Command Prompt.</span></span>
    <span data-ttu-id="bbc92-177">Use this version of the CLI for the majority of the tutorial.</span><span class="sxs-lookup"><span data-stu-id="bbc92-177">Use this version of the CLI for the majority of the tutorial.</span></span> <span data-ttu-id="bbc92-178">(Where indicated, you are asked to open another version of the CLI to prepare Batch AI resources.)</span><span class="sxs-lookup"><span data-stu-id="bbc92-178">(Where indicated, you are asked to open another version of the CLI to prepare Batch AI resources.)</span></span>

1. <span data-ttu-id="bbc92-179">From the command-line interface, log in to your Azure account by running the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-179">From the command-line interface, log in to your Azure account by running the following command:</span></span>

    ```
    az login
    ```

    <span data-ttu-id="bbc92-180">You are asked to visit a URL and type in a provided temporary code; the website requests your Azure account credentials.</span><span class="sxs-lookup"><span data-stu-id="bbc92-180">You are asked to visit a URL and type in a provided temporary code; the website requests your Azure account credentials.</span></span>
    
1. <span data-ttu-id="bbc92-181">When login is complete, return to the CLI and run the following command to determine which Azure subscriptions are available to your Azure account:</span><span class="sxs-lookup"><span data-stu-id="bbc92-181">When login is complete, return to the CLI and run the following command to determine which Azure subscriptions are available to your Azure account:</span></span>

    ```
    az account list
    ```

    <span data-ttu-id="bbc92-182">This command lists all subscriptions associated with your Azure account.</span><span class="sxs-lookup"><span data-stu-id="bbc92-182">This command lists all subscriptions associated with your Azure account.</span></span> <span data-ttu-id="bbc92-183">Find the ID of the subscription you would like to use.</span><span class="sxs-lookup"><span data-stu-id="bbc92-183">Find the ID of the subscription you would like to use.</span></span> <span data-ttu-id="bbc92-184">Write the subscription ID where indicated in the following command, then set the active subscription by executing the command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-184">Write the subscription ID where indicated in the following command, then set the active subscription by executing the command:</span></span>

    ```
    az account set --subscription [subscription ID]
    ```

1. <span data-ttu-id="bbc92-185">The Azure resources created in this example are stored together in an Azure resource group.</span><span class="sxs-lookup"><span data-stu-id="bbc92-185">The Azure resources created in this example are stored together in an Azure resource group.</span></span> <span data-ttu-id="bbc92-186">Choose a unique resource group name and write it where indicated, then execute both commands to create the Azure resource group:</span><span class="sxs-lookup"><span data-stu-id="bbc92-186">Choose a unique resource group name and write it where indicated, then execute both commands to create the Azure resource group:</span></span>

    ```
    set AZURE_RESOURCE_GROUP=[resource group name]
    az group create --location eastus --name %AZURE_RESOURCE_GROUP%
    ```

#### <a name="create-the-storage-account"></a><span data-ttu-id="bbc92-187">Create the storage account</span><span class="sxs-lookup"><span data-stu-id="bbc92-187">Create the storage account</span></span>

<span data-ttu-id="bbc92-188">We now create the storage account that hosts project files that must be accessed by the HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="bbc92-188">We now create the storage account that hosts project files that must be accessed by the HDInsight Spark.</span></span>

1. <span data-ttu-id="bbc92-189">Choose a unique storage account name and write it where indicated in the following `set` command, then create an Azure storage account by executing both commands:</span><span class="sxs-lookup"><span data-stu-id="bbc92-189">Choose a unique storage account name and write it where indicated in the following `set` command, then create an Azure storage account by executing both commands:</span></span>

    ```
    set STORAGE_ACCOUNT_NAME=[storage account name]
    az storage account create --name %STORAGE_ACCOUNT_NAME% --resource-group %AZURE_RESOURCE_GROUP% --sku Standard_LRS
    ```

1. <span data-ttu-id="bbc92-190">List the storage account keys by running the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-190">List the storage account keys by running the following command:</span></span>

    ```
    az storage account keys list --resource-group %AZURE_RESOURCE_GROUP% --account-name %STORAGE_ACCOUNT_NAME%
    ```

    <span data-ttu-id="bbc92-191">Record the value of `key1` as the storage key in the following command, then run the command to store the value.</span><span class="sxs-lookup"><span data-stu-id="bbc92-191">Record the value of `key1` as the storage key in the following command, then run the command to store the value.</span></span>
    ```
    set STORAGE_ACCOUNT_KEY=[storage account key]
    ```
1. <span data-ttu-id="bbc92-192">Create a file share named `baitshare` in your storage account with the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-192">Create a file share named `baitshare` in your storage account with the following command:</span></span>

    ```
    az storage share create --account-name %STORAGE_ACCOUNT_NAME% --account-key %STORAGE_ACCOUNT_KEY% --name baitshare
    ```
1. <span data-ttu-id="bbc92-193">In your favorite text editor, load the `settings.cfg` file from the Azure Machine Learning Workbench project's "Code" subdirectory, and insert the storage account name and key as indicated.</span><span class="sxs-lookup"><span data-stu-id="bbc92-193">In your favorite text editor, load the `settings.cfg` file from the Azure Machine Learning Workbench project's "Code" subdirectory, and insert the storage account name and key as indicated.</span></span> <span data-ttu-id="bbc92-194">Save and close the `settings.cfg` file.</span><span class="sxs-lookup"><span data-stu-id="bbc92-194">Save and close the `settings.cfg` file.</span></span>
1. <span data-ttu-id="bbc92-195">If you have not already done so, download and install the [AzCopy](http://aka.ms/downloadazcopy) utility.</span><span class="sxs-lookup"><span data-stu-id="bbc92-195">If you have not already done so, download and install the [AzCopy](http://aka.ms/downloadazcopy) utility.</span></span> <span data-ttu-id="bbc92-196">Ensure that the AzCopy executable is on your system path by typing "AzCopy" and pressing Enter to show its documentation.</span><span class="sxs-lookup"><span data-stu-id="bbc92-196">Ensure that the AzCopy executable is on your system path by typing "AzCopy" and pressing Enter to show its documentation.</span></span>
1. <span data-ttu-id="bbc92-197">Issue the following commands to copy all of the sample data, pretrained models, and model training scripts to the appropriate locations in your storage account:</span><span class="sxs-lookup"><span data-stu-id="bbc92-197">Issue the following commands to copy all of the sample data, pretrained models, and model training scripts to the appropriate locations in your storage account:</span></span>

    ```
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/test /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/test /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/train /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/train /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/middlesexma2016 /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/middlesexma2016 /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/pretrainedmodels /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/pretrainedmodels /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/pretrainedmodels /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.file.core.windows.net/baitshare/pretrainedmodels /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/scripts /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.file.core.windows.net/baitshare/scripts /DestKey:%STORAGE_ACCOUNT_KEY% /S
    ```

    <span data-ttu-id="bbc92-198">Expect file transfer to take around one hour.</span><span class="sxs-lookup"><span data-stu-id="bbc92-198">Expect file transfer to take around one hour.</span></span> <span data-ttu-id="bbc92-199">While you wait, you can proceed to the following section: you may need to open another Command Line Interface through Workbench and redefine the temporary variables there.</span><span class="sxs-lookup"><span data-stu-id="bbc92-199">While you wait, you can proceed to the following section: you may need to open another Command Line Interface through Workbench and redefine the temporary variables there.</span></span>

#### <a name="create-the-hdinsight-spark-cluster"></a><span data-ttu-id="bbc92-200">Create the HDInsight Spark cluster</span><span class="sxs-lookup"><span data-stu-id="bbc92-200">Create the HDInsight Spark cluster</span></span>

<span data-ttu-id="bbc92-201">Our recommended method to create an HDInsight cluster uses the HDInsight Spark cluster resource manager template included in the "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning" subfolder of this project.</span><span class="sxs-lookup"><span data-stu-id="bbc92-201">Our recommended method to create an HDInsight cluster uses the HDInsight Spark cluster resource manager template included in the "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning" subfolder of this project.</span></span>

1. <span data-ttu-id="bbc92-202">The HDInsight Spark cluster template is the "template.json" file under the "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning" subfolder of this project.</span><span class="sxs-lookup"><span data-stu-id="bbc92-202">The HDInsight Spark cluster template is the "template.json" file under the "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning" subfolder of this project.</span></span> <span data-ttu-id="bbc92-203">By default, the template creates a Spark cluster with 40 worker nodes.</span><span class="sxs-lookup"><span data-stu-id="bbc92-203">By default, the template creates a Spark cluster with 40 worker nodes.</span></span> <span data-ttu-id="bbc92-204">If you must adjust that number, open the template in your favorite text editor and replace any instances of "40" with the worker node number of your choice.</span><span class="sxs-lookup"><span data-stu-id="bbc92-204">If you must adjust that number, open the template in your favorite text editor and replace any instances of "40" with the worker node number of your choice.</span></span>
    - <span data-ttu-id="bbc92-205">You may encounter out-of-memory errors later if the number of worker nodes you choose is smaller.</span><span class="sxs-lookup"><span data-stu-id="bbc92-205">You may encounter out-of-memory errors later if the number of worker nodes you choose is smaller.</span></span> <span data-ttu-id="bbc92-206">To combat memory errors, you may run the training and operationalization scripts on a subset of the available data as described later in this document.</span><span class="sxs-lookup"><span data-stu-id="bbc92-206">To combat memory errors, you may run the training and operationalization scripts on a subset of the available data as described later in this document.</span></span>
2. <span data-ttu-id="bbc92-207">Choose a unique name and password for the HDInsight cluster and write them where indicated in the following command: Then create the cluster by issuing the commands:</span><span class="sxs-lookup"><span data-stu-id="bbc92-207">Choose a unique name and password for the HDInsight cluster and write them where indicated in the following command: Then create the cluster by issuing the commands:</span></span>

    ```
    set HDINSIGHT_CLUSTER_NAME=[HDInsight cluster name]
    set HDINSIGHT_CLUSTER_PASSWORD=[HDInsight cluster password]
    az group deployment create --resource-group %AZURE_RESOURCE_GROUP% --name hdispark --template-file "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning\template.json" --parameters storageAccountName=%STORAGE_ACCOUNT_NAME%.blob.core.windows.net storageAccountKey=%STORAGE_ACCOUNT_KEY% clusterName=%HDINSIGHT_CLUSTER_NAME% clusterLoginPassword=%HDINSIGHT_CLUSTER_PASSWORD%
    ```

<span data-ttu-id="bbc92-208">Your cluster's deployment may take up to 30 minutes (including provisioning and script action execution).</span><span class="sxs-lookup"><span data-stu-id="bbc92-208">Your cluster's deployment may take up to 30 minutes (including provisioning and script action execution).</span></span>

### <a name="set-up-batch-ai-resources"></a><span data-ttu-id="bbc92-209">Set up Batch AI resources</span><span class="sxs-lookup"><span data-stu-id="bbc92-209">Set up Batch AI resources</span></span>

<span data-ttu-id="bbc92-210">While you wait for your Storage account file transfer and Spark cluster deployment to complete, you can prepare the Batch AI Network File Server (NFS) and GPU cluster.</span><span class="sxs-lookup"><span data-stu-id="bbc92-210">While you wait for your Storage account file transfer and Spark cluster deployment to complete, you can prepare the Batch AI Network File Server (NFS) and GPU cluster.</span></span> <span data-ttu-id="bbc92-211">Open an Azure CLI command prompt and run the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-211">Open an Azure CLI command prompt and run the following command:</span></span>

```
az --version 
```

<span data-ttu-id="bbc92-212">Confirm that `batchai` is listed among the installed modules.</span><span class="sxs-lookup"><span data-stu-id="bbc92-212">Confirm that `batchai` is listed among the installed modules.</span></span> <span data-ttu-id="bbc92-213">If not, you may be using a different Command Line Interface (for example, one opened through Workbench).</span><span class="sxs-lookup"><span data-stu-id="bbc92-213">If not, you may be using a different Command Line Interface (for example, one opened through Workbench).</span></span>

<span data-ttu-id="bbc92-214">Next, check that provider registration has successfully completed.</span><span class="sxs-lookup"><span data-stu-id="bbc92-214">Next, check that provider registration has successfully completed.</span></span> <span data-ttu-id="bbc92-215">(Provider registration takes up to fifteen minutes and may still be ongoing if you recently completed the [Batch AI setup instructions](https://github.com/Azure/BatchAI/tree/master/recipes).) Confirm that both "Microsoft.Batch" and "Microsoft.BatchAI" appear with status "Registered" in the output of the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-215">(Provider registration takes up to fifteen minutes and may still be ongoing if you recently completed the [Batch AI setup instructions](https://github.com/Azure/BatchAI/tree/master/recipes).) Confirm that both "Microsoft.Batch" and "Microsoft.BatchAI" appear with status "Registered" in the output of the following command:</span></span>

```
az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table
```

<span data-ttu-id="bbc92-216">If not, run the following provider registration commands and wait ~15 minutes for registration to complete.</span><span class="sxs-lookup"><span data-stu-id="bbc92-216">If not, run the following provider registration commands and wait ~15 minutes for registration to complete.</span></span>
```
az provider register --namespace Microsoft.Batch
az provider register --namespace Microsoft.BatchAI
```

<span data-ttu-id="bbc92-217">Modify the following commands to replace the bracketed expressions with the values you used earlier during resource group and storage account creation.</span><span class="sxs-lookup"><span data-stu-id="bbc92-217">Modify the following commands to replace the bracketed expressions with the values you used earlier during resource group and storage account creation.</span></span> <span data-ttu-id="bbc92-218">Then, store the values as variables by executing the commands:</span><span class="sxs-lookup"><span data-stu-id="bbc92-218">Then, store the values as variables by executing the commands:</span></span>
```
az account set --subscription [subscription ID]
set AZURE_RESOURCE_GROUP=[resource group name]
set STORAGE_ACCOUNT_NAME=[storage account name]
set STORAGE_ACCOUNT_KEY=[storage account key]
az configure --defaults location=eastus
az configure --defaults group=%AZURE_RESOURCE_GROUP%
```

<span data-ttu-id="bbc92-219">Identify the folder containing your Azure Machine Learning project (for example, `C:\Users\<your username>\AzureML\aerialimageclassification`).</span><span class="sxs-lookup"><span data-stu-id="bbc92-219">Identify the folder containing your Azure Machine Learning project (for example, `C:\Users\<your username>\AzureML\aerialimageclassification`).</span></span> <span data-ttu-id="bbc92-220">Replace the bracketed value with the folder's filepath (with no trailing backslash) and execute the command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-220">Replace the bracketed value with the folder's filepath (with no trailing backslash) and execute the command:</span></span>
```
set PATH_TO_PROJECT=[The filepath of your project's root directory]
```
<span data-ttu-id="bbc92-221">You are now ready to create the Batch AI resources needed for this tutorial.</span><span class="sxs-lookup"><span data-stu-id="bbc92-221">You are now ready to create the Batch AI resources needed for this tutorial.</span></span>

#### <a name="prepare-the-batch-ai-network-file-server"></a><span data-ttu-id="bbc92-222">Prepare the Batch AI Network File Server</span><span class="sxs-lookup"><span data-stu-id="bbc92-222">Prepare the Batch AI Network File Server</span></span>

<span data-ttu-id="bbc92-223">Your Batch AI cluster accesses your training data on a Network File Server.</span><span class="sxs-lookup"><span data-stu-id="bbc92-223">Your Batch AI cluster accesses your training data on a Network File Server.</span></span> <span data-ttu-id="bbc92-224">Data access may be several-fold faster when accessing files from an NFS vs. an Azure File Share or Azure Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="bbc92-224">Data access may be several-fold faster when accessing files from an NFS vs. an Azure File Share or Azure Blob Storage.</span></span>

1. <span data-ttu-id="bbc92-225">Issue the following command to create a Network File Server:</span><span class="sxs-lookup"><span data-stu-id="bbc92-225">Issue the following command to create a Network File Server:</span></span>

    ```
    az batchai file-server create -n landuseclassifier -u demoUser -p "Dem0Pa$$w0rd" --vm-size Standard_DS2_V2 --disk-count 1 --disk-size 1000 --storage-sku Premium_LRS
    ```

1. <span data-ttu-id="bbc92-226">Check the provisioning status of your Network File Server using the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-226">Check the provisioning status of your Network File Server using the following command:</span></span>

    ```
    az batchai file-server list
    ```

    <span data-ttu-id="bbc92-227">When the "provisioningState" of the Network File Server named "landuseclassifier" is "succeeded", it is ready for use.</span><span class="sxs-lookup"><span data-stu-id="bbc92-227">When the "provisioningState" of the Network File Server named "landuseclassifier" is "succeeded", it is ready for use.</span></span> <span data-ttu-id="bbc92-228">Expect provisioning to take about five minutes.</span><span class="sxs-lookup"><span data-stu-id="bbc92-228">Expect provisioning to take about five minutes.</span></span>
1. <span data-ttu-id="bbc92-229">Find the IP address of your NFS in the output of the previous command (the "fileServerPublicIp" property under "mountSettings").</span><span class="sxs-lookup"><span data-stu-id="bbc92-229">Find the IP address of your NFS in the output of the previous command (the "fileServerPublicIp" property under "mountSettings").</span></span> <span data-ttu-id="bbc92-230">Write the IP address where indicated in the following command, then store the value by executing the command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-230">Write the IP address where indicated in the following command, then store the value by executing the command:</span></span>

    ```
    set AZURE_BATCH_AI_TRAINING_NFS_IP=[your NFS IP address]
    ```

1. <span data-ttu-id="bbc92-231">Using your favorite SSH tool (the following sample command uses [PuTTY](http://www.putty.org/)), execute this project's `prep_nfs.sh` script on the NFS to transfer the training and validation image sets there.</span><span class="sxs-lookup"><span data-stu-id="bbc92-231">Using your favorite SSH tool (the following sample command uses [PuTTY](http://www.putty.org/)), execute this project's `prep_nfs.sh` script on the NFS to transfer the training and validation image sets there.</span></span>

    ```
    putty -ssh demoUser@%AZURE_BATCH_AI_TRAINING_NFS_IP% -pw Dem0Pa$$w0rd -m %PATH_TO_PROJECT%\Code\01_Data_Acquisition_and_Understanding\02_Batch_AI_Training_Provisioning\prep_nfs.sh
    ```

    <span data-ttu-id="bbc92-232">Do not be concerned if the data download and extraction progress updates scroll across the shell window so quickly that they are illegible.</span><span class="sxs-lookup"><span data-stu-id="bbc92-232">Do not be concerned if the data download and extraction progress updates scroll across the shell window so quickly that they are illegible.</span></span>

<span data-ttu-id="bbc92-233">If desired, you can confirm that the data transfer has proceeded as planned by logging in to the file server with your favorite SSH tool and checking the `/mnt/data` directory contents.</span><span class="sxs-lookup"><span data-stu-id="bbc92-233">If desired, you can confirm that the data transfer has proceeded as planned by logging in to the file server with your favorite SSH tool and checking the `/mnt/data` directory contents.</span></span> <span data-ttu-id="bbc92-234">You should find two folders, training_images and validation_images, each containing with subfolders named according to land use categories.</span><span class="sxs-lookup"><span data-stu-id="bbc92-234">You should find two folders, training_images and validation_images, each containing with subfolders named according to land use categories.</span></span>  <span data-ttu-id="bbc92-235">The training and validation sets should contain ~44k and ~11k images, respectively.</span><span class="sxs-lookup"><span data-stu-id="bbc92-235">The training and validation sets should contain ~44k and ~11k images, respectively.</span></span>

#### <a name="create-a-batch-ai-cluster"></a><span data-ttu-id="bbc92-236">Create a Batch AI cluster</span><span class="sxs-lookup"><span data-stu-id="bbc92-236">Create a Batch AI cluster</span></span>

1. <span data-ttu-id="bbc92-237">Create the cluster by issuing the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-237">Create the cluster by issuing the following command:</span></span>

    ```
    az batchai cluster create -n landuseclassifier2 -u demoUser -p "Dem0Pa$$w0rd" --afs-name baitshare --nfs landuseclassifier --image UbuntuDSVM --vm-size STANDARD_NC6 --max 2 --min 2 --storage-account-name %STORAGE_ACCOUNT_NAME% 
    ```

1. <span data-ttu-id="bbc92-238">Use the following command to check your cluster's provisioning status:</span><span class="sxs-lookup"><span data-stu-id="bbc92-238">Use the following command to check your cluster's provisioning status:</span></span>

    ```
    az batchai cluster list
    ```

    <span data-ttu-id="bbc92-239">When the allocation state for the cluster named "landuseclassifier" changes from resizing to steady, it's possible to submit jobs.</span><span class="sxs-lookup"><span data-stu-id="bbc92-239">When the allocation state for the cluster named "landuseclassifier" changes from resizing to steady, it's possible to submit jobs.</span></span> <span data-ttu-id="bbc92-240">However, jobs do not start running until all VMs in the cluster have left the "preparing" state.</span><span class="sxs-lookup"><span data-stu-id="bbc92-240">However, jobs do not start running until all VMs in the cluster have left the "preparing" state.</span></span> <span data-ttu-id="bbc92-241">If the "errors" property of the cluster is not null, an error occurred during cluster creation and it should not be used.</span><span class="sxs-lookup"><span data-stu-id="bbc92-241">If the "errors" property of the cluster is not null, an error occurred during cluster creation and it should not be used.</span></span>

#### <a name="record-batch-ai-training-credentials"></a><span data-ttu-id="bbc92-242">Record Batch AI Training credentials</span><span class="sxs-lookup"><span data-stu-id="bbc92-242">Record Batch AI Training credentials</span></span>

<span data-ttu-id="bbc92-243">While you wait for cluster allocation to complete, open the `settings.cfg` file from the "Code" subdirectory of this project in the text editor of your choice.</span><span class="sxs-lookup"><span data-stu-id="bbc92-243">While you wait for cluster allocation to complete, open the `settings.cfg` file from the "Code" subdirectory of this project in the text editor of your choice.</span></span> <span data-ttu-id="bbc92-244">Update the following variables with your own credentials:</span><span class="sxs-lookup"><span data-stu-id="bbc92-244">Update the following variables with your own credentials:</span></span>
- <span data-ttu-id="bbc92-245">`bait_subscription_id` (your 36-character Azure subscription ID)</span><span class="sxs-lookup"><span data-stu-id="bbc92-245">`bait_subscription_id` (your 36-character Azure subscription ID)</span></span>
- <span data-ttu-id="bbc92-246">`bait_aad_client_id` (the Azure Active Directory application/client ID mentioned in the "Prerequisites" section)</span><span class="sxs-lookup"><span data-stu-id="bbc92-246">`bait_aad_client_id` (the Azure Active Directory application/client ID mentioned in the "Prerequisites" section)</span></span>
- <span data-ttu-id="bbc92-247">`bait_aad_secret` (the Azure Active Directory application secret mentioned in the "Prerequisites" section)</span><span class="sxs-lookup"><span data-stu-id="bbc92-247">`bait_aad_secret` (the Azure Active Directory application secret mentioned in the "Prerequisites" section)</span></span>
- <span data-ttu-id="bbc92-248">`bait_aad_tenant` (the Azure Active Directory tenant ID mentioned in the "Prerequisites" section)</span><span class="sxs-lookup"><span data-stu-id="bbc92-248">`bait_aad_tenant` (the Azure Active Directory tenant ID mentioned in the "Prerequisites" section)</span></span>
- <span data-ttu-id="bbc92-249">`bait_region` (as of this writing, the only option is: eastus)</span><span class="sxs-lookup"><span data-stu-id="bbc92-249">`bait_region` (as of this writing, the only option is: eastus)</span></span>
- <span data-ttu-id="bbc92-250">`bait_resource_group_name` (the resource group you chose earlier)</span><span class="sxs-lookup"><span data-stu-id="bbc92-250">`bait_resource_group_name` (the resource group you chose earlier)</span></span>

<span data-ttu-id="bbc92-251">Once you have assigned these values, the modified lines of your settings.cfg file should resemble the following text:</span><span class="sxs-lookup"><span data-stu-id="bbc92-251">Once you have assigned these values, the modified lines of your settings.cfg file should resemble the following text:</span></span>

```
[Settings]
    # Credentials for the Azure Storage account
    storage_account_name = yoursaname
    storage_account_key = kpIXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXQ==
    
    # Batch AI training credentials
    bait_subscription_id = 0caXXXXX-XXXX-XXXX-XXXX-XXXXXXXXX9c3
    bait_aad_client_id = d0aXXXXX-XXXX-XXXX-XXXX-XXXXXXXXX7f8
    bait_aad_secret = ygSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX6I=
    bait_aad_tenant = 72fXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXb47
    bait_region = eastus
    bait_resource_group_name = yourrgname
```

<span data-ttu-id="bbc92-252">Save and close `settings.cfg`.</span><span class="sxs-lookup"><span data-stu-id="bbc92-252">Save and close `settings.cfg`.</span></span>

<span data-ttu-id="bbc92-253">You may now close the CLI window where you executed the Batch AI resource creation commands.</span><span class="sxs-lookup"><span data-stu-id="bbc92-253">You may now close the CLI window where you executed the Batch AI resource creation commands.</span></span> <span data-ttu-id="bbc92-254">All further steps in this tutorial use a CLI launched from Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="bbc92-254">All further steps in this tutorial use a CLI launched from Azure Machine Learning Workbench.</span></span>

### <a name="prepare-the-azure-machine-learning-workbench-execution-environment"></a><span data-ttu-id="bbc92-255">Prepare the Azure Machine Learning Workbench execution environment</span><span class="sxs-lookup"><span data-stu-id="bbc92-255">Prepare the Azure Machine Learning Workbench execution environment</span></span>

#### <a name="register-the-hdinsight-cluster-as-an-azure-machine-learning-workbench-compute-target"></a><span data-ttu-id="bbc92-256">Register the HDInsight cluster as an Azure Machine Learning Workbench compute target</span><span class="sxs-lookup"><span data-stu-id="bbc92-256">Register the HDInsight cluster as an Azure Machine Learning Workbench compute target</span></span>

<span data-ttu-id="bbc92-257">Once HDInsight cluster creation is complete, register the cluster as a compute target for your project as follows:</span><span class="sxs-lookup"><span data-stu-id="bbc92-257">Once HDInsight cluster creation is complete, register the cluster as a compute target for your project as follows:</span></span>

1.  <span data-ttu-id="bbc92-258">Issue the following command from the Azure Machine Learning Command Line Interface:</span><span class="sxs-lookup"><span data-stu-id="bbc92-258">Issue the following command from the Azure Machine Learning Command Line Interface:</span></span>

    ```
    az ml computetarget attach cluster --name myhdi --address %HDINSIGHT_CLUSTER_NAME%-ssh.azurehdinsight.net --username sshuser --password %HDINSIGHT_CLUSTER_PASSWORD%
    ```

    <span data-ttu-id="bbc92-259">This command adds two files, `myhdi.runconfig` and `myhdi.compute`, to your project's `aml_config` folder.</span><span class="sxs-lookup"><span data-stu-id="bbc92-259">This command adds two files, `myhdi.runconfig` and `myhdi.compute`, to your project's `aml_config` folder.</span></span>

1. <span data-ttu-id="bbc92-260">Open the `myhdi.compute` file in your favorite text editor.</span><span class="sxs-lookup"><span data-stu-id="bbc92-260">Open the `myhdi.compute` file in your favorite text editor.</span></span> <span data-ttu-id="bbc92-261">Modify the `yarnDeployMode: cluster` line to read `yarnDeployMode: client`, then save and close the file.</span><span class="sxs-lookup"><span data-stu-id="bbc92-261">Modify the `yarnDeployMode: cluster` line to read `yarnDeployMode: client`, then save and close the file.</span></span>
1. <span data-ttu-id="bbc92-262">Run the following command to prepare your HDInsight environment for use:</span><span class="sxs-lookup"><span data-stu-id="bbc92-262">Run the following command to prepare your HDInsight environment for use:</span></span>
   ```
   az ml experiment prepare -c myhdi
   ```

#### <a name="install-local-dependencies"></a><span data-ttu-id="bbc92-263">Install local dependencies</span><span class="sxs-lookup"><span data-stu-id="bbc92-263">Install local dependencies</span></span>

<span data-ttu-id="bbc92-264">Open a CLI from Azure Machine Learning Workbench and install dependencies needed for local execution by issuing the following command:</span><span class="sxs-lookup"><span data-stu-id="bbc92-264">Open a CLI from Azure Machine Learning Workbench and install dependencies needed for local execution by issuing the following command:</span></span>

```
pip install matplotlib azure-storage==0.36.0 pillow scikit-learn azure-mgmt-batchai
```

## <a name="data-acquisition-and-understanding"></a><span data-ttu-id="bbc92-265">Data acquisition and understanding</span><span class="sxs-lookup"><span data-stu-id="bbc92-265">Data acquisition and understanding</span></span>

<span data-ttu-id="bbc92-266">This scenario uses publicly available aerial imagery data from the [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) at 1-meter resolution.</span><span class="sxs-lookup"><span data-stu-id="bbc92-266">This scenario uses publicly available aerial imagery data from the [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) at 1-meter resolution.</span></span> <span data-ttu-id="bbc92-267">We have generated sets of 224 pixel x 224 pixel PNG files cropped from the original NAIP data and sorted according to land use labels from the [National Land Cover Database](https://www.mrlc.gov/nlcd2011.php).</span><span class="sxs-lookup"><span data-stu-id="bbc92-267">We have generated sets of 224 pixel x 224 pixel PNG files cropped from the original NAIP data and sorted according to land use labels from the [National Land Cover Database](https://www.mrlc.gov/nlcd2011.php).</span></span> <span data-ttu-id="bbc92-268">A sample image with label "Developed" is shown at full size:</span><span class="sxs-lookup"><span data-stu-id="bbc92-268">A sample image with label "Developed" is shown at full size:</span></span>

![A sample tile of developed land](media/scenario-aerial-image-classification/sample-tile-developed.png)

<span data-ttu-id="bbc92-270">Class-balanced sets of ~44k and 11k images are used for model training and validation, respectively.</span><span class="sxs-lookup"><span data-stu-id="bbc92-270">Class-balanced sets of ~44k and 11k images are used for model training and validation, respectively.</span></span> <span data-ttu-id="bbc92-271">We demonstrate model deployment on a ~67k image set tiling Middlesex County, MA -- home of Microsoft's New England Research and Development (NERD) center.</span><span class="sxs-lookup"><span data-stu-id="bbc92-271">We demonstrate model deployment on a ~67k image set tiling Middlesex County, MA -- home of Microsoft's New England Research and Development (NERD) center.</span></span> <span data-ttu-id="bbc92-272">For more information on how these image sets were constructed, see the [Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).</span><span class="sxs-lookup"><span data-stu-id="bbc92-272">For more information on how these image sets were constructed, see the [Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).</span></span>

![Location of Middlesex County, Massachusetts](media/scenario-aerial-image-classification/middlesex-ma.png)

<span data-ttu-id="bbc92-274">During setup, the aerial image sets used in this example were transferred to the storage account that you created.</span><span class="sxs-lookup"><span data-stu-id="bbc92-274">During setup, the aerial image sets used in this example were transferred to the storage account that you created.</span></span> <span data-ttu-id="bbc92-275">The training, validation, and operationalization images are all 224 pixel x 224 pixel PNG files at a resolution of one pixel per square meter.</span><span class="sxs-lookup"><span data-stu-id="bbc92-275">The training, validation, and operationalization images are all 224 pixel x 224 pixel PNG files at a resolution of one pixel per square meter.</span></span> <span data-ttu-id="bbc92-276">The training and validation images have been organized into subfolders based on their land use label.</span><span class="sxs-lookup"><span data-stu-id="bbc92-276">The training and validation images have been organized into subfolders based on their land use label.</span></span> <span data-ttu-id="bbc92-277">(The land use labels of the operationalization images are unknown and in many cases ambiguous; some of these images contain multiple land types.) For more information on how these image sets were constructed, see the [Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).</span><span class="sxs-lookup"><span data-stu-id="bbc92-277">(The land use labels of the operationalization images are unknown and in many cases ambiguous; some of these images contain multiple land types.) For more information on how these image sets were constructed, see the [Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).</span></span>

<span data-ttu-id="bbc92-278">To view example images in your Azure storage account (optional):</span><span class="sxs-lookup"><span data-stu-id="bbc92-278">To view example images in your Azure storage account (optional):</span></span>
1. <span data-ttu-id="bbc92-279">Log in to the [Azure portal](https://portal.azure.com).</span><span class="sxs-lookup"><span data-stu-id="bbc92-279">Log in to the [Azure portal](https://portal.azure.com).</span></span>
1. <span data-ttu-id="bbc92-280">Search for the name of your storage account in the search bar along the top of your screen.</span><span class="sxs-lookup"><span data-stu-id="bbc92-280">Search for the name of your storage account in the search bar along the top of your screen.</span></span> <span data-ttu-id="bbc92-281">Click on your storage account in the search results.</span><span class="sxs-lookup"><span data-stu-id="bbc92-281">Click on your storage account in the search results.</span></span>
2. <span data-ttu-id="bbc92-282">Click on the "Blobs" link in the storage account's main pane.</span><span class="sxs-lookup"><span data-stu-id="bbc92-282">Click on the "Blobs" link in the storage account's main pane.</span></span>
3. <span data-ttu-id="bbc92-283">Click on the container named "train."</span><span class="sxs-lookup"><span data-stu-id="bbc92-283">Click on the container named "train."</span></span> <span data-ttu-id="bbc92-284">You should see a list of directories named according to land use.</span><span class="sxs-lookup"><span data-stu-id="bbc92-284">You should see a list of directories named according to land use.</span></span>
4. <span data-ttu-id="bbc92-285">Click on any of these directories to load the list of images it contains.</span><span class="sxs-lookup"><span data-stu-id="bbc92-285">Click on any of these directories to load the list of images it contains.</span></span>
5. <span data-ttu-id="bbc92-286">Click on any image and download it to view the image.</span><span class="sxs-lookup"><span data-stu-id="bbc92-286">Click on any image and download it to view the image.</span></span>
6. <span data-ttu-id="bbc92-287">If desired, click on the containers named "test" and "middlesexma2016" to view their contents as well.</span><span class="sxs-lookup"><span data-stu-id="bbc92-287">If desired, click on the containers named "test" and "middlesexma2016" to view their contents as well.</span></span>

## <a name="modeling"></a><span data-ttu-id="bbc92-288">Modeling</span><span class="sxs-lookup"><span data-stu-id="bbc92-288">Modeling</span></span>

### <a name="training-models-with-azure-batch-ai"></a><span data-ttu-id="bbc92-289">Training models with Azure Batch AI</span><span class="sxs-lookup"><span data-stu-id="bbc92-289">Training models with Azure Batch AI</span></span>

<span data-ttu-id="bbc92-290">The `run_batch_ai.py` script in the "Code\02_Modeling" subfolder of the Workbench project is used to issue a Batch AI Training job.</span><span class="sxs-lookup"><span data-stu-id="bbc92-290">The `run_batch_ai.py` script in the "Code\02_Modeling" subfolder of the Workbench project is used to issue a Batch AI Training job.</span></span> <span data-ttu-id="bbc92-291">This job retrains an image classifier DNN chosen by the user (AlexNet or ResNet 18 pretrained on ImageNet).</span><span class="sxs-lookup"><span data-stu-id="bbc92-291">This job retrains an image classifier DNN chosen by the user (AlexNet or ResNet 18 pretrained on ImageNet).</span></span> <span data-ttu-id="bbc92-292">The depth of retraining can also be specified: retraining just the final layer of the network may reduce overfitting when few training samples are available, while fine-tuning the whole network (or, for AlexNet, the fully connected layers) can lead to greater model performance when the training set is sufficiently large.</span><span class="sxs-lookup"><span data-stu-id="bbc92-292">The depth of retraining can also be specified: retraining just the final layer of the network may reduce overfitting when few training samples are available, while fine-tuning the whole network (or, for AlexNet, the fully connected layers) can lead to greater model performance when the training set is sufficiently large.</span></span>

<span data-ttu-id="bbc92-293">When the training job completes, this script saves the model (along with a file describing the mapping between the model's integer output and the string labels) and the predictions to blob storage.</span><span class="sxs-lookup"><span data-stu-id="bbc92-293">When the training job completes, this script saves the model (along with a file describing the mapping between the model's integer output and the string labels) and the predictions to blob storage.</span></span> <span data-ttu-id="bbc92-294">The BAIT job's log file is parsed to extract the timecourse of error rate improvement over the training epochs.</span><span class="sxs-lookup"><span data-stu-id="bbc92-294">The BAIT job's log file is parsed to extract the timecourse of error rate improvement over the training epochs.</span></span> <span data-ttu-id="bbc92-295">The error rate improvement timecourse is logged to AML Workbench's run history feature for later viewing.</span><span class="sxs-lookup"><span data-stu-id="bbc92-295">The error rate improvement timecourse is logged to AML Workbench's run history feature for later viewing.</span></span>

<span data-ttu-id="bbc92-296">Select a name for your trained model, a pretrained model type, and a retraining depth.</span><span class="sxs-lookup"><span data-stu-id="bbc92-296">Select a name for your trained model, a pretrained model type, and a retraining depth.</span></span> <span data-ttu-id="bbc92-297">Write your selections where indicated in the following command, then begin retraining by executing the command from an Azure ML Command Line Interface:</span><span class="sxs-lookup"><span data-stu-id="bbc92-297">Write your selections where indicated in the following command, then begin retraining by executing the command from an Azure ML Command Line Interface:</span></span>

```
az ml experiment submit -c local Code\02_Modeling\run_batch_ai.py --config_filename Code/settings.cfg --output_model_name [unique model name, alphanumeric characters only] --pretrained_model_type {alexnet,resnet18} --retraining_type {last_only,fully_connected,all} --num_epochs 10
```

<span data-ttu-id="bbc92-298">Expect the Azure Machine Learning run to take about half an hour to complete.</span><span class="sxs-lookup"><span data-stu-id="bbc92-298">Expect the Azure Machine Learning run to take about half an hour to complete.</span></span> <span data-ttu-id="bbc92-299">We recommend that you run a few similar commands (varying the output model name, the pretrained model type, and the retraining depth) so that you can compare the performance of models trained with different methods.</span><span class="sxs-lookup"><span data-stu-id="bbc92-299">We recommend that you run a few similar commands (varying the output model name, the pretrained model type, and the retraining depth) so that you can compare the performance of models trained with different methods.</span></span>

### <a name="training-models-with-mmlspark"></a><span data-ttu-id="bbc92-300">Training models with MMLSpark</span><span class="sxs-lookup"><span data-stu-id="bbc92-300">Training models with MMLSpark</span></span>

<span data-ttu-id="bbc92-301">The `run_mmlspark.py` script in the "Code\02_Modeling" subfolder of the Workbench project is used to train an [MMLSpark](https://github.com/Azure/mmlspark) model for image classification.</span><span class="sxs-lookup"><span data-stu-id="bbc92-301">The `run_mmlspark.py` script in the "Code\02_Modeling" subfolder of the Workbench project is used to train an [MMLSpark](https://github.com/Azure/mmlspark) model for image classification.</span></span> <span data-ttu-id="bbc92-302">The script first featurizes the training set images using an image classifier DNN pretrained on the ImageNet dataset (either AlexNet or an 18-layer ResNet).</span><span class="sxs-lookup"><span data-stu-id="bbc92-302">The script first featurizes the training set images using an image classifier DNN pretrained on the ImageNet dataset (either AlexNet or an 18-layer ResNet).</span></span> <span data-ttu-id="bbc92-303">The script then uses the featurized images to train an MMLSpark model (either a random forest or a logistic regression model) to classify the images.</span><span class="sxs-lookup"><span data-stu-id="bbc92-303">The script then uses the featurized images to train an MMLSpark model (either a random forest or a logistic regression model) to classify the images.</span></span> <span data-ttu-id="bbc92-304">The test image set is then featurized and scored with the trained model.</span><span class="sxs-lookup"><span data-stu-id="bbc92-304">The test image set is then featurized and scored with the trained model.</span></span> <span data-ttu-id="bbc92-305">The accuracy of the model's predictions on the test set is calculated and logged to Azure Machine Learning Workbench's run history feature.</span><span class="sxs-lookup"><span data-stu-id="bbc92-305">The accuracy of the model's predictions on the test set is calculated and logged to Azure Machine Learning Workbench's run history feature.</span></span> <span data-ttu-id="bbc92-306">Finally, the trained MMLSpark model and its predictions on the test set are saved to blob storage.</span><span class="sxs-lookup"><span data-stu-id="bbc92-306">Finally, the trained MMLSpark model and its predictions on the test set are saved to blob storage.</span></span>

<span data-ttu-id="bbc92-307">Select a unique output model name for your trained model, a pretrained model type, and an MMLSpark model type.</span><span class="sxs-lookup"><span data-stu-id="bbc92-307">Select a unique output model name for your trained model, a pretrained model type, and an MMLSpark model type.</span></span> <span data-ttu-id="bbc92-308">Write your selections where indicated in the following command template, then begin retraining by executing the command from an Azure ML Command Line Interface:</span><span class="sxs-lookup"><span data-stu-id="bbc92-308">Write your selections where indicated in the following command template, then begin retraining by executing the command from an Azure ML Command Line Interface:</span></span>

```
az ml experiment submit -c myhdi Code\02_Modeling\run_mmlspark.py --config_filename Code/settings.cfg --output_model_name [unique model name, alphanumeric characters only] --pretrained_model_type {alexnet,resnet18} --mmlspark_model_type {randomforest,logisticregression}
```

<span data-ttu-id="bbc92-309">An additional `--sample_frac` parameter can be used to train and test the model with a subset of available data.</span><span class="sxs-lookup"><span data-stu-id="bbc92-309">An additional `--sample_frac` parameter can be used to train and test the model with a subset of available data.</span></span> <span data-ttu-id="bbc92-310">Using a small sample fraction decreases runtime and memory requirements at the expense of trained model accuracy.</span><span class="sxs-lookup"><span data-stu-id="bbc92-310">Using a small sample fraction decreases runtime and memory requirements at the expense of trained model accuracy.</span></span> <span data-ttu-id="bbc92-311">(For example, a run with `--sample_frac 0.1` is expected to take roughly twenty minutes.) For more information on this and other parameters, run `python Code\02_Modeling\run_mmlspark.py -h`.</span><span class="sxs-lookup"><span data-stu-id="bbc92-311">(For example, a run with `--sample_frac 0.1` is expected to take roughly twenty minutes.) For more information on this and other parameters, run `python Code\02_Modeling\run_mmlspark.py -h`.</span></span>

<span data-ttu-id="bbc92-312">Users are encouraged to run this script several times with different input parameters.</span><span class="sxs-lookup"><span data-stu-id="bbc92-312">Users are encouraged to run this script several times with different input parameters.</span></span> <span data-ttu-id="bbc92-313">The performance of the resulting models can then be compared in Azure Machine Learning Workbench's Run History feature.</span><span class="sxs-lookup"><span data-stu-id="bbc92-313">The performance of the resulting models can then be compared in Azure Machine Learning Workbench's Run History feature.</span></span>

### <a name="comparing-model-performance-using-the-workbench-run-history-feature"></a><span data-ttu-id="bbc92-314">Comparing model performance using the Workbench Run History feature</span><span class="sxs-lookup"><span data-stu-id="bbc92-314">Comparing model performance using the Workbench Run History feature</span></span>

<span data-ttu-id="bbc92-315">After you have executed two or more training runs of either type, navigate to the Run History feature in Workbench by clicking the clock icon along the left-hand menu bar.</span><span class="sxs-lookup"><span data-stu-id="bbc92-315">After you have executed two or more training runs of either type, navigate to the Run History feature in Workbench by clicking the clock icon along the left-hand menu bar.</span></span> <span data-ttu-id="bbc92-316">Select `run_mmlspark.py` from the list of scripts at left.</span><span class="sxs-lookup"><span data-stu-id="bbc92-316">Select `run_mmlspark.py` from the list of scripts at left.</span></span> <span data-ttu-id="bbc92-317">A pane loads comparing the test set accuracy for all runs.</span><span class="sxs-lookup"><span data-stu-id="bbc92-317">A pane loads comparing the test set accuracy for all runs.</span></span> <span data-ttu-id="bbc92-318">To see more detail, scroll down and click on the name of an individual run.</span><span class="sxs-lookup"><span data-stu-id="bbc92-318">To see more detail, scroll down and click on the name of an individual run.</span></span>

## <a name="deployment"></a><span data-ttu-id="bbc92-319">Deployment</span><span class="sxs-lookup"><span data-stu-id="bbc92-319">Deployment</span></span>

<span data-ttu-id="bbc92-320">To apply one of your trained models to aerial images tiling Middlesex County, MA using remote execution on HDInsight, insert your desired model's name into the following command and execute it:</span><span class="sxs-lookup"><span data-stu-id="bbc92-320">To apply one of your trained models to aerial images tiling Middlesex County, MA using remote execution on HDInsight, insert your desired model's name into the following command and execute it:</span></span>

```
az ml experiment submit -c myhdi Code\03_Deployment\batch_score_spark.py --config_filename Code/settings.cfg --output_model_name [trained model name chosen earlier]
```

<span data-ttu-id="bbc92-321">An additional `--sample_frac` parameter can be used to operationalize the model with a subset of available data.</span><span class="sxs-lookup"><span data-stu-id="bbc92-321">An additional `--sample_frac` parameter can be used to operationalize the model with a subset of available data.</span></span> <span data-ttu-id="bbc92-322">Using a small sample fraction decreases runtime and memory requirements at the expense of prediction completeness.</span><span class="sxs-lookup"><span data-stu-id="bbc92-322">Using a small sample fraction decreases runtime and memory requirements at the expense of prediction completeness.</span></span> <span data-ttu-id="bbc92-323">For more information on this and other parameters, run `python Code\03_Deployment\batch_score_spark -h`.</span><span class="sxs-lookup"><span data-stu-id="bbc92-323">For more information on this and other parameters, run `python Code\03_Deployment\batch_score_spark -h`.</span></span>

<span data-ttu-id="bbc92-324">This script writes the model's predictions to your storage account.</span><span class="sxs-lookup"><span data-stu-id="bbc92-324">This script writes the model's predictions to your storage account.</span></span> <span data-ttu-id="bbc92-325">The predictions can be examined as described in the next section.</span><span class="sxs-lookup"><span data-stu-id="bbc92-325">The predictions can be examined as described in the next section.</span></span>

## <a name="visualization"></a><span data-ttu-id="bbc92-326">Visualization</span><span class="sxs-lookup"><span data-stu-id="bbc92-326">Visualization</span></span>

<span data-ttu-id="bbc92-327">The "Model prediction analysis" Jupyter notebook in the "Code\04_Result_Analysis" subfolder of the Workbench project visualizes a model's predictions.</span><span class="sxs-lookup"><span data-stu-id="bbc92-327">The "Model prediction analysis" Jupyter notebook in the "Code\04_Result_Analysis" subfolder of the Workbench project visualizes a model's predictions.</span></span> <span data-ttu-id="bbc92-328">Load and run the notebook as follows:</span><span class="sxs-lookup"><span data-stu-id="bbc92-328">Load and run the notebook as follows:</span></span>
1. <span data-ttu-id="bbc92-329">Open the project in Workbench and click on the folder ("Files") icon along the left-hand menu to load the directory listing.</span><span class="sxs-lookup"><span data-stu-id="bbc92-329">Open the project in Workbench and click on the folder ("Files") icon along the left-hand menu to load the directory listing.</span></span>
2. <span data-ttu-id="bbc92-330">Navigate to the "Code\04_Result_Analysis" subfolder and click on the notebook named "Model prediction analysis."</span><span class="sxs-lookup"><span data-stu-id="bbc92-330">Navigate to the "Code\04_Result_Analysis" subfolder and click on the notebook named "Model prediction analysis."</span></span> <span data-ttu-id="bbc92-331">A preview rendering of the notebook should be displayed.</span><span class="sxs-lookup"><span data-stu-id="bbc92-331">A preview rendering of the notebook should be displayed.</span></span>
3. <span data-ttu-id="bbc92-332">Click "Start Notebook Server" to load the notebook.</span><span class="sxs-lookup"><span data-stu-id="bbc92-332">Click "Start Notebook Server" to load the notebook.</span></span>
4. <span data-ttu-id="bbc92-333">In the first cell, enter the name of the model whose results you would like to analyze where indicated.</span><span class="sxs-lookup"><span data-stu-id="bbc92-333">In the first cell, enter the name of the model whose results you would like to analyze where indicated.</span></span>
5. <span data-ttu-id="bbc92-334">Click on "Cell -> Run All" to execute all cells in the notebook.</span><span class="sxs-lookup"><span data-stu-id="bbc92-334">Click on "Cell -> Run All" to execute all cells in the notebook.</span></span>
6. <span data-ttu-id="bbc92-335">Read along with the notebook to learn more about the analyses and visualizations it presents.</span><span class="sxs-lookup"><span data-stu-id="bbc92-335">Read along with the notebook to learn more about the analyses and visualizations it presents.</span></span>

## <a name="cleanup"></a><span data-ttu-id="bbc92-336">Cleanup</span><span class="sxs-lookup"><span data-stu-id="bbc92-336">Cleanup</span></span>
<span data-ttu-id="bbc92-337">When you have completed the example, we recommend that you delete all of the resources you have created by executing the following command from the Azure Command Line Interface:</span><span class="sxs-lookup"><span data-stu-id="bbc92-337">When you have completed the example, we recommend that you delete all of the resources you have created by executing the following command from the Azure Command Line Interface:</span></span>

  ```
  az group delete --name %AZURE_RESOURCE_GROUP%
  ```

## <a name="references"></a><span data-ttu-id="bbc92-338">References</span><span class="sxs-lookup"><span data-stu-id="bbc92-338">References</span></span>

- [<span data-ttu-id="bbc92-339">The Embarrassingly Parallel Image Classification repository</span><span class="sxs-lookup"><span data-stu-id="bbc92-339">The Embarrassingly Parallel Image Classification repository</span></span>](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification)
   - <span data-ttu-id="bbc92-340">Describes dataset construction from freely available imagery and labels</span><span class="sxs-lookup"><span data-stu-id="bbc92-340">Describes dataset construction from freely available imagery and labels</span></span>
- <span data-ttu-id="bbc92-341">[MMLSpark](https://github.com/Azure/mmlspark) GitHub repository</span><span class="sxs-lookup"><span data-stu-id="bbc92-341">[MMLSpark](https://github.com/Azure/mmlspark) GitHub repository</span></span>
   - <span data-ttu-id="bbc92-342">Contains additional examples of model training and evaluation with MMLSpark</span><span class="sxs-lookup"><span data-stu-id="bbc92-342">Contains additional examples of model training and evaluation with MMLSpark</span></span>

## <a name="conclusions"></a><span data-ttu-id="bbc92-343">Conclusions</span><span class="sxs-lookup"><span data-stu-id="bbc92-343">Conclusions</span></span>

<span data-ttu-id="bbc92-344">Azure Machine Learning Workbench helps data scientists easily deploy their code on remote compute targets.</span><span class="sxs-lookup"><span data-stu-id="bbc92-344">Azure Machine Learning Workbench helps data scientists easily deploy their code on remote compute targets.</span></span> <span data-ttu-id="bbc92-345">In this example, local MMLSpark training code was deployed for remote execution on an HDInsight cluster, and a local script launched a training job on an Azure Batch AI GPU cluster.</span><span class="sxs-lookup"><span data-stu-id="bbc92-345">In this example, local MMLSpark training code was deployed for remote execution on an HDInsight cluster, and a local script launched a training job on an Azure Batch AI GPU cluster.</span></span> <span data-ttu-id="bbc92-346">Azure Machine Learning Workbench's run history feature tracked the performance of multiple models and helped us identify the most accurate model.</span><span class="sxs-lookup"><span data-stu-id="bbc92-346">Azure Machine Learning Workbench's run history feature tracked the performance of multiple models and helped us identify the most accurate model.</span></span> <span data-ttu-id="bbc92-347">Workbench's Jupyter notebooks feature helped visualize our models' predictions in an interactive, graphical environment.</span><span class="sxs-lookup"><span data-stu-id="bbc92-347">Workbench's Jupyter notebooks feature helped visualize our models' predictions in an interactive, graphical environment.</span></span>

## <a name="next-steps"></a><span data-ttu-id="bbc92-348">Next steps</span><span class="sxs-lookup"><span data-stu-id="bbc92-348">Next steps</span></span>
<span data-ttu-id="bbc92-349">To dive deeper into this example:</span><span class="sxs-lookup"><span data-stu-id="bbc92-349">To dive deeper into this example:</span></span>
- <span data-ttu-id="bbc92-350">In Azure Machine Learning Workbench's Run History feature, click the gear symbols to select which graphs and metrics are displayed.</span><span class="sxs-lookup"><span data-stu-id="bbc92-350">In Azure Machine Learning Workbench's Run History feature, click the gear symbols to select which graphs and metrics are displayed.</span></span>
- <span data-ttu-id="bbc92-351">Examine the sample scripts for statements calling the `run_logger`.</span><span class="sxs-lookup"><span data-stu-id="bbc92-351">Examine the sample scripts for statements calling the `run_logger`.</span></span> <span data-ttu-id="bbc92-352">Check that you understand how each metric is being recorded.</span><span class="sxs-lookup"><span data-stu-id="bbc92-352">Check that you understand how each metric is being recorded.</span></span>
- <span data-ttu-id="bbc92-353">Examine the sample scripts for statements calling the `blob_service`.</span><span class="sxs-lookup"><span data-stu-id="bbc92-353">Examine the sample scripts for statements calling the `blob_service`.</span></span> <span data-ttu-id="bbc92-354">Check that you understand how trained models and predictions are stored and retrieved from the cloud.</span><span class="sxs-lookup"><span data-stu-id="bbc92-354">Check that you understand how trained models and predictions are stored and retrieved from the cloud.</span></span>
- <span data-ttu-id="bbc92-355">Explore the contents of the containers created in your blob storage account.</span><span class="sxs-lookup"><span data-stu-id="bbc92-355">Explore the contents of the containers created in your blob storage account.</span></span> <span data-ttu-id="bbc92-356">Ensure that you understand which script or command is responsible for creating each group of files.</span><span class="sxs-lookup"><span data-stu-id="bbc92-356">Ensure that you understand which script or command is responsible for creating each group of files.</span></span>
- <span data-ttu-id="bbc92-357">Modify the training script to train a different MMLSpark model type or to change the model hyperparameters.</span><span class="sxs-lookup"><span data-stu-id="bbc92-357">Modify the training script to train a different MMLSpark model type or to change the model hyperparameters.</span></span> <span data-ttu-id="bbc92-358">Use the run history feature to determine whether your changes increased or decreased the model's accuracy.</span><span class="sxs-lookup"><span data-stu-id="bbc92-358">Use the run history feature to determine whether your changes increased or decreased the model's accuracy.</span></span>
