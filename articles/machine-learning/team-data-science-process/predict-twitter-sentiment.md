---
title: Predict Twitter sentiment with word embeddings by using the Team Data Science Process in Azure | Microsoft Docs
description: The steps that are needed to execute your data-science projects.
services: machine-learning
documentationcenter: ''
author: deguhath
manager: cgronlun
editor: cgronlun
ms.assetid: ''
ms.service: machine-learning
ms.component: team-data-science-process
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/15/2017
ms.author: deguhath
ms.openlocfilehash: f47668cd706b78977418925d64eca583d7878cd3
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44866536"
---
# <a name="predict-twitter-sentiment-with-word-embeddings-by-using-the-team-data-science-process"></a><span data-ttu-id="e0d44-103">Predict Twitter sentiment with word embeddings by using the Team Data Science Process</span><span class="sxs-lookup"><span data-stu-id="e0d44-103">Predict Twitter sentiment with word embeddings by using the Team Data Science Process</span></span>

<span data-ttu-id="e0d44-104">This article shows you how to collaborate effectively by using the _Word2Vec_ word embedding algorithm and the _Sentiment-Specific Word Embedding (SSWE)_ algorithm to predict Twitter sentiment with [Azure Machine Learning](../service/index.yml).</span><span class="sxs-lookup"><span data-stu-id="e0d44-104">This article shows you how to collaborate effectively by using the _Word2Vec_ word embedding algorithm and the _Sentiment-Specific Word Embedding (SSWE)_ algorithm to predict Twitter sentiment with [Azure Machine Learning](../service/index.yml).</span></span> <span data-ttu-id="e0d44-105">For more information on predicting Twitter sentiment polarity, see the [MachineLearningSamples-TwitterSentimentPrediction repository](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction) on GitHub.</span><span class="sxs-lookup"><span data-stu-id="e0d44-105">For more information on predicting Twitter sentiment polarity, see the [MachineLearningSamples-TwitterSentimentPrediction repository](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction) on GitHub.</span></span> <span data-ttu-id="e0d44-106">The key to facilitating effective team collaboration on data-science projects is to standardize the structure and documentation of the projects with an established data-science lifecycle.</span><span class="sxs-lookup"><span data-stu-id="e0d44-106">The key to facilitating effective team collaboration on data-science projects is to standardize the structure and documentation of the projects with an established data-science lifecycle.</span></span> <span data-ttu-id="e0d44-107">The [Team Data Science Process (TDSP)](overview.md) provides this type of structured [lifecycle](lifecycle.md).</span><span class="sxs-lookup"><span data-stu-id="e0d44-107">The [Team Data Science Process (TDSP)](overview.md) provides this type of structured [lifecycle](lifecycle.md).</span></span> 

<span data-ttu-id="e0d44-108">Creating data-science projects with the _TDSP template_ provides the standardized framework for Azure Machine Learning projects.</span><span class="sxs-lookup"><span data-stu-id="e0d44-108">Creating data-science projects with the _TDSP template_ provides the standardized framework for Azure Machine Learning projects.</span></span> <span data-ttu-id="e0d44-109">Previously, the TDSP team released a [GitHub repository for the TDSP project structure and templates](https://github.com/Azure/Azure-TDSP-ProjectTemplate).</span><span class="sxs-lookup"><span data-stu-id="e0d44-109">Previously, the TDSP team released a [GitHub repository for the TDSP project structure and templates](https://github.com/Azure/Azure-TDSP-ProjectTemplate).</span></span> <span data-ttu-id="e0d44-110">Now Machine Learning projects that are instantiated with [TDSP templates for Azure Machine Learning](https://github.com/amlsamples/tdsp) are enabled.</span><span class="sxs-lookup"><span data-stu-id="e0d44-110">Now Machine Learning projects that are instantiated with [TDSP templates for Azure Machine Learning](https://github.com/amlsamples/tdsp) are enabled.</span></span> <span data-ttu-id="e0d44-111">For instructions, see how to use [TDSP structure projects with the TDSP template](../desktop-workbench/how-to-use-tdsp-in-azure-ml.md) in Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="e0d44-111">For instructions, see how to use [TDSP structure projects with the TDSP template](../desktop-workbench/how-to-use-tdsp-in-azure-ml.md) in Azure Machine Learning.</span></span> 


## <a name="twitter-sentiment-polarity-sample"></a><span data-ttu-id="e0d44-112">Twitter sentiment polarity sample</span><span class="sxs-lookup"><span data-stu-id="e0d44-112">Twitter sentiment polarity sample</span></span>

<span data-ttu-id="e0d44-113">This article uses a sample to show you how to instantiate and execute a Machine Learning project.</span><span class="sxs-lookup"><span data-stu-id="e0d44-113">This article uses a sample to show you how to instantiate and execute a Machine Learning project.</span></span> <span data-ttu-id="e0d44-114">The sample uses the TDSP structure and templates in Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="e0d44-114">The sample uses the TDSP structure and templates in Azure Machine Learning Workbench.</span></span> <span data-ttu-id="e0d44-115">The complete sample is provided in [this walkthrough](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/blob/master/docs/deliverable_docs/Step_By_Step_Tutorial.md).</span><span class="sxs-lookup"><span data-stu-id="e0d44-115">The complete sample is provided in [this walkthrough](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/blob/master/docs/deliverable_docs/Step_By_Step_Tutorial.md).</span></span> <span data-ttu-id="e0d44-116">The modeling task predicts sentiment polarity (positive or negative) by using the text from tweets.</span><span class="sxs-lookup"><span data-stu-id="e0d44-116">The modeling task predicts sentiment polarity (positive or negative) by using the text from tweets.</span></span> <span data-ttu-id="e0d44-117">This article outlines the data-modeling tasks that are described in the walkthrough.</span><span class="sxs-lookup"><span data-stu-id="e0d44-117">This article outlines the data-modeling tasks that are described in the walkthrough.</span></span> <span data-ttu-id="e0d44-118">The walkthrough covers the following tasks:</span><span class="sxs-lookup"><span data-stu-id="e0d44-118">The walkthrough covers the following tasks:</span></span>

- <span data-ttu-id="e0d44-119">Data exploration, training, and deployment of a machine learning model that address the prediction problem that's described in the use case overview.</span><span class="sxs-lookup"><span data-stu-id="e0d44-119">Data exploration, training, and deployment of a machine learning model that address the prediction problem that's described in the use case overview.</span></span> <span data-ttu-id="e0d44-120">[Twitter sentiment data](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip) is used for these tasks.</span><span class="sxs-lookup"><span data-stu-id="e0d44-120">[Twitter sentiment data](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip) is used for these tasks.</span></span>
- <span data-ttu-id="e0d44-121">Execution of the project by using the TDSP template from Azure Machine Learning for this project.</span><span class="sxs-lookup"><span data-stu-id="e0d44-121">Execution of the project by using the TDSP template from Azure Machine Learning for this project.</span></span> <span data-ttu-id="e0d44-122">For project execution and reporting, the TDSP lifecycle is used.</span><span class="sxs-lookup"><span data-stu-id="e0d44-122">For project execution and reporting, the TDSP lifecycle is used.</span></span>
- <span data-ttu-id="e0d44-123">Operationalization of the solution directly from Azure Machine Learning in Azure Container Service.</span><span class="sxs-lookup"><span data-stu-id="e0d44-123">Operationalization of the solution directly from Azure Machine Learning in Azure Container Service.</span></span>

<span data-ttu-id="e0d44-124">The project highlights the following features of Azure Machine Learning:</span><span class="sxs-lookup"><span data-stu-id="e0d44-124">The project highlights the following features of Azure Machine Learning:</span></span>

- <span data-ttu-id="e0d44-125">Instantiation and use of the TDSP structure.</span><span class="sxs-lookup"><span data-stu-id="e0d44-125">Instantiation and use of the TDSP structure.</span></span>
- <span data-ttu-id="e0d44-126">Execution of code in Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="e0d44-126">Execution of code in Azure Machine Learning Workbench.</span></span>
- <span data-ttu-id="e0d44-127">Easy operationalization in Container Service by using Docker and Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="e0d44-127">Easy operationalization in Container Service by using Docker and Kubernetes.</span></span>

## <a name="team-data-science-process"></a><span data-ttu-id="e0d44-128">Team Data Science Process</span><span class="sxs-lookup"><span data-stu-id="e0d44-128">Team Data Science Process</span></span>
<span data-ttu-id="e0d44-129">To execute this sample, you use the TDSP project structure and documentation templates in Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="e0d44-129">To execute this sample, you use the TDSP project structure and documentation templates in Azure Machine Learning Workbench.</span></span> <span data-ttu-id="e0d44-130">The sample implements the [TDSP lifecycle](https://github.com/Azure/Microsoft-TDSP/blob/master/Docs/lifecycle-detail.md), as shown in the following figure:</span><span class="sxs-lookup"><span data-stu-id="e0d44-130">The sample implements the [TDSP lifecycle](https://github.com/Azure/Microsoft-TDSP/blob/master/Docs/lifecycle-detail.md), as shown in the following figure:</span></span>

![TDSP lifecycle](./media/predict-twitter-sentiment/tdsp-lifecycle.PNG)

<span data-ttu-id="e0d44-132">The TDSP project is created in Azure Machine Learning Workbench based on [these instructions](https://github.com/amlsamples/tdsp/blob/master/docs/how-to-use-tdsp-in-azure-ml.md), as shown in the following figure:</span><span class="sxs-lookup"><span data-stu-id="e0d44-132">The TDSP project is created in Azure Machine Learning Workbench based on [these instructions](https://github.com/amlsamples/tdsp/blob/master/docs/how-to-use-tdsp-in-azure-ml.md), as shown in the following figure:</span></span>

![Create TDSP in Azure Machine Learning Workbench](./media/predict-twitter-sentiment/tdsp-instantiation.PNG) 


## <a name="data-acquisition-and-preparationhttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode01dataacquisitionandunderstanding"></a>[<span data-ttu-id="e0d44-134">Data acquisition and preparation</span><span class="sxs-lookup"><span data-stu-id="e0d44-134">Data acquisition and preparation</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/01_data_acquisition_and_understanding)
<span data-ttu-id="e0d44-135">The first step in this sample is to download the sentiment140 dataset and divide the data into training and testing datasets.</span><span class="sxs-lookup"><span data-stu-id="e0d44-135">The first step in this sample is to download the sentiment140 dataset and divide the data into training and testing datasets.</span></span> <span data-ttu-id="e0d44-136">The sentiment140 dataset contains the actual content of the tweet (with emoticons removed).</span><span class="sxs-lookup"><span data-stu-id="e0d44-136">The sentiment140 dataset contains the actual content of the tweet (with emoticons removed).</span></span> <span data-ttu-id="e0d44-137">The dataset also contains the polarity of each tweet (negative=0, positive=4) with the neutral tweets removed.</span><span class="sxs-lookup"><span data-stu-id="e0d44-137">The dataset also contains the polarity of each tweet (negative=0, positive=4) with the neutral tweets removed.</span></span> <span data-ttu-id="e0d44-138">After the data is divided, the training data has 1.3 million rows and the testing data has 320,000 rows.</span><span class="sxs-lookup"><span data-stu-id="e0d44-138">After the data is divided, the training data has 1.3 million rows and the testing data has 320,000 rows.</span></span>


## <a name="model-developmenthttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode02modeling"></a>[<span data-ttu-id="e0d44-139">Model development</span><span class="sxs-lookup"><span data-stu-id="e0d44-139">Model development</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/02_modeling)

<span data-ttu-id="e0d44-140">The next step in the sample is to develop a model for the data.</span><span class="sxs-lookup"><span data-stu-id="e0d44-140">The next step in the sample is to develop a model for the data.</span></span> <span data-ttu-id="e0d44-141">The modeling task is divided into three parts:</span><span class="sxs-lookup"><span data-stu-id="e0d44-141">The modeling task is divided into three parts:</span></span>

- <span data-ttu-id="e0d44-142">Feature engineering: Generate features for the model by using different word embedding algorithms.</span><span class="sxs-lookup"><span data-stu-id="e0d44-142">Feature engineering: Generate features for the model by using different word embedding algorithms.</span></span> 
- <span data-ttu-id="e0d44-143">Model creation: Train different models to predict the sentiment of the input text.</span><span class="sxs-lookup"><span data-stu-id="e0d44-143">Model creation: Train different models to predict the sentiment of the input text.</span></span> <span data-ttu-id="e0d44-144">Examples of these models include _Logistic Regression_ and _Gradient Boosting_.</span><span class="sxs-lookup"><span data-stu-id="e0d44-144">Examples of these models include _Logistic Regression_ and _Gradient Boosting_.</span></span>
- <span data-ttu-id="e0d44-145">Model evaluation: Evaluate the trained models over the testing data.</span><span class="sxs-lookup"><span data-stu-id="e0d44-145">Model evaluation: Evaluate the trained models over the testing data.</span></span>


### <a name="feature-engineeringhttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode02modeling01featureengineering"></a>[<span data-ttu-id="e0d44-146">Feature Engineering</span><span class="sxs-lookup"><span data-stu-id="e0d44-146">Feature Engineering</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/02_modeling/01_FeatureEngineering)

<span data-ttu-id="e0d44-147">The Word2Vec and SSWE algorithms are used to generate word embeddings.</span><span class="sxs-lookup"><span data-stu-id="e0d44-147">The Word2Vec and SSWE algorithms are used to generate word embeddings.</span></span> 


#### <a name="word2vec-algorithm"></a><span data-ttu-id="e0d44-148">Word2Vec algorithm</span><span class="sxs-lookup"><span data-stu-id="e0d44-148">Word2Vec algorithm</span></span>

<span data-ttu-id="e0d44-149">The Word2Vec algorithm is used in the Skip-Gram model.</span><span class="sxs-lookup"><span data-stu-id="e0d44-149">The Word2Vec algorithm is used in the Skip-Gram model.</span></span> <span data-ttu-id="e0d44-150">This model is explained in the paper by Tomas Mikolov, et al. "[Distributed Representations of Words and Phrases and their Compositionality. Advances in neural information processing systems.](https://arxiv.org/abs/1310.4546)"</span><span class="sxs-lookup"><span data-stu-id="e0d44-150">This model is explained in the paper by Tomas Mikolov, et al. "[Distributed Representations of Words and Phrases and their Compositionality. Advances in neural information processing systems.](https://arxiv.org/abs/1310.4546)"</span></span> <span data-ttu-id="e0d44-151">2013.</span><span class="sxs-lookup"><span data-stu-id="e0d44-151">2013.</span></span>

<span data-ttu-id="e0d44-152">The Skip-Gram model is a shallow neural network.</span><span class="sxs-lookup"><span data-stu-id="e0d44-152">The Skip-Gram model is a shallow neural network.</span></span> <span data-ttu-id="e0d44-153">The input is the target word that's encoded as a one-hot vector, which is used to predict nearby words.</span><span class="sxs-lookup"><span data-stu-id="e0d44-153">The input is the target word that's encoded as a one-hot vector, which is used to predict nearby words.</span></span> <span data-ttu-id="e0d44-154">If **V** is the size of the vocabulary, then the size of the output layer is __C\*V__ where C is the size of the context window.</span><span class="sxs-lookup"><span data-stu-id="e0d44-154">If **V** is the size of the vocabulary, then the size of the output layer is __C\*V__ where C is the size of the context window.</span></span> <span data-ttu-id="e0d44-155">The following figure shows an architecture that's based on the Skip-Gram model:</span><span class="sxs-lookup"><span data-stu-id="e0d44-155">The following figure shows an architecture that's based on the Skip-Gram model:</span></span>

![Skip-Gram model](./media/predict-twitter-sentiment/skip-gram-model.PNG)

<span data-ttu-id="e0d44-157">The detailed mechanics of the Word2Vec algorithm and Skip-Gram model are beyond the scope of this sample.</span><span class="sxs-lookup"><span data-stu-id="e0d44-157">The detailed mechanics of the Word2Vec algorithm and Skip-Gram model are beyond the scope of this sample.</span></span> <span data-ttu-id="e0d44-158">For more information, see the following references:</span><span class="sxs-lookup"><span data-stu-id="e0d44-158">For more information, see the following references:</span></span>

- [<span data-ttu-id="e0d44-159">02_A_Word2Vec.py code with referenced TensorFlow examples</span><span class="sxs-lookup"><span data-stu-id="e0d44-159">02_A_Word2Vec.py code with referenced TensorFlow examples</span></span>](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py) 
- [<span data-ttu-id="e0d44-160">Vector Representations of Words</span><span class="sxs-lookup"><span data-stu-id="e0d44-160">Vector Representations of Words</span></span>](https://www.tensorflow.org/tutorials/word2vec)
- [<span data-ttu-id="e0d44-161">How exactly does word2vec work?</span><span class="sxs-lookup"><span data-stu-id="e0d44-161">How exactly does word2vec work?</span></span>](http://www.1-4-5.net/~dmm/ml/how_does_word2vec_work.pdf)
- [<span data-ttu-id="e0d44-162">Notes on Noise Contrastive Estimation and Negative Sampling</span><span class="sxs-lookup"><span data-stu-id="e0d44-162">Notes on Noise Contrastive Estimation and Negative Sampling</span></span>](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf)




#### <a name="sentiment-specific-word-embedding-algorithm"></a><span data-ttu-id="e0d44-163">Sentiment-Specific Word Embedding algorithm</span><span class="sxs-lookup"><span data-stu-id="e0d44-163">Sentiment-Specific Word Embedding algorithm</span></span>
<span data-ttu-id="e0d44-164">The SSWE algorithm tries to overcome a weakness of the Word2Vec algorithm where words with similar contexts and opposite polarity can have similar word vectors.</span><span class="sxs-lookup"><span data-stu-id="e0d44-164">The SSWE algorithm tries to overcome a weakness of the Word2Vec algorithm where words with similar contexts and opposite polarity can have similar word vectors.</span></span> <span data-ttu-id="e0d44-165">The similarities can cause the Word2Vec algorithm to not perform accurately for tasks like sentiment analysis.</span><span class="sxs-lookup"><span data-stu-id="e0d44-165">The similarities can cause the Word2Vec algorithm to not perform accurately for tasks like sentiment analysis.</span></span> <span data-ttu-id="e0d44-166">The SSWE algorithm tries to handle this weakness by incorporating both the sentence polarity and the word's context into its loss function.</span><span class="sxs-lookup"><span data-stu-id="e0d44-166">The SSWE algorithm tries to handle this weakness by incorporating both the sentence polarity and the word's context into its loss function.</span></span>

<span data-ttu-id="e0d44-167">The sample uses a variant of the SSWE algorithm as follows:</span><span class="sxs-lookup"><span data-stu-id="e0d44-167">The sample uses a variant of the SSWE algorithm as follows:</span></span>

- <span data-ttu-id="e0d44-168">Both the original _ngram_ and the corrupted _ngram_ are used as inputs.</span><span class="sxs-lookup"><span data-stu-id="e0d44-168">Both the original _ngram_ and the corrupted _ngram_ are used as inputs.</span></span>
- <span data-ttu-id="e0d44-169">A ranking style hinge loss function is used for both the syntactic loss and the semantic loss.</span><span class="sxs-lookup"><span data-stu-id="e0d44-169">A ranking style hinge loss function is used for both the syntactic loss and the semantic loss.</span></span>
- <span data-ttu-id="e0d44-170">The ultimate loss function is the weighted combination of both the syntactic loss and the semantic loss.</span><span class="sxs-lookup"><span data-stu-id="e0d44-170">The ultimate loss function is the weighted combination of both the syntactic loss and the semantic loss.</span></span>
- <span data-ttu-id="e0d44-171">For simplicity, only the semantic cross entropy is used as the loss function.</span><span class="sxs-lookup"><span data-stu-id="e0d44-171">For simplicity, only the semantic cross entropy is used as the loss function.</span></span>

<span data-ttu-id="e0d44-172">The sample shows that even with the simpler loss function, the performance of the SSWE embedding is better than the Word2Vec embedding.</span><span class="sxs-lookup"><span data-stu-id="e0d44-172">The sample shows that even with the simpler loss function, the performance of the SSWE embedding is better than the Word2Vec embedding.</span></span> <span data-ttu-id="e0d44-173">The following figure shows the convolutional model that's used to generate sentiment-specific word embedding:</span><span class="sxs-lookup"><span data-stu-id="e0d44-173">The following figure shows the convolutional model that's used to generate sentiment-specific word embedding:</span></span>

![Neural network model inspired by SSWE](./media/predict-twitter-sentiment/embedding-model-2.PNG)

<span data-ttu-id="e0d44-175">After the training process is done, two embedding files in the tab-separated values (TSV) format are generated for the modeling stage.</span><span class="sxs-lookup"><span data-stu-id="e0d44-175">After the training process is done, two embedding files in the tab-separated values (TSV) format are generated for the modeling stage.</span></span>

<span data-ttu-id="e0d44-176">For more information about the SSWE algorithms, see the paper by Duyu Tang, et al. "[Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification](http://www.aclweb.org/anthology/P14-1146)."</span><span class="sxs-lookup"><span data-stu-id="e0d44-176">For more information about the SSWE algorithms, see the paper by Duyu Tang, et al. "[Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification](http://www.aclweb.org/anthology/P14-1146)."</span></span> <span data-ttu-id="e0d44-177">Association for Computational Linguistics (1).</span><span class="sxs-lookup"><span data-stu-id="e0d44-177">Association for Computational Linguistics (1).</span></span> <span data-ttu-id="e0d44-178">2014.</span><span class="sxs-lookup"><span data-stu-id="e0d44-178">2014.</span></span>


### <a name="model-creationhttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode02modeling02modelcreation"></a>[<span data-ttu-id="e0d44-179">Model creation</span><span class="sxs-lookup"><span data-stu-id="e0d44-179">Model creation</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/02_modeling/02_ModelCreation)
<span data-ttu-id="e0d44-180">After the word vectors are generated by using the SSWE or Word2Vec algorithm, the classification models are trained to predict the actual sentiment polarity.</span><span class="sxs-lookup"><span data-stu-id="e0d44-180">After the word vectors are generated by using the SSWE or Word2Vec algorithm, the classification models are trained to predict the actual sentiment polarity.</span></span> <span data-ttu-id="e0d44-181">Two types of features: Word2Vec and SSWE, are applied to two models: the Gradient Boosting model and the Logistic Regression model.</span><span class="sxs-lookup"><span data-stu-id="e0d44-181">Two types of features: Word2Vec and SSWE, are applied to two models: the Gradient Boosting model and the Logistic Regression model.</span></span> <span data-ttu-id="e0d44-182">As a result, four different models are trained.</span><span class="sxs-lookup"><span data-stu-id="e0d44-182">As a result, four different models are trained.</span></span>


### <a name="model-evaluationhttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode02modeling03modelevaluation"></a>[<span data-ttu-id="e0d44-183">Model evaluation</span><span class="sxs-lookup"><span data-stu-id="e0d44-183">Model evaluation</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/02_modeling/03_ModelEvaluation)
<span data-ttu-id="e0d44-184">After the models are trained, the models are used to test Twitter text data and evaluate each model's performance.</span><span class="sxs-lookup"><span data-stu-id="e0d44-184">After the models are trained, the models are used to test Twitter text data and evaluate each model's performance.</span></span> <span data-ttu-id="e0d44-185">The sample evaluates the following four models:</span><span class="sxs-lookup"><span data-stu-id="e0d44-185">The sample evaluates the following four models:</span></span>

- <span data-ttu-id="e0d44-186">Gradient Boosting over SSWE embedding.</span><span class="sxs-lookup"><span data-stu-id="e0d44-186">Gradient Boosting over SSWE embedding.</span></span>
- <span data-ttu-id="e0d44-187">Logistic Regression over SSWE embedding.</span><span class="sxs-lookup"><span data-stu-id="e0d44-187">Logistic Regression over SSWE embedding.</span></span>
- <span data-ttu-id="e0d44-188">Gradient Boosting over Word2Vec embedding.</span><span class="sxs-lookup"><span data-stu-id="e0d44-188">Gradient Boosting over Word2Vec embedding.</span></span>
- <span data-ttu-id="e0d44-189">Logistic Regression over Word2Vec embedding.</span><span class="sxs-lookup"><span data-stu-id="e0d44-189">Logistic Regression over Word2Vec embedding.</span></span>

<span data-ttu-id="e0d44-190">A comparison of the performance of the four models is shown in the following figure:</span><span class="sxs-lookup"><span data-stu-id="e0d44-190">A comparison of the performance of the four models is shown in the following figure:</span></span>

![Receiver operating characteristic (ROC) model comparison](./media/predict-twitter-sentiment/roc-model-comparison.PNG)

<span data-ttu-id="e0d44-192">The Gradient Boosting model with the SSWE feature gives the best performance when comparing the models by using the area under curve (AUC) metric.</span><span class="sxs-lookup"><span data-stu-id="e0d44-192">The Gradient Boosting model with the SSWE feature gives the best performance when comparing the models by using the area under curve (AUC) metric.</span></span>


## <a name="deploymenthttpsgithubcomazuremachinelearningsamples-twittersentimentpredictiontreemastercode03deployment"></a>[<span data-ttu-id="e0d44-193">Deployment</span><span class="sxs-lookup"><span data-stu-id="e0d44-193">Deployment</span></span>](https://github.com/Azure/MachineLearningSamples-TwitterSentimentPrediction/tree/master/code/03_deployment)

<span data-ttu-id="e0d44-194">The final step is deployment of the trained sentiment prediction model to a web service on a cluster in Azure Container Service.</span><span class="sxs-lookup"><span data-stu-id="e0d44-194">The final step is deployment of the trained sentiment prediction model to a web service on a cluster in Azure Container Service.</span></span> <span data-ttu-id="e0d44-195">The sample uses the Gradient Boosting model with the SSWE embedding algorithm as the trained model.</span><span class="sxs-lookup"><span data-stu-id="e0d44-195">The sample uses the Gradient Boosting model with the SSWE embedding algorithm as the trained model.</span></span> <span data-ttu-id="e0d44-196">The operationalization environment provisions Docker and Kubernetes in the cluster to manage the web-service deployment, as shown in the following figure:</span><span class="sxs-lookup"><span data-stu-id="e0d44-196">The operationalization environment provisions Docker and Kubernetes in the cluster to manage the web-service deployment, as shown in the following figure:</span></span> 

![Kubernetes dashboard](./media/predict-twitter-sentiment/kubernetes-dashboard.PNG)

<span data-ttu-id="e0d44-198">For more information on the operationalization process, see [Deploying an Azure Machine Learning model as a web service](../desktop-workbench/model-management-service-deploy.md).</span><span class="sxs-lookup"><span data-stu-id="e0d44-198">For more information on the operationalization process, see [Deploying an Azure Machine Learning model as a web service](../desktop-workbench/model-management-service-deploy.md).</span></span>

## <a name="conclusion"></a><span data-ttu-id="e0d44-199">Conclusion</span><span class="sxs-lookup"><span data-stu-id="e0d44-199">Conclusion</span></span>

<span data-ttu-id="e0d44-200">In this article, you learned how to train a word-embedding model by using the Word2Vec and Sentiment-Specific Word Embedding algorithms.</span><span class="sxs-lookup"><span data-stu-id="e0d44-200">In this article, you learned how to train a word-embedding model by using the Word2Vec and Sentiment-Specific Word Embedding algorithms.</span></span> <span data-ttu-id="e0d44-201">The extracted embeddings were used as features to train several models to predict sentiment scores for Twitter text data.</span><span class="sxs-lookup"><span data-stu-id="e0d44-201">The extracted embeddings were used as features to train several models to predict sentiment scores for Twitter text data.</span></span> <span data-ttu-id="e0d44-202">The SSWE feature used with the Gradient Boosting model gave the best performance.</span><span class="sxs-lookup"><span data-stu-id="e0d44-202">The SSWE feature used with the Gradient Boosting model gave the best performance.</span></span> <span data-ttu-id="e0d44-203">The model was then deployed as a real-time web service in Container Service by using Azure Machine Learning Workbench.</span><span class="sxs-lookup"><span data-stu-id="e0d44-203">The model was then deployed as a real-time web service in Container Service by using Azure Machine Learning Workbench.</span></span>


## <a name="references"></a><span data-ttu-id="e0d44-204">References</span><span class="sxs-lookup"><span data-stu-id="e0d44-204">References</span></span>

* [<span data-ttu-id="e0d44-205">Team Data Science Process</span><span class="sxs-lookup"><span data-stu-id="e0d44-205">Team Data Science Process</span></span>](https://docs.microsoft.com/azure/machine-learning/team-data-science-process/overview) 
* [<span data-ttu-id="e0d44-206">How to use Team Data Science Process (TDSP) in Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="e0d44-206">How to use Team Data Science Process (TDSP) in Azure Machine Learning</span></span>](https://aka.ms/how-to-use-tdsp-in-aml)
* [<span data-ttu-id="e0d44-207">TDSP project templates for Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="e0d44-207">TDSP project templates for Azure Machine Learning</span></span>](https://aka.ms/tdspamlgithubrepo)
* [<span data-ttu-id="e0d44-208">Azure Machine Learning Workbench</span><span class="sxs-lookup"><span data-stu-id="e0d44-208">Azure Machine Learning Workbench</span></span>](../service/index.yml)
* [<span data-ttu-id="e0d44-209">US income data-set from UCI ML repository</span><span class="sxs-lookup"><span data-stu-id="e0d44-209">US income data-set from UCI ML repository</span></span>](https://archive.ics.uci.edu/ml/datasets/adult)
* [<span data-ttu-id="e0d44-210">Biomedical entity recognition by using TDSP templates</span><span class="sxs-lookup"><span data-stu-id="e0d44-210">Biomedical entity recognition by using TDSP templates</span></span>](../desktop-workbench/scenario-tdsp-biomedical-recognition.md)
* [<span data-ttu-id="e0d44-211">Mikolov, Tomas, et al. "Distributed Representations of Words and Phrases and their Compositionality. Advances in neural information processing systems." 2013.</span><span class="sxs-lookup"><span data-stu-id="e0d44-211">Mikolov, Tomas, et al. "Distributed Representations of Words and Phrases and their Compositionality. Advances in neural information processing systems." 2013.</span></span>](https://arxiv.org/abs/1310.4546)
* [<span data-ttu-id="e0d44-212">Tang, Duyu, et al. "Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification." ACL (1). 2014.</span><span class="sxs-lookup"><span data-stu-id="e0d44-212">Tang, Duyu, et al. "Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification." ACL (1). 2014.</span></span>](http://www.aclweb.org/anthology/P14-1146)
