---
title: Better accuracy of computer vision & classification models in Azure Machine Learning
description: Learn how to improve the accuracy of your computer vision image classification, object detection, and image similarity models using the Azure Machine Learning Package for Computer Vision.
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.reviewer: jmartens
ms.author: netahw
author: nhaiby
ms.date: 04/23/2018
ms.openlocfilehash: f8b62a1a1c7ccc6e84d2a777ac4fa90e2ede54dc
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44857219"
---
# <a name="improve-the-accuracy-of-computer-vision-models"></a><span data-ttu-id="f8f35-103">Improve the accuracy of computer vision models</span><span class="sxs-lookup"><span data-stu-id="f8f35-103">Improve the accuracy of computer vision models</span></span>

<span data-ttu-id="f8f35-104">With the **Azure Machine Learning Package for Computer Vision**, you can build and deploy image classification, object detection, and image similarity models.</span><span class="sxs-lookup"><span data-stu-id="f8f35-104">With the **Azure Machine Learning Package for Computer Vision**, you can build and deploy image classification, object detection, and image similarity models.</span></span> <span data-ttu-id="f8f35-105">Learn more about this package and how to install it.</span><span class="sxs-lookup"><span data-stu-id="f8f35-105">Learn more about this package and how to install it.</span></span>

<span data-ttu-id="f8f35-106">In this article, you learn how to fine-tune these models to increase their accuracy.</span><span class="sxs-lookup"><span data-stu-id="f8f35-106">In this article, you learn how to fine-tune these models to increase their accuracy.</span></span> 

## <a name="accuracy-of-image-classification-models"></a><span data-ttu-id="f8f35-107">Accuracy of image classification models</span><span class="sxs-lookup"><span data-stu-id="f8f35-107">Accuracy of image classification models</span></span>

<span data-ttu-id="f8f35-108">The Computer Vision Package is shown to give good results for a wide variety of datasets.</span><span class="sxs-lookup"><span data-stu-id="f8f35-108">The Computer Vision Package is shown to give good results for a wide variety of datasets.</span></span> <span data-ttu-id="f8f35-109">However, as is true for most machine learning projects, getting the best possible results for a new dataset requires careful parameter tuning, as well as evaluating different design decisions.</span><span class="sxs-lookup"><span data-stu-id="f8f35-109">However, as is true for most machine learning projects, getting the best possible results for a new dataset requires careful parameter tuning, as well as evaluating different design decisions.</span></span> <span data-ttu-id="f8f35-110">The following sections provide guidance on how to improve accuracy on a given dataset, that is, what parameters are most promising to optimize first, what values for these parameters one should try, and what pitfalls to avoid.</span><span class="sxs-lookup"><span data-stu-id="f8f35-110">The following sections provide guidance on how to improve accuracy on a given dataset, that is, what parameters are most promising to optimize first, what values for these parameters one should try, and what pitfalls to avoid.</span></span>

<span data-ttu-id="f8f35-111">Generally speaking, training Deep Learning models comes with a trade-off between training time versus model accuracy.</span><span class="sxs-lookup"><span data-stu-id="f8f35-111">Generally speaking, training Deep Learning models comes with a trade-off between training time versus model accuracy.</span></span> <span data-ttu-id="f8f35-112">The Computer Vision Package has pre-set default parameters (see first row in the table below) which focus on fast training speed while typically producing high accuracy models.</span><span class="sxs-lookup"><span data-stu-id="f8f35-112">The Computer Vision Package has pre-set default parameters (see first row in the table below) which focus on fast training speed while typically producing high accuracy models.</span></span> <span data-ttu-id="f8f35-113">This accuracy can often be improved further using, for example,  higher image resolution or deeper models, however at the cost of increasing training time by a factor of 10x or more.</span><span class="sxs-lookup"><span data-stu-id="f8f35-113">This accuracy can often be improved further using, for example,  higher image resolution or deeper models, however at the cost of increasing training time by a factor of 10x or more.</span></span>

<span data-ttu-id="f8f35-114">It is recommended that you first work with the default parameters, train a model, inspect the results, correct ground truth annotations as needed, and only then try parameters that slow down training time (see table below suggested parameter values).</span><span class="sxs-lookup"><span data-stu-id="f8f35-114">It is recommended that you first work with the default parameters, train a model, inspect the results, correct ground truth annotations as needed, and only then try parameters that slow down training time (see table below suggested parameter values).</span></span> <span data-ttu-id="f8f35-115">An understanding of these parameters while technically not necessary is however recommended.</span><span class="sxs-lookup"><span data-stu-id="f8f35-115">An understanding of these parameters while technically not necessary is however recommended.</span></span>


### <a name="best-practices-and-tips"></a><span data-ttu-id="f8f35-116">Best practices and tips</span><span class="sxs-lookup"><span data-stu-id="f8f35-116">Best practices and tips</span></span>

* <span data-ttu-id="f8f35-117">Data quality: the training and test sets should be of high quality.</span><span class="sxs-lookup"><span data-stu-id="f8f35-117">Data quality: the training and test sets should be of high quality.</span></span> <span data-ttu-id="f8f35-118">That is, the images are annotated correctly, ambiguous images removed (for example where it is unclear to a human eye if the image shows a tennis ball or a lemon), and the attributes are mutually exclusive (that is, each image belongs to exactly one attribute).</span><span class="sxs-lookup"><span data-stu-id="f8f35-118">That is, the images are annotated correctly, ambiguous images removed (for example where it is unclear to a human eye if the image shows a tennis ball or a lemon), and the attributes are mutually exclusive (that is, each image belongs to exactly one attribute).</span></span>

* <span data-ttu-id="f8f35-119">Before refining the DNN, an SVM classifier should be trained using a pre-trained and fixed DNN as featurizer.</span><span class="sxs-lookup"><span data-stu-id="f8f35-119">Before refining the DNN, an SVM classifier should be trained using a pre-trained and fixed DNN as featurizer.</span></span> <span data-ttu-id="f8f35-120">This is supported in Computer Vision Package and does not require long to train since the DNN itself is not modified.</span><span class="sxs-lookup"><span data-stu-id="f8f35-120">This is supported in Computer Vision Package and does not require long to train since the DNN itself is not modified.</span></span> <span data-ttu-id="f8f35-121">Even this simple approach often achieves good accuracies and hence represents a strong baseline.</span><span class="sxs-lookup"><span data-stu-id="f8f35-121">Even this simple approach often achieves good accuracies and hence represents a strong baseline.</span></span> <span data-ttu-id="f8f35-122">The next step is then to refine the DNN that should give better accuracy.</span><span class="sxs-lookup"><span data-stu-id="f8f35-122">The next step is then to refine the DNN that should give better accuracy.</span></span>

* <span data-ttu-id="f8f35-123">If the object-of-interest is small in the image, then Image classification approaches are known to not work well.</span><span class="sxs-lookup"><span data-stu-id="f8f35-123">If the object-of-interest is small in the image, then Image classification approaches are known to not work well.</span></span> <span data-ttu-id="f8f35-124">In such cases, consider using an object detection approach such as Computer Vision Package's Faster R-CNN based on Tensorflow.</span><span class="sxs-lookup"><span data-stu-id="f8f35-124">In such cases, consider using an object detection approach such as Computer Vision Package's Faster R-CNN based on Tensorflow.</span></span>

* <span data-ttu-id="f8f35-125">The more training data the better.</span><span class="sxs-lookup"><span data-stu-id="f8f35-125">The more training data the better.</span></span> <span data-ttu-id="f8f35-126">As a rule-of-thumb, one should have at least 100 examples for each class, that is, 100 images for "dog", 100 images for "cat", etc. Training a model with fewer images is possible but might not produce good results.</span><span class="sxs-lookup"><span data-stu-id="f8f35-126">As a rule-of-thumb, one should have at least 100 examples for each class, that is, 100 images for "dog", 100 images for "cat", etc. Training a model with fewer images is possible but might not produce good results.</span></span>

* <span data-ttu-id="f8f35-127">The training images need to reside locally on the machine with the GPU, and be on an SSD drive (not an HDD).</span><span class="sxs-lookup"><span data-stu-id="f8f35-127">The training images need to reside locally on the machine with the GPU, and be on an SSD drive (not an HDD).</span></span> <span data-ttu-id="f8f35-128">Otherwise, latency from image reading can drastically reduce training speed (by even a factor of 100x).</span><span class="sxs-lookup"><span data-stu-id="f8f35-128">Otherwise, latency from image reading can drastically reduce training speed (by even a factor of 100x).</span></span>


### <a name="parameters-to-optimize"></a><span data-ttu-id="f8f35-129">Parameters to optimize</span><span class="sxs-lookup"><span data-stu-id="f8f35-129">Parameters to optimize</span></span>

<span data-ttu-id="f8f35-130">Finding optimal values for these parameters is important and can often improve accuracy significantly:</span><span class="sxs-lookup"><span data-stu-id="f8f35-130">Finding optimal values for these parameters is important and can often improve accuracy significantly:</span></span>
* <span data-ttu-id="f8f35-131">Learning rate (`lr_per_mb`): The arguably most important parameter to get right.</span><span class="sxs-lookup"><span data-stu-id="f8f35-131">Learning rate (`lr_per_mb`): The arguably most important parameter to get right.</span></span> <span data-ttu-id="f8f35-132">If the accuracy on the training set after DNN refinement is above ~5%, then most likely the learning rate is either too high, or the number of training epochs too low.</span><span class="sxs-lookup"><span data-stu-id="f8f35-132">If the accuracy on the training set after DNN refinement is above ~5%, then most likely the learning rate is either too high, or the number of training epochs too low.</span></span> <span data-ttu-id="f8f35-133">Especially with small datasets, the DNN tends to over-fit on the training data, however in practice this will lead to good models on the test set.</span><span class="sxs-lookup"><span data-stu-id="f8f35-133">Especially with small datasets, the DNN tends to over-fit on the training data, however in practice this will lead to good models on the test set.</span></span> <span data-ttu-id="f8f35-134">We typically use 15 epochs where the initial learning rate is reduced twice; training using more epochs can in some cases improve performance.</span><span class="sxs-lookup"><span data-stu-id="f8f35-134">We typically use 15 epochs where the initial learning rate is reduced twice; training using more epochs can in some cases improve performance.</span></span>

* <span data-ttu-id="f8f35-135">Input resolution (`image_dims`): The default image resolution is 224x224 pixels.</span><span class="sxs-lookup"><span data-stu-id="f8f35-135">Input resolution (`image_dims`): The default image resolution is 224x224 pixels.</span></span> <span data-ttu-id="f8f35-136">Using higher image resolution of, for example, 500x500 pixels or 1000x1000 pixels can significantly improve accuracy but slows down DNN refinement.</span><span class="sxs-lookup"><span data-stu-id="f8f35-136">Using higher image resolution of, for example, 500x500 pixels or 1000x1000 pixels can significantly improve accuracy but slows down DNN refinement.</span></span> <span data-ttu-id="f8f35-137">The Computer Vision Package expects the input resolution to be a tuple of (color-channels, image-width, image-height), for example (3, 224, 224), where the number of color channels has to be set to 3 (the Red-Green-Blue bands).</span><span class="sxs-lookup"><span data-stu-id="f8f35-137">The Computer Vision Package expects the input resolution to be a tuple of (color-channels, image-width, image-height), for example (3, 224, 224), where the number of color channels has to be set to 3 (the Red-Green-Blue bands).</span></span>

* <span data-ttu-id="f8f35-138">Model architecture(`base_model_name`): Try using deeper DNNs such as ResNet-34 or ResNet-50 instead of the default ResNet-18 model.</span><span class="sxs-lookup"><span data-stu-id="f8f35-138">Model architecture(`base_model_name`): Try using deeper DNNs such as ResNet-34 or ResNet-50 instead of the default ResNet-18 model.</span></span> <span data-ttu-id="f8f35-139">The Resnet-50 model is not only deeper, but its output of the penultimate layer is of size 2048 floats (vs. 512 floats of the ResNet-18 and ResNet-34 models).</span><span class="sxs-lookup"><span data-stu-id="f8f35-139">The Resnet-50 model is not only deeper, but its output of the penultimate layer is of size 2048 floats (vs. 512 floats of the ResNet-18 and ResNet-34 models).</span></span> <span data-ttu-id="f8f35-140">This increased dimensionality can be especially beneficial when keeping the DNN fixed and instead training an SVM classifier.</span><span class="sxs-lookup"><span data-stu-id="f8f35-140">This increased dimensionality can be especially beneficial when keeping the DNN fixed and instead training an SVM classifier.</span></span>

* <span data-ttu-id="f8f35-141">Minibatch size (`mb_size`): High minibatch sizes will lead to faster training time however at the expense of an increased DNN memory consumption.</span><span class="sxs-lookup"><span data-stu-id="f8f35-141">Minibatch size (`mb_size`): High minibatch sizes will lead to faster training time however at the expense of an increased DNN memory consumption.</span></span> <span data-ttu-id="f8f35-142">Hence, when selecting deeper models (for example, ResNet-50 versus ResNet-18) and/or higher image resolution (500\*500 pixels versus 224\*224 pixels), one typically has to reduce the minibatch size to avoid out-of-memory errors.</span><span class="sxs-lookup"><span data-stu-id="f8f35-142">Hence, when selecting deeper models (for example, ResNet-50 versus ResNet-18) and/or higher image resolution (500\*500 pixels versus 224\*224 pixels), one typically has to reduce the minibatch size to avoid out-of-memory errors.</span></span> <span data-ttu-id="f8f35-143">When changing the minibatch size, often also the learning rate needs to be adjusted as can be seen in the table below.</span><span class="sxs-lookup"><span data-stu-id="f8f35-143">When changing the minibatch size, often also the learning rate needs to be adjusted as can be seen in the table below.</span></span>
* <span data-ttu-id="f8f35-144">Drop-out rate (`dropout_rate`) and L2-regularizer (`l2_reg_weight`): DNN over-fitting can be reduced by using a dropout rate of 0.5 (default is 0.5 in Computer Vision Package) or more, and by increasing the regularizer weight (default is 0.0005 in Computer Vision Package).</span><span class="sxs-lookup"><span data-stu-id="f8f35-144">Drop-out rate (`dropout_rate`) and L2-regularizer (`l2_reg_weight`): DNN over-fitting can be reduced by using a dropout rate of 0.5 (default is 0.5 in Computer Vision Package) or more, and by increasing the regularizer weight (default is 0.0005 in Computer Vision Package).</span></span> <span data-ttu-id="f8f35-145">Note though that especially with small datasets DNN over-fitting is hard and often impossible to avoid.</span><span class="sxs-lookup"><span data-stu-id="f8f35-145">Note though that especially with small datasets DNN over-fitting is hard and often impossible to avoid.</span></span>


### <a name="parameter-definitions"></a><span data-ttu-id="f8f35-146">Parameter definitions</span><span class="sxs-lookup"><span data-stu-id="f8f35-146">Parameter definitions</span></span>

- <span data-ttu-id="f8f35-147">**Learning rate**: step size used during gradient descent learning.</span><span class="sxs-lookup"><span data-stu-id="f8f35-147">**Learning rate**: step size used during gradient descent learning.</span></span> <span data-ttu-id="f8f35-148">If set too low then the model will take many epochs to train, if set too high then the model will not converge to a good solution.</span><span class="sxs-lookup"><span data-stu-id="f8f35-148">If set too low then the model will take many epochs to train, if set too high then the model will not converge to a good solution.</span></span> <span data-ttu-id="f8f35-149">Typically a schedule is used where the learning rate is reduced after a certain number of epochs.</span><span class="sxs-lookup"><span data-stu-id="f8f35-149">Typically a schedule is used where the learning rate is reduced after a certain number of epochs.</span></span> <span data-ttu-id="f8f35-150">E.For example the learning rate schedule `[0.05]*7 + [0.005]*7 + [0.0005]` corresponds to using an initial learning rate of 0.05 for the first seven epochs, followed by a 10x reduced learning rate of 0.005 for another seven epochs, and finally fine-tuning the model for a single epoch with a 100x reduced learning rate of 0.0005.</span><span class="sxs-lookup"><span data-stu-id="f8f35-150">E.For example the learning rate schedule `[0.05]*7 + [0.005]*7 + [0.0005]` corresponds to using an initial learning rate of 0.05 for the first seven epochs, followed by a 10x reduced learning rate of 0.005 for another seven epochs, and finally fine-tuning the model for a single epoch with a 100x reduced learning rate of 0.0005.</span></span>

- <span data-ttu-id="f8f35-151">**Minibatch size**: GPUs can process multiple images in parallel to speed up computation.</span><span class="sxs-lookup"><span data-stu-id="f8f35-151">**Minibatch size**: GPUs can process multiple images in parallel to speed up computation.</span></span> <span data-ttu-id="f8f35-152">These parallel processed images are also referred as a minibatch.</span><span class="sxs-lookup"><span data-stu-id="f8f35-152">These parallel processed images are also referred as a minibatch.</span></span> <span data-ttu-id="f8f35-153">The higher the minibatch size the faster training will be, however at the expense of an increased DNN memory consumption.</span><span class="sxs-lookup"><span data-stu-id="f8f35-153">The higher the minibatch size the faster training will be, however at the expense of an increased DNN memory consumption.</span></span>

### <a name="recommended-parameter-values"></a><span data-ttu-id="f8f35-154">Recommended parameter values</span><span class="sxs-lookup"><span data-stu-id="f8f35-154">Recommended parameter values</span></span>

<span data-ttu-id="f8f35-155">The table below provides different parameter sets that were shown to produce high accuracy models on a wide variety of image classification tasks.</span><span class="sxs-lookup"><span data-stu-id="f8f35-155">The table below provides different parameter sets that were shown to produce high accuracy models on a wide variety of image classification tasks.</span></span> <span data-ttu-id="f8f35-156">The optimal parameters depend on the specific dataset and on the exact GPU used, hence the table should be seen as a guideline only.</span><span class="sxs-lookup"><span data-stu-id="f8f35-156">The optimal parameters depend on the specific dataset and on the exact GPU used, hence the table should be seen as a guideline only.</span></span> <span data-ttu-id="f8f35-157">After trying these parameters, consider also image resolutions of more than 500x500 pixels, or deeper models such as Resnet-101 or Resnet-152.</span><span class="sxs-lookup"><span data-stu-id="f8f35-157">After trying these parameters, consider also image resolutions of more than 500x500 pixels, or deeper models such as Resnet-101 or Resnet-152.</span></span>

<span data-ttu-id="f8f35-158">The first row in the table corresponds to the default parameters that are set inside Computer Vision Package.</span><span class="sxs-lookup"><span data-stu-id="f8f35-158">The first row in the table corresponds to the default parameters that are set inside Computer Vision Package.</span></span> <span data-ttu-id="f8f35-159">All other rows take longer to train (indicated in the first column) however at the benefit of increased accuracy (see the second column for the average accuracy over three internal datasets).</span><span class="sxs-lookup"><span data-stu-id="f8f35-159">All other rows take longer to train (indicated in the first column) however at the benefit of increased accuracy (see the second column for the average accuracy over three internal datasets).</span></span> <span data-ttu-id="f8f35-160">For example, the parameters in the last row take 5-15x longer to train, however resulted in increased (averaged) accuracy on three internal test sets from 82.6% to 92.8%.</span><span class="sxs-lookup"><span data-stu-id="f8f35-160">For example, the parameters in the last row take 5-15x longer to train, however resulted in increased (averaged) accuracy on three internal test sets from 82.6% to 92.8%.</span></span>

<span data-ttu-id="f8f35-161">Deeper models and higher input resolution take up more DNN memory, and hence the minibatch size needs to be reduced with increased model complexity to avoid out-of-memory-errors.</span><span class="sxs-lookup"><span data-stu-id="f8f35-161">Deeper models and higher input resolution take up more DNN memory, and hence the minibatch size needs to be reduced with increased model complexity to avoid out-of-memory-errors.</span></span> <span data-ttu-id="f8f35-162">As can be seen in the table below, it is beneficial to decrease the learning rate by a factor of two whenever decreasing the minibatch size by the same multiplier.</span><span class="sxs-lookup"><span data-stu-id="f8f35-162">As can be seen in the table below, it is beneficial to decrease the learning rate by a factor of two whenever decreasing the minibatch size by the same multiplier.</span></span> <span data-ttu-id="f8f35-163">The minibatch size might need to get reduced further on GPUs with smaller amounts of memory.</span><span class="sxs-lookup"><span data-stu-id="f8f35-163">The minibatch size might need to get reduced further on GPUs with smaller amounts of memory.</span></span>

| <span data-ttu-id="f8f35-164">Training time (rough estimate)</span><span class="sxs-lookup"><span data-stu-id="f8f35-164">Training time (rough estimate)</span></span> | <span data-ttu-id="f8f35-165">Example accuracy</span><span class="sxs-lookup"><span data-stu-id="f8f35-165">Example accuracy</span></span> | <span data-ttu-id="f8f35-166">Minibatch size (*mb_size*)</span><span class="sxs-lookup"><span data-stu-id="f8f35-166">Minibatch size (*mb_size*)</span></span> | <span data-ttu-id="f8f35-167">Learning rate (*lr_per_mb*)</span><span class="sxs-lookup"><span data-stu-id="f8f35-167">Learning rate (*lr_per_mb*)</span></span> | <span data-ttu-id="f8f35-168">Image resolution (*image_dims*)</span><span class="sxs-lookup"><span data-stu-id="f8f35-168">Image resolution (*image_dims*)</span></span> | <span data-ttu-id="f8f35-169">DNN architecture (*base_model_name*)</span><span class="sxs-lookup"><span data-stu-id="f8f35-169">DNN architecture (*base_model_name*)</span></span> |
|------------- |:-------------:|:-------------:|:-----:|:-----:|:---:|
| <span data-ttu-id="f8f35-170">1x (reference)</span><span class="sxs-lookup"><span data-stu-id="f8f35-170">1x (reference)</span></span> | <span data-ttu-id="f8f35-171">82.6%</span><span class="sxs-lookup"><span data-stu-id="f8f35-171">82.6%</span></span> | <span data-ttu-id="f8f35-172">32</span><span class="sxs-lookup"><span data-stu-id="f8f35-172">32</span></span> | <span data-ttu-id="f8f35-173">[0.05]\*7  + [0.005]\*7  + [0.0005]</span><span class="sxs-lookup"><span data-stu-id="f8f35-173">[0.05]\*7  + [0.005]\*7  + [0.0005]</span></span>  | <span data-ttu-id="f8f35-174">(3, 224, 224)</span><span class="sxs-lookup"><span data-stu-id="f8f35-174">(3, 224, 224)</span></span> | <span data-ttu-id="f8f35-175">ResNet18_ImageNet_CNTK</span><span class="sxs-lookup"><span data-stu-id="f8f35-175">ResNet18_ImageNet_CNTK</span></span> |
| <span data-ttu-id="f8f35-176">2-5x</span><span class="sxs-lookup"><span data-stu-id="f8f35-176">2-5x</span></span>    | <span data-ttu-id="f8f35-177">90.2%</span><span class="sxs-lookup"><span data-stu-id="f8f35-177">90.2%</span></span> | <span data-ttu-id="f8f35-178">16</span><span class="sxs-lookup"><span data-stu-id="f8f35-178">16</span></span> | <span data-ttu-id="f8f35-179">[0.025]\*7 + [0.0025]\*7 + [0.00025]</span><span class="sxs-lookup"><span data-stu-id="f8f35-179">[0.025]\*7 + [0.0025]\*7 + [0.00025]</span></span> | <span data-ttu-id="f8f35-180">(3, 500, 500)</span><span class="sxs-lookup"><span data-stu-id="f8f35-180">(3, 500, 500)</span></span> | <span data-ttu-id="f8f35-181">ResNet18_ImageNet_CNTK</span><span class="sxs-lookup"><span data-stu-id="f8f35-181">ResNet18_ImageNet_CNTK</span></span> |
| <span data-ttu-id="f8f35-182">2-5x</span><span class="sxs-lookup"><span data-stu-id="f8f35-182">2-5x</span></span>    | <span data-ttu-id="f8f35-183">87.5%</span><span class="sxs-lookup"><span data-stu-id="f8f35-183">87.5%</span></span> | <span data-ttu-id="f8f35-184">16</span><span class="sxs-lookup"><span data-stu-id="f8f35-184">16</span></span> | <span data-ttu-id="f8f35-185">[0.025]\*7 + [0.0025]\*7 + [0.00025]</span><span class="sxs-lookup"><span data-stu-id="f8f35-185">[0.025]\*7 + [0.0025]\*7 + [0.00025]</span></span> | <span data-ttu-id="f8f35-186">(3, 224, 224)</span><span class="sxs-lookup"><span data-stu-id="f8f35-186">(3, 224, 224)</span></span> | <span data-ttu-id="f8f35-187">ResNet50_ImageNet_CNTK</span><span class="sxs-lookup"><span data-stu-id="f8f35-187">ResNet50_ImageNet_CNTK</span></span> |
| <span data-ttu-id="f8f35-188">5-15x</span><span class="sxs-lookup"><span data-stu-id="f8f35-188">5-15x</span></span>        | <span data-ttu-id="f8f35-189">92.8%</span><span class="sxs-lookup"><span data-stu-id="f8f35-189">92.8%</span></span> |  <span data-ttu-id="f8f35-190">8</span><span class="sxs-lookup"><span data-stu-id="f8f35-190">8</span></span> | <span data-ttu-id="f8f35-191">[0.01]\*7  + [0.001]\*7  + [0.0001]</span><span class="sxs-lookup"><span data-stu-id="f8f35-191">[0.01]\*7  + [0.001]\*7  + [0.0001]</span></span>  | <span data-ttu-id="f8f35-192">(3, 500, 500)</span><span class="sxs-lookup"><span data-stu-id="f8f35-192">(3, 500, 500)</span></span> | <span data-ttu-id="f8f35-193">ResNet50_ImageNet_CNTK</span><span class="sxs-lookup"><span data-stu-id="f8f35-193">ResNet50_ImageNet_CNTK</span></span> |


## <a name="next-steps"></a><span data-ttu-id="f8f35-194">Next steps</span><span class="sxs-lookup"><span data-stu-id="f8f35-194">Next steps</span></span>

<span data-ttu-id="f8f35-195">For information about the Azure Machine Learning Package for Computer Vision:</span><span class="sxs-lookup"><span data-stu-id="f8f35-195">For information about the Azure Machine Learning Package for Computer Vision:</span></span>
+ <span data-ttu-id="f8f35-196">Check out the reference documentation</span><span class="sxs-lookup"><span data-stu-id="f8f35-196">Check out the reference documentation</span></span>

+ <span data-ttu-id="f8f35-197">Learn about [other Python packages for Azure Machine Learning](reference-python-package-overview.md)</span><span class="sxs-lookup"><span data-stu-id="f8f35-197">Learn about [other Python packages for Azure Machine Learning](reference-python-package-overview.md)</span></span>