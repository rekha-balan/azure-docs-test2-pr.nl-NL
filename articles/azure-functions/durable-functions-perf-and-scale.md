---
title: Performance and scale in Durable Functions - Azure
description: Introduction to the Durable Functions extension for Azure Functions.
services: functions
author: cgillum
manager: jeconnoc
keywords: ''
ms.service: azure-functions
ms.devlang: multiple
ms.topic: conceptual
ms.date: 04/25/2018
ms.author: azfuncdf
ms.openlocfilehash: 52582a6fe3f6c8ccc22c57268e20a94139be9e6f
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44867100"
---
# <a name="performance-and-scale-in-durable-functions-azure-functions"></a><span data-ttu-id="b816f-103">Performance and scale in Durable Functions (Azure Functions)</span><span class="sxs-lookup"><span data-stu-id="b816f-103">Performance and scale in Durable Functions (Azure Functions)</span></span>

<span data-ttu-id="b816f-104">To optimize performance and scalability, it's important to understand the unique scaling characteristics of [Durable Functions](durable-functions-overview.md).</span><span class="sxs-lookup"><span data-stu-id="b816f-104">To optimize performance and scalability, it's important to understand the unique scaling characteristics of [Durable Functions](durable-functions-overview.md).</span></span>

<span data-ttu-id="b816f-105">To understand the scale behavior, you have to understand some of the details of the underlying Azure Storage provider.</span><span class="sxs-lookup"><span data-stu-id="b816f-105">To understand the scale behavior, you have to understand some of the details of the underlying Azure Storage provider.</span></span>

## <a name="history-table"></a><span data-ttu-id="b816f-106">History table</span><span class="sxs-lookup"><span data-stu-id="b816f-106">History table</span></span>

<span data-ttu-id="b816f-107">The **History** table is an Azure Storage table that contains the history events for all orchestration instances within a task hub.</span><span class="sxs-lookup"><span data-stu-id="b816f-107">The **History** table is an Azure Storage table that contains the history events for all orchestration instances within a task hub.</span></span> <span data-ttu-id="b816f-108">The name of this table is in the form *TaskHubName*History.</span><span class="sxs-lookup"><span data-stu-id="b816f-108">The name of this table is in the form *TaskHubName*History.</span></span> <span data-ttu-id="b816f-109">As instances run, new rows are added to this table.</span><span class="sxs-lookup"><span data-stu-id="b816f-109">As instances run, new rows are added to this table.</span></span> <span data-ttu-id="b816f-110">The partition key of this table is derived from the instance ID of the orchestration.</span><span class="sxs-lookup"><span data-stu-id="b816f-110">The partition key of this table is derived from the instance ID of the orchestration.</span></span> <span data-ttu-id="b816f-111">An instance ID is random in most cases, which ensures optimal distribution of internal partitions in Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="b816f-111">An instance ID is random in most cases, which ensures optimal distribution of internal partitions in Azure Storage.</span></span>

<span data-ttu-id="b816f-112">When an orchestration instance needs to run, the appropriate rows of the History table are loaded into memory.</span><span class="sxs-lookup"><span data-stu-id="b816f-112">When an orchestration instance needs to run, the appropriate rows of the History table are loaded into memory.</span></span> <span data-ttu-id="b816f-113">These *history events* are then replayed into the orchestrator function code to get it back into its previously checkpointed state.</span><span class="sxs-lookup"><span data-stu-id="b816f-113">These *history events* are then replayed into the orchestrator function code to get it back into its previously checkpointed state.</span></span> <span data-ttu-id="b816f-114">The use of execution history to rebuild state in this way is influenced by the [Event Sourcing pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing).</span><span class="sxs-lookup"><span data-stu-id="b816f-114">The use of execution history to rebuild state in this way is influenced by the [Event Sourcing pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing).</span></span>

## <a name="instances-table"></a><span data-ttu-id="b816f-115">Instances table</span><span class="sxs-lookup"><span data-stu-id="b816f-115">Instances table</span></span>

<span data-ttu-id="b816f-116">The **Instances** table is another Azure Storage table that contains the statuses of all orchestration instances within a task hub.</span><span class="sxs-lookup"><span data-stu-id="b816f-116">The **Instances** table is another Azure Storage table that contains the statuses of all orchestration instances within a task hub.</span></span> <span data-ttu-id="b816f-117">As instances are created, new rows are added to this table.</span><span class="sxs-lookup"><span data-stu-id="b816f-117">As instances are created, new rows are added to this table.</span></span> <span data-ttu-id="b816f-118">The partition key of this table is the orchestration instance ID and the row key is a fixed constant.</span><span class="sxs-lookup"><span data-stu-id="b816f-118">The partition key of this table is the orchestration instance ID and the row key is a fixed constant.</span></span> <span data-ttu-id="b816f-119">There is one row per orchestration instance.</span><span class="sxs-lookup"><span data-stu-id="b816f-119">There is one row per orchestration instance.</span></span>

<span data-ttu-id="b816f-120">This table is used to satisfy instance query requests from the [GetStatusAsync](https://azure.github.io/azure-functions-durable-extension/api/Microsoft.Azure.WebJobs.DurableOrchestrationClient.html#Microsoft_Azure_WebJobs_DurableOrchestrationClient_GetStatusAsync_System_String_) API as well as the [status query HTTP API](https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-http-api#get-instance-status).</span><span class="sxs-lookup"><span data-stu-id="b816f-120">This table is used to satisfy instance query requests from the [GetStatusAsync](https://azure.github.io/azure-functions-durable-extension/api/Microsoft.Azure.WebJobs.DurableOrchestrationClient.html#Microsoft_Azure_WebJobs_DurableOrchestrationClient_GetStatusAsync_System_String_) API as well as the [status query HTTP API](https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-http-api#get-instance-status).</span></span> <span data-ttu-id="b816f-121">It is kept eventually consistent with the contents of the **History** table mentioned previously.</span><span class="sxs-lookup"><span data-stu-id="b816f-121">It is kept eventually consistent with the contents of the **History** table mentioned previously.</span></span> <span data-ttu-id="b816f-122">The use of a separate Azure Storage table to efficiently satisfy instance query operations in this way is influenced by the [Command and Query Responsibility Segregation (CQRS) pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs).</span><span class="sxs-lookup"><span data-stu-id="b816f-122">The use of a separate Azure Storage table to efficiently satisfy instance query operations in this way is influenced by the [Command and Query Responsibility Segregation (CQRS) pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs).</span></span>

## <a name="internal-queue-triggers"></a><span data-ttu-id="b816f-123">Internal queue triggers</span><span class="sxs-lookup"><span data-stu-id="b816f-123">Internal queue triggers</span></span>

<span data-ttu-id="b816f-124">Orchestrator functions and activity functions are both triggered by internal queues in the function app's task hub.</span><span class="sxs-lookup"><span data-stu-id="b816f-124">Orchestrator functions and activity functions are both triggered by internal queues in the function app's task hub.</span></span> <span data-ttu-id="b816f-125">Using queues in this way provides reliable "at-least-once" message delivery guarantees.</span><span class="sxs-lookup"><span data-stu-id="b816f-125">Using queues in this way provides reliable "at-least-once" message delivery guarantees.</span></span> <span data-ttu-id="b816f-126">There are two types of queues in Durable Functions: the **control queue** and the **work-item queue**.</span><span class="sxs-lookup"><span data-stu-id="b816f-126">There are two types of queues in Durable Functions: the **control queue** and the **work-item queue**.</span></span>

### <a name="the-work-item-queue"></a><span data-ttu-id="b816f-127">The work-item queue</span><span class="sxs-lookup"><span data-stu-id="b816f-127">The work-item queue</span></span>

<span data-ttu-id="b816f-128">There is one work-item queue per task hub in Durable Functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-128">There is one work-item queue per task hub in Durable Functions.</span></span> <span data-ttu-id="b816f-129">It is a basic queue and behaves similarly to any other `queueTrigger` queue in Azure Functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-129">It is a basic queue and behaves similarly to any other `queueTrigger` queue in Azure Functions.</span></span> <span data-ttu-id="b816f-130">This queue is used to trigger stateless *activity functions* by dequeueing a single message at a time.</span><span class="sxs-lookup"><span data-stu-id="b816f-130">This queue is used to trigger stateless *activity functions* by dequeueing a single message at a time.</span></span> <span data-ttu-id="b816f-131">Each of these messages contains activity function inputs and additional metadata, such as which function to execute.</span><span class="sxs-lookup"><span data-stu-id="b816f-131">Each of these messages contains activity function inputs and additional metadata, such as which function to execute.</span></span> <span data-ttu-id="b816f-132">When a Durable Functions application scales out to multiple VMs, these VMs all compete to acquire work from the work-item queue.</span><span class="sxs-lookup"><span data-stu-id="b816f-132">When a Durable Functions application scales out to multiple VMs, these VMs all compete to acquire work from the work-item queue.</span></span>

### <a name="control-queues"></a><span data-ttu-id="b816f-133">Control queue(s)</span><span class="sxs-lookup"><span data-stu-id="b816f-133">Control queue(s)</span></span>

<span data-ttu-id="b816f-134">There are multiple *control queues* per task hub in Durable Functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-134">There are multiple *control queues* per task hub in Durable Functions.</span></span> <span data-ttu-id="b816f-135">A *control queue* is more sophisticated than the simpler work-item queue.</span><span class="sxs-lookup"><span data-stu-id="b816f-135">A *control queue* is more sophisticated than the simpler work-item queue.</span></span> <span data-ttu-id="b816f-136">Control queues are used to trigger the stateful orchestrator functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-136">Control queues are used to trigger the stateful orchestrator functions.</span></span> <span data-ttu-id="b816f-137">Because the orchestrator function instances are stateful singletons, it's not possible to use a competing consumer model to distribute load across VMs.</span><span class="sxs-lookup"><span data-stu-id="b816f-137">Because the orchestrator function instances are stateful singletons, it's not possible to use a competing consumer model to distribute load across VMs.</span></span> <span data-ttu-id="b816f-138">Instead, orchestrator messages are load-balanced across the control queues.</span><span class="sxs-lookup"><span data-stu-id="b816f-138">Instead, orchestrator messages are load-balanced across the control queues.</span></span> <span data-ttu-id="b816f-139">More details on this behavior can be found in subsequent sections.</span><span class="sxs-lookup"><span data-stu-id="b816f-139">More details on this behavior can be found in subsequent sections.</span></span>

<span data-ttu-id="b816f-140">Control queues contain a variety of orchestration lifecycle message types.</span><span class="sxs-lookup"><span data-stu-id="b816f-140">Control queues contain a variety of orchestration lifecycle message types.</span></span> <span data-ttu-id="b816f-141">Examples include [orchestrator control messages](durable-functions-instance-management.md), activity function *response* messages, and timer messages.</span><span class="sxs-lookup"><span data-stu-id="b816f-141">Examples include [orchestrator control messages](durable-functions-instance-management.md), activity function *response* messages, and timer messages.</span></span> <span data-ttu-id="b816f-142">As many as 32 messages will be dequeued from a control queue in a single poll.</span><span class="sxs-lookup"><span data-stu-id="b816f-142">As many as 32 messages will be dequeued from a control queue in a single poll.</span></span> <span data-ttu-id="b816f-143">These messages contain payload data as well as metadata including which orchestration instance it is intended for.</span><span class="sxs-lookup"><span data-stu-id="b816f-143">These messages contain payload data as well as metadata including which orchestration instance it is intended for.</span></span> <span data-ttu-id="b816f-144">If multiple dequeued messages are intended for the same orchestration instance, they will be processed as a batch.</span><span class="sxs-lookup"><span data-stu-id="b816f-144">If multiple dequeued messages are intended for the same orchestration instance, they will be processed as a batch.</span></span>

## <a name="storage-account-selection"></a><span data-ttu-id="b816f-145">Storage account selection</span><span class="sxs-lookup"><span data-stu-id="b816f-145">Storage account selection</span></span>

<span data-ttu-id="b816f-146">The queues, tables, and blobs used by Durable Functions are created by in a configured Azure Storage account.</span><span class="sxs-lookup"><span data-stu-id="b816f-146">The queues, tables, and blobs used by Durable Functions are created by in a configured Azure Storage account.</span></span> <span data-ttu-id="b816f-147">The account to use can be specified using the `durableTask/azureStorageConnectionStringName` setting in **host.json** file.</span><span class="sxs-lookup"><span data-stu-id="b816f-147">The account to use can be specified using the `durableTask/azureStorageConnectionStringName` setting in **host.json** file.</span></span>

```json
{
  "durableTask": {
    "azureStorageConnectionStringName": "MyStorageAccountAppSetting"
  }
}
```

<span data-ttu-id="b816f-148">If not specified, the default `AzureWebJobsStorage` storage account is used.</span><span class="sxs-lookup"><span data-stu-id="b816f-148">If not specified, the default `AzureWebJobsStorage` storage account is used.</span></span> <span data-ttu-id="b816f-149">For performance-sensitive workloads, however, configuring a non-default storage account is recommended.</span><span class="sxs-lookup"><span data-stu-id="b816f-149">For performance-sensitive workloads, however, configuring a non-default storage account is recommended.</span></span> <span data-ttu-id="b816f-150">Durable Functions uses Azure Storage heavily, and using a dedicated storage account isolates Durable Functions storage usage from the internal usage by the Azure Functions host.</span><span class="sxs-lookup"><span data-stu-id="b816f-150">Durable Functions uses Azure Storage heavily, and using a dedicated storage account isolates Durable Functions storage usage from the internal usage by the Azure Functions host.</span></span>

## <a name="orchestrator-scale-out"></a><span data-ttu-id="b816f-151">Orchestrator scale-out</span><span class="sxs-lookup"><span data-stu-id="b816f-151">Orchestrator scale-out</span></span>

<span data-ttu-id="b816f-152">Activity functions are stateless and scaled out automatically by adding VMs.</span><span class="sxs-lookup"><span data-stu-id="b816f-152">Activity functions are stateless and scaled out automatically by adding VMs.</span></span> <span data-ttu-id="b816f-153">Orchestrator functions, on the other hand, are *partitioned* across one or more control queues.</span><span class="sxs-lookup"><span data-stu-id="b816f-153">Orchestrator functions, on the other hand, are *partitioned* across one or more control queues.</span></span> <span data-ttu-id="b816f-154">The number of control queues is defined in the **host.json** file.</span><span class="sxs-lookup"><span data-stu-id="b816f-154">The number of control queues is defined in the **host.json** file.</span></span> <span data-ttu-id="b816f-155">The following example host.json snippet sets the `durableTask/partitionCount` property to `3`.</span><span class="sxs-lookup"><span data-stu-id="b816f-155">The following example host.json snippet sets the `durableTask/partitionCount` property to `3`.</span></span>

```json
{
  "durableTask": {
    "partitionCount": 3
  }
}
```
<span data-ttu-id="b816f-156">A task hub can be configured with between 1 and 16 partitions.</span><span class="sxs-lookup"><span data-stu-id="b816f-156">A task hub can be configured with between 1 and 16 partitions.</span></span> <span data-ttu-id="b816f-157">If not specified, the default partition count is **4**.</span><span class="sxs-lookup"><span data-stu-id="b816f-157">If not specified, the default partition count is **4**.</span></span>

<span data-ttu-id="b816f-158">When scaling out to multiple function host instances (typically on different VMs), each instance acquires a lock on one of the control queues.</span><span class="sxs-lookup"><span data-stu-id="b816f-158">When scaling out to multiple function host instances (typically on different VMs), each instance acquires a lock on one of the control queues.</span></span> <span data-ttu-id="b816f-159">These locks are internally implemented as blob storage leases and ensure that an orchestration instance only runs on a single host instance at a time.</span><span class="sxs-lookup"><span data-stu-id="b816f-159">These locks are internally implemented as blob storage leases and ensure that an orchestration instance only runs on a single host instance at a time.</span></span> <span data-ttu-id="b816f-160">If a task hub is configured with three control queues, orchestration instances can be load-balanced across as many as three VMs.</span><span class="sxs-lookup"><span data-stu-id="b816f-160">If a task hub is configured with three control queues, orchestration instances can be load-balanced across as many as three VMs.</span></span> <span data-ttu-id="b816f-161">Additional VMs can be added to increase capacity for activity function execution.</span><span class="sxs-lookup"><span data-stu-id="b816f-161">Additional VMs can be added to increase capacity for activity function execution.</span></span>

<span data-ttu-id="b816f-162">The following diagram illustrates how the Azure Functions host interacts with the storage entities in a scaled out environment.</span><span class="sxs-lookup"><span data-stu-id="b816f-162">The following diagram illustrates how the Azure Functions host interacts with the storage entities in a scaled out environment.</span></span>

![Scale diagram](media/durable-functions-perf-and-scale/scale-diagram.png)

<span data-ttu-id="b816f-164">As shown in the previous diagram, all VMs compete for messages on the work-item queue.</span><span class="sxs-lookup"><span data-stu-id="b816f-164">As shown in the previous diagram, all VMs compete for messages on the work-item queue.</span></span> <span data-ttu-id="b816f-165">However, only three VMs can acquire messages from control queues, and each VM locks a single control queue.</span><span class="sxs-lookup"><span data-stu-id="b816f-165">However, only three VMs can acquire messages from control queues, and each VM locks a single control queue.</span></span>

<span data-ttu-id="b816f-166">The orchestration instances are distributed across all control queue instances.</span><span class="sxs-lookup"><span data-stu-id="b816f-166">The orchestration instances are distributed across all control queue instances.</span></span> <span data-ttu-id="b816f-167">The distribution is done by hashing the instance ID of the orchestration.</span><span class="sxs-lookup"><span data-stu-id="b816f-167">The distribution is done by hashing the instance ID of the orchestration.</span></span> <span data-ttu-id="b816f-168">Instance IDs by default are random GUIDs, ensuring that instances are equally distributed across all control queues.</span><span class="sxs-lookup"><span data-stu-id="b816f-168">Instance IDs by default are random GUIDs, ensuring that instances are equally distributed across all control queues.</span></span>

<span data-ttu-id="b816f-169">Generally speaking, orchestrator functions are intended to be lightweight and should not require large amounts of computing power.</span><span class="sxs-lookup"><span data-stu-id="b816f-169">Generally speaking, orchestrator functions are intended to be lightweight and should not require large amounts of computing power.</span></span> <span data-ttu-id="b816f-170">It is therefore not necessary to create a large number of control queue partitions to get great throughput.</span><span class="sxs-lookup"><span data-stu-id="b816f-170">It is therefore not necessary to create a large number of control queue partitions to get great throughput.</span></span> <span data-ttu-id="b816f-171">Most of the heavy work should be done in stateless activity functions, which can be scaled out infinitely.</span><span class="sxs-lookup"><span data-stu-id="b816f-171">Most of the heavy work should be done in stateless activity functions, which can be scaled out infinitely.</span></span>

## <a name="auto-scale"></a><span data-ttu-id="b816f-172">Auto-scale</span><span class="sxs-lookup"><span data-stu-id="b816f-172">Auto-scale</span></span>

<span data-ttu-id="b816f-173">As with all Azure Functions running in the Consumption plan, Durable Functions supports auto-scale via the [Azure Functions scale controller](functions-scale.md#runtime-scaling).</span><span class="sxs-lookup"><span data-stu-id="b816f-173">As with all Azure Functions running in the Consumption plan, Durable Functions supports auto-scale via the [Azure Functions scale controller](functions-scale.md#runtime-scaling).</span></span> <span data-ttu-id="b816f-174">The Scale Controller monitors the latency of all queues by periodically issuing _peek_ commands.</span><span class="sxs-lookup"><span data-stu-id="b816f-174">The Scale Controller monitors the latency of all queues by periodically issuing _peek_ commands.</span></span> <span data-ttu-id="b816f-175">Based on the latencies of the peeked messages, the Scale Controller will decide whether to add or remove VMs.</span><span class="sxs-lookup"><span data-stu-id="b816f-175">Based on the latencies of the peeked messages, the Scale Controller will decide whether to add or remove VMs.</span></span>

<span data-ttu-id="b816f-176">If the Scale Controller determines that control queue message latencies are too high, it will add VM instances until either the message latency decreases to an acceptable level or it reaches the control queue partition count.</span><span class="sxs-lookup"><span data-stu-id="b816f-176">If the Scale Controller determines that control queue message latencies are too high, it will add VM instances until either the message latency decreases to an acceptable level or it reaches the control queue partition count.</span></span> <span data-ttu-id="b816f-177">Similarly, the Scale Controller will continually add VM instances if work-item queue latencies are high, regardless of the partition count.</span><span class="sxs-lookup"><span data-stu-id="b816f-177">Similarly, the Scale Controller will continually add VM instances if work-item queue latencies are high, regardless of the partition count.</span></span>

## <a name="thread-usage"></a><span data-ttu-id="b816f-178">Thread usage</span><span class="sxs-lookup"><span data-stu-id="b816f-178">Thread usage</span></span>

<span data-ttu-id="b816f-179">Orchestrator functions are executed on a single thread to ensure that execution can be deterministic across many replays.</span><span class="sxs-lookup"><span data-stu-id="b816f-179">Orchestrator functions are executed on a single thread to ensure that execution can be deterministic across many replays.</span></span> <span data-ttu-id="b816f-180">Because of this single-threaded execution, it's important that orchestrator function threads do not perform CPU-intensive tasks, do I/O, or block for any reason.</span><span class="sxs-lookup"><span data-stu-id="b816f-180">Because of this single-threaded execution, it's important that orchestrator function threads do not perform CPU-intensive tasks, do I/O, or block for any reason.</span></span> <span data-ttu-id="b816f-181">Any work that may require I/O, blocking, or multiple threads should be moved into activity functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-181">Any work that may require I/O, blocking, or multiple threads should be moved into activity functions.</span></span>

<span data-ttu-id="b816f-182">Activity functions have all the same behaviors as regular queue-triggered functions.</span><span class="sxs-lookup"><span data-stu-id="b816f-182">Activity functions have all the same behaviors as regular queue-triggered functions.</span></span> <span data-ttu-id="b816f-183">They can safely do I/O, execute CPU intensive operations, and use multiple threads.</span><span class="sxs-lookup"><span data-stu-id="b816f-183">They can safely do I/O, execute CPU intensive operations, and use multiple threads.</span></span> <span data-ttu-id="b816f-184">Because activity triggers are stateless, they can freely scale out to an unbounded number of VMs.</span><span class="sxs-lookup"><span data-stu-id="b816f-184">Because activity triggers are stateless, they can freely scale out to an unbounded number of VMs.</span></span>

## <a name="concurrency-throttles"></a><span data-ttu-id="b816f-185">Concurrency throttles</span><span class="sxs-lookup"><span data-stu-id="b816f-185">Concurrency throttles</span></span>

<span data-ttu-id="b816f-186">Azure Functions supports executing multiple functions concurrently within a single app instance.</span><span class="sxs-lookup"><span data-stu-id="b816f-186">Azure Functions supports executing multiple functions concurrently within a single app instance.</span></span> <span data-ttu-id="b816f-187">This concurrent execution helps increase parallelism and minimizes the number of "cold starts" that a typical app will experience over time.</span><span class="sxs-lookup"><span data-stu-id="b816f-187">This concurrent execution helps increase parallelism and minimizes the number of "cold starts" that a typical app will experience over time.</span></span> <span data-ttu-id="b816f-188">However, high concurrency can result in high per-VM memory usage.</span><span class="sxs-lookup"><span data-stu-id="b816f-188">However, high concurrency can result in high per-VM memory usage.</span></span> <span data-ttu-id="b816f-189">Depending on the needs of the function app, it may be necessary to throttle the per-instance concurrency to avoid the possibility of running out of memory in high-load situations.</span><span class="sxs-lookup"><span data-stu-id="b816f-189">Depending on the needs of the function app, it may be necessary to throttle the per-instance concurrency to avoid the possibility of running out of memory in high-load situations.</span></span>

<span data-ttu-id="b816f-190">Both activity function and orchestrator function concurrency limits can be configured in the **host.json** file.</span><span class="sxs-lookup"><span data-stu-id="b816f-190">Both activity function and orchestrator function concurrency limits can be configured in the **host.json** file.</span></span> <span data-ttu-id="b816f-191">The relevant settings are `durableTask/maxConcurrentActivityFunctions` and `durableTask/maxConcurrentOrchestratorFunctions` respectively.</span><span class="sxs-lookup"><span data-stu-id="b816f-191">The relevant settings are `durableTask/maxConcurrentActivityFunctions` and `durableTask/maxConcurrentOrchestratorFunctions` respectively.</span></span>

```json
{
  "durableTask": {
    "maxConcurrentActivityFunctions": 10,
    "maxConcurrentOrchestratorFunctions": 10,
  }
}
```

<span data-ttu-id="b816f-192">In the previous example, a maximum of 10 orchestrator functions and 10 activity functions can run on a single VM concurrently.</span><span class="sxs-lookup"><span data-stu-id="b816f-192">In the previous example, a maximum of 10 orchestrator functions and 10 activity functions can run on a single VM concurrently.</span></span> <span data-ttu-id="b816f-193">If not specified, the number of concurrent activity and orchestrator function executions is capped at 10X the number of cores on the VM.</span><span class="sxs-lookup"><span data-stu-id="b816f-193">If not specified, the number of concurrent activity and orchestrator function executions is capped at 10X the number of cores on the VM.</span></span>

> [!NOTE]
> <span data-ttu-id="b816f-194">These settings are useful to help manage memory and CPU usage on a single VM.</span><span class="sxs-lookup"><span data-stu-id="b816f-194">These settings are useful to help manage memory and CPU usage on a single VM.</span></span> <span data-ttu-id="b816f-195">However, when scaled out across multiple VMs, each VM will have its own set of limits.</span><span class="sxs-lookup"><span data-stu-id="b816f-195">However, when scaled out across multiple VMs, each VM will have its own set of limits.</span></span> <span data-ttu-id="b816f-196">These settings cannot be used to control concurrency at a global level.</span><span class="sxs-lookup"><span data-stu-id="b816f-196">These settings cannot be used to control concurrency at a global level.</span></span>

## <a name="orchestrator-function-replay"></a><span data-ttu-id="b816f-197">Orchestrator function replay</span><span class="sxs-lookup"><span data-stu-id="b816f-197">Orchestrator function replay</span></span>
<span data-ttu-id="b816f-198">As mentioned previously, orchestrator functions are replayed using the contents of the **History** table.</span><span class="sxs-lookup"><span data-stu-id="b816f-198">As mentioned previously, orchestrator functions are replayed using the contents of the **History** table.</span></span> <span data-ttu-id="b816f-199">By default, the orchestrator function code is replayed every time a batch of messages are dequeued from a control queue.</span><span class="sxs-lookup"><span data-stu-id="b816f-199">By default, the orchestrator function code is replayed every time a batch of messages are dequeued from a control queue.</span></span>

<span data-ttu-id="b816f-200">This aggressive replay behavior can be disabled by enabling **extended sessions**.</span><span class="sxs-lookup"><span data-stu-id="b816f-200">This aggressive replay behavior can be disabled by enabling **extended sessions**.</span></span> <span data-ttu-id="b816f-201">When extended sessions are enabled, orchestrator function instances are held in memory longer and new messages can be processed without a full replay.</span><span class="sxs-lookup"><span data-stu-id="b816f-201">When extended sessions are enabled, orchestrator function instances are held in memory longer and new messages can be processed without a full replay.</span></span> <span data-ttu-id="b816f-202">Extended sessions are enabled by setting `durableTask/extendedSessionsEnabled` to `true` in the **host.json** file.</span><span class="sxs-lookup"><span data-stu-id="b816f-202">Extended sessions are enabled by setting `durableTask/extendedSessionsEnabled` to `true` in the **host.json** file.</span></span> <span data-ttu-id="b816f-203">The `durableTask/extendedSessionIdleTimeoutInSeconds` setting is used to control how long an idle session will be held in memory:</span><span class="sxs-lookup"><span data-stu-id="b816f-203">The `durableTask/extendedSessionIdleTimeoutInSeconds` setting is used to control how long an idle session will be held in memory:</span></span>

```json
{
  "durableTask": {
    "extendedSessionsEnabled": true,
    "extendedSessionIdleTimeoutInSeconds": 30
  }
}
```

<span data-ttu-id="b816f-204">The typical effect of enabling extended sessions is reduced I/O against the Azure Storage account and overall improved throughput.</span><span class="sxs-lookup"><span data-stu-id="b816f-204">The typical effect of enabling extended sessions is reduced I/O against the Azure Storage account and overall improved throughput.</span></span>

<span data-ttu-id="b816f-205">However, one potential downside of this feature is that idle orchestrator function instances will stay in memory longer.</span><span class="sxs-lookup"><span data-stu-id="b816f-205">However, one potential downside of this feature is that idle orchestrator function instances will stay in memory longer.</span></span> <span data-ttu-id="b816f-206">There are two effects to be aware of:</span><span class="sxs-lookup"><span data-stu-id="b816f-206">There are two effects to be aware of:</span></span>

1. <span data-ttu-id="b816f-207">Overall increase in function app memory usage.</span><span class="sxs-lookup"><span data-stu-id="b816f-207">Overall increase in function app memory usage.</span></span>
2. <span data-ttu-id="b816f-208">Overall decrease in throughput if there are many concurrent, short-lived orchestrator function executions.</span><span class="sxs-lookup"><span data-stu-id="b816f-208">Overall decrease in throughput if there are many concurrent, short-lived orchestrator function executions.</span></span>

<span data-ttu-id="b816f-209">As an example, if `durableTask/extendedSessionIdleTimeoutInSeconds` is set to 30 seconds, then a short-lived orchestrator function episode that executes in less than 1 second will still occupy memory for 30 seconds.</span><span class="sxs-lookup"><span data-stu-id="b816f-209">As an example, if `durableTask/extendedSessionIdleTimeoutInSeconds` is set to 30 seconds, then a short-lived orchestrator function episode that executes in less than 1 second will still occupy memory for 30 seconds.</span></span> <span data-ttu-id="b816f-210">It will also count against the `durableTask/maxConcurrentOrchestratorFunctions` quota mentioned previously, potentially preventing other orchestrator functions from running.</span><span class="sxs-lookup"><span data-stu-id="b816f-210">It will also count against the `durableTask/maxConcurrentOrchestratorFunctions` quota mentioned previously, potentially preventing other orchestrator functions from running.</span></span>

> [!NOTE]
> <span data-ttu-id="b816f-211">These settings should only be used after an orchestrator function has been fully developed and tested.</span><span class="sxs-lookup"><span data-stu-id="b816f-211">These settings should only be used after an orchestrator function has been fully developed and tested.</span></span> <span data-ttu-id="b816f-212">The default aggressive replay behavior is useful for detecting idempotency errors in orchestrator functions at development time.</span><span class="sxs-lookup"><span data-stu-id="b816f-212">The default aggressive replay behavior is useful for detecting idempotency errors in orchestrator functions at development time.</span></span>

## <a name="performance-targets"></a><span data-ttu-id="b816f-213">Performance targets</span><span class="sxs-lookup"><span data-stu-id="b816f-213">Performance targets</span></span>

<span data-ttu-id="b816f-214">When planning to use Durable Functions for a production application, it is important to consider the performance requirements early in the planning process.</span><span class="sxs-lookup"><span data-stu-id="b816f-214">When planning to use Durable Functions for a production application, it is important to consider the performance requirements early in the planning process.</span></span> <span data-ttu-id="b816f-215">This section covers some basic usage scenarios and the expected maximum throughput numbers.</span><span class="sxs-lookup"><span data-stu-id="b816f-215">This section covers some basic usage scenarios and the expected maximum throughput numbers.</span></span>

* <span data-ttu-id="b816f-216">**Sequential activity execution**: This scenario describes an orchestrator function that runs a series of activity functions one after the other.</span><span class="sxs-lookup"><span data-stu-id="b816f-216">**Sequential activity execution**: This scenario describes an orchestrator function that runs a series of activity functions one after the other.</span></span> <span data-ttu-id="b816f-217">It most closely resembles the [Function Chaining](durable-functions-sequence.md) sample.</span><span class="sxs-lookup"><span data-stu-id="b816f-217">It most closely resembles the [Function Chaining](durable-functions-sequence.md) sample.</span></span>
* <span data-ttu-id="b816f-218">**Parallel activity execution**: This scenario describes an orchestrator function that executes many activity functions in parallel using the [Fan-out, Fan-in](durable-functions-cloud-backup.md) pattern.</span><span class="sxs-lookup"><span data-stu-id="b816f-218">**Parallel activity execution**: This scenario describes an orchestrator function that executes many activity functions in parallel using the [Fan-out, Fan-in](durable-functions-cloud-backup.md) pattern.</span></span>
* <span data-ttu-id="b816f-219">**Parallel response processing**: This scenario is the second half of the [Fan-out, Fan-in](durable-functions-cloud-backup.md) pattern.</span><span class="sxs-lookup"><span data-stu-id="b816f-219">**Parallel response processing**: This scenario is the second half of the [Fan-out, Fan-in](durable-functions-cloud-backup.md) pattern.</span></span> <span data-ttu-id="b816f-220">It focuses on the performance of the fan-in.</span><span class="sxs-lookup"><span data-stu-id="b816f-220">It focuses on the performance of the fan-in.</span></span> <span data-ttu-id="b816f-221">It's important to note that unlike fan-out, fan-in is done by a single orchestrator function instance, and therefore can only run on a single VM.</span><span class="sxs-lookup"><span data-stu-id="b816f-221">It's important to note that unlike fan-out, fan-in is done by a single orchestrator function instance, and therefore can only run on a single VM.</span></span>
* <span data-ttu-id="b816f-222">**External event processing**: This scenario represents a single orchestrator function instance that waits on [external events](durable-functions-external-events.md), one at a time.</span><span class="sxs-lookup"><span data-stu-id="b816f-222">**External event processing**: This scenario represents a single orchestrator function instance that waits on [external events](durable-functions-external-events.md), one at a time.</span></span>

> [!TIP]
> <span data-ttu-id="b816f-223">Unlike fan-out, fan-in operations are limited to a single VM.</span><span class="sxs-lookup"><span data-stu-id="b816f-223">Unlike fan-out, fan-in operations are limited to a single VM.</span></span> <span data-ttu-id="b816f-224">If your application uses the fan-out, fan-in pattern and you are concerned about fan-in performance, consider sub-dividing the activity function fan-out across multiple [sub-orchestrations](durable-functions-sub-orchestrations.md).</span><span class="sxs-lookup"><span data-stu-id="b816f-224">If your application uses the fan-out, fan-in pattern and you are concerned about fan-in performance, consider sub-dividing the activity function fan-out across multiple [sub-orchestrations](durable-functions-sub-orchestrations.md).</span></span>

<span data-ttu-id="b816f-225">The following table shows the expected *maximum* throughput numbers for the previously described scenarios.</span><span class="sxs-lookup"><span data-stu-id="b816f-225">The following table shows the expected *maximum* throughput numbers for the previously described scenarios.</span></span> <span data-ttu-id="b816f-226">"Instance" refers to a single instance of an orchestrator function running on a single small ([A1](../virtual-machines/windows/sizes-previous-gen.md#a-series)) VM in Azure App Service.</span><span class="sxs-lookup"><span data-stu-id="b816f-226">"Instance" refers to a single instance of an orchestrator function running on a single small ([A1](../virtual-machines/windows/sizes-previous-gen.md#a-series)) VM in Azure App Service.</span></span> <span data-ttu-id="b816f-227">In all cases, it is assumed that [extended sessions](#orchestrator-function-replay) are enabled.</span><span class="sxs-lookup"><span data-stu-id="b816f-227">In all cases, it is assumed that [extended sessions](#orchestrator-function-replay) are enabled.</span></span> <span data-ttu-id="b816f-228">Actual results may vary depending on the CPU or I/O work performed by the function code.</span><span class="sxs-lookup"><span data-stu-id="b816f-228">Actual results may vary depending on the CPU or I/O work performed by the function code.</span></span>

| <span data-ttu-id="b816f-229">Scenario</span><span class="sxs-lookup"><span data-stu-id="b816f-229">Scenario</span></span> | <span data-ttu-id="b816f-230">Maximum throughput</span><span class="sxs-lookup"><span data-stu-id="b816f-230">Maximum throughput</span></span> |
|-|-|
| <span data-ttu-id="b816f-231">Sequential activity execution</span><span class="sxs-lookup"><span data-stu-id="b816f-231">Sequential activity execution</span></span> | <span data-ttu-id="b816f-232">5 activities per second, per instance</span><span class="sxs-lookup"><span data-stu-id="b816f-232">5 activities per second, per instance</span></span> |
| <span data-ttu-id="b816f-233">Parallel activity execution (fan-out)</span><span class="sxs-lookup"><span data-stu-id="b816f-233">Parallel activity execution (fan-out)</span></span> | <span data-ttu-id="b816f-234">100 activities per second, per instance</span><span class="sxs-lookup"><span data-stu-id="b816f-234">100 activities per second, per instance</span></span> |
| <span data-ttu-id="b816f-235">Parallel response processing (fan-in)</span><span class="sxs-lookup"><span data-stu-id="b816f-235">Parallel response processing (fan-in)</span></span> | <span data-ttu-id="b816f-236">150 responses per second, per instance</span><span class="sxs-lookup"><span data-stu-id="b816f-236">150 responses per second, per instance</span></span> |
| <span data-ttu-id="b816f-237">External event processing</span><span class="sxs-lookup"><span data-stu-id="b816f-237">External event processing</span></span> | <span data-ttu-id="b816f-238">50 events per second, per instance</span><span class="sxs-lookup"><span data-stu-id="b816f-238">50 events per second, per instance</span></span> |

> [!NOTE]
> <span data-ttu-id="b816f-239">These numbers are current as of the v1.4.0 (GA) release of the Durable Functions extension.</span><span class="sxs-lookup"><span data-stu-id="b816f-239">These numbers are current as of the v1.4.0 (GA) release of the Durable Functions extension.</span></span> <span data-ttu-id="b816f-240">These numbers may change over time as the feature matures and as optimizations are made.</span><span class="sxs-lookup"><span data-stu-id="b816f-240">These numbers may change over time as the feature matures and as optimizations are made.</span></span>

<span data-ttu-id="b816f-241">If you are not seeing the throughput numbers you expect and your CPU and memory usage appears healthy, check to see whether the cause is related to [the health of your storage account](../storage/common/storage-monitoring-diagnosing-troubleshooting.md#troubleshooting-guidance).</span><span class="sxs-lookup"><span data-stu-id="b816f-241">If you are not seeing the throughput numbers you expect and your CPU and memory usage appears healthy, check to see whether the cause is related to [the health of your storage account](../storage/common/storage-monitoring-diagnosing-troubleshooting.md#troubleshooting-guidance).</span></span> <span data-ttu-id="b816f-242">The Durable Functions extension can put significant load on an Azure Storage account and sufficiently high loads may result in storage account throttling.</span><span class="sxs-lookup"><span data-stu-id="b816f-242">The Durable Functions extension can put significant load on an Azure Storage account and sufficiently high loads may result in storage account throttling.</span></span>

## <a name="next-steps"></a><span data-ttu-id="b816f-243">Next steps</span><span class="sxs-lookup"><span data-stu-id="b816f-243">Next steps</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="b816f-244">Install the Durable Functions extension and samples</span><span class="sxs-lookup"><span data-stu-id="b816f-244">Install the Durable Functions extension and samples</span></span>](durable-functions-install.md)
