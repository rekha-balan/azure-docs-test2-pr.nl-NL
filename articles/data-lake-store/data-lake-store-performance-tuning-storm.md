---
title: Azure Data Lake Store Storm performance tuning guidelines | Microsoft Docs
description: Azure Data Lake Store Storm performance tuning guidelines
services: data-lake-store
documentationcenter: ''
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 1dfa93643f45a96ded3fd022aa8b1c71d487acb4
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44669458"
---
# <a name="performance-tuning-guidance-for-storm-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="ad0ab-103">Performance tuning guidance for Storm on HDInsight and Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="ad0ab-103">Performance tuning guidance for Storm on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="ad0ab-104">Understand the factors that should be considered when you tune the performance of an Azure Storm topology.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-104">Understand the factors that should be considered when you tune the performance of an Azure Storm topology.</span></span> <span data-ttu-id="ad0ab-105">For example, it's important to understand the characteristics of the work done by the spouts and the bolts (whether the work is I/O or memory intensive).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-105">For example, it's important to understand the characteristics of the work done by the spouts and the bolts (whether the work is I/O or memory intensive).</span></span> <span data-ttu-id="ad0ab-106">This article covers a range of performance tuning guidelines, including troubleshooting common issues.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-106">This article covers a range of performance tuning guidelines, including troubleshooting common issues.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="ad0ab-107">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="ad0ab-107">Prerequisites</span></span>

* <span data-ttu-id="ad0ab-108">**An Azure subscription**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-108">**An Azure subscription**.</span></span> <span data-ttu-id="ad0ab-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="ad0ab-110">**An Azure Data Lake Store account**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="ad0ab-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md).</span></span>
* <span data-ttu-id="ad0ab-112">**An Azure HDInsight cluster** with access to a Data Lake Store account.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-112">**An Azure HDInsight cluster** with access to a Data Lake Store account.</span></span> <span data-ttu-id="ad0ab-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="ad0ab-114">Make sure you enable Remote Desktop for the cluster.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-114">Make sure you enable Remote Desktop for the cluster.</span></span>
* <span data-ttu-id="ad0ab-115">**Running a Storm cluster on Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-115">**Running a Storm cluster on Data Lake Store**.</span></span> <span data-ttu-id="ad0ab-116">For more information, see [Storm on HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-116">For more information, see [Storm on HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview).</span></span>
* <span data-ttu-id="ad0ab-117">**Performance tuning guidelines on Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-117">**Performance tuning guidelines on Data Lake Store**.</span></span>  <span data-ttu-id="ad0ab-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span></span>  

## <a name="tune-the-parallelism-of-the-topology"></a><span data-ttu-id="ad0ab-119">Tune the parallelism of the topology</span><span class="sxs-lookup"><span data-stu-id="ad0ab-119">Tune the parallelism of the topology</span></span>

<span data-ttu-id="ad0ab-120">You might be able to improve performance by increasing the concurrency of the I/O to and from Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-120">You might be able to improve performance by increasing the concurrency of the I/O to and from Data Lake Store.</span></span> <span data-ttu-id="ad0ab-121">A Storm topology has a set of configurations that determine the parallelism:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-121">A Storm topology has a set of configurations that determine the parallelism:</span></span>
* <span data-ttu-id="ad0ab-122">Number of worker processes (the workers are evenly distributed across the VMs).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-122">Number of worker processes (the workers are evenly distributed across the VMs).</span></span>
* <span data-ttu-id="ad0ab-123">Number of spout executor instances.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-123">Number of spout executor instances.</span></span>
* <span data-ttu-id="ad0ab-124">Number of bolt executor instances.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-124">Number of bolt executor instances.</span></span>
* <span data-ttu-id="ad0ab-125">Number of spout tasks.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-125">Number of spout tasks.</span></span>
* <span data-ttu-id="ad0ab-126">Number of bolt tasks.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-126">Number of bolt tasks.</span></span>

<span data-ttu-id="ad0ab-127">For example, on a cluster with 4 VMs and 4 worker processes, 32 spout executors and 32 spout tasks, and 256 bolt executors and 512 bolt tasks, consider the following:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-127">For example, on a cluster with 4 VMs and 4 worker processes, 32 spout executors and 32 spout tasks, and 256 bolt executors and 512 bolt tasks, consider the following:</span></span>

<span data-ttu-id="ad0ab-128">Each supervisor, which is a worker node, has a single worker Java virtual machine (JVM) process.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-128">Each supervisor, which is a worker node, has a single worker Java virtual machine (JVM) process.</span></span> <span data-ttu-id="ad0ab-129">This JVM process manages 4 spout threads and 64 bolt threads.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-129">This JVM process manages 4 spout threads and 64 bolt threads.</span></span> <span data-ttu-id="ad0ab-130">Within each thread, tasks are run sequentially.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-130">Within each thread, tasks are run sequentially.</span></span> <span data-ttu-id="ad0ab-131">With the preceding configuration, each spout thread has 1 task, and each bolt thread has 2 tasks.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-131">With the preceding configuration, each spout thread has 1 task, and each bolt thread has 2 tasks.</span></span>

<span data-ttu-id="ad0ab-132">In Storm, here are the various components involved, and how they affect the level of parallelism you have:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-132">In Storm, here are the various components involved, and how they affect the level of parallelism you have:</span></span>
* <span data-ttu-id="ad0ab-133">The head node (called Nimbus in Storm) is used to submit and manage jobs.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-133">The head node (called Nimbus in Storm) is used to submit and manage jobs.</span></span> <span data-ttu-id="ad0ab-134">These nodes have no impact on the degree of parallelism.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-134">These nodes have no impact on the degree of parallelism.</span></span>
* <span data-ttu-id="ad0ab-135">The supervisor nodes.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-135">The supervisor nodes.</span></span> <span data-ttu-id="ad0ab-136">In HDInsight, this corresponds to a worker node Azure VM.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-136">In HDInsight, this corresponds to a worker node Azure VM.</span></span>
* <span data-ttu-id="ad0ab-137">The worker tasks are Storm processes running in the VMs.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-137">The worker tasks are Storm processes running in the VMs.</span></span> <span data-ttu-id="ad0ab-138">Each worker task corresponds to a JVM instance.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-138">Each worker task corresponds to a JVM instance.</span></span> <span data-ttu-id="ad0ab-139">Storm distributes the number of worker processes you specify to the worker nodes as evenly as possible.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-139">Storm distributes the number of worker processes you specify to the worker nodes as evenly as possible.</span></span>
* <span data-ttu-id="ad0ab-140">Spout and bolt executor instances.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-140">Spout and bolt executor instances.</span></span> <span data-ttu-id="ad0ab-141">Each executor instance corresponds to a thread running within the workers (JVMs).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-141">Each executor instance corresponds to a thread running within the workers (JVMs).</span></span>
* <span data-ttu-id="ad0ab-142">Storm tasks.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-142">Storm tasks.</span></span> <span data-ttu-id="ad0ab-143">These are logical tasks that each of these threads run.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-143">These are logical tasks that each of these threads run.</span></span> <span data-ttu-id="ad0ab-144">This does not change the level of parallelism, so you should evaluate if you need multiple tasks per executor or not.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-144">This does not change the level of parallelism, so you should evaluate if you need multiple tasks per executor or not.</span></span>

### <a name="get-the-best-performance-from-data-lake-store"></a><span data-ttu-id="ad0ab-145">Get the best performance from Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="ad0ab-145">Get the best performance from Data Lake Store</span></span>

<span data-ttu-id="ad0ab-146">When working with Data Lake Store, you get the best performance if you do the following:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-146">When working with Data Lake Store, you get the best performance if you do the following:</span></span>
* <span data-ttu-id="ad0ab-147">Coalesce your small appends into larger sizes (ideally 4 MB).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-147">Coalesce your small appends into larger sizes (ideally 4 MB).</span></span>
* <span data-ttu-id="ad0ab-148">Do as many concurrent requests as you can.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-148">Do as many concurrent requests as you can.</span></span> <span data-ttu-id="ad0ab-149">Because each bolt thread is doing blocking reads, you want to have somewhere in the range of 8-12 threads per core.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-149">Because each bolt thread is doing blocking reads, you want to have somewhere in the range of 8-12 threads per core.</span></span> <span data-ttu-id="ad0ab-150">This keeps the NIC and the CPU well utilized.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-150">This keeps the NIC and the CPU well utilized.</span></span> <span data-ttu-id="ad0ab-151">A larger VM enables more concurrent requests.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-151">A larger VM enables more concurrent requests.</span></span>  

### <a name="example-topology"></a><span data-ttu-id="ad0ab-152">Example topology</span><span class="sxs-lookup"><span data-stu-id="ad0ab-152">Example topology</span></span>

<span data-ttu-id="ad0ab-153">Let’s assume you have an 8 worker node cluster with a D13v2 Azure VM.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-153">Let’s assume you have an 8 worker node cluster with a D13v2 Azure VM.</span></span> <span data-ttu-id="ad0ab-154">This VM has 8 cores, so among the 8 worker nodes, you have 64 total cores.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-154">This VM has 8 cores, so among the 8 worker nodes, you have 64 total cores.</span></span>

<span data-ttu-id="ad0ab-155">Let’s say we do 8 bolt threads per core.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-155">Let’s say we do 8 bolt threads per core.</span></span> <span data-ttu-id="ad0ab-156">Given 64 cores, that means we want 512 total bolt executor instances (that is, threads).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-156">Given 64 cores, that means we want 512 total bolt executor instances (that is, threads).</span></span> <span data-ttu-id="ad0ab-157">In this case, let’s say we start with one JVM per VM, and mainly use the thread concurrency within the JVM to achieve concurrency.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-157">In this case, let’s say we start with one JVM per VM, and mainly use the thread concurrency within the JVM to achieve concurrency.</span></span> <span data-ttu-id="ad0ab-158">That means we need 8 worker tasks (one per Azure VM), and 512 bolt executors.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-158">That means we need 8 worker tasks (one per Azure VM), and 512 bolt executors.</span></span> <span data-ttu-id="ad0ab-159">Given this configuration, Storm tries to distribute the workers evenly across worker nodes (also known as supervisor nodes), giving each worker node 1 JVM.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-159">Given this configuration, Storm tries to distribute the workers evenly across worker nodes (also known as supervisor nodes), giving each worker node 1 JVM.</span></span> <span data-ttu-id="ad0ab-160">Now within the supervisors, Storm tries to distribute the executors evenly between supervisors, giving each supervisor (that is, JVM) 8 threads each.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-160">Now within the supervisors, Storm tries to distribute the executors evenly between supervisors, giving each supervisor (that is, JVM) 8 threads each.</span></span>

## <a name="tune-additional-parameters"></a><span data-ttu-id="ad0ab-161">Tune additional parameters</span><span class="sxs-lookup"><span data-stu-id="ad0ab-161">Tune additional parameters</span></span>
<span data-ttu-id="ad0ab-162">After you have the basic topology, you can consider whether you want to tweak any of the parameters:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-162">After you have the basic topology, you can consider whether you want to tweak any of the parameters:</span></span>
* <span data-ttu-id="ad0ab-163">**Number of JVMs per worker node.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-163">**Number of JVMs per worker node.**</span></span> <span data-ttu-id="ad0ab-164">If you have a large data structure (for example, a lookup table) that you host in memory, each JVM requires a separate copy.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-164">If you have a large data structure (for example, a lookup table) that you host in memory, each JVM requires a separate copy.</span></span> <span data-ttu-id="ad0ab-165">Alternatively, you can use the data structure across many threads if you have fewer JVMs.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-165">Alternatively, you can use the data structure across many threads if you have fewer JVMs.</span></span> <span data-ttu-id="ad0ab-166">For the bolt’s I/O, the number of JVMs does not make as much of a difference as the number of threads added across those JVMs.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-166">For the bolt’s I/O, the number of JVMs does not make as much of a difference as the number of threads added across those JVMs.</span></span> <span data-ttu-id="ad0ab-167">For simplicity, it's a good idea to have one JVM per worker.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-167">For simplicity, it's a good idea to have one JVM per worker.</span></span> <span data-ttu-id="ad0ab-168">Depending on what your bolt is doing or what application processing you require, though, you may need to change this number.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-168">Depending on what your bolt is doing or what application processing you require, though, you may need to change this number.</span></span>
* <span data-ttu-id="ad0ab-169">**Number of spout executors.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-169">**Number of spout executors.**</span></span> <span data-ttu-id="ad0ab-170">Because the preceding example uses bolts for writing to Data Lake Store, the number of spouts is not directly relevant to the bolt performance.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-170">Because the preceding example uses bolts for writing to Data Lake Store, the number of spouts is not directly relevant to the bolt performance.</span></span> <span data-ttu-id="ad0ab-171">However, depending on the amount of processing or I/O happening in the spout, it's a good idea to tune the spouts for best performance.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-171">However, depending on the amount of processing or I/O happening in the spout, it's a good idea to tune the spouts for best performance.</span></span> <span data-ttu-id="ad0ab-172">Ensure that you have enough spouts to be able to keep the bolts busy.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-172">Ensure that you have enough spouts to be able to keep the bolts busy.</span></span> <span data-ttu-id="ad0ab-173">The output rates of the spouts should match the throughput of the bolts.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-173">The output rates of the spouts should match the throughput of the bolts.</span></span> <span data-ttu-id="ad0ab-174">The actual configuration depends on the spout.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-174">The actual configuration depends on the spout.</span></span>
* <span data-ttu-id="ad0ab-175">**Number of tasks.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-175">**Number of tasks.**</span></span> <span data-ttu-id="ad0ab-176">Each bolt runs as a single thread.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-176">Each bolt runs as a single thread.</span></span> <span data-ttu-id="ad0ab-177">Additional tasks per bolt don't provide any additional concurrency.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-177">Additional tasks per bolt don't provide any additional concurrency.</span></span> <span data-ttu-id="ad0ab-178">The only time they are of benefit is if your process of acknowledging the tuple takes a large proportion of your bolt execution time.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-178">The only time they are of benefit is if your process of acknowledging the tuple takes a large proportion of your bolt execution time.</span></span> <span data-ttu-id="ad0ab-179">It's a good idea to group many tuples into a larger append before you send an acknowledgement from the bolt.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-179">It's a good idea to group many tuples into a larger append before you send an acknowledgement from the bolt.</span></span> <span data-ttu-id="ad0ab-180">So, in most cases, multiple tasks provide no additional benefit.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-180">So, in most cases, multiple tasks provide no additional benefit.</span></span>
* <span data-ttu-id="ad0ab-181">**Local or shuffle grouping.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-181">**Local or shuffle grouping.**</span></span> <span data-ttu-id="ad0ab-182">When this setting is enabled, tuples are sent to bolts within the same worker process.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-182">When this setting is enabled, tuples are sent to bolts within the same worker process.</span></span> <span data-ttu-id="ad0ab-183">This reduces inter-process communication and network calls.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-183">This reduces inter-process communication and network calls.</span></span> <span data-ttu-id="ad0ab-184">This is recommended for most topologies.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-184">This is recommended for most topologies.</span></span>

<span data-ttu-id="ad0ab-185">This basic scenario is a good starting point.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-185">This basic scenario is a good starting point.</span></span> <span data-ttu-id="ad0ab-186">Test with your own data to tweak the preceding parameters to achieve optimal performance.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-186">Test with your own data to tweak the preceding parameters to achieve optimal performance.</span></span>

## <a name="tune-the-spout"></a><span data-ttu-id="ad0ab-187">Tune the spout</span><span class="sxs-lookup"><span data-stu-id="ad0ab-187">Tune the spout</span></span>

<span data-ttu-id="ad0ab-188">You can modify the following settings to tune the spout.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-188">You can modify the following settings to tune the spout.</span></span>

- <span data-ttu-id="ad0ab-189">**Tuple timeout: topology.message.timeout.secs**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-189">**Tuple timeout: topology.message.timeout.secs**.</span></span> <span data-ttu-id="ad0ab-190">This setting determines the amount of time a message takes to complete, and receive acknowledgement, before it is considered failed.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-190">This setting determines the amount of time a message takes to complete, and receive acknowledgement, before it is considered failed.</span></span>

- <span data-ttu-id="ad0ab-191">**Max memory per worker process: worker.childopts**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-191">**Max memory per worker process: worker.childopts**.</span></span> <span data-ttu-id="ad0ab-192">This setting lets you specify additional command-line parameters to the Java workers.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-192">This setting lets you specify additional command-line parameters to the Java workers.</span></span> <span data-ttu-id="ad0ab-193">The most commonly used setting here is XmX, which determines the maximum memory allocated to a JVM’s heap.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-193">The most commonly used setting here is XmX, which determines the maximum memory allocated to a JVM’s heap.</span></span>

- <span data-ttu-id="ad0ab-194">**Max spout pending: topology.max.spout.pending**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-194">**Max spout pending: topology.max.spout.pending**.</span></span> <span data-ttu-id="ad0ab-195">This setting determines the number of tuples that can in be flight (not yet acknowledged at all nodes in the topology) per spout thread at any time.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-195">This setting determines the number of tuples that can in be flight (not yet acknowledged at all nodes in the topology) per spout thread at any time.</span></span>

 <span data-ttu-id="ad0ab-196">A good calculation to do is to estimate the size of each of your tuples.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-196">A good calculation to do is to estimate the size of each of your tuples.</span></span> <span data-ttu-id="ad0ab-197">Then figure out how much memory one spout thread has.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-197">Then figure out how much memory one spout thread has.</span></span> <span data-ttu-id="ad0ab-198">The total memory allocated to a thread, divided by this value, should give you the upper bound for the max spout pending parameter.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-198">The total memory allocated to a thread, divided by this value, should give you the upper bound for the max spout pending parameter.</span></span>

## <a name="tune-the-bolt"></a><span data-ttu-id="ad0ab-199">Tune the bolt</span><span class="sxs-lookup"><span data-stu-id="ad0ab-199">Tune the bolt</span></span>
<span data-ttu-id="ad0ab-200">When you're writing to Data Lake Store, set a size sync policy (buffer on the client side) to 4 MB.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-200">When you're writing to Data Lake Store, set a size sync policy (buffer on the client side) to 4 MB.</span></span> <span data-ttu-id="ad0ab-201">A flushing or hsync() is then performed only when the buffer size is the at this value.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-201">A flushing or hsync() is then performed only when the buffer size is the at this value.</span></span> <span data-ttu-id="ad0ab-202">The Data Lake Store driver on the worker VM automatically does this buffering, unless you explicitly perform an hsync().</span><span class="sxs-lookup"><span data-stu-id="ad0ab-202">The Data Lake Store driver on the worker VM automatically does this buffering, unless you explicitly perform an hsync().</span></span>

<span data-ttu-id="ad0ab-203">The default Data Lake Store Storm bolt has a size sync policy parameter (fileBufferSize) that can be used to tune this parameter.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-203">The default Data Lake Store Storm bolt has a size sync policy parameter (fileBufferSize) that can be used to tune this parameter.</span></span>

<span data-ttu-id="ad0ab-204">In I/O-intensive topologies, it's a good idea to have each bolt thread write to its own file, and to set a file rotation policy (fileRotationSize).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-204">In I/O-intensive topologies, it's a good idea to have each bolt thread write to its own file, and to set a file rotation policy (fileRotationSize).</span></span> <span data-ttu-id="ad0ab-205">When the file reaches a certain size, the stream is automatically flushed and a new file is written to.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-205">When the file reaches a certain size, the stream is automatically flushed and a new file is written to.</span></span> <span data-ttu-id="ad0ab-206">The recommended file size for rotation is 1 GB.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-206">The recommended file size for rotation is 1 GB.</span></span>

### <a name="handle-tuple-data"></a><span data-ttu-id="ad0ab-207">Handle tuple data</span><span class="sxs-lookup"><span data-stu-id="ad0ab-207">Handle tuple data</span></span>

<span data-ttu-id="ad0ab-208">In Storm, a spout holds on to a tuple until it is explicitly acknowledged by the bolt.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-208">In Storm, a spout holds on to a tuple until it is explicitly acknowledged by the bolt.</span></span> <span data-ttu-id="ad0ab-209">If a tuple has been read by the bolt but has not been acknowledged yet, the spout might not have persisted into Data Lake Store back end.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-209">If a tuple has been read by the bolt but has not been acknowledged yet, the spout might not have persisted into Data Lake Store back end.</span></span> <span data-ttu-id="ad0ab-210">After a tuple is acknowledged, the spout can be guaranteed persistence by the bolt, and can then delete the source data from whatever source it is reading from.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-210">After a tuple is acknowledged, the spout can be guaranteed persistence by the bolt, and can then delete the source data from whatever source it is reading from.</span></span>  

<span data-ttu-id="ad0ab-211">For best performance on Data Lake Store, have the bolt buffer 4 MB of tuple data.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-211">For best performance on Data Lake Store, have the bolt buffer 4 MB of tuple data.</span></span> <span data-ttu-id="ad0ab-212">Then write to the Data Lake Store back end as one 4-MB write.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-212">Then write to the Data Lake Store back end as one 4-MB write.</span></span> <span data-ttu-id="ad0ab-213">After the data has been successfully written to the store (by calling hflush()), the bolt can acknowledge the data back to the spout.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-213">After the data has been successfully written to the store (by calling hflush()), the bolt can acknowledge the data back to the spout.</span></span> <span data-ttu-id="ad0ab-214">This is what the example bolt supplied here does.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-214">This is what the example bolt supplied here does.</span></span> <span data-ttu-id="ad0ab-215">It is also acceptable to hold a larger number of tuples before the hflush() call is made and the tuples acknowledged.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-215">It is also acceptable to hold a larger number of tuples before the hflush() call is made and the tuples acknowledged.</span></span> <span data-ttu-id="ad0ab-216">However, this increases the number of tuples in flight that the spout needs to hold, and therefore increases the amount of memory required per JVM.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-216">However, this increases the number of tuples in flight that the spout needs to hold, and therefore increases the amount of memory required per JVM.</span></span>

> [!NOTE]
<span data-ttu-id="ad0ab-217">Applications might have a requirement to acknowledge tuples more frequently (at data sizes less than 4 MB) for other non-performance reasons.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-217">Applications might have a requirement to acknowledge tuples more frequently (at data sizes less than 4 MB) for other non-performance reasons.</span></span> <span data-ttu-id="ad0ab-218">However, that might affect the I/O throughput to the storage back end.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-218">However, that might affect the I/O throughput to the storage back end.</span></span> <span data-ttu-id="ad0ab-219">Carefully weigh this tradeoff against the bolt’s I/O performance.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-219">Carefully weigh this tradeoff against the bolt’s I/O performance.</span></span>

<span data-ttu-id="ad0ab-220">If the incoming rate of tuples is not high, so the 4-MB buffer takes a long time to fill, consider mitigating this by:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-220">If the incoming rate of tuples is not high, so the 4-MB buffer takes a long time to fill, consider mitigating this by:</span></span>
* <span data-ttu-id="ad0ab-221">Reducing the number of bolts, so there are fewer buffers to fill.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-221">Reducing the number of bolts, so there are fewer buffers to fill.</span></span>
* <span data-ttu-id="ad0ab-222">Having a time-based or count-based policy, where an hflush() is triggered every x flushes or every y milliseconds, and the tuples accumulated so far are acknowledged back.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-222">Having a time-based or count-based policy, where an hflush() is triggered every x flushes or every y milliseconds, and the tuples accumulated so far are acknowledged back.</span></span>

<span data-ttu-id="ad0ab-223">Note that the throughput in this case is lower, but with a slow rate of events, maximum throughput is not the biggest objective anyway.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-223">Note that the throughput in this case is lower, but with a slow rate of events, maximum throughput is not the biggest objective anyway.</span></span> <span data-ttu-id="ad0ab-224">These mitigations help you reduce the total time that it takes for a tuple to flow through to the store.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-224">These mitigations help you reduce the total time that it takes for a tuple to flow through to the store.</span></span> <span data-ttu-id="ad0ab-225">This might matter if you want a real-time pipeline even with a low event rate.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-225">This might matter if you want a real-time pipeline even with a low event rate.</span></span> <span data-ttu-id="ad0ab-226">Also note that if your incoming tuple rate is low, you should adjust the topology.message.timeout_secs parameter, so the tuples don’t time out while they are getting buffered or processed.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-226">Also note that if your incoming tuple rate is low, you should adjust the topology.message.timeout_secs parameter, so the tuples don’t time out while they are getting buffered or processed.</span></span>

## <a name="monitor-your-topology-in-storm"></a><span data-ttu-id="ad0ab-227">Monitor your topology in Storm</span><span class="sxs-lookup"><span data-stu-id="ad0ab-227">Monitor your topology in Storm</span></span>  
<span data-ttu-id="ad0ab-228">While your topology is running, you can monitor it in the Storm user interface.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-228">While your topology is running, you can monitor it in the Storm user interface.</span></span> <span data-ttu-id="ad0ab-229">Here are the main parameters to look at:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-229">Here are the main parameters to look at:</span></span>

* <span data-ttu-id="ad0ab-230">**Total process execution latency.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-230">**Total process execution latency.**</span></span> <span data-ttu-id="ad0ab-231">This is the average time one tuple takes to be emitted by the spout, processed by the bolt, and acknowledged.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-231">This is the average time one tuple takes to be emitted by the spout, processed by the bolt, and acknowledged.</span></span>

* <span data-ttu-id="ad0ab-232">**Total bolt process latency.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-232">**Total bolt process latency.**</span></span> <span data-ttu-id="ad0ab-233">This is the average time spent by the tuple at the bolt until it receives an acknowledgement.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-233">This is the average time spent by the tuple at the bolt until it receives an acknowledgement.</span></span>

* <span data-ttu-id="ad0ab-234">**Total bolt execute latency.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-234">**Total bolt execute latency.**</span></span> <span data-ttu-id="ad0ab-235">This is the average time spent by the bolt in the execute method.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-235">This is the average time spent by the bolt in the execute method.</span></span>

* <span data-ttu-id="ad0ab-236">**Number of failures.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-236">**Number of failures.**</span></span> <span data-ttu-id="ad0ab-237">This refers to the number of tuples that failed to be fully processed before they timed out.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-237">This refers to the number of tuples that failed to be fully processed before they timed out.</span></span>

* <span data-ttu-id="ad0ab-238">**Capacity.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-238">**Capacity.**</span></span> <span data-ttu-id="ad0ab-239">This is a measure of how busy your system is.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-239">This is a measure of how busy your system is.</span></span> <span data-ttu-id="ad0ab-240">If this number is 1, your bolts are working as fast as they can.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-240">If this number is 1, your bolts are working as fast as they can.</span></span> <span data-ttu-id="ad0ab-241">If it is less than 1, increase the parallelism.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-241">If it is less than 1, increase the parallelism.</span></span> <span data-ttu-id="ad0ab-242">If it is greater than 1, reduce the parallelism.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-242">If it is greater than 1, reduce the parallelism.</span></span>

## <a name="troubleshoot-common-problems"></a><span data-ttu-id="ad0ab-243">Troubleshoot common problems</span><span class="sxs-lookup"><span data-stu-id="ad0ab-243">Troubleshoot common problems</span></span>
<span data-ttu-id="ad0ab-244">Here are a few common troubleshooting scenarios.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-244">Here are a few common troubleshooting scenarios.</span></span>
* <span data-ttu-id="ad0ab-245">**Many tuples are timing out.** Look at each node in the topology to determine where the bottleneck is.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-245">**Many tuples are timing out.** Look at each node in the topology to determine where the bottleneck is.</span></span> <span data-ttu-id="ad0ab-246">The most common reason for this is that the bolts are not able to keep up with the spouts.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-246">The most common reason for this is that the bolts are not able to keep up with the spouts.</span></span> <span data-ttu-id="ad0ab-247">This leads to tuples clogging the internal buffers while waiting to be processed.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-247">This leads to tuples clogging the internal buffers while waiting to be processed.</span></span> <span data-ttu-id="ad0ab-248">Consider increasing the timeout value or decreasing the max spout pending.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-248">Consider increasing the timeout value or decreasing the max spout pending.</span></span>

* <span data-ttu-id="ad0ab-249">**There is a high total process execution latency, but a low bolt process latency.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-249">**There is a high total process execution latency, but a low bolt process latency.**</span></span> <span data-ttu-id="ad0ab-250">In this case, it is possible that the tuples are not being acknowledged fast enough.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-250">In this case, it is possible that the tuples are not being acknowledged fast enough.</span></span> <span data-ttu-id="ad0ab-251">Check that there are a sufficient number of acknowledgers.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-251">Check that there are a sufficient number of acknowledgers.</span></span> <span data-ttu-id="ad0ab-252">Another possibility is that they are waiting in the queue for too long before the bolts start processing them.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-252">Another possibility is that they are waiting in the queue for too long before the bolts start processing them.</span></span> <span data-ttu-id="ad0ab-253">Decrease the max spout pending.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-253">Decrease the max spout pending.</span></span>

* <span data-ttu-id="ad0ab-254">**There is a high bolt execute latency.**</span><span class="sxs-lookup"><span data-stu-id="ad0ab-254">**There is a high bolt execute latency.**</span></span> <span data-ttu-id="ad0ab-255">This means that the execute() method of your bolt is taking too long.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-255">This means that the execute() method of your bolt is taking too long.</span></span> <span data-ttu-id="ad0ab-256">Optimize the code, or look at write sizes and flush behavior.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-256">Optimize the code, or look at write sizes and flush behavior.</span></span>

### <a name="data-lake-store-throttling"></a><span data-ttu-id="ad0ab-257">Data Lake Store throttling</span><span class="sxs-lookup"><span data-stu-id="ad0ab-257">Data Lake Store throttling</span></span>
<span data-ttu-id="ad0ab-258">If you hit the limits of bandwidth provided by Data Lake Store, you might see task failures.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-258">If you hit the limits of bandwidth provided by Data Lake Store, you might see task failures.</span></span> <span data-ttu-id="ad0ab-259">Check task logs for throttling errors.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-259">Check task logs for throttling errors.</span></span> <span data-ttu-id="ad0ab-260">You can decrease the parallelism by increasing container size.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-260">You can decrease the parallelism by increasing container size.</span></span>    

<span data-ttu-id="ad0ab-261">To check if you are getting throttled, enable the debug logging on the client side:</span><span class="sxs-lookup"><span data-stu-id="ad0ab-261">To check if you are getting throttled, enable the debug logging on the client side:</span></span>

1. <span data-ttu-id="ad0ab-262">In **Ambari** > **Storm** > **Config** > **Advanced storm-worker-log4j**, change **&lt;root level="info"&gt;** to **&lt;root level=”debug”&gt;**.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-262">In **Ambari** > **Storm** > **Config** > **Advanced storm-worker-log4j**, change **&lt;root level="info"&gt;** to **&lt;root level=”debug”&gt;**.</span></span> <span data-ttu-id="ad0ab-263">Restart all the nodes/service for the configuration to take effect.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-263">Restart all the nodes/service for the configuration to take effect.</span></span>
2. <span data-ttu-id="ad0ab-264">Monitor the Storm topology logs on worker nodes (under /var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log) for Data Lake Store throttling exceptions.</span><span class="sxs-lookup"><span data-stu-id="ad0ab-264">Monitor the Storm topology logs on worker nodes (under /var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log) for Data Lake Store throttling exceptions.</span></span>

## <a name="next-steps"></a><span data-ttu-id="ad0ab-265">Next steps</span><span class="sxs-lookup"><span data-stu-id="ad0ab-265">Next steps</span></span>
<span data-ttu-id="ad0ab-266">Additional performance tuning for Storm can be referenced in [this blog](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-266">Additional performance tuning for Storm can be referenced in [this blog](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/).</span></span>

<span data-ttu-id="ad0ab-267">For an additional example to run, see [this one on GitHub](https://github.com/hdinsight/storm-performance-automation).</span><span class="sxs-lookup"><span data-stu-id="ad0ab-267">For an additional example to run, see [this one on GitHub](https://github.com/hdinsight/storm-performance-automation).</span></span>
