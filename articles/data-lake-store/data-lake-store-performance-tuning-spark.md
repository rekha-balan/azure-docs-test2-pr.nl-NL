---
title: Azure Data Lake Store Spark Performance Tuning Guidelines | Microsoft Docs
description: Azure Data Lake Store Spark Performance Tuning Guidelines
services: data-lake-store
documentationcenter: ''
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 2109744fb7ffdfafb7a86bbea355e119718af099
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44549276"
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="99608-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="99608-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="99608-104">When tuning performance on Spark, you need to consider the number of apps that will be running on your cluster.</span><span class="sxs-lookup"><span data-stu-id="99608-104">When tuning performance on Spark, you need to consider the number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="99608-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: the default setting is subject to change).</span><span class="sxs-lookup"><span data-stu-id="99608-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: the default setting is subject to change).</span></span>  <span data-ttu-id="99608-106">You may decide to use fewer apps so you can override the default settings and use more of the cluster for those apps.</span><span class="sxs-lookup"><span data-stu-id="99608-106">You may decide to use fewer apps so you can override the default settings and use more of the cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="99608-107">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="99608-107">Prerequisites</span></span>

* <span data-ttu-id="99608-108">**An Azure subscription**.</span><span class="sxs-lookup"><span data-stu-id="99608-108">**An Azure subscription**.</span></span> <span data-ttu-id="99608-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="99608-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="99608-110">**An Azure Data Lake Store account**.</span><span class="sxs-lookup"><span data-stu-id="99608-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="99608-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span><span class="sxs-lookup"><span data-stu-id="99608-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="99608-112">**Azure HDInsight cluster** with access to a Data Lake Store account.</span><span class="sxs-lookup"><span data-stu-id="99608-112">**Azure HDInsight cluster** with access to a Data Lake Store account.</span></span> <span data-ttu-id="99608-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="99608-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="99608-114">Make sure you enable Remote Desktop for the cluster.</span><span class="sxs-lookup"><span data-stu-id="99608-114">Make sure you enable Remote Desktop for the cluster.</span></span>
* <span data-ttu-id="99608-115">**Running Spark cluster on Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="99608-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="99608-116">For more information, see [Use HDInsight Spark cluster to analyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span><span class="sxs-lookup"><span data-stu-id="99608-116">For more information, see [Use HDInsight Spark cluster to analyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="99608-117">**Performance tuning guidelines on ADLS**.</span><span class="sxs-lookup"><span data-stu-id="99608-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="99608-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span><span class="sxs-lookup"><span data-stu-id="99608-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="99608-119">Parameters</span><span class="sxs-lookup"><span data-stu-id="99608-119">Parameters</span></span>

<span data-ttu-id="99608-120">When running Spark jobs, here are the most important settings that can be tuned to increase performance on ADLS:</span><span class="sxs-lookup"><span data-stu-id="99608-120">When running Spark jobs, here are the most important settings that can be tuned to increase performance on ADLS:</span></span>

* <span data-ttu-id="99608-121">**Num-executors** - The number of concurrent tasks that can be executed.</span><span class="sxs-lookup"><span data-stu-id="99608-121">**Num-executors** - The number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="99608-122">**Executor-memory** - The amount of memory allocated to each executor.</span><span class="sxs-lookup"><span data-stu-id="99608-122">**Executor-memory** - The amount of memory allocated to each executor.</span></span>

* <span data-ttu-id="99608-123">**Executor-cores** - The number of cores allocated to each executor.</span><span class="sxs-lookup"><span data-stu-id="99608-123">**Executor-cores** - The number of cores allocated to each executor.</span></span>                     

<span data-ttu-id="99608-124">**Num-executors** Num-executors will set the maximum number of tasks that can run in parallel.</span><span class="sxs-lookup"><span data-stu-id="99608-124">**Num-executors** Num-executors will set the maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="99608-125">The actual number of tasks that can run in parallel is bounded by the memory and CPU resources available in your cluster.</span><span class="sxs-lookup"><span data-stu-id="99608-125">The actual number of tasks that can run in parallel is bounded by the memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="99608-126">**Executor-memory** This is the amount of memory that is being allocated to each executor.</span><span class="sxs-lookup"><span data-stu-id="99608-126">**Executor-memory** This is the amount of memory that is being allocated to each executor.</span></span>  <span data-ttu-id="99608-127">The memory needed for each executor is dependent on the job.</span><span class="sxs-lookup"><span data-stu-id="99608-127">The memory needed for each executor is dependent on the job.</span></span>  <span data-ttu-id="99608-128">For complex operations, the memory needs to be higher.</span><span class="sxs-lookup"><span data-stu-id="99608-128">For complex operations, the memory needs to be higher.</span></span>  <span data-ttu-id="99608-129">For simple operations like read and write, memory requirements will be lower.</span><span class="sxs-lookup"><span data-stu-id="99608-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="99608-130">The amount of memory for each executor can be viewed in Ambari.</span><span class="sxs-lookup"><span data-stu-id="99608-130">The amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="99608-131">In Ambari, navigate to Spark and view the Configs tab.</span><span class="sxs-lookup"><span data-stu-id="99608-131">In Ambari, navigate to Spark and view the Configs tab.</span></span>  

<span data-ttu-id="99608-132">**Executor-cores** This sets the amount of cores used per executor, which determines the number of parallel threads that can be run per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-132">**Executor-cores** This sets the amount of cores used per executor, which determines the number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="99608-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in the executor.</span><span class="sxs-lookup"><span data-stu-id="99608-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in the executor.</span></span>  <span data-ttu-id="99608-134">The executor-cores needed will be dependent on the job.</span><span class="sxs-lookup"><span data-stu-id="99608-134">The executor-cores needed will be dependent on the job.</span></span>  <span data-ttu-id="99608-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span><span class="sxs-lookup"><span data-stu-id="99608-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="99608-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span><span class="sxs-lookup"><span data-stu-id="99608-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="99608-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span><span class="sxs-lookup"><span data-stu-id="99608-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="99608-138">Guidance</span><span class="sxs-lookup"><span data-stu-id="99608-138">Guidance</span></span>

<span data-ttu-id="99608-139">While running Spark analytic workloads to work with data in Data Lake Store, we recommend that you use the most recent HDInsight version to get the best performance with Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="99608-139">While running Spark analytic workloads to work with data in Data Lake Store, we recommend that you use the most recent HDInsight version to get the best performance with Data Lake Store.</span></span> <span data-ttu-id="99608-140">When your job is more I/O intensive, then certain parameters can be configured to improve performance.</span><span class="sxs-lookup"><span data-stu-id="99608-140">When your job is more I/O intensive, then certain parameters can be configured to improve performance.</span></span>  <span data-ttu-id="99608-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span><span class="sxs-lookup"><span data-stu-id="99608-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="99608-142">If the job mainly consists of read or writes, then increasing concurrency for I/O to and from Azure Data Lake Store could increase performance.</span><span class="sxs-lookup"><span data-stu-id="99608-142">If the job mainly consists of read or writes, then increasing concurrency for I/O to and from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="99608-143">There are a few general ways to increase concurrency for I/O intensive jobs.</span><span class="sxs-lookup"><span data-stu-id="99608-143">There are a few general ways to increase concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="99608-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on the cluster including the current one.</span><span class="sxs-lookup"><span data-stu-id="99608-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on the cluster including the current one.</span></span>  <span data-ttu-id="99608-145">The default values for each Spark setting assumes that there are 4 apps running concurrently.</span><span class="sxs-lookup"><span data-stu-id="99608-145">The default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="99608-146">Therefore, you will only have 25% of the cluster available for each app.</span><span class="sxs-lookup"><span data-stu-id="99608-146">Therefore, you will only have 25% of the cluster available for each app.</span></span>  <span data-ttu-id="99608-147">To get better performance, you can override the defaults by changing the number of executors.</span><span class="sxs-lookup"><span data-stu-id="99608-147">To get better performance, you can override the defaults by changing the number of executors.</span></span>  

<span data-ttu-id="99608-148">**Step 2: Set executor-memory** – the first thing to set is the executor-memory.</span><span class="sxs-lookup"><span data-stu-id="99608-148">**Step 2: Set executor-memory** – the first thing to set is the executor-memory.</span></span>  <span data-ttu-id="99608-149">The memory will be dependent on the job that you are going to run.</span><span class="sxs-lookup"><span data-stu-id="99608-149">The memory will be dependent on the job that you are going to run.</span></span>  <span data-ttu-id="99608-150">You can increase concurrency by allocating less memory per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="99608-151">If you see out of memory exceptions when you run your job, then you should increase the value for this parameter.</span><span class="sxs-lookup"><span data-stu-id="99608-151">If you see out of memory exceptions when you run your job, then you should increase the value for this parameter.</span></span>  <span data-ttu-id="99608-152">One alternative is to get more memory by using a cluster that has higher amounts of memory or increasing the size of your cluster.</span><span class="sxs-lookup"><span data-stu-id="99608-152">One alternative is to get more memory by using a cluster that has higher amounts of memory or increasing the size of your cluster.</span></span>  <span data-ttu-id="99608-153">More memory will enable more executors to be used, which means more concurrency.</span><span class="sxs-lookup"><span data-stu-id="99608-153">More memory will enable more executors to be used, which means more concurrency.</span></span>

<span data-ttu-id="99608-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good to start with a high number of executor-cores to increase the number of parallel tasks per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good to start with a high number of executor-cores to increase the number of parallel tasks per executor.</span></span>  <span data-ttu-id="99608-155">Setting executor-cores to 4 is a good start.</span><span class="sxs-lookup"><span data-stu-id="99608-155">Setting executor-cores to 4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="99608-156">Increasing the number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span><span class="sxs-lookup"><span data-stu-id="99608-156">Increasing the number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="99608-157">For jobs that have more complex operations, you should reduce the number of cores per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-157">For jobs that have more complex operations, you should reduce the number of cores per executor.</span></span>  <span data-ttu-id="99608-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span><span class="sxs-lookup"><span data-stu-id="99608-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="99608-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span><span class="sxs-lookup"><span data-stu-id="99608-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="99608-160">Navigate to YARN and view the Configs tab.  The YARN memory is displayed in this window.</span><span class="sxs-lookup"><span data-stu-id="99608-160">Navigate to YARN and view the Configs tab.  The YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="99608-161">Note: while you are in the window, you can also see the default YARN container size.</span><span class="sxs-lookup"><span data-stu-id="99608-161">Note: while you are in the window, you can also see the default YARN container size.</span></span>  <span data-ttu-id="99608-162">The YARN container size is the same as memory per executor paramter.</span><span class="sxs-lookup"><span data-stu-id="99608-162">The YARN container size is the same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="99608-163">**Step 5: Calculate num-executors**</span><span class="sxs-lookup"><span data-stu-id="99608-163">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="99608-164">**Calculate memory constraint** - The num-executors parameter is constrained either by memory or by CPU.</span><span class="sxs-lookup"><span data-stu-id="99608-164">**Calculate memory constraint** - The num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="99608-165">The memory constraint is determined by the amount of available YARN memory for your application.</span><span class="sxs-lookup"><span data-stu-id="99608-165">The memory constraint is determined by the amount of available YARN memory for your application.</span></span>  <span data-ttu-id="99608-166">You should take total YARN memory and divide that by executor-memory.</span><span class="sxs-lookup"><span data-stu-id="99608-166">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="99608-167">The constraint needs to be de-scaled for the number of apps so we divide by the number of apps.</span><span class="sxs-lookup"><span data-stu-id="99608-167">The constraint needs to be de-scaled for the number of apps so we divide by the number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="99608-168">**Calculate CPU constraint** - The CPU constraint is calculated as the total virtual cores divided by the number of cores per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-168">**Calculate CPU constraint** - The CPU constraint is calculated as the total virtual cores divided by the number of cores per executor.</span></span>  <span data-ttu-id="99608-169">There are 2 virtual cores for each physical core.</span><span class="sxs-lookup"><span data-stu-id="99608-169">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="99608-170">Similar to the memory constraint, we have divide by the number of apps.</span><span class="sxs-lookup"><span data-stu-id="99608-170">Similar to the memory constraint, we have divide by the number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="99608-171">**Set num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint.</span><span class="sxs-lookup"><span data-stu-id="99608-171">**Set num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="99608-172">Setting a higher number of num-executors does not necessarily increase performance.</span><span class="sxs-lookup"><span data-stu-id="99608-172">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="99608-173">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span><span class="sxs-lookup"><span data-stu-id="99608-173">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="99608-174">Num-executors is bounded by the cluster resources.</span><span class="sxs-lookup"><span data-stu-id="99608-174">Num-executors is bounded by the cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="99608-175">Example Calculation</span><span class="sxs-lookup"><span data-stu-id="99608-175">Example Calculation</span></span>

<span data-ttu-id="99608-176">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including the one you are going to run.</span><span class="sxs-lookup"><span data-stu-id="99608-176">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including the one you are going to run.</span></span>  

<span data-ttu-id="99608-177">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including the one you are going to run.</span><span class="sxs-lookup"><span data-stu-id="99608-177">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including the one you are going to run.</span></span>  

<span data-ttu-id="99608-178">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span><span class="sxs-lookup"><span data-stu-id="99608-178">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="99608-179">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set the number of cores for each executor to 4.</span><span class="sxs-lookup"><span data-stu-id="99608-179">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set the number of cores for each executor to 4.</span></span>  <span data-ttu-id="99608-180">Setting cores per executor to larger than 4 may cause garbage collection problems.</span><span class="sxs-lookup"><span data-stu-id="99608-180">Setting cores per executor to larger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="99608-181">**Step 4: Determine amount of YARN memory in cluster** – We navigate to Ambari to find out that each D4v2 has 25GB of YARN memory.</span><span class="sxs-lookup"><span data-stu-id="99608-181">**Step 4: Determine amount of YARN memory in cluster** – We navigate to Ambari to find out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="99608-182">Since there are 8 nodes, the available YARN memory is multiplied by 8.</span><span class="sxs-lookup"><span data-stu-id="99608-182">Since there are 8 nodes, the available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="99608-183">**Step 5: Calculate num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint divided by the # of apps running on Spark.</span><span class="sxs-lookup"><span data-stu-id="99608-183">**Step 5: Calculate num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint divided by the # of apps running on Spark.</span></span>    

<span data-ttu-id="99608-184">**Calculate memory constraint** – The memory constraint is calculated as the total YARN memory divided by the memory per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-184">**Calculate memory constraint** – The memory constraint is calculated as the total YARN memory divided by the memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="99608-185">**Calculate CPU constraint** - The CPU constraint is calculated as the total yarn cores divided by the number of cores per executor.</span><span class="sxs-lookup"><span data-stu-id="99608-185">**Calculate CPU constraint** - The CPU constraint is calculated as the total yarn cores divided by the number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="99608-186">**Set num-executors**</span><span class="sxs-lookup"><span data-stu-id="99608-186">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    

