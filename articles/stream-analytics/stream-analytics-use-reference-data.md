---
title: Use reference data and lookup tables in Stream Analytics | Microsoft Docs
description: Use reference data in a Stream Analytics query
keywords: lookup table, reference data
services: stream-analytics
documentationcenter: ''
author: jeffstokes72
manager: jhubbard
editor: cgronlun
ms.assetid: 06103be5-553a-4da1-8a8d-3be9ca2aff54
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 03/28/2017
ms.author: jeffstok
ms.openlocfilehash: b2927931904a2169c3a84737841ee702b10123c1
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44563456"
---
# <a name="using-reference-data-or-lookup-tables-in-a-stream-analytics-input-stream"></a><span data-ttu-id="56f92-104">Using reference data or lookup tables in a Stream Analytics input stream</span><span class="sxs-lookup"><span data-stu-id="56f92-104">Using reference data or lookup tables in a Stream Analytics input stream</span></span>
<span data-ttu-id="56f92-105">Reference data (also known as a lookup table) is a finite data set that is static or slowing changing in nature, used to perform a lookup or to correlate with your data stream.</span><span class="sxs-lookup"><span data-stu-id="56f92-105">Reference data (also known as a lookup table) is a finite data set that is static or slowing changing in nature, used to perform a lookup or to correlate with your data stream.</span></span> <span data-ttu-id="56f92-106">To make use of reference data in your Azure Stream Analytics job, you will generally use a [Reference Data Join](https://msdn.microsoft.com/library/azure/dn949258.aspx) in your Query.</span><span class="sxs-lookup"><span data-stu-id="56f92-106">To make use of reference data in your Azure Stream Analytics job, you will generally use a [Reference Data Join](https://msdn.microsoft.com/library/azure/dn949258.aspx) in your Query.</span></span> <span data-ttu-id="56f92-107">Stream Analytics uses Azure Blob storage as the storage layer for Reference Data, and with Azure Data Factory reference data can be transformed and/or copied to Azure Blob storage, for use as Reference Data, from [any number of cloud-based and on-premises data stores](../data-factory/data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="56f92-107">Stream Analytics uses Azure Blob storage as the storage layer for Reference Data, and with Azure Data Factory reference data can be transformed and/or copied to Azure Blob storage, for use as Reference Data, from [any number of cloud-based and on-premises data stores](../data-factory/data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="56f92-108">Reference data is modeled as a sequence of blobs (defined in the input configuration) in ascending order of the date/time specified in the blob name.</span><span class="sxs-lookup"><span data-stu-id="56f92-108">Reference data is modeled as a sequence of blobs (defined in the input configuration) in ascending order of the date/time specified in the blob name.</span></span> <span data-ttu-id="56f92-109">It **only** supports adding to the end of the sequence by using a date/time **greater** than the one specified by the last blob in the sequence.</span><span class="sxs-lookup"><span data-stu-id="56f92-109">It **only** supports adding to the end of the sequence by using a date/time **greater** than the one specified by the last blob in the sequence.</span></span>

<span data-ttu-id="56f92-110">Stream Analytics has a **limit of 100 MB per blob** but jobs can process multiple reference blobs by using the **path pattern** property.</span><span class="sxs-lookup"><span data-stu-id="56f92-110">Stream Analytics has a **limit of 100 MB per blob** but jobs can process multiple reference blobs by using the **path pattern** property.</span></span>


## <a name="configuring-reference-data"></a><span data-ttu-id="56f92-111">Configuring reference data</span><span class="sxs-lookup"><span data-stu-id="56f92-111">Configuring reference data</span></span>
<span data-ttu-id="56f92-112">To configure your reference data, you first need to create an input that is of type **Reference Data**.</span><span class="sxs-lookup"><span data-stu-id="56f92-112">To configure your reference data, you first need to create an input that is of type **Reference Data**.</span></span> <span data-ttu-id="56f92-113">The table below explains each property that you will need to provide while creating the reference data input with its description:</span><span class="sxs-lookup"><span data-stu-id="56f92-113">The table below explains each property that you will need to provide while creating the reference data input with its description:</span></span>


<table>
<tbody>
<tr>
<td><span data-ttu-id="56f92-114">Property Name</span><span class="sxs-lookup"><span data-stu-id="56f92-114">Property Name</span></span></td>
<td><span data-ttu-id="56f92-115">Description</span><span class="sxs-lookup"><span data-stu-id="56f92-115">Description</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-116">Input Alias</span><span class="sxs-lookup"><span data-stu-id="56f92-116">Input Alias</span></span></td>
<td><span data-ttu-id="56f92-117">A friendly name that will be used in the job query to reference this input.</span><span class="sxs-lookup"><span data-stu-id="56f92-117">A friendly name that will be used in the job query to reference this input.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-118">Storage Account</span><span class="sxs-lookup"><span data-stu-id="56f92-118">Storage Account</span></span></td>
<td><span data-ttu-id="56f92-119">The name of the storage account where your blobs are located.</span><span class="sxs-lookup"><span data-stu-id="56f92-119">The name of the storage account where your blobs are located.</span></span> <span data-ttu-id="56f92-120">If it’s in the same subscription as your Stream Analytics Job, you can select it from the drop-down.</span><span class="sxs-lookup"><span data-stu-id="56f92-120">If it’s in the same subscription as your Stream Analytics Job, you can select it from the drop-down.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-121">Storage Account Key</span><span class="sxs-lookup"><span data-stu-id="56f92-121">Storage Account Key</span></span></td>
<td><span data-ttu-id="56f92-122">The secret key associated with the storage account.</span><span class="sxs-lookup"><span data-stu-id="56f92-122">The secret key associated with the storage account.</span></span> <span data-ttu-id="56f92-123">This gets automatically populated if the storage account is in the same subscription as your Stream Analytics job.</span><span class="sxs-lookup"><span data-stu-id="56f92-123">This gets automatically populated if the storage account is in the same subscription as your Stream Analytics job.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-124">Storage Container</span><span class="sxs-lookup"><span data-stu-id="56f92-124">Storage Container</span></span></td>
<td><span data-ttu-id="56f92-125">Containers provide a logical grouping for blobs stored in the Microsoft Azure Blob service.</span><span class="sxs-lookup"><span data-stu-id="56f92-125">Containers provide a logical grouping for blobs stored in the Microsoft Azure Blob service.</span></span> <span data-ttu-id="56f92-126">When you upload a blob to the Blob service, you must specify a container for that blob.</span><span class="sxs-lookup"><span data-stu-id="56f92-126">When you upload a blob to the Blob service, you must specify a container for that blob.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-127">Path Pattern</span><span class="sxs-lookup"><span data-stu-id="56f92-127">Path Pattern</span></span></td>
<td><span data-ttu-id="56f92-128">The path used to locate your blobs within the specified container.</span><span class="sxs-lookup"><span data-stu-id="56f92-128">The path used to locate your blobs within the specified container.</span></span> <span data-ttu-id="56f92-129">Within the path, you may choose to specify one or more instances of the following 2 variables:</span><span class="sxs-lookup"><span data-stu-id="56f92-129">Within the path, you may choose to specify one or more instances of the following 2 variables:</span></span><BR><span data-ttu-id="56f92-130">{date}, {time}</span><span class="sxs-lookup"><span data-stu-id="56f92-130">{date}, {time}</span></span><BR><span data-ttu-id="56f92-131">Example 1: products/{date}/{time}/product-list.csv</span><span class="sxs-lookup"><span data-stu-id="56f92-131">Example 1: products/{date}/{time}/product-list.csv</span></span><BR><span data-ttu-id="56f92-132">Example 2: products/{date}/product-list.csv</span><span class="sxs-lookup"><span data-stu-id="56f92-132">Example 2: products/{date}/product-list.csv</span></span>
</tr>
<tr>
<td><span data-ttu-id="56f92-133">Date Format [optional]</span><span class="sxs-lookup"><span data-stu-id="56f92-133">Date Format [optional]</span></span></td>
<td><span data-ttu-id="56f92-134">If you have used {date} within the Path Pattern that you specified, then you can select the date format in which your blobs are organized from the drop-down of supported formats.</span><span class="sxs-lookup"><span data-stu-id="56f92-134">If you have used {date} within the Path Pattern that you specified, then you can select the date format in which your blobs are organized from the drop-down of supported formats.</span></span><BR><span data-ttu-id="56f92-135">Example: YYYY/MM/DD, MM/DD/YYYY, etc.</span><span class="sxs-lookup"><span data-stu-id="56f92-135">Example: YYYY/MM/DD, MM/DD/YYYY, etc.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-136">Time Format [optional]</span><span class="sxs-lookup"><span data-stu-id="56f92-136">Time Format [optional]</span></span></td>
<td><span data-ttu-id="56f92-137">If you have used {time} within the Path Pattern that you specified, then you can select the time format in which your blobs are organized from the drop-down of supported formats.</span><span class="sxs-lookup"><span data-stu-id="56f92-137">If you have used {time} within the Path Pattern that you specified, then you can select the time format in which your blobs are organized from the drop-down of supported formats.</span></span><BR><span data-ttu-id="56f92-138">Example: HH, HH/mm, or HH-mm</span><span class="sxs-lookup"><span data-stu-id="56f92-138">Example: HH, HH/mm, or HH-mm</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-139">Event Serialization Format</span><span class="sxs-lookup"><span data-stu-id="56f92-139">Event Serialization Format</span></span></td>
<td><span data-ttu-id="56f92-140">To make sure your queries work the way you expect, Stream Analytics needs to know which serialization format you're using for incoming data streams.</span><span class="sxs-lookup"><span data-stu-id="56f92-140">To make sure your queries work the way you expect, Stream Analytics needs to know which serialization format you're using for incoming data streams.</span></span> <span data-ttu-id="56f92-141">For Reference Data, the supported formats are CSV and JSON.</span><span class="sxs-lookup"><span data-stu-id="56f92-141">For Reference Data, the supported formats are CSV and JSON.</span></span></td>
</tr>
<tr>
<td><span data-ttu-id="56f92-142">Encoding</span><span class="sxs-lookup"><span data-stu-id="56f92-142">Encoding</span></span></td>
<td><span data-ttu-id="56f92-143">UTF-8 is the only supported encoding format at this time</span><span class="sxs-lookup"><span data-stu-id="56f92-143">UTF-8 is the only supported encoding format at this time</span></span></td>
</tr>
</tbody>
</table>

## <a name="generating-reference-data-on-a-schedule"></a><span data-ttu-id="56f92-144">Generating reference data on a schedule</span><span class="sxs-lookup"><span data-stu-id="56f92-144">Generating reference data on a schedule</span></span>
<span data-ttu-id="56f92-145">If your reference data is a slowly changing data set, then support for refreshing reference data is enabled by specifying a path pattern in the input configuration using the {date} and {time} substitution tokens.</span><span class="sxs-lookup"><span data-stu-id="56f92-145">If your reference data is a slowly changing data set, then support for refreshing reference data is enabled by specifying a path pattern in the input configuration using the {date} and {time} substitution tokens.</span></span> <span data-ttu-id="56f92-146">Stream Analytics picks up the updated reference data definitions based on this path pattern.</span><span class="sxs-lookup"><span data-stu-id="56f92-146">Stream Analytics picks up the updated reference data definitions based on this path pattern.</span></span> <span data-ttu-id="56f92-147">For example, a pattern of `sample/{date}/{time}/products.csv` with a date format of **“YYYY-MM-DD”** and a time format of **“HH-mm”** instructs Stream Analytics to pick up the updated blob `sample/2015-04-16/17-30/products.csv` at 5:30 PM on April 16th, 2015 UTC time zone.</span><span class="sxs-lookup"><span data-stu-id="56f92-147">For example, a pattern of `sample/{date}/{time}/products.csv` with a date format of **“YYYY-MM-DD”** and a time format of **“HH-mm”** instructs Stream Analytics to pick up the updated blob `sample/2015-04-16/17-30/products.csv` at 5:30 PM on April 16th, 2015 UTC time zone.</span></span>

> [!NOTE]
> <span data-ttu-id="56f92-148">Currently Stream Analytics jobs look for the blob refresh only when the machine time advances to the time encoded in the blob name.</span><span class="sxs-lookup"><span data-stu-id="56f92-148">Currently Stream Analytics jobs look for the blob refresh only when the machine time advances to the time encoded in the blob name.</span></span> <span data-ttu-id="56f92-149">For example, the job will look for `sample/2015-04-16/17-30/products.csv` as soon as possible but no earlier than 5:30 PM on April 16th, 2015 UTC time zone.</span><span class="sxs-lookup"><span data-stu-id="56f92-149">For example, the job will look for `sample/2015-04-16/17-30/products.csv` as soon as possible but no earlier than 5:30 PM on April 16th, 2015 UTC time zone.</span></span> <span data-ttu-id="56f92-150">It will *never* look for a blob with an encoded time earlier than the last one that is discovered.</span><span class="sxs-lookup"><span data-stu-id="56f92-150">It will *never* look for a blob with an encoded time earlier than the last one that is discovered.</span></span>
> 
> <span data-ttu-id="56f92-151">E.g.</span><span class="sxs-lookup"><span data-stu-id="56f92-151">E.g.</span></span> <span data-ttu-id="56f92-152">once the job finds the blob `sample/2015-04-16/17-30/products.csv` it will ignore any files with an encoded date earlier than 5:30 PM April 16th, 2015 so if a late arriving `sample/2015-04-16/17-25/products.csv` blob gets created in the same container the job will not use it.</span><span class="sxs-lookup"><span data-stu-id="56f92-152">once the job finds the blob `sample/2015-04-16/17-30/products.csv` it will ignore any files with an encoded date earlier than 5:30 PM April 16th, 2015 so if a late arriving `sample/2015-04-16/17-25/products.csv` blob gets created in the same container the job will not use it.</span></span>
> 
> <span data-ttu-id="56f92-153">Likewise if `sample/2015-04-16/17-30/products.csv` is only produced at 10:03 PM April 16th, 2015 but no blob with an earlier date is present in the container, the job will use this file starting at 10:03 PM April 16th, 2015 and use the previous reference data until then.</span><span class="sxs-lookup"><span data-stu-id="56f92-153">Likewise if `sample/2015-04-16/17-30/products.csv` is only produced at 10:03 PM April 16th, 2015 but no blob with an earlier date is present in the container, the job will use this file starting at 10:03 PM April 16th, 2015 and use the previous reference data until then.</span></span>
> 
> <span data-ttu-id="56f92-154">An exception to this is when the job needs to re-process data back in time or when the job is first started.</span><span class="sxs-lookup"><span data-stu-id="56f92-154">An exception to this is when the job needs to re-process data back in time or when the job is first started.</span></span> <span data-ttu-id="56f92-155">At start time the job is looking for the most recent blob produced before the job start time specified.</span><span class="sxs-lookup"><span data-stu-id="56f92-155">At start time the job is looking for the most recent blob produced before the job start time specified.</span></span> <span data-ttu-id="56f92-156">This is done to ensure that there is a **non-empty** reference data set when the job starts.</span><span class="sxs-lookup"><span data-stu-id="56f92-156">This is done to ensure that there is a **non-empty** reference data set when the job starts.</span></span> <span data-ttu-id="56f92-157">If one cannot be found, the job displays the following diagnostic: `Initializing input without a valid reference data blob for UTC time <start time>`.</span><span class="sxs-lookup"><span data-stu-id="56f92-157">If one cannot be found, the job displays the following diagnostic: `Initializing input without a valid reference data blob for UTC time <start time>`.</span></span>
> 
> 

<span data-ttu-id="56f92-158">[Azure Data Factory](https://azure.microsoft.com/documentation/services/data-factory/) can be used to orchestrate the task of creating the updated blobs required by Stream Analytics to update reference data definitions.</span><span class="sxs-lookup"><span data-stu-id="56f92-158">[Azure Data Factory](https://azure.microsoft.com/documentation/services/data-factory/) can be used to orchestrate the task of creating the updated blobs required by Stream Analytics to update reference data definitions.</span></span> <span data-ttu-id="56f92-159">Data Factory is a cloud-based data integration service that orchestrates and automates the movement and transformation of data.</span><span class="sxs-lookup"><span data-stu-id="56f92-159">Data Factory is a cloud-based data integration service that orchestrates and automates the movement and transformation of data.</span></span> <span data-ttu-id="56f92-160">Data Factory supports [connecting to a large number of cloud based and on-premises data stores](../data-factory/data-factory-data-movement-activities.md) and moving data easily on a regular schedule that you specify.</span><span class="sxs-lookup"><span data-stu-id="56f92-160">Data Factory supports [connecting to a large number of cloud based and on-premises data stores](../data-factory/data-factory-data-movement-activities.md) and moving data easily on a regular schedule that you specify.</span></span> <span data-ttu-id="56f92-161">For more information and step by step guidance on how to set up a Data Factory pipeline to generate reference data for Stream Analytics which refreshes on a pre-defined schedule, check out this [GitHub sample](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ReferenceDataRefreshForASAJobs).</span><span class="sxs-lookup"><span data-stu-id="56f92-161">For more information and step by step guidance on how to set up a Data Factory pipeline to generate reference data for Stream Analytics which refreshes on a pre-defined schedule, check out this [GitHub sample](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ReferenceDataRefreshForASAJobs).</span></span>

## <a name="tips-on-refreshing-your-reference-data"></a><span data-ttu-id="56f92-162">Tips on refreshing your reference data</span><span class="sxs-lookup"><span data-stu-id="56f92-162">Tips on refreshing your reference data</span></span>
1. <span data-ttu-id="56f92-163">Overwriting reference data blobs will not cause Stream Analytics to reload the blob and in some cases it can cause the job to fail.</span><span class="sxs-lookup"><span data-stu-id="56f92-163">Overwriting reference data blobs will not cause Stream Analytics to reload the blob and in some cases it can cause the job to fail.</span></span> <span data-ttu-id="56f92-164">The recommended way to change reference data is to add a new blob using the same container and path pattern defined in the job input and use a date/time **greater** than the one specified by the last blob in the sequence.</span><span class="sxs-lookup"><span data-stu-id="56f92-164">The recommended way to change reference data is to add a new blob using the same container and path pattern defined in the job input and use a date/time **greater** than the one specified by the last blob in the sequence.</span></span>
2. <span data-ttu-id="56f92-165">Reference data blobs are **not** ordered by the blob’s “Last Modified” time but only by the time and date specified in the blob name using the {date} and {time} substitutions.</span><span class="sxs-lookup"><span data-stu-id="56f92-165">Reference data blobs are **not** ordered by the blob’s “Last Modified” time but only by the time and date specified in the blob name using the {date} and {time} substitutions.</span></span>
3. <span data-ttu-id="56f92-166">On a few occasions, a job must go back in time, therefore reference data blobs must not be altered or deleted.</span><span class="sxs-lookup"><span data-stu-id="56f92-166">On a few occasions, a job must go back in time, therefore reference data blobs must not be altered or deleted.</span></span>

## <a name="get-help"></a><span data-ttu-id="56f92-167">Get help</span><span class="sxs-lookup"><span data-stu-id="56f92-167">Get help</span></span>
<span data-ttu-id="56f92-168">For further assistance, try our [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics)</span><span class="sxs-lookup"><span data-stu-id="56f92-168">For further assistance, try our [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics)</span></span>

## <a name="next-steps"></a><span data-ttu-id="56f92-169">Next steps</span><span class="sxs-lookup"><span data-stu-id="56f92-169">Next steps</span></span>
<span data-ttu-id="56f92-170">You've been introduced to Stream Analytics, a managed service for streaming analytics on data from the Internet of Things.</span><span class="sxs-lookup"><span data-stu-id="56f92-170">You've been introduced to Stream Analytics, a managed service for streaming analytics on data from the Internet of Things.</span></span> <span data-ttu-id="56f92-171">To learn more about this service, see:</span><span class="sxs-lookup"><span data-stu-id="56f92-171">To learn more about this service, see:</span></span>

* [<span data-ttu-id="56f92-172">Get started using Azure Stream Analytics</span><span class="sxs-lookup"><span data-stu-id="56f92-172">Get started using Azure Stream Analytics</span></span>](stream-analytics-get-started.md)
* [<span data-ttu-id="56f92-173">Scale Azure Stream Analytics jobs</span><span class="sxs-lookup"><span data-stu-id="56f92-173">Scale Azure Stream Analytics jobs</span></span>](stream-analytics-scale-jobs.md)
* [<span data-ttu-id="56f92-174">Azure Stream Analytics Query Language Reference</span><span class="sxs-lookup"><span data-stu-id="56f92-174">Azure Stream Analytics Query Language Reference</span></span>](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [<span data-ttu-id="56f92-175">Azure Stream Analytics Management REST API Reference</span><span class="sxs-lookup"><span data-stu-id="56f92-175">Azure Stream Analytics Management REST API Reference</span></span>](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301
