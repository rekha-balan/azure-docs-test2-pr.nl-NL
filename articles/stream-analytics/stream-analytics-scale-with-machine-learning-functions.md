---
title: Scale Machine Learning functions in Azure Stream Analytics
description: This article describes how to scale Stream Analytics jobs that use Machine Learning functions, by configuring partitioning and stream units.
services: stream-analytics
author: jseb225
ms.author: jeanb
manager: kfile
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/28/2017
ms.openlocfilehash: 115273086eeb88064c4b179f67d2d400d9f84692
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44770477"
---
# <a name="scale-your-stream-analytics-job-with-azure-machine-learning-functions"></a><span data-ttu-id="b5dee-103">Scale your Stream Analytics job with Azure Machine Learning functions</span><span class="sxs-lookup"><span data-stu-id="b5dee-103">Scale your Stream Analytics job with Azure Machine Learning functions</span></span>
<span data-ttu-id="b5dee-104">It is straight forward to set up a Stream Analytics job and run some sample data through it.</span><span class="sxs-lookup"><span data-stu-id="b5dee-104">It is straight forward to set up a Stream Analytics job and run some sample data through it.</span></span> <span data-ttu-id="b5dee-105">What should we do when we need to run the same job with higher data volume?</span><span class="sxs-lookup"><span data-stu-id="b5dee-105">What should we do when we need to run the same job with higher data volume?</span></span> <span data-ttu-id="b5dee-106">It requires us to understand how to configure the Stream Analytics job so that it scales.</span><span class="sxs-lookup"><span data-stu-id="b5dee-106">It requires us to understand how to configure the Stream Analytics job so that it scales.</span></span> <span data-ttu-id="b5dee-107">In this document, we focus on the special aspects of scaling Stream Analytics jobs with Machine Learning functions.</span><span class="sxs-lookup"><span data-stu-id="b5dee-107">In this document, we focus on the special aspects of scaling Stream Analytics jobs with Machine Learning functions.</span></span> <span data-ttu-id="b5dee-108">For information on how to scale Stream Analytics jobs in general see the article [Scaling jobs](stream-analytics-scale-jobs.md).</span><span class="sxs-lookup"><span data-stu-id="b5dee-108">For information on how to scale Stream Analytics jobs in general see the article [Scaling jobs](stream-analytics-scale-jobs.md).</span></span>

## <a name="what-is-an-azure-machine-learning-function-in-stream-analytics"></a><span data-ttu-id="b5dee-109">What is an Azure Machine Learning function in Stream Analytics?</span><span class="sxs-lookup"><span data-stu-id="b5dee-109">What is an Azure Machine Learning function in Stream Analytics?</span></span>
<span data-ttu-id="b5dee-110">A Machine Learning function in Stream Analytics can be used like a regular function call in the Stream Analytics query language.</span><span class="sxs-lookup"><span data-stu-id="b5dee-110">A Machine Learning function in Stream Analytics can be used like a regular function call in the Stream Analytics query language.</span></span> <span data-ttu-id="b5dee-111">However, behind the scene, the function calls are actually Azure Machine Learning Web Service requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-111">However, behind the scene, the function calls are actually Azure Machine Learning Web Service requests.</span></span> <span data-ttu-id="b5dee-112">Machine Learning web services support "batching" multiple rows, which is called mini-batch, in the same web service API call, to improve overall throughput.</span><span class="sxs-lookup"><span data-stu-id="b5dee-112">Machine Learning web services support "batching" multiple rows, which is called mini-batch, in the same web service API call, to improve overall throughput.</span></span> <span data-ttu-id="b5dee-113">For more information, see [Azure Machine Learning functions in Stream Analytics](https://blogs.technet.microsoft.com/machinelearning/2015/12/10/azure-ml-now-available-as-a-function-in-azure-stream-analytics/) and [Azure Machine Learning Web Services](../machine-learning/studio/consume-web-services.md).</span><span class="sxs-lookup"><span data-stu-id="b5dee-113">For more information, see [Azure Machine Learning functions in Stream Analytics](https://blogs.technet.microsoft.com/machinelearning/2015/12/10/azure-ml-now-available-as-a-function-in-azure-stream-analytics/) and [Azure Machine Learning Web Services](../machine-learning/studio/consume-web-services.md).</span></span>

## <a name="configure-a-stream-analytics-job-with-machine-learning-functions"></a><span data-ttu-id="b5dee-114">Configure a Stream Analytics job with Machine Learning functions</span><span class="sxs-lookup"><span data-stu-id="b5dee-114">Configure a Stream Analytics job with Machine Learning functions</span></span>
<span data-ttu-id="b5dee-115">When configuring a Machine Learning function for Stream Analytics job, there are two parameters to consider, the batch size of the Machine Learning function calls, and the streaming units (SUs) provisioned for the Stream Analytics job.</span><span class="sxs-lookup"><span data-stu-id="b5dee-115">When configuring a Machine Learning function for Stream Analytics job, there are two parameters to consider, the batch size of the Machine Learning function calls, and the streaming units (SUs) provisioned for the Stream Analytics job.</span></span> <span data-ttu-id="b5dee-116">To determine the appropriate values for these, first a decision must be made between latency and throughput, that is, latency of the Stream Analytics job, and throughput of each SU.</span><span class="sxs-lookup"><span data-stu-id="b5dee-116">To determine the appropriate values for these, first a decision must be made between latency and throughput, that is, latency of the Stream Analytics job, and throughput of each SU.</span></span> <span data-ttu-id="b5dee-117">SUs may always be added to a job to increase throughput of a well partitioned Stream Analytics query, although additional SUs increase the cost of running the job.</span><span class="sxs-lookup"><span data-stu-id="b5dee-117">SUs may always be added to a job to increase throughput of a well partitioned Stream Analytics query, although additional SUs increase the cost of running the job.</span></span>

<span data-ttu-id="b5dee-118">Therefore it is important to determine the *tolerance* of latency in running a Stream Analytics job.</span><span class="sxs-lookup"><span data-stu-id="b5dee-118">Therefore it is important to determine the *tolerance* of latency in running a Stream Analytics job.</span></span> <span data-ttu-id="b5dee-119">Additional latency from running Azure Machine Learning service requests will naturally increase with batch size, which compounds the latency of the Stream Analytics job.</span><span class="sxs-lookup"><span data-stu-id="b5dee-119">Additional latency from running Azure Machine Learning service requests will naturally increase with batch size, which compounds the latency of the Stream Analytics job.</span></span> <span data-ttu-id="b5dee-120">On the other hand, increasing batch size allows the Stream Analytics job to process \*more events with the *same number* of Machine Learning web service requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-120">On the other hand, increasing batch size allows the Stream Analytics job to process \*more events with the *same number* of Machine Learning web service requests.</span></span> <span data-ttu-id="b5dee-121">Often the increase of Machine Learning web service latency is sublinear to the increase of batch size so it is important to consider the most cost-efficient batch size for a Machine Learning web service in any given situation.</span><span class="sxs-lookup"><span data-stu-id="b5dee-121">Often the increase of Machine Learning web service latency is sublinear to the increase of batch size so it is important to consider the most cost-efficient batch size for a Machine Learning web service in any given situation.</span></span> <span data-ttu-id="b5dee-122">The default batch size for the web service requests is 1000 and may be modified either by using the [Stream Analytics REST API](https://msdn.microsoft.com/library/mt653706.aspx "Stream Analytics REST API") or the [PowerShell client for Stream Analytics](stream-analytics-monitor-and-manage-jobs-use-powershell.md "PowerShell client for Stream Analytics").</span><span class="sxs-lookup"><span data-stu-id="b5dee-122">The default batch size for the web service requests is 1000 and may be modified either by using the [Stream Analytics REST API](https://msdn.microsoft.com/library/mt653706.aspx "Stream Analytics REST API") or the [PowerShell client for Stream Analytics](stream-analytics-monitor-and-manage-jobs-use-powershell.md "PowerShell client for Stream Analytics").</span></span>

<span data-ttu-id="b5dee-123">Once a batch size has been determined, the number of streaming units (SUs) can be determined, based on the number of events that the function needs to process per second.</span><span class="sxs-lookup"><span data-stu-id="b5dee-123">Once a batch size has been determined, the number of streaming units (SUs) can be determined, based on the number of events that the function needs to process per second.</span></span> <span data-ttu-id="b5dee-124">For more information about streaming units, see [Stream Analytics scale jobs](stream-analytics-scale-jobs.md).</span><span class="sxs-lookup"><span data-stu-id="b5dee-124">For more information about streaming units, see [Stream Analytics scale jobs](stream-analytics-scale-jobs.md).</span></span>

<span data-ttu-id="b5dee-125">In general, there are 20 concurrent connections to the Machine Learning web service for every 6 SUs, except that 1 SU jobs and 3 SU jobs get 20 concurrent connections also.</span><span class="sxs-lookup"><span data-stu-id="b5dee-125">In general, there are 20 concurrent connections to the Machine Learning web service for every 6 SUs, except that 1 SU jobs and 3 SU jobs get 20 concurrent connections also.</span></span>  <span data-ttu-id="b5dee-126">For example, if the input data rate is 200,000 events per second and the batch size is left to the default of 1000 the resulting web service latency with 1000 events mini-batch is 200 ms.</span><span class="sxs-lookup"><span data-stu-id="b5dee-126">For example, if the input data rate is 200,000 events per second and the batch size is left to the default of 1000 the resulting web service latency with 1000 events mini-batch is 200 ms.</span></span> <span data-ttu-id="b5dee-127">This means every connection can make five requests to the Machine Learning web service in a second.</span><span class="sxs-lookup"><span data-stu-id="b5dee-127">This means every connection can make five requests to the Machine Learning web service in a second.</span></span> <span data-ttu-id="b5dee-128">With 20 connections, the Stream Analytics job can process 20,000 events in 200 ms  and therefore 100,000 events in a second.</span><span class="sxs-lookup"><span data-stu-id="b5dee-128">With 20 connections, the Stream Analytics job can process 20,000 events in 200 ms  and therefore 100,000 events in a second.</span></span> <span data-ttu-id="b5dee-129">So to process 200,000 events per second, the Stream Analytics job needs 40 concurrent connections, which come out to 12 SUs.</span><span class="sxs-lookup"><span data-stu-id="b5dee-129">So to process 200,000 events per second, the Stream Analytics job needs 40 concurrent connections, which come out to 12 SUs.</span></span> <span data-ttu-id="b5dee-130">The following diagram illustrates the requests from the Stream Analytics job to the Machine Learning web service endpoint – Every 6 SUs has 20 concurrent connections to Machine Learning web service at max.</span><span class="sxs-lookup"><span data-stu-id="b5dee-130">The following diagram illustrates the requests from the Stream Analytics job to the Machine Learning web service endpoint – Every 6 SUs has 20 concurrent connections to Machine Learning web service at max.</span></span>

<span data-ttu-id="b5dee-131">![Scale Stream Analytics with Machine Learning Functions two job example](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-00.png "Scale Stream Analytics with Machine Learning Functions two job example")</span><span class="sxs-lookup"><span data-stu-id="b5dee-131">![Scale Stream Analytics with Machine Learning Functions two job example](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-00.png "Scale Stream Analytics with Machine Learning Functions two job example")</span></span>

<span data-ttu-id="b5dee-132">In general, ***B*** for batch size, ***L*** for the web service latency at batch size B in milliseconds, the throughput of a Stream Analytics job with ***N*** SUs is:</span><span class="sxs-lookup"><span data-stu-id="b5dee-132">In general, ***B*** for batch size, ***L*** for the web service latency at batch size B in milliseconds, the throughput of a Stream Analytics job with ***N*** SUs is:</span></span>

<span data-ttu-id="b5dee-133">![Scale Stream Analytics with Machine Learning Functions Formula](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-02.png "Scale Stream Analytics with Machine Learning Functions Formula")</span><span class="sxs-lookup"><span data-stu-id="b5dee-133">![Scale Stream Analytics with Machine Learning Functions Formula](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-02.png "Scale Stream Analytics with Machine Learning Functions Formula")</span></span>

<span data-ttu-id="b5dee-134">An additional consideration may be the 'max concurrent calls' on the Machine Learning web service side, it’s recommended to set this to the maximum value (200 currently).</span><span class="sxs-lookup"><span data-stu-id="b5dee-134">An additional consideration may be the 'max concurrent calls' on the Machine Learning web service side, it’s recommended to set this to the maximum value (200 currently).</span></span>

<span data-ttu-id="b5dee-135">For more information on this setting please review the [Scaling article for Machine Learning Web Services](../machine-learning/studio/scaling-webservice.md).</span><span class="sxs-lookup"><span data-stu-id="b5dee-135">For more information on this setting please review the [Scaling article for Machine Learning Web Services](../machine-learning/studio/scaling-webservice.md).</span></span>

## <a name="example--sentiment-analysis"></a><span data-ttu-id="b5dee-136">Example – Sentiment Analysis</span><span class="sxs-lookup"><span data-stu-id="b5dee-136">Example – Sentiment Analysis</span></span>
<span data-ttu-id="b5dee-137">The following example includes a Stream Analytics job with the sentiment analysis Machine Learning function, as described in the [Stream Analytics Machine Learning integration tutorial](stream-analytics-machine-learning-integration-tutorial.md).</span><span class="sxs-lookup"><span data-stu-id="b5dee-137">The following example includes a Stream Analytics job with the sentiment analysis Machine Learning function, as described in the [Stream Analytics Machine Learning integration tutorial](stream-analytics-machine-learning-integration-tutorial.md).</span></span>

<span data-ttu-id="b5dee-138">The query is a simple fully partitioned query followed by the **sentiment** function, as shown following:</span><span class="sxs-lookup"><span data-stu-id="b5dee-138">The query is a simple fully partitioned query followed by the **sentiment** function, as shown following:</span></span>

    WITH subquery AS (
        SELECT text, sentiment(text) as result from input
    )

    Select text, result.[Score]
    Into output
    From subquery

<span data-ttu-id="b5dee-139">Consider the following scenario; with a throughput of 10,000 tweets per second a Stream Analytics job must be created to perform sentiment analysis of the tweets (events).</span><span class="sxs-lookup"><span data-stu-id="b5dee-139">Consider the following scenario; with a throughput of 10,000 tweets per second a Stream Analytics job must be created to perform sentiment analysis of the tweets (events).</span></span> <span data-ttu-id="b5dee-140">Using 1 SU, could this Stream Analytics job be able to handle the traffic?</span><span class="sxs-lookup"><span data-stu-id="b5dee-140">Using 1 SU, could this Stream Analytics job be able to handle the traffic?</span></span> <span data-ttu-id="b5dee-141">Using the default batch size of 1000 the job should be able to keep up with the input.</span><span class="sxs-lookup"><span data-stu-id="b5dee-141">Using the default batch size of 1000 the job should be able to keep up with the input.</span></span> <span data-ttu-id="b5dee-142">Further the added Machine Learning function should generate no more than a second of latency, which is the general default latency of the sentiment analysis Machine Learning web service (with a default batch size of 1000).</span><span class="sxs-lookup"><span data-stu-id="b5dee-142">Further the added Machine Learning function should generate no more than a second of latency, which is the general default latency of the sentiment analysis Machine Learning web service (with a default batch size of 1000).</span></span> <span data-ttu-id="b5dee-143">The Stream Analytics job’s **overall** or end-to-end latency would typically be a few seconds.</span><span class="sxs-lookup"><span data-stu-id="b5dee-143">The Stream Analytics job’s **overall** or end-to-end latency would typically be a few seconds.</span></span> <span data-ttu-id="b5dee-144">Take a more detailed look into this Stream Analytics job, *especially* the Machine Learning function calls.</span><span class="sxs-lookup"><span data-stu-id="b5dee-144">Take a more detailed look into this Stream Analytics job, *especially* the Machine Learning function calls.</span></span> <span data-ttu-id="b5dee-145">Having the batch size as 1000, a throughput of 10,000 events take about 10 requests to web service.</span><span class="sxs-lookup"><span data-stu-id="b5dee-145">Having the batch size as 1000, a throughput of 10,000 events take about 10 requests to web service.</span></span> <span data-ttu-id="b5dee-146">Even with 1 SU, there are enough concurrent connections to accommodate this input traffic.</span><span class="sxs-lookup"><span data-stu-id="b5dee-146">Even with 1 SU, there are enough concurrent connections to accommodate this input traffic.</span></span>

<span data-ttu-id="b5dee-147">If the input event rate increases by 100x, then the Stream Analytics job needs to process 1,000,000 tweets per second.</span><span class="sxs-lookup"><span data-stu-id="b5dee-147">If the input event rate increases by 100x, then the Stream Analytics job needs to process 1,000,000 tweets per second.</span></span> <span data-ttu-id="b5dee-148">There are two options to accomplish the increased scale:</span><span class="sxs-lookup"><span data-stu-id="b5dee-148">There are two options to accomplish the increased scale:</span></span>

1. <span data-ttu-id="b5dee-149">Increase the batch size, or</span><span class="sxs-lookup"><span data-stu-id="b5dee-149">Increase the batch size, or</span></span>
2. <span data-ttu-id="b5dee-150">Partition the input stream to process the events in parallel</span><span class="sxs-lookup"><span data-stu-id="b5dee-150">Partition the input stream to process the events in parallel</span></span>

<span data-ttu-id="b5dee-151">With the first option, the job **latency** increases.</span><span class="sxs-lookup"><span data-stu-id="b5dee-151">With the first option, the job **latency** increases.</span></span>

<span data-ttu-id="b5dee-152">With the second option, more SUs would need to be provisioned and therefore generate more concurrent Machine Learning web service requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-152">With the second option, more SUs would need to be provisioned and therefore generate more concurrent Machine Learning web service requests.</span></span> <span data-ttu-id="b5dee-153">This means the job **cost** increases.</span><span class="sxs-lookup"><span data-stu-id="b5dee-153">This means the job **cost** increases.</span></span>

<span data-ttu-id="b5dee-154">Assume the latency of the sentiment analysis Machine Learning web service is 200 ms for 1000-event batches or below, 250 ms for 5,000-event batches, 300 ms for 10,000-event batches or 500 ms for 25,000-event batches.</span><span class="sxs-lookup"><span data-stu-id="b5dee-154">Assume the latency of the sentiment analysis Machine Learning web service is 200 ms for 1000-event batches or below, 250 ms for 5,000-event batches, 300 ms for 10,000-event batches or 500 ms for 25,000-event batches.</span></span>

1. <span data-ttu-id="b5dee-155">Using the first option (**not** provisioning more SUs).</span><span class="sxs-lookup"><span data-stu-id="b5dee-155">Using the first option (**not** provisioning more SUs).</span></span> <span data-ttu-id="b5dee-156">The batch size could be increased to **25,000**.</span><span class="sxs-lookup"><span data-stu-id="b5dee-156">The batch size could be increased to **25,000**.</span></span> <span data-ttu-id="b5dee-157">This in turn would allow the job to process 1,000,000 events with 20 concurrent connections to the Machine Learning web service (with a latency of 500 ms per call).</span><span class="sxs-lookup"><span data-stu-id="b5dee-157">This in turn would allow the job to process 1,000,000 events with 20 concurrent connections to the Machine Learning web service (with a latency of 500 ms per call).</span></span> <span data-ttu-id="b5dee-158">So the additional latency of the Stream Analytics job due to the sentiment function requests against the Machine Learning web service requests would be increased from **200 ms** to **500 ms**.</span><span class="sxs-lookup"><span data-stu-id="b5dee-158">So the additional latency of the Stream Analytics job due to the sentiment function requests against the Machine Learning web service requests would be increased from **200 ms** to **500 ms**.</span></span> <span data-ttu-id="b5dee-159">However, batch size **cannot** be increased infinitely as the Machine Learning web services requires the payload size of a request be 4 MB or smaller web service requests timeout after 100 seconds of operation.</span><span class="sxs-lookup"><span data-stu-id="b5dee-159">However, batch size **cannot** be increased infinitely as the Machine Learning web services requires the payload size of a request be 4 MB or smaller web service requests timeout after 100 seconds of operation.</span></span>
2. <span data-ttu-id="b5dee-160">Using the second option, the batch size is left at 1000, with 200 ms web service latency, every 20 concurrent connections to the web service would be able to process 1000 \* 20 \* 5 events = 100,000 per second.</span><span class="sxs-lookup"><span data-stu-id="b5dee-160">Using the second option, the batch size is left at 1000, with 200 ms web service latency, every 20 concurrent connections to the web service would be able to process 1000 \* 20 \* 5 events = 100,000 per second.</span></span> <span data-ttu-id="b5dee-161">So to process 1,000,000 events per second, the job would need 60 SUs.</span><span class="sxs-lookup"><span data-stu-id="b5dee-161">So to process 1,000,000 events per second, the job would need 60 SUs.</span></span> <span data-ttu-id="b5dee-162">Compared to the first option, Stream Analytics job would make more web service batch requests, in turn generating an increased cost.</span><span class="sxs-lookup"><span data-stu-id="b5dee-162">Compared to the first option, Stream Analytics job would make more web service batch requests, in turn generating an increased cost.</span></span>

<span data-ttu-id="b5dee-163">Below is a table for the throughput of the Stream Analytics job for different SUs and batch sizes (in number of events per second).</span><span class="sxs-lookup"><span data-stu-id="b5dee-163">Below is a table for the throughput of the Stream Analytics job for different SUs and batch sizes (in number of events per second).</span></span>

| <span data-ttu-id="b5dee-164">batch size (ML latency)</span><span class="sxs-lookup"><span data-stu-id="b5dee-164">batch size (ML latency)</span></span> | <span data-ttu-id="b5dee-165">500 (200 ms)</span><span class="sxs-lookup"><span data-stu-id="b5dee-165">500 (200 ms)</span></span> | <span data-ttu-id="b5dee-166">1,000 (200 ms)</span><span class="sxs-lookup"><span data-stu-id="b5dee-166">1,000 (200 ms)</span></span> | <span data-ttu-id="b5dee-167">5,000 (250 ms)</span><span class="sxs-lookup"><span data-stu-id="b5dee-167">5,000 (250 ms)</span></span> | <span data-ttu-id="b5dee-168">10,000 (300 ms)</span><span class="sxs-lookup"><span data-stu-id="b5dee-168">10,000 (300 ms)</span></span> | <span data-ttu-id="b5dee-169">25,000 (500 ms)</span><span class="sxs-lookup"><span data-stu-id="b5dee-169">25,000 (500 ms)</span></span> |
| --- | --- | --- | --- | --- | --- |
| <span data-ttu-id="b5dee-170">**1 SU**</span><span class="sxs-lookup"><span data-stu-id="b5dee-170">**1 SU**</span></span> |<span data-ttu-id="b5dee-171">2,500</span><span class="sxs-lookup"><span data-stu-id="b5dee-171">2,500</span></span> |<span data-ttu-id="b5dee-172">5,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-172">5,000</span></span> |<span data-ttu-id="b5dee-173">20,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-173">20,000</span></span> |<span data-ttu-id="b5dee-174">30,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-174">30,000</span></span> |<span data-ttu-id="b5dee-175">50,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-175">50,000</span></span> |
| <span data-ttu-id="b5dee-176">**3 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-176">**3 SUs**</span></span> |<span data-ttu-id="b5dee-177">2,500</span><span class="sxs-lookup"><span data-stu-id="b5dee-177">2,500</span></span> |<span data-ttu-id="b5dee-178">5,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-178">5,000</span></span> |<span data-ttu-id="b5dee-179">20,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-179">20,000</span></span> |<span data-ttu-id="b5dee-180">30,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-180">30,000</span></span> |<span data-ttu-id="b5dee-181">50,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-181">50,000</span></span> |
| <span data-ttu-id="b5dee-182">**6 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-182">**6 SUs**</span></span> |<span data-ttu-id="b5dee-183">2,500</span><span class="sxs-lookup"><span data-stu-id="b5dee-183">2,500</span></span> |<span data-ttu-id="b5dee-184">5,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-184">5,000</span></span> |<span data-ttu-id="b5dee-185">20,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-185">20,000</span></span> |<span data-ttu-id="b5dee-186">30,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-186">30,000</span></span> |<span data-ttu-id="b5dee-187">50,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-187">50,000</span></span> |
| <span data-ttu-id="b5dee-188">**12 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-188">**12 SUs**</span></span> |<span data-ttu-id="b5dee-189">5,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-189">5,000</span></span> |<span data-ttu-id="b5dee-190">10,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-190">10,000</span></span> |<span data-ttu-id="b5dee-191">40,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-191">40,000</span></span> |<span data-ttu-id="b5dee-192">60,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-192">60,000</span></span> |<span data-ttu-id="b5dee-193">100,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-193">100,000</span></span> |
| <span data-ttu-id="b5dee-194">**18 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-194">**18 SUs**</span></span> |<span data-ttu-id="b5dee-195">7,500</span><span class="sxs-lookup"><span data-stu-id="b5dee-195">7,500</span></span> |<span data-ttu-id="b5dee-196">15,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-196">15,000</span></span> |<span data-ttu-id="b5dee-197">60,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-197">60,000</span></span> |<span data-ttu-id="b5dee-198">90,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-198">90,000</span></span> |<span data-ttu-id="b5dee-199">150,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-199">150,000</span></span> |
| <span data-ttu-id="b5dee-200">**24 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-200">**24 SUs**</span></span> |<span data-ttu-id="b5dee-201">10,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-201">10,000</span></span> |<span data-ttu-id="b5dee-202">20,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-202">20,000</span></span> |<span data-ttu-id="b5dee-203">80,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-203">80,000</span></span> |<span data-ttu-id="b5dee-204">120,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-204">120,000</span></span> |<span data-ttu-id="b5dee-205">200,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-205">200,000</span></span> |
| <span data-ttu-id="b5dee-206">**…**</span><span class="sxs-lookup"><span data-stu-id="b5dee-206">**…**</span></span> |<span data-ttu-id="b5dee-207">…</span><span class="sxs-lookup"><span data-stu-id="b5dee-207">…</span></span> |<span data-ttu-id="b5dee-208">…</span><span class="sxs-lookup"><span data-stu-id="b5dee-208">…</span></span> |<span data-ttu-id="b5dee-209">…</span><span class="sxs-lookup"><span data-stu-id="b5dee-209">…</span></span> |<span data-ttu-id="b5dee-210">…</span><span class="sxs-lookup"><span data-stu-id="b5dee-210">…</span></span> |<span data-ttu-id="b5dee-211">…</span><span class="sxs-lookup"><span data-stu-id="b5dee-211">…</span></span> |
| <span data-ttu-id="b5dee-212">**60 SUs**</span><span class="sxs-lookup"><span data-stu-id="b5dee-212">**60 SUs**</span></span> |<span data-ttu-id="b5dee-213">25,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-213">25,000</span></span> |<span data-ttu-id="b5dee-214">50,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-214">50,000</span></span> |<span data-ttu-id="b5dee-215">200,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-215">200,000</span></span> |<span data-ttu-id="b5dee-216">300,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-216">300,000</span></span> |<span data-ttu-id="b5dee-217">500,000</span><span class="sxs-lookup"><span data-stu-id="b5dee-217">500,000</span></span> |

<span data-ttu-id="b5dee-218">By now, you should already have a good understanding of how Machine Learning functions in Stream Analytics work.</span><span class="sxs-lookup"><span data-stu-id="b5dee-218">By now, you should already have a good understanding of how Machine Learning functions in Stream Analytics work.</span></span> <span data-ttu-id="b5dee-219">You likely also understand that Stream Analytics jobs "pull" data from data sources and each "pull" returns a batch of events for the Stream Analytics job to process.</span><span class="sxs-lookup"><span data-stu-id="b5dee-219">You likely also understand that Stream Analytics jobs "pull" data from data sources and each "pull" returns a batch of events for the Stream Analytics job to process.</span></span> <span data-ttu-id="b5dee-220">How does this pull model impact the Machine Learning web service requests?</span><span class="sxs-lookup"><span data-stu-id="b5dee-220">How does this pull model impact the Machine Learning web service requests?</span></span>

<span data-ttu-id="b5dee-221">Normally, the batch size we set for Machine Learning functions won’t exactly be divisible by the number of events returned by each Stream Analytics job "pull".</span><span class="sxs-lookup"><span data-stu-id="b5dee-221">Normally, the batch size we set for Machine Learning functions won’t exactly be divisible by the number of events returned by each Stream Analytics job "pull".</span></span> <span data-ttu-id="b5dee-222">When this occurs the Machine Learning web service is called with "partial" batches.</span><span class="sxs-lookup"><span data-stu-id="b5dee-222">When this occurs the Machine Learning web service is called with "partial" batches.</span></span> <span data-ttu-id="b5dee-223">This is done to not incur additional job latency overhead in coalescing events from pull to pull.</span><span class="sxs-lookup"><span data-stu-id="b5dee-223">This is done to not incur additional job latency overhead in coalescing events from pull to pull.</span></span>

## <a name="new-function-related-monitoring-metrics"></a><span data-ttu-id="b5dee-224">New function-related monitoring metrics</span><span class="sxs-lookup"><span data-stu-id="b5dee-224">New function-related monitoring metrics</span></span>
<span data-ttu-id="b5dee-225">In the Monitor area of a Stream Analytics job, three additional function-related metrics have been added.</span><span class="sxs-lookup"><span data-stu-id="b5dee-225">In the Monitor area of a Stream Analytics job, three additional function-related metrics have been added.</span></span> <span data-ttu-id="b5dee-226">They are FUNCTION REQUESTS, FUNCTION EVENTS and FAILED FUNCTION REQUESTS, as shown in the graphic below.</span><span class="sxs-lookup"><span data-stu-id="b5dee-226">They are FUNCTION REQUESTS, FUNCTION EVENTS and FAILED FUNCTION REQUESTS, as shown in the graphic below.</span></span>

<span data-ttu-id="b5dee-227">![Scale Stream Analytics with Machine Learning Functions Metrics](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-01.png "Scale Stream Analytics with Machine Learning Functions Metrics")</span><span class="sxs-lookup"><span data-stu-id="b5dee-227">![Scale Stream Analytics with Machine Learning Functions Metrics](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-01.png "Scale Stream Analytics with Machine Learning Functions Metrics")</span></span>

<span data-ttu-id="b5dee-228">The are defined as follows:</span><span class="sxs-lookup"><span data-stu-id="b5dee-228">The are defined as follows:</span></span>

<span data-ttu-id="b5dee-229">**FUNCTION REQUESTS**: The number of function requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-229">**FUNCTION REQUESTS**: The number of function requests.</span></span>

<span data-ttu-id="b5dee-230">**FUNCTION EVENTS**: The number events in the function requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-230">**FUNCTION EVENTS**: The number events in the function requests.</span></span>

<span data-ttu-id="b5dee-231">**FAILED FUNCTION REQUESTS**: The number of failed function requests.</span><span class="sxs-lookup"><span data-stu-id="b5dee-231">**FAILED FUNCTION REQUESTS**: The number of failed function requests.</span></span>

## <a name="key-takeaways"></a><span data-ttu-id="b5dee-232">Key Takeaways</span><span class="sxs-lookup"><span data-stu-id="b5dee-232">Key Takeaways</span></span>
<span data-ttu-id="b5dee-233">To summarize the main points, in order to scale a Stream Analytics job with Machine Learning functions, the following items must be considered:</span><span class="sxs-lookup"><span data-stu-id="b5dee-233">To summarize the main points, in order to scale a Stream Analytics job with Machine Learning functions, the following items must be considered:</span></span>

1. <span data-ttu-id="b5dee-234">The input event rate</span><span class="sxs-lookup"><span data-stu-id="b5dee-234">The input event rate</span></span>
2. <span data-ttu-id="b5dee-235">The tolerated latency for the running Stream Analytics job (and thus the batch size of the Machine Learning web service requests)</span><span class="sxs-lookup"><span data-stu-id="b5dee-235">The tolerated latency for the running Stream Analytics job (and thus the batch size of the Machine Learning web service requests)</span></span>
3. <span data-ttu-id="b5dee-236">The provisioned Stream Analytics SUs and the number of Machine Learning web service requests (the additional function-related costs)</span><span class="sxs-lookup"><span data-stu-id="b5dee-236">The provisioned Stream Analytics SUs and the number of Machine Learning web service requests (the additional function-related costs)</span></span>

<span data-ttu-id="b5dee-237">A fully partitioned Stream Analytics query was used as an example.</span><span class="sxs-lookup"><span data-stu-id="b5dee-237">A fully partitioned Stream Analytics query was used as an example.</span></span> <span data-ttu-id="b5dee-238">If a more complex query is needed the [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics) is a great resource for getting additional help from the Stream Analytics team.</span><span class="sxs-lookup"><span data-stu-id="b5dee-238">If a more complex query is needed the [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics) is a great resource for getting additional help from the Stream Analytics team.</span></span>

## <a name="next-steps"></a><span data-ttu-id="b5dee-239">Next steps</span><span class="sxs-lookup"><span data-stu-id="b5dee-239">Next steps</span></span>
<span data-ttu-id="b5dee-240">To learn more about Stream Analytics, see:</span><span class="sxs-lookup"><span data-stu-id="b5dee-240">To learn more about Stream Analytics, see:</span></span>

* [<span data-ttu-id="b5dee-241">Get started using Azure Stream Analytics</span><span class="sxs-lookup"><span data-stu-id="b5dee-241">Get started using Azure Stream Analytics</span></span>](stream-analytics-real-time-fraud-detection.md)
* [<span data-ttu-id="b5dee-242">Scale Azure Stream Analytics jobs</span><span class="sxs-lookup"><span data-stu-id="b5dee-242">Scale Azure Stream Analytics jobs</span></span>](stream-analytics-scale-jobs.md)
* [<span data-ttu-id="b5dee-243">Azure Stream Analytics Query Language Reference</span><span class="sxs-lookup"><span data-stu-id="b5dee-243">Azure Stream Analytics Query Language Reference</span></span>](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [<span data-ttu-id="b5dee-244">Azure Stream Analytics Management REST API Reference</span><span class="sxs-lookup"><span data-stu-id="b5dee-244">Azure Stream Analytics Management REST API Reference</span></span>](https://msdn.microsoft.com/library/azure/dn835031.aspx)
