---
title: JSON output for Stream Analytics | Microsoft Docs
description: Learn how Stream Analytics can target Azure DocumentDB for JSON output, for data archiving and low-latency queries on unstructured JSON data.
keywords: JSON output
documentationcenter: ''
services: stream-analytics,documentdb
author: jeffstokes72
manager: jhubbard
editor: cgronlun
ms.assetid: 5d2a61a6-0dbf-4f1b-80af-60a80eb25dd1
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 03/28/2017
ms.author: jeffstok
ms.openlocfilehash: 3702e525afbf510b4d01946373d5ca5f37220fb5
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44555236"
---
# <a name="target-azure-documentdb-for-json-output-from-stream-analytics"></a><span data-ttu-id="95a39-104">Target Azure DocumentDB for JSON output from Stream Analytics</span><span class="sxs-lookup"><span data-stu-id="95a39-104">Target Azure DocumentDB for JSON output from Stream Analytics</span></span>
<span data-ttu-id="95a39-105">Stream Analytics can target [Azure DocumentDB](https://azure.microsoft.com/services/documentdb/) for JSON output, enabling data archiving and low-latency queries on unstructured JSON data.</span><span class="sxs-lookup"><span data-stu-id="95a39-105">Stream Analytics can target [Azure DocumentDB](https://azure.microsoft.com/services/documentdb/) for JSON output, enabling data archiving and low-latency queries on unstructured JSON data.</span></span> <span data-ttu-id="95a39-106">This document covers some best practices for implementing this configuration.</span><span class="sxs-lookup"><span data-stu-id="95a39-106">This document covers some best practices for implementing this configuration.</span></span>

<span data-ttu-id="95a39-107">For those who are unfamiliar with DocumentDB, take a look at [DocumentDB’s learning path](https://azure.microsoft.com/documentation/learning-paths/documentdb/) to get started.</span><span class="sxs-lookup"><span data-stu-id="95a39-107">For those who are unfamiliar with DocumentDB, take a look at [DocumentDB’s learning path](https://azure.microsoft.com/documentation/learning-paths/documentdb/) to get started.</span></span>

## <a name="basics-of-documentdb-as-an-output-target"></a><span data-ttu-id="95a39-108">Basics of DocumentDB as an output target</span><span class="sxs-lookup"><span data-stu-id="95a39-108">Basics of DocumentDB as an output target</span></span>
<span data-ttu-id="95a39-109">The Azure DocumentDB output in Stream Analytics enables writing your stream processing results as JSON output into your DocumentDB collection(s).</span><span class="sxs-lookup"><span data-stu-id="95a39-109">The Azure DocumentDB output in Stream Analytics enables writing your stream processing results as JSON output into your DocumentDB collection(s).</span></span> <span data-ttu-id="95a39-110">Stream Analytics does not create collections in your database, instead requiring you to create them upfront.</span><span class="sxs-lookup"><span data-stu-id="95a39-110">Stream Analytics does not create collections in your database, instead requiring you to create them upfront.</span></span> <span data-ttu-id="95a39-111">This is so that the billing costs of DocumentDB collections are transparent to you, and so that you can tune the performance, consistency and capacity of your collections directly using the [DocumentDB APIs](https://msdn.microsoft.com/library/azure/dn781481.aspx).</span><span class="sxs-lookup"><span data-stu-id="95a39-111">This is so that the billing costs of DocumentDB collections are transparent to you, and so that you can tune the performance, consistency and capacity of your collections directly using the [DocumentDB APIs](https://msdn.microsoft.com/library/azure/dn781481.aspx).</span></span> <span data-ttu-id="95a39-112">We recommend using one DocumentDB Database per streaming job to logically separate your collections for a streaming job.</span><span class="sxs-lookup"><span data-stu-id="95a39-112">We recommend using one DocumentDB Database per streaming job to logically separate your collections for a streaming job.</span></span>

<span data-ttu-id="95a39-113">Some of the DocumentDB collection options are detailed below.</span><span class="sxs-lookup"><span data-stu-id="95a39-113">Some of the DocumentDB collection options are detailed below.</span></span>

## <a name="tune-consistency-availability-and-latency"></a><span data-ttu-id="95a39-114">Tune consistency, availability, and latency</span><span class="sxs-lookup"><span data-stu-id="95a39-114">Tune consistency, availability, and latency</span></span>
<span data-ttu-id="95a39-115">To match your application requirements, DocumentDB allows you to fine tune the database and collections and make trade-offs between consistency, availability and latency.</span><span class="sxs-lookup"><span data-stu-id="95a39-115">To match your application requirements, DocumentDB allows you to fine tune the database and collections and make trade-offs between consistency, availability and latency.</span></span> <span data-ttu-id="95a39-116">Depending on what levels of read consistency your scenario needs against read and write latency, you can choose a consistency level on your database account.</span><span class="sxs-lookup"><span data-stu-id="95a39-116">Depending on what levels of read consistency your scenario needs against read and write latency, you can choose a consistency level on your database account.</span></span> <span data-ttu-id="95a39-117">Also by default, DocumentDB enables synchronous indexing on each CRUD operation to your collection.</span><span class="sxs-lookup"><span data-stu-id="95a39-117">Also by default, DocumentDB enables synchronous indexing on each CRUD operation to your collection.</span></span> <span data-ttu-id="95a39-118">This is another useful option to control the write/read performance in DocumentDB.</span><span class="sxs-lookup"><span data-stu-id="95a39-118">This is another useful option to control the write/read performance in DocumentDB.</span></span> <span data-ttu-id="95a39-119">For further information on this topic, review the [change your database and query consistency levels](../documentdb/documentdb-consistency-levels.md) article.</span><span class="sxs-lookup"><span data-stu-id="95a39-119">For further information on this topic, review the [change your database and query consistency levels](../documentdb/documentdb-consistency-levels.md) article.</span></span>

## <a name="upserts-from-stream-analytics"></a><span data-ttu-id="95a39-120">Upserts from Stream Analytics</span><span class="sxs-lookup"><span data-stu-id="95a39-120">Upserts from Stream Analytics</span></span>
<span data-ttu-id="95a39-121">Stream Analytics integration with DocumentDB allows you to insert or update records in your DocumentDB collection based on a given Document ID column.</span><span class="sxs-lookup"><span data-stu-id="95a39-121">Stream Analytics integration with DocumentDB allows you to insert or update records in your DocumentDB collection based on a given Document ID column.</span></span> <span data-ttu-id="95a39-122">This is also referred to as an *Upsert*.</span><span class="sxs-lookup"><span data-stu-id="95a39-122">This is also referred to as an *Upsert*.</span></span>

<span data-ttu-id="95a39-123">Stream Analytics utilizes an optimistic Upsert approach, where updates are only done when insert fails due to a Document ID conflict.</span><span class="sxs-lookup"><span data-stu-id="95a39-123">Stream Analytics utilizes an optimistic Upsert approach, where updates are only done when insert fails due to a Document ID conflict.</span></span> <span data-ttu-id="95a39-124">This update is performed by Stream Analytics as a PATCH, so it enables partial updates to the document, i.e. addition of new properties or replacing an existing property is performed incrementally.</span><span class="sxs-lookup"><span data-stu-id="95a39-124">This update is performed by Stream Analytics as a PATCH, so it enables partial updates to the document, i.e. addition of new properties or replacing an existing property is performed incrementally.</span></span> <span data-ttu-id="95a39-125">Note that changes in the values of array properties in your JSON document result in the entire array getting overwritten, i.e. the array is not merged.</span><span class="sxs-lookup"><span data-stu-id="95a39-125">Note that changes in the values of array properties in your JSON document result in the entire array getting overwritten, i.e. the array is not merged.</span></span>

## <a name="data-partitioning-in-documentdb"></a><span data-ttu-id="95a39-126">Data partitioning in DocumentDB</span><span class="sxs-lookup"><span data-stu-id="95a39-126">Data partitioning in DocumentDB</span></span>
<span data-ttu-id="95a39-127">DocumentDB [partitioned collections](../documentdb/documentdb-partition-data.md#single-partition-and-partitioned-collections) are the recommended approach for partitioning your data.</span><span class="sxs-lookup"><span data-stu-id="95a39-127">DocumentDB [partitioned collections](../documentdb/documentdb-partition-data.md#single-partition-and-partitioned-collections) are the recommended approach for partitioning your data.</span></span> 

<span data-ttu-id="95a39-128">For single DocumentDB collections, Stream Analytics still allows you to partition your data based on both the query patterns and performance needs of your application.</span><span class="sxs-lookup"><span data-stu-id="95a39-128">For single DocumentDB collections, Stream Analytics still allows you to partition your data based on both the query patterns and performance needs of your application.</span></span> <span data-ttu-id="95a39-129">Each collection may contain up to 10GB of data (maximum) and currently there is no way to scale up (or overflow) a collection.</span><span class="sxs-lookup"><span data-stu-id="95a39-129">Each collection may contain up to 10GB of data (maximum) and currently there is no way to scale up (or overflow) a collection.</span></span> <span data-ttu-id="95a39-130">For scaling out, Stream Analytics allows you to write to multiple collections with a given prefix (see usage details below).</span><span class="sxs-lookup"><span data-stu-id="95a39-130">For scaling out, Stream Analytics allows you to write to multiple collections with a given prefix (see usage details below).</span></span> <span data-ttu-id="95a39-131">Stream Analytics uses the consistent [Hash Partition Resolver](https://msdn.microsoft.com/library/azure/microsoft.azure.documents.partitioning.hashpartitionresolver.aspx) strategy based on the user provided PartitionKey column to partition its output records.</span><span class="sxs-lookup"><span data-stu-id="95a39-131">Stream Analytics uses the consistent [Hash Partition Resolver](https://msdn.microsoft.com/library/azure/microsoft.azure.documents.partitioning.hashpartitionresolver.aspx) strategy based on the user provided PartitionKey column to partition its output records.</span></span> <span data-ttu-id="95a39-132">The number of collections with the given prefix at the streaming job’s start time is used as the output partition count, to which the job writes to in parallel (DocumentDB Collections = Output Partitions).</span><span class="sxs-lookup"><span data-stu-id="95a39-132">The number of collections with the given prefix at the streaming job’s start time is used as the output partition count, to which the job writes to in parallel (DocumentDB Collections = Output Partitions).</span></span> <span data-ttu-id="95a39-133">For a single collection with lazy indexing doing only inserts, about 0.4 MB/s write throughput can be expected.</span><span class="sxs-lookup"><span data-stu-id="95a39-133">For a single collection with lazy indexing doing only inserts, about 0.4 MB/s write throughput can be expected.</span></span> <span data-ttu-id="95a39-134">Using multiple collections can allow you to achieve higher throughput and increased capacity.</span><span class="sxs-lookup"><span data-stu-id="95a39-134">Using multiple collections can allow you to achieve higher throughput and increased capacity.</span></span>

<span data-ttu-id="95a39-135">If you intend to increase the partition count in the future, you may need to stop your job, repartition the data from your existing collections into new collections and then restart the Stream Analytics job.</span><span class="sxs-lookup"><span data-stu-id="95a39-135">If you intend to increase the partition count in the future, you may need to stop your job, repartition the data from your existing collections into new collections and then restart the Stream Analytics job.</span></span> <span data-ttu-id="95a39-136">More details on using PartitionResolver and re-partitioning along with sample code, will be included in a follow-up post.</span><span class="sxs-lookup"><span data-stu-id="95a39-136">More details on using PartitionResolver and re-partitioning along with sample code, will be included in a follow-up post.</span></span> <span data-ttu-id="95a39-137">The article [Partitioning and scaling in DocumentDB](../documentdb/documentdb-partition-data.md) also provides details on this.</span><span class="sxs-lookup"><span data-stu-id="95a39-137">The article [Partitioning and scaling in DocumentDB](../documentdb/documentdb-partition-data.md) also provides details on this.</span></span>

## <a name="documentdb-settings-for-json-output"></a><span data-ttu-id="95a39-138">DocumentDB settings for JSON output</span><span class="sxs-lookup"><span data-stu-id="95a39-138">DocumentDB settings for JSON output</span></span>
<span data-ttu-id="95a39-139">Creating DocumentDB as an output in Stream Analytics generates a prompt for information as seen below.</span><span class="sxs-lookup"><span data-stu-id="95a39-139">Creating DocumentDB as an output in Stream Analytics generates a prompt for information as seen below.</span></span> <span data-ttu-id="95a39-140">This section provides an explanation of the properties definition.</span><span class="sxs-lookup"><span data-stu-id="95a39-140">This section provides an explanation of the properties definition.</span></span>

<span data-ttu-id="95a39-141">Partitioned Collection</span><span class="sxs-lookup"><span data-stu-id="95a39-141">Partitioned Collection</span></span> | <span data-ttu-id="95a39-142">Multiple “Single Partition” collections</span><span class="sxs-lookup"><span data-stu-id="95a39-142">Multiple “Single Partition” collections</span></span>
---|---
![documentdb stream analytics output screen](https://docstestmedia1.blob.core.windows.net/azure-media/articles/stream-analytics/media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png) |  ![documentdb stream analytics output screen](https://docstestmedia1.blob.core.windows.net/azure-media/articles/stream-analytics/media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)


  
> [!NOTE]
> <span data-ttu-id="95a39-145">The **Multiple “Single Partition” collections** scenario requires a partition key and is a supported configuration.</span><span class="sxs-lookup"><span data-stu-id="95a39-145">The **Multiple “Single Partition” collections** scenario requires a partition key and is a supported configuration.</span></span> 

* <span data-ttu-id="95a39-146">**Output Alias** – An alias to refer this output in your ASA query</span><span class="sxs-lookup"><span data-stu-id="95a39-146">**Output Alias** – An alias to refer this output in your ASA query</span></span>  
* <span data-ttu-id="95a39-147">**Account Name** – The name or endpoint URI of the DocumentDB account.</span><span class="sxs-lookup"><span data-stu-id="95a39-147">**Account Name** – The name or endpoint URI of the DocumentDB account.</span></span>  
* <span data-ttu-id="95a39-148">**Account Key** – The shared access key for the DocumentDB account.</span><span class="sxs-lookup"><span data-stu-id="95a39-148">**Account Key** – The shared access key for the DocumentDB account.</span></span>  
* <span data-ttu-id="95a39-149">**Database** – The DocumentDB database name.</span><span class="sxs-lookup"><span data-stu-id="95a39-149">**Database** – The DocumentDB database name.</span></span>  
* <span data-ttu-id="95a39-150">**Collection Name Pattern** – The collection name or their pattern for the collections to be used.</span><span class="sxs-lookup"><span data-stu-id="95a39-150">**Collection Name Pattern** – The collection name or their pattern for the collections to be used.</span></span> <span data-ttu-id="95a39-151">The collection name format can be constructed using the optional {partition} token, where partitions start from 0.</span><span class="sxs-lookup"><span data-stu-id="95a39-151">The collection name format can be constructed using the optional {partition} token, where partitions start from 0.</span></span> <span data-ttu-id="95a39-152">Following are sample valid inputs:</span><span class="sxs-lookup"><span data-stu-id="95a39-152">Following are sample valid inputs:</span></span>  
  <span data-ttu-id="95a39-153">1\) MyCollection – One collection named “MyCollection” must exist.</span><span class="sxs-lookup"><span data-stu-id="95a39-153">1\) MyCollection – One collection named “MyCollection” must exist.</span></span>  
  <span data-ttu-id="95a39-154">2\) MyCollection{partition} – Such collections must exist– "MyCollection0”, “MyCollection1”, “MyCollection2” and so on.</span><span class="sxs-lookup"><span data-stu-id="95a39-154">2\) MyCollection{partition} – Such collections must exist– "MyCollection0”, “MyCollection1”, “MyCollection2” and so on.</span></span>  
* <span data-ttu-id="95a39-155">**Partition Key** – Optional.</span><span class="sxs-lookup"><span data-stu-id="95a39-155">**Partition Key** – Optional.</span></span> <span data-ttu-id="95a39-156">This is only needed if you are using a {parition} token in your collection name pattern.</span><span class="sxs-lookup"><span data-stu-id="95a39-156">This is only needed if you are using a {parition} token in your collection name pattern.</span></span> <span data-ttu-id="95a39-157">The name of the field in output events used to specify the key for partitioning output across collections.</span><span class="sxs-lookup"><span data-stu-id="95a39-157">The name of the field in output events used to specify the key for partitioning output across collections.</span></span> <span data-ttu-id="95a39-158">For single collection output, any arbitrary output column can be used e.g. PartitionId.</span><span class="sxs-lookup"><span data-stu-id="95a39-158">For single collection output, any arbitrary output column can be used e.g. PartitionId.</span></span>  
* <span data-ttu-id="95a39-159">**Document ID** – Optional.</span><span class="sxs-lookup"><span data-stu-id="95a39-159">**Document ID** – Optional.</span></span> <span data-ttu-id="95a39-160">The name of the field in output events used to specify the primary key on which insert or update operations are based.</span><span class="sxs-lookup"><span data-stu-id="95a39-160">The name of the field in output events used to specify the primary key on which insert or update operations are based.</span></span>  


