---
title: Azure Media Services fragmented MP4 live ingest specification | Microsoft Docs
description: This specification describes the protocol and format for Fragmented MP4 based live streaming ingestion for Microsoft Azure Media Services. Microsoft Azure Media Services provides live streaming service which allows customers to stream live events and broadcast content in real-time using Microsoft Azure as the cloud platform. This document also discusses best practices in building highly redundant and robust live ingest mechanisms.
services: media-services
documentationcenter: ''
author: cenkdin
manager: erikre
editor: ''
ms.assetid: 43fac263-a5ea-44af-8dd5-cc88e423b4de
ms.service: media-services
ms.workload: media
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/07/2016
ms.author: cenkd;juliako
ms.openlocfilehash: 1ca3b8634235521654665e3a677dd72a417fe1fe
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44554614"
---
# <a name="azure-media-services-fragmented-mp4-live-ingest-specification"></a><span data-ttu-id="9d886-105">Azure Media Services fragmented MP4 live ingest specification</span><span class="sxs-lookup"><span data-stu-id="9d886-105">Azure Media Services fragmented MP4 live ingest specification</span></span>
<span data-ttu-id="9d886-106">This specification describes the protocol and format for Fragmented MP4 based live streaming ingestion for Microsoft Azure Media Services.</span><span class="sxs-lookup"><span data-stu-id="9d886-106">This specification describes the protocol and format for Fragmented MP4 based live streaming ingestion for Microsoft Azure Media Services.</span></span> <span data-ttu-id="9d886-107">Microsoft Azure Media Services provides live streaming service which allows customers to stream live events and broadcast content in real-time using Microsoft Azure as the cloud platform.</span><span class="sxs-lookup"><span data-stu-id="9d886-107">Microsoft Azure Media Services provides live streaming service which allows customers to stream live events and broadcast content in real-time using Microsoft Azure as the cloud platform.</span></span> <span data-ttu-id="9d886-108">This document also discusses best practices in building highly redundant and robust live ingest mechanisms.</span><span class="sxs-lookup"><span data-stu-id="9d886-108">This document also discusses best practices in building highly redundant and robust live ingest mechanisms.</span></span>

## <a name="1-conformance-notation"></a><span data-ttu-id="9d886-109">1. Conformance Notation</span><span class="sxs-lookup"><span data-stu-id="9d886-109">1. Conformance Notation</span></span>
<span data-ttu-id="9d886-110">The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in RFC 2119.</span><span class="sxs-lookup"><span data-stu-id="9d886-110">The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in RFC 2119.</span></span>

## <a name="2-service-diagram"></a><span data-ttu-id="9d886-111">2. Service Diagram</span><span class="sxs-lookup"><span data-stu-id="9d886-111">2. Service Diagram</span></span>
<span data-ttu-id="9d886-112">The diagram below shows the high level architecture of the live streaming service in Microsoft Azure Media Services:</span><span class="sxs-lookup"><span data-stu-id="9d886-112">The diagram below shows the high level architecture of the live streaming service in Microsoft Azure Media Services:</span></span>

1. <span data-ttu-id="9d886-113">Live Encoder pushes live feeds into Channels which are created and provisioned via the Microsoft Azure Media Services SDK.</span><span class="sxs-lookup"><span data-stu-id="9d886-113">Live Encoder pushes live feeds into Channels which are created and provisioned via the Microsoft Azure Media Services SDK.</span></span>
2. <span data-ttu-id="9d886-114">Channels, Programs and Streaming endpoint in Microsoft Azure Media Services handle all the live streaming functionalities including ingest, formatting, cloud DVR, security, scalability and redundancy.</span><span class="sxs-lookup"><span data-stu-id="9d886-114">Channels, Programs and Streaming endpoint in Microsoft Azure Media Services handle all the live streaming functionalities including ingest, formatting, cloud DVR, security, scalability and redundancy.</span></span>
3. <span data-ttu-id="9d886-115">Optionally customers could choose to deploy a CDN layer between the Streaming endpoint and the client endpoints.</span><span class="sxs-lookup"><span data-stu-id="9d886-115">Optionally customers could choose to deploy a CDN layer between the Streaming endpoint and the client endpoints.</span></span>
4. <span data-ttu-id="9d886-116">Client endpoints stream from the Streaming endpoint using HTTP Adaptive Streaming protocols (e.g. Smooth Streaming, DASH, or HLS).</span><span class="sxs-lookup"><span data-stu-id="9d886-116">Client endpoints stream from the Streaming endpoint using HTTP Adaptive Streaming protocols (e.g. Smooth Streaming, DASH, or HLS).</span></span>

![image1][image1]

## <a name="3-bit-stream-format--iso-14496-12-fragmented-mp4"></a><span data-ttu-id="9d886-118">3. Bit-stream Format – ISO 14496-12 Fragmented MP4</span><span class="sxs-lookup"><span data-stu-id="9d886-118">3. Bit-stream Format – ISO 14496-12 Fragmented MP4</span></span>
<span data-ttu-id="9d886-119">The wire format for live streaming ingest that is discussed in this document is based on [ISO-14496-12].</span><span class="sxs-lookup"><span data-stu-id="9d886-119">The wire format for live streaming ingest that is discussed in this document is based on [ISO-14496-12].</span></span> <span data-ttu-id="9d886-120">Please refer to [[MS-SSTR]](http://msdn.microsoft.com/library/ff469518.aspx) for detailed explanation of Fragmented MP4 format and extensions for both video-on-demand files and live streaming ingestion.</span><span class="sxs-lookup"><span data-stu-id="9d886-120">Please refer to [[MS-SSTR]](http://msdn.microsoft.com/library/ff469518.aspx) for detailed explanation of Fragmented MP4 format and extensions for both video-on-demand files and live streaming ingestion.</span></span>

### <a name="live-ingest-format-definitions"></a><span data-ttu-id="9d886-121">Live ingest format definitions</span><span class="sxs-lookup"><span data-stu-id="9d886-121">Live ingest format definitions</span></span>
<span data-ttu-id="9d886-122">Below is a list of special format definitions that apply to live ingest into Microsoft Azure Media Services:</span><span class="sxs-lookup"><span data-stu-id="9d886-122">Below is a list of special format definitions that apply to live ingest into Microsoft Azure Media Services:</span></span>

1. <span data-ttu-id="9d886-123">The 'ftyp', LiveServerManifestBox, and 'moov' box MUST be sent with each request (HTTP POST).</span><span class="sxs-lookup"><span data-stu-id="9d886-123">The 'ftyp', LiveServerManifestBox, and 'moov' box MUST be sent with each request (HTTP POST).</span></span>  <span data-ttu-id="9d886-124">It MUST be sent at the beginning of the stream and anytime the encoder must reconnect to resume stream ingest.</span><span class="sxs-lookup"><span data-stu-id="9d886-124">It MUST be sent at the beginning of the stream and anytime the encoder must reconnect to resume stream ingest.</span></span>  <span data-ttu-id="9d886-125">Please refer to Section 6 in [1] for more details.</span><span class="sxs-lookup"><span data-stu-id="9d886-125">Please refer to Section 6 in [1] for more details.</span></span>
2. <span data-ttu-id="9d886-126">Section 3.3.2 in [1] defines an optional box called StreamManifestBox for live ingest.</span><span class="sxs-lookup"><span data-stu-id="9d886-126">Section 3.3.2 in [1] defines an optional box called StreamManifestBox for live ingest.</span></span> <span data-ttu-id="9d886-127">Due to the routing logic of Microsoft Azure’s load balancer, usage of this box is deprecated and SHOULD NOT be present when ingesting into Microsoft Azure Media Service.</span><span class="sxs-lookup"><span data-stu-id="9d886-127">Due to the routing logic of Microsoft Azure’s load balancer, usage of this box is deprecated and SHOULD NOT be present when ingesting into Microsoft Azure Media Service.</span></span> <span data-ttu-id="9d886-128">If this box is present, Azure Media Services silently ignores it.</span><span class="sxs-lookup"><span data-stu-id="9d886-128">If this box is present, Azure Media Services silently ignores it.</span></span>
3. <span data-ttu-id="9d886-129">The TrackFragmentExtendedHeaderBox defined in 3.2.3.2 in [1] MUST be present for each fragment.</span><span class="sxs-lookup"><span data-stu-id="9d886-129">The TrackFragmentExtendedHeaderBox defined in 3.2.3.2 in [1] MUST be present for each fragment.</span></span>
4. <span data-ttu-id="9d886-130">Version 2 of the TrackFragmentExtendedHeaderBox SHOULD be used in order to generate media segments with identical URLs in multiple datacenters.</span><span class="sxs-lookup"><span data-stu-id="9d886-130">Version 2 of the TrackFragmentExtendedHeaderBox SHOULD be used in order to generate media segments with identical URLs in multiple datacenters.</span></span> <span data-ttu-id="9d886-131">The fragment index field is REQUIRED for cross-datacenter failover of index-based streaming formats such as Apple HTTP Live Streaming (HLS) and index-based MPEG-DASH.</span><span class="sxs-lookup"><span data-stu-id="9d886-131">The fragment index field is REQUIRED for cross-datacenter failover of index-based streaming formats such as Apple HTTP Live Streaming (HLS) and index-based MPEG-DASH.</span></span>  <span data-ttu-id="9d886-132">To enable cross-datacenter failover, the fragment index MUST be synchronized across multiple encoders, and increase by 1 for each successive media fragment, even across encoder restarts or failures.</span><span class="sxs-lookup"><span data-stu-id="9d886-132">To enable cross-datacenter failover, the fragment index MUST be synchronized across multiple encoders, and increase by 1 for each successive media fragment, even across encoder restarts or failures.</span></span>
5. <span data-ttu-id="9d886-133">Section 3.3.6 in [1] defines box called MovieFragmentRandomAccessBox ('mfra') that MAY be sent at the end of live ingestion to indicate EOS (End-of-Stream) to the channel.</span><span class="sxs-lookup"><span data-stu-id="9d886-133">Section 3.3.6 in [1] defines box called MovieFragmentRandomAccessBox ('mfra') that MAY be sent at the end of live ingestion to indicate EOS (End-of-Stream) to the channel.</span></span> <span data-ttu-id="9d886-134">Due to the ingest logic of Azure Media Services, usage of EOS (End-of-Stream) is deprecated and the ‘mfra’ box for live ingestion SHOULD NOT be sent.</span><span class="sxs-lookup"><span data-stu-id="9d886-134">Due to the ingest logic of Azure Media Services, usage of EOS (End-of-Stream) is deprecated and the ‘mfra’ box for live ingestion SHOULD NOT be sent.</span></span> <span data-ttu-id="9d886-135">If sent, Azure Media Services silently ignores it.</span><span class="sxs-lookup"><span data-stu-id="9d886-135">If sent, Azure Media Services silently ignores it.</span></span> <span data-ttu-id="9d886-136">It is recommended to use [Channel Reset](https://docs.microsoft.com/rest/api/media/operations/channel#reset_channels) to reset the state of the ingest point and also it is recommended to use [Program Stop](https://msdn.microsoft.com/library/azure/dn783463.aspx#stop_programs) to end a presentation and stream.</span><span class="sxs-lookup"><span data-stu-id="9d886-136">It is recommended to use [Channel Reset](https://docs.microsoft.com/rest/api/media/operations/channel#reset_channels) to reset the state of the ingest point and also it is recommended to use [Program Stop](https://msdn.microsoft.com/library/azure/dn783463.aspx#stop_programs) to end a presentation and stream.</span></span>
6. <span data-ttu-id="9d886-137">The MP4 fragment duration SHOULD be constant, in order to reduce the size of the client manifests and improve client download heuristics through use of repeat tags.</span><span class="sxs-lookup"><span data-stu-id="9d886-137">The MP4 fragment duration SHOULD be constant, in order to reduce the size of the client manifests and improve client download heuristics through use of repeat tags.</span></span>  <span data-ttu-id="9d886-138">The duration MAY fluctuate in order to compensate for non-integer frame rates.</span><span class="sxs-lookup"><span data-stu-id="9d886-138">The duration MAY fluctuate in order to compensate for non-integer frame rates.</span></span>
7. <span data-ttu-id="9d886-139">The MP4 fragment duration SHOULD be between approximately 2 and 6 seconds.</span><span class="sxs-lookup"><span data-stu-id="9d886-139">The MP4 fragment duration SHOULD be between approximately 2 and 6 seconds.</span></span>
8. <span data-ttu-id="9d886-140">MP4 fragment timestamps and indexes (TrackFragmentExtendedHeaderBox fragment_ absolute_ time and fragment_index) SHOULD arrive in increasing order.</span><span class="sxs-lookup"><span data-stu-id="9d886-140">MP4 fragment timestamps and indexes (TrackFragmentExtendedHeaderBox fragment_ absolute_ time and fragment_index) SHOULD arrive in increasing order.</span></span>  <span data-ttu-id="9d886-141">Although Azure Media Services is resilient to duplicate fragments, it has very limited ability to reorder fragments according to the media timeline.</span><span class="sxs-lookup"><span data-stu-id="9d886-141">Although Azure Media Services is resilient to duplicate fragments, it has very limited ability to reorder fragments according to the media timeline.</span></span>

## <a name="4-protocol-format--http"></a><span data-ttu-id="9d886-142">4. Protocol Format – HTTP</span><span class="sxs-lookup"><span data-stu-id="9d886-142">4. Protocol Format – HTTP</span></span>
<span data-ttu-id="9d886-143">ISO Fragmented MP4 based live ingest for Microsoft Azure Media Services uses a standard long running HTTP POST request to transmit encoded media data packaged in Fragmented MP4 format to the service.</span><span class="sxs-lookup"><span data-stu-id="9d886-143">ISO Fragmented MP4 based live ingest for Microsoft Azure Media Services uses a standard long running HTTP POST request to transmit encoded media data packaged in Fragmented MP4 format to the service.</span></span> <span data-ttu-id="9d886-144">Each HTTP POST sends a complete Fragmented MP4 bit-stream ("Stream") starting from beginning with header boxes ( 'ftyp', "Live Server Manifest Box", and 'moov' box) and continuing with a sequence of fragments (‘moof’ and ‘mdat’ boxes).</span><span class="sxs-lookup"><span data-stu-id="9d886-144">Each HTTP POST sends a complete Fragmented MP4 bit-stream ("Stream") starting from beginning with header boxes ( 'ftyp', "Live Server Manifest Box", and 'moov' box) and continuing with a sequence of fragments (‘moof’ and ‘mdat’ boxes).</span></span> <span data-ttu-id="9d886-145">Please refer to section 9.2 in [1] for URL syntax for HTTP POST request.</span><span class="sxs-lookup"><span data-stu-id="9d886-145">Please refer to section 9.2 in [1] for URL syntax for HTTP POST request.</span></span> <span data-ttu-id="9d886-146">An example of the POST URL is:</span><span class="sxs-lookup"><span data-stu-id="9d886-146">An example of the POST URL is:</span></span> 

    http://customer.channel.mediaservices.windows.net/ingest.isml/streams(720p)

### <a name="requirements"></a><span data-ttu-id="9d886-147">Requirements</span><span class="sxs-lookup"><span data-stu-id="9d886-147">Requirements</span></span>
<span data-ttu-id="9d886-148">Here are the detailed requirements:</span><span class="sxs-lookup"><span data-stu-id="9d886-148">Here are the detailed requirements:</span></span>

1. <span data-ttu-id="9d886-149">Encoder SHOULD start the broadcast by sending an HTTP POST request with an empty “body” (zero content length) using the same ingestion URL.</span><span class="sxs-lookup"><span data-stu-id="9d886-149">Encoder SHOULD start the broadcast by sending an HTTP POST request with an empty “body” (zero content length) using the same ingestion URL.</span></span> <span data-ttu-id="9d886-150">This can help quickly detect if the live ingestion endpoint is valid and if there is any authentication or other conditions required.</span><span class="sxs-lookup"><span data-stu-id="9d886-150">This can help quickly detect if the live ingestion endpoint is valid and if there is any authentication or other conditions required.</span></span> <span data-ttu-id="9d886-151">Per HTTP protocol, the server won’t be able to send back HTTP response until the entire request including POST body is received.</span><span class="sxs-lookup"><span data-stu-id="9d886-151">Per HTTP protocol, the server won’t be able to send back HTTP response until the entire request including POST body is received.</span></span> <span data-ttu-id="9d886-152">Given the long running nature of live event, without this step, the encoder may not be able to detect any error until it finishes sending all the data.</span><span class="sxs-lookup"><span data-stu-id="9d886-152">Given the long running nature of live event, without this step, the encoder may not be able to detect any error until it finishes sending all the data.</span></span>
2. <span data-ttu-id="9d886-153">Encoder MUST handle any errors or authentication challenges as a result of (1).</span><span class="sxs-lookup"><span data-stu-id="9d886-153">Encoder MUST handle any errors or authentication challenges as a result of (1).</span></span> <span data-ttu-id="9d886-154">If (1) succeeds with a 200 response, continue.</span><span class="sxs-lookup"><span data-stu-id="9d886-154">If (1) succeeds with a 200 response, continue.</span></span>
3. <span data-ttu-id="9d886-155">Encoder MUST start a new HTTP POST request with the fragmented MP4 stream.</span><span class="sxs-lookup"><span data-stu-id="9d886-155">Encoder MUST start a new HTTP POST request with the fragmented MP4 stream.</span></span>  <span data-ttu-id="9d886-156">The payload MUST start with the header boxes followed by fragments.</span><span class="sxs-lookup"><span data-stu-id="9d886-156">The payload MUST start with the header boxes followed by fragments.</span></span>  <span data-ttu-id="9d886-157">Note the ‘ftyp’, “Live Server Manifest Box”, and ‘moov’ box (in this order) MUST be sent with each request, even if the encoder must reconnect because the previous request was terminated prior to the end of the stream.</span><span class="sxs-lookup"><span data-stu-id="9d886-157">Note the ‘ftyp’, “Live Server Manifest Box”, and ‘moov’ box (in this order) MUST be sent with each request, even if the encoder must reconnect because the previous request was terminated prior to the end of the stream.</span></span> 
4. <span data-ttu-id="9d886-158">Encoder MUST use Chunked Transfer Encoding for uploading since it’s impossible to predict the entire content length of the live event.</span><span class="sxs-lookup"><span data-stu-id="9d886-158">Encoder MUST use Chunked Transfer Encoding for uploading since it’s impossible to predict the entire content length of the live event.</span></span>
5. <span data-ttu-id="9d886-159">When the event is over, after sending the last fragment, the encoder MUST gracefully end the Chunked Transfer Encoding message sequence (most HTTP client stacks handle it automatically).</span><span class="sxs-lookup"><span data-stu-id="9d886-159">When the event is over, after sending the last fragment, the encoder MUST gracefully end the Chunked Transfer Encoding message sequence (most HTTP client stacks handle it automatically).</span></span> <span data-ttu-id="9d886-160">Encoder MUST wait for the service to return the final response code and then terminate the connection.</span><span class="sxs-lookup"><span data-stu-id="9d886-160">Encoder MUST wait for the service to return the final response code and then terminate the connection.</span></span> 
6. <span data-ttu-id="9d886-161">Encoder MUST NOT use the Events() noun as described in 9.2 in [1] for live ingestion into Microsoft Azure Media Services.</span><span class="sxs-lookup"><span data-stu-id="9d886-161">Encoder MUST NOT use the Events() noun as described in 9.2 in [1] for live ingestion into Microsoft Azure Media Services.</span></span>
7. <span data-ttu-id="9d886-162">If the HTTP POST request terminates or times out prior to the end of the stream with a TCP error, the encoder MUST issue a new POST request using a new connection and follow the requirements above with the additional requirement that the encoder MUST resend the previous two MP4 fragments for each track in the stream, and resume without introducing discontinuities in the media timeline.</span><span class="sxs-lookup"><span data-stu-id="9d886-162">If the HTTP POST request terminates or times out prior to the end of the stream with a TCP error, the encoder MUST issue a new POST request using a new connection and follow the requirements above with the additional requirement that the encoder MUST resend the previous two MP4 fragments for each track in the stream, and resume without introducing discontinuities in the media timeline.</span></span>  <span data-ttu-id="9d886-163">Resending the last two MP4 fragments for each track ensures that there is no data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-163">Resending the last two MP4 fragments for each track ensures that there is no data loss.</span></span>  <span data-ttu-id="9d886-164">In other words, if a stream contains both an audio and video track, and the current POST request fails, the encoder must reconnect and resend the last two fragments for the audio track, which were previously successfully sent, and the last two fragments for the video track, which were previously successfully sent, in order to ensure that there is no data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-164">In other words, if a stream contains both an audio and video track, and the current POST request fails, the encoder must reconnect and resend the last two fragments for the audio track, which were previously successfully sent, and the last two fragments for the video track, which were previously successfully sent, in order to ensure that there is no data loss.</span></span>  <span data-ttu-id="9d886-165">The encoder MUST maintain a “forward” buffer of media fragments, which it resends when reconnecting.</span><span class="sxs-lookup"><span data-stu-id="9d886-165">The encoder MUST maintain a “forward” buffer of media fragments, which it resends when reconnecting.</span></span>

## <a name="5-timescale"></a><span data-ttu-id="9d886-166">5. Timescale</span><span class="sxs-lookup"><span data-stu-id="9d886-166">5. Timescale</span></span>
<span data-ttu-id="9d886-167">[[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx) describes the usage of “Timescale” for SmoothStreamingMedia (Section 2.2.2.1), StreamElement (Section 2.2.2.3), StreamFragmentElement(2.2.2.6) and LiveSMIL (Section 2.2.7.3.1).</span><span class="sxs-lookup"><span data-stu-id="9d886-167">[[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx) describes the usage of “Timescale” for SmoothStreamingMedia (Section 2.2.2.1), StreamElement (Section 2.2.2.3), StreamFragmentElement(2.2.2.6) and LiveSMIL (Section 2.2.7.3.1).</span></span> <span data-ttu-id="9d886-168">If timescale value is not present, the default value used is 10,000,000 (10 MHz).</span><span class="sxs-lookup"><span data-stu-id="9d886-168">If timescale value is not present, the default value used is 10,000,000 (10 MHz).</span></span> <span data-ttu-id="9d886-169">Although Smooth Streaming Format Specification doesn’t block usage of other timescale values, most of the encoder implementations uses this default value (10 MHz) to generate Smooth Streaming ingest data.</span><span class="sxs-lookup"><span data-stu-id="9d886-169">Although Smooth Streaming Format Specification doesn’t block usage of other timescale values, most of the encoder implementations uses this default value (10 MHz) to generate Smooth Streaming ingest data.</span></span> <span data-ttu-id="9d886-170">Due to [Azure Media Dynamic Packaging](media-services-dynamic-packaging-overview.md) feature, it is recommend to use 90 kHz timescale for video streams and 44.1 or 48.1 kHz for audio streams.</span><span class="sxs-lookup"><span data-stu-id="9d886-170">Due to [Azure Media Dynamic Packaging](media-services-dynamic-packaging-overview.md) feature, it is recommend to use 90 kHz timescale for video streams and 44.1 or 48.1 kHz for audio streams.</span></span> <span data-ttu-id="9d886-171">If different timescale values are used for different streams, the stream level timescale MUST be sent.</span><span class="sxs-lookup"><span data-stu-id="9d886-171">If different timescale values are used for different streams, the stream level timescale MUST be sent.</span></span> <span data-ttu-id="9d886-172">Please refer to [[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx).</span><span class="sxs-lookup"><span data-stu-id="9d886-172">Please refer to [[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx).</span></span>     

## <a name="6-definition-of-stream"></a><span data-ttu-id="9d886-173">6. Definition of “Stream”</span><span class="sxs-lookup"><span data-stu-id="9d886-173">6. Definition of “Stream”</span></span>
<span data-ttu-id="9d886-174">“Stream” is the basic unit of operation in live ingestion for composing live presentation, handling streaming failover and redundancy scenarios.</span><span class="sxs-lookup"><span data-stu-id="9d886-174">“Stream” is the basic unit of operation in live ingestion for composing live presentation, handling streaming failover and redundancy scenarios.</span></span> <span data-ttu-id="9d886-175">“Stream” is defined as one unique Fragmented MP4 bit-stream which may contain a single track or multiple tracks.</span><span class="sxs-lookup"><span data-stu-id="9d886-175">“Stream” is defined as one unique Fragmented MP4 bit-stream which may contain a single track or multiple tracks.</span></span> <span data-ttu-id="9d886-176">A full live presentation could contain one or more streams depending on the configuration of the live encoder(s).</span><span class="sxs-lookup"><span data-stu-id="9d886-176">A full live presentation could contain one or more streams depending on the configuration of the live encoder(s).</span></span> <span data-ttu-id="9d886-177">The examples below illustrate various options of using stream(s) to compose a full live presentation.</span><span class="sxs-lookup"><span data-stu-id="9d886-177">The examples below illustrate various options of using stream(s) to compose a full live presentation.</span></span>

<span data-ttu-id="9d886-178">**Example:**</span><span class="sxs-lookup"><span data-stu-id="9d886-178">**Example:**</span></span> 

<span data-ttu-id="9d886-179">Customer wants to create a live streaming presentation which includes the following audio/video bitrates:</span><span class="sxs-lookup"><span data-stu-id="9d886-179">Customer wants to create a live streaming presentation which includes the following audio/video bitrates:</span></span>

<span data-ttu-id="9d886-180">Video – 3000kbps, 1500kbps, 750kbps</span><span class="sxs-lookup"><span data-stu-id="9d886-180">Video – 3000kbps, 1500kbps, 750kbps</span></span>

<span data-ttu-id="9d886-181">Audio – 128kbps</span><span class="sxs-lookup"><span data-stu-id="9d886-181">Audio – 128kbps</span></span>

### <a name="option-1-all-tracks-in-one-stream"></a><span data-ttu-id="9d886-182">Option 1: All tracks in one stream</span><span class="sxs-lookup"><span data-stu-id="9d886-182">Option 1: All tracks in one stream</span></span>
<span data-ttu-id="9d886-183">In this option, a single encoder generates all audio/video tracks and bundle them into one Fragmented MP4 bit-stream which then gets sent via a single HTTP POST connection.</span><span class="sxs-lookup"><span data-stu-id="9d886-183">In this option, a single encoder generates all audio/video tracks and bundle them into one Fragmented MP4 bit-stream which then gets sent via a single HTTP POST connection.</span></span> <span data-ttu-id="9d886-184">In this example, there is only one stream for this live presentation:</span><span class="sxs-lookup"><span data-stu-id="9d886-184">In this example, there is only one stream for this live presentation:</span></span>

![image2][image2]

### <a name="option-2-each-track-in-a-separate-stream"></a><span data-ttu-id="9d886-186">Option 2: Each track in a separate stream</span><span class="sxs-lookup"><span data-stu-id="9d886-186">Option 2: Each track in a separate stream</span></span>
<span data-ttu-id="9d886-187">In this option, the encoder(s) only put one track into each Fragment MP4 bit-stream and post all the streams over multiple separate HTTP connections.</span><span class="sxs-lookup"><span data-stu-id="9d886-187">In this option, the encoder(s) only put one track into each Fragment MP4 bit-stream and post all the streams over multiple separate HTTP connections.</span></span> <span data-ttu-id="9d886-188">This could be done with one encoders or multiple encoders.</span><span class="sxs-lookup"><span data-stu-id="9d886-188">This could be done with one encoders or multiple encoders.</span></span> <span data-ttu-id="9d886-189">From live ingestion’s point of view, this live presentation is composed of four streams.</span><span class="sxs-lookup"><span data-stu-id="9d886-189">From live ingestion’s point of view, this live presentation is composed of four streams.</span></span>

![image3][image3]

### <a name="option-3-bundle-audio-track-with-the-lowest-bitrate-video-track-into-one-stream"></a><span data-ttu-id="9d886-191">Option 3: Bundle audio track with the lowest bitrate video track into one stream</span><span class="sxs-lookup"><span data-stu-id="9d886-191">Option 3: Bundle audio track with the lowest bitrate video track into one stream</span></span>
<span data-ttu-id="9d886-192">In this option, the customer chooses to bundle the audio track with the lowest bitrate video track into one Fragment MP4 bit-stream and leave the other two video tracks each being its own stream.</span><span class="sxs-lookup"><span data-stu-id="9d886-192">In this option, the customer chooses to bundle the audio track with the lowest bitrate video track into one Fragment MP4 bit-stream and leave the other two video tracks each being its own stream.</span></span> 

![image4][image4]

### <a name="summary"></a><span data-ttu-id="9d886-194">Summary</span><span class="sxs-lookup"><span data-stu-id="9d886-194">Summary</span></span>
<span data-ttu-id="9d886-195">What’s shown above is NOT an exhaustive list of all the possible ingestion options for this example.</span><span class="sxs-lookup"><span data-stu-id="9d886-195">What’s shown above is NOT an exhaustive list of all the possible ingestion options for this example.</span></span> <span data-ttu-id="9d886-196">As a matter of fact, any grouping of tracks into streams is supported by the live ingestion.</span><span class="sxs-lookup"><span data-stu-id="9d886-196">As a matter of fact, any grouping of tracks into streams is supported by the live ingestion.</span></span> <span data-ttu-id="9d886-197">Customers and encoder vendors can choose their own implementations based on engineering complexity, encoder capacity, and redundancy and failover considerations.</span><span class="sxs-lookup"><span data-stu-id="9d886-197">Customers and encoder vendors can choose their own implementations based on engineering complexity, encoder capacity, and redundancy and failover considerations.</span></span> <span data-ttu-id="9d886-198">However it should be noted that in most cases there is only one audio track for the entire live presentation so it’s important to ensure the healthiness of the ingest stream that contains the audio track. This consideration often results in putting audio track into its own stream (as in Option 2) or bundling it with the lowest bitrate video track (as in Option 3).</span><span class="sxs-lookup"><span data-stu-id="9d886-198">However it should be noted that in most cases there is only one audio track for the entire live presentation so it’s important to ensure the healthiness of the ingest stream that contains the audio track. This consideration often results in putting audio track into its own stream (as in Option 2) or bundling it with the lowest bitrate video track (as in Option 3).</span></span> <span data-ttu-id="9d886-199">Also for better redundancy and fault-tolerance, sending the same audio track in two different streams (Option 2 with redundant audio tracks) or bundling the audio track at least two of the lowest bitrate video tracks (Option 3 with audio bundled in at least two video streams)  is highly recommended for live ingest into Microsoft Azure Media Services.</span><span class="sxs-lookup"><span data-stu-id="9d886-199">Also for better redundancy and fault-tolerance, sending the same audio track in two different streams (Option 2 with redundant audio tracks) or bundling the audio track at least two of the lowest bitrate video tracks (Option 3 with audio bundled in at least two video streams)  is highly recommended for live ingest into Microsoft Azure Media Services.</span></span>

## <a name="7-service-failover"></a><span data-ttu-id="9d886-200">7. Service Failover</span><span class="sxs-lookup"><span data-stu-id="9d886-200">7. Service Failover</span></span>
<span data-ttu-id="9d886-201">Given the nature of live streaming, good failover support is critical for ensuring the availability of the service.</span><span class="sxs-lookup"><span data-stu-id="9d886-201">Given the nature of live streaming, good failover support is critical for ensuring the availability of the service.</span></span> <span data-ttu-id="9d886-202">Microsoft Azure Media Services is designed to handle various types of failures including network errors, server errors, storage problems, etc. When used in conjunction with proper failover logic from the live encoder side, customer can achieve a highly reliable live streaming service from the cloud.</span><span class="sxs-lookup"><span data-stu-id="9d886-202">Microsoft Azure Media Services is designed to handle various types of failures including network errors, server errors, storage problems, etc. When used in conjunction with proper failover logic from the live encoder side, customer can achieve a highly reliable live streaming service from the cloud.</span></span>

<span data-ttu-id="9d886-203">In this section, we will discuss service failover scenarios.</span><span class="sxs-lookup"><span data-stu-id="9d886-203">In this section, we will discuss service failover scenarios.</span></span> <span data-ttu-id="9d886-204">In this case, the failure happens somewhere within the service and manifests itself as a network error.</span><span class="sxs-lookup"><span data-stu-id="9d886-204">In this case, the failure happens somewhere within the service and manifests itself as a network error.</span></span> <span data-ttu-id="9d886-205">Here are some recommendations for the encoder implementation for handling service failover:</span><span class="sxs-lookup"><span data-stu-id="9d886-205">Here are some recommendations for the encoder implementation for handling service failover:</span></span>

1. <span data-ttu-id="9d886-206">Use a 10 second timeout for establishing the TCP connection.</span><span class="sxs-lookup"><span data-stu-id="9d886-206">Use a 10 second timeout for establishing the TCP connection.</span></span>  <span data-ttu-id="9d886-207">If an attempt to establish the connection takes longer than 10 seconds, abort the operation and try again.</span><span class="sxs-lookup"><span data-stu-id="9d886-207">If an attempt to establish the connection takes longer than 10 seconds, abort the operation and try again.</span></span> 
2. <span data-ttu-id="9d886-208">Use a short timeout for sending the HTTP request message chunks.</span><span class="sxs-lookup"><span data-stu-id="9d886-208">Use a short timeout for sending the HTTP request message chunks.</span></span>  <span data-ttu-id="9d886-209">If the target MP4 fragment duration is N seconds, use a send timeout between N and 2N seconds; for example, use a timeout of 6 to 12 seconds if the MP4 fragment duration is 6 seconds.</span><span class="sxs-lookup"><span data-stu-id="9d886-209">If the target MP4 fragment duration is N seconds, use a send timeout between N and 2N seconds; for example, use a timeout of 6 to 12 seconds if the MP4 fragment duration is 6 seconds.</span></span>  <span data-ttu-id="9d886-210">If a timeout occurs, reset the connection, open a new connection, and resume stream ingest on the new connection.</span><span class="sxs-lookup"><span data-stu-id="9d886-210">If a timeout occurs, reset the connection, open a new connection, and resume stream ingest on the new connection.</span></span> 
3. <span data-ttu-id="9d886-211">Maintain a rolling buffer containing the last two fragments, for each track, that were successfully and completely sent to the service.</span><span class="sxs-lookup"><span data-stu-id="9d886-211">Maintain a rolling buffer containing the last two fragments, for each track, that were successfully and completely sent to the service.</span></span>  <span data-ttu-id="9d886-212">If the HTTP POST request for a stream is terminated or times out prior to the end of the stream, open a new connection and begin another HTTP POST request, resend the stream headers, resend the last two fragments for each track, and resume the stream without introducing a discontinuity in the media timeline.</span><span class="sxs-lookup"><span data-stu-id="9d886-212">If the HTTP POST request for a stream is terminated or times out prior to the end of the stream, open a new connection and begin another HTTP POST request, resend the stream headers, resend the last two fragments for each track, and resume the stream without introducing a discontinuity in the media timeline.</span></span>  <span data-ttu-id="9d886-213">This will reduce the chance of data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-213">This will reduce the chance of data loss.</span></span>
4. <span data-ttu-id="9d886-214">It is recommended that the encoder does NOT limit the number of retries to establish a connection or resume streaming after a TCP error occurs.</span><span class="sxs-lookup"><span data-stu-id="9d886-214">It is recommended that the encoder does NOT limit the number of retries to establish a connection or resume streaming after a TCP error occurs.</span></span>
5. <span data-ttu-id="9d886-215">After a TCP error:</span><span class="sxs-lookup"><span data-stu-id="9d886-215">After a TCP error:</span></span>
   1. <span data-ttu-id="9d886-216">The current connection MUST be closed, and a new connection MUST be created for a new HTTP POST request.</span><span class="sxs-lookup"><span data-stu-id="9d886-216">The current connection MUST be closed, and a new connection MUST be created for a new HTTP POST request.</span></span>
   2. <span data-ttu-id="9d886-217">The new HTTP POST URL MUST be the same as the initial POST URL.</span><span class="sxs-lookup"><span data-stu-id="9d886-217">The new HTTP POST URL MUST be the same as the initial POST URL.</span></span>
   3. <span data-ttu-id="9d886-218">The new HTTP POST MUST include stream headers (‘ftyp’, “Live Server Manifest Box”, and ‘moov’ box) identical to the stream headers in the initial POST.</span><span class="sxs-lookup"><span data-stu-id="9d886-218">The new HTTP POST MUST include stream headers (‘ftyp’, “Live Server Manifest Box”, and ‘moov’ box) identical to the stream headers in the initial POST.</span></span>
   4. <span data-ttu-id="9d886-219">The last two fragments sent for each track MUST be resent, and streaming resumed without introducing a discontinuity in the media timeline.</span><span class="sxs-lookup"><span data-stu-id="9d886-219">The last two fragments sent for each track MUST be resent, and streaming resumed without introducing a discontinuity in the media timeline.</span></span>  <span data-ttu-id="9d886-220">The MP4 fragment timestamps must increase continuously, even across HTTP POST requests.</span><span class="sxs-lookup"><span data-stu-id="9d886-220">The MP4 fragment timestamps must increase continuously, even across HTTP POST requests.</span></span>
6. <span data-ttu-id="9d886-221">The encoder SHOULD terminate the HTTP POST request if data is not being sent at a rate commensurate with the MP4 fragment duration.</span><span class="sxs-lookup"><span data-stu-id="9d886-221">The encoder SHOULD terminate the HTTP POST request if data is not being sent at a rate commensurate with the MP4 fragment duration.</span></span>  <span data-ttu-id="9d886-222">An HTTP POST request that does not send data can prevent Azure Media Services from quickly disconnecting from the encoder in the event of a service update.</span><span class="sxs-lookup"><span data-stu-id="9d886-222">An HTTP POST request that does not send data can prevent Azure Media Services from quickly disconnecting from the encoder in the event of a service update.</span></span>  <span data-ttu-id="9d886-223">For this reason, the HTTP POST for sparse (ad signal) tracks SHOULD be short lived, terminating as soon as the sparse fragment is sent.</span><span class="sxs-lookup"><span data-stu-id="9d886-223">For this reason, the HTTP POST for sparse (ad signal) tracks SHOULD be short lived, terminating as soon as the sparse fragment is sent.</span></span>

## <a name="8-encoder-failover"></a><span data-ttu-id="9d886-224">8. Encoder Failover</span><span class="sxs-lookup"><span data-stu-id="9d886-224">8. Encoder Failover</span></span>
<span data-ttu-id="9d886-225">Encoder failover is the second type of failover scenario that needs to be addressed for end-to-end live streaming delivery.</span><span class="sxs-lookup"><span data-stu-id="9d886-225">Encoder failover is the second type of failover scenario that needs to be addressed for end-to-end live streaming delivery.</span></span> <span data-ttu-id="9d886-226">In this scenario, the error condition happened on the encoder side.</span><span class="sxs-lookup"><span data-stu-id="9d886-226">In this scenario, the error condition happened on the encoder side.</span></span> 

![image5][image5]

<span data-ttu-id="9d886-228">Below are the expectations from the live ingestion endpoint when encoder failover happens:</span><span class="sxs-lookup"><span data-stu-id="9d886-228">Below are the expectations from the live ingestion endpoint when encoder failover happens:</span></span>

1. <span data-ttu-id="9d886-229">A new encoder instance SHOULD be created in order to continue streaming, as illustrated in the diagram above (Stream for 3000k video with dashed line).</span><span class="sxs-lookup"><span data-stu-id="9d886-229">A new encoder instance SHOULD be created in order to continue streaming, as illustrated in the diagram above (Stream for 3000k video with dashed line).</span></span>
2. <span data-ttu-id="9d886-230">The new encoder MUST use the same URL for HTTP POST requests as the failed instance.</span><span class="sxs-lookup"><span data-stu-id="9d886-230">The new encoder MUST use the same URL for HTTP POST requests as the failed instance.</span></span>
3. <span data-ttu-id="9d886-231">The new encoder’s POST request MUST include the same fragmented MP4 header boxes as the failed instance.</span><span class="sxs-lookup"><span data-stu-id="9d886-231">The new encoder’s POST request MUST include the same fragmented MP4 header boxes as the failed instance.</span></span>
4. <span data-ttu-id="9d886-232">The new encoder MUST be properly synchronized with all other running encoders for the same live presentation to generate synchronized audio/video samples with aligned fragment boundaries.</span><span class="sxs-lookup"><span data-stu-id="9d886-232">The new encoder MUST be properly synchronized with all other running encoders for the same live presentation to generate synchronized audio/video samples with aligned fragment boundaries.</span></span>
5. <span data-ttu-id="9d886-233">The new stream MUST be semantically equivalent with the previous stream and interchangeable at header and fragment level.</span><span class="sxs-lookup"><span data-stu-id="9d886-233">The new stream MUST be semantically equivalent with the previous stream and interchangeable at header and fragment level.</span></span>
6. <span data-ttu-id="9d886-234">The new encoder SHOULD try to minimize data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-234">The new encoder SHOULD try to minimize data loss.</span></span>  <span data-ttu-id="9d886-235">The fragment_absolute_time and fragment_index of media fragments SHOULD increase from the point where the encoder last stopped.</span><span class="sxs-lookup"><span data-stu-id="9d886-235">The fragment_absolute_time and fragment_index of media fragments SHOULD increase from the point where the encoder last stopped.</span></span>  <span data-ttu-id="9d886-236">The fragment_absolute_time and fragment_index SHOULD increase in a continuous fashion, but it is permissible to introduce a discontinuity if necessary.</span><span class="sxs-lookup"><span data-stu-id="9d886-236">The fragment_absolute_time and fragment_index SHOULD increase in a continuous fashion, but it is permissible to introduce a discontinuity if necessary.</span></span>  <span data-ttu-id="9d886-237">Azure Media Services will ignore fragments that it has already received and processed, so it is better to err on the side of resending fragments than to introduce discontinuities in the media timeline.</span><span class="sxs-lookup"><span data-stu-id="9d886-237">Azure Media Services will ignore fragments that it has already received and processed, so it is better to err on the side of resending fragments than to introduce discontinuities in the media timeline.</span></span> 

## <a name="9-encoder-redundancy"></a><span data-ttu-id="9d886-238">9. Encoder Redundancy</span><span class="sxs-lookup"><span data-stu-id="9d886-238">9. Encoder Redundancy</span></span>
<span data-ttu-id="9d886-239">For certain critical live events that demand even higher availability and quality of experience, it is recommended to employ active-active redundant encoders to achieve seamless failover with no data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-239">For certain critical live events that demand even higher availability and quality of experience, it is recommended to employ active-active redundant encoders to achieve seamless failover with no data loss.</span></span>

![image6][image6]

<span data-ttu-id="9d886-241">As illustrated in the diagram above, there are two group of encoders pushing two copies of each stream simultaneously into the live service.</span><span class="sxs-lookup"><span data-stu-id="9d886-241">As illustrated in the diagram above, there are two group of encoders pushing two copies of each stream simultaneously into the live service.</span></span> <span data-ttu-id="9d886-242">This setup is supported because Microsoft Azure Media Services has the ability to filter out duplicate fragments based on stream ID and fragment timestamp.</span><span class="sxs-lookup"><span data-stu-id="9d886-242">This setup is supported because Microsoft Azure Media Services has the ability to filter out duplicate fragments based on stream ID and fragment timestamp.</span></span> <span data-ttu-id="9d886-243">The resulting live stream and archive will be a single of copy of all the streams that is the best possible aggregation from the two sources.</span><span class="sxs-lookup"><span data-stu-id="9d886-243">The resulting live stream and archive will be a single of copy of all the streams that is the best possible aggregation from the two sources.</span></span> <span data-ttu-id="9d886-244">For example, in a hypothetical extreme case, as long as there is one encoder (doesn’t have to be the same one) running at any given point in time for each stream, the resulting live stream from the service will be continuous without data loss.</span><span class="sxs-lookup"><span data-stu-id="9d886-244">For example, in a hypothetical extreme case, as long as there is one encoder (doesn’t have to be the same one) running at any given point in time for each stream, the resulting live stream from the service will be continuous without data loss.</span></span> 

<span data-ttu-id="9d886-245">The requirement for this scenario is almost the same as the requirements in Encoder Failover case with the exception that the second set of encoders are running at the same time as the primary encoders.</span><span class="sxs-lookup"><span data-stu-id="9d886-245">The requirement for this scenario is almost the same as the requirements in Encoder Failover case with the exception that the second set of encoders are running at the same time as the primary encoders.</span></span>

## <a name="10-service-redundancy"></a><span data-ttu-id="9d886-246">10. Service Redundancy</span><span class="sxs-lookup"><span data-stu-id="9d886-246">10. Service Redundancy</span></span>
<span data-ttu-id="9d886-247">For highly redundant global distribution, it is sometimes required to have cross-region backup to handle regional disasters.</span><span class="sxs-lookup"><span data-stu-id="9d886-247">For highly redundant global distribution, it is sometimes required to have cross-region backup to handle regional disasters.</span></span> <span data-ttu-id="9d886-248">Expanding on the “Encoder Redundancy” topology, customers can choose to have a redundant service deployment in a different region which is connected with the 2nd set of encoders.</span><span class="sxs-lookup"><span data-stu-id="9d886-248">Expanding on the “Encoder Redundancy” topology, customers can choose to have a redundant service deployment in a different region which is connected with the 2nd set of encoders.</span></span> <span data-ttu-id="9d886-249">Customers could also work with a CDN provider to deploy a GTM (Global Traffic Manager) in front of the two service deployments to seamlessly route client traffic.</span><span class="sxs-lookup"><span data-stu-id="9d886-249">Customers could also work with a CDN provider to deploy a GTM (Global Traffic Manager) in front of the two service deployments to seamlessly route client traffic.</span></span> <span data-ttu-id="9d886-250">The requirements for the encoders are the same as “Encoder Redundancy” case with the only exception that the second set of encoders need to be pointed to a different live ingest end point.</span><span class="sxs-lookup"><span data-stu-id="9d886-250">The requirements for the encoders are the same as “Encoder Redundancy” case with the only exception that the second set of encoders need to be pointed to a different live ingest end point.</span></span> <span data-ttu-id="9d886-251">The diagram below shows this setup:</span><span class="sxs-lookup"><span data-stu-id="9d886-251">The diagram below shows this setup:</span></span>

![image7][image7]

## <a name="11-special-types-of-ingestion-formats"></a><span data-ttu-id="9d886-253">11. Special Types of Ingestion Formats</span><span class="sxs-lookup"><span data-stu-id="9d886-253">11. Special Types of Ingestion Formats</span></span>
<span data-ttu-id="9d886-254">This section discusses some special type of live ingestion formats that are designed to handle some specific scenarios.</span><span class="sxs-lookup"><span data-stu-id="9d886-254">This section discusses some special type of live ingestion formats that are designed to handle some specific scenarios.</span></span>

### <a name="sparse-track"></a><span data-ttu-id="9d886-255">Sparse Track</span><span class="sxs-lookup"><span data-stu-id="9d886-255">Sparse Track</span></span>
<span data-ttu-id="9d886-256">When delivering a live streaming presentation with rich client experience, it is often necessary to transmit time-synchronized events or signals in-band with the main media data.</span><span class="sxs-lookup"><span data-stu-id="9d886-256">When delivering a live streaming presentation with rich client experience, it is often necessary to transmit time-synchronized events or signals in-band with the main media data.</span></span> <span data-ttu-id="9d886-257">One example of this is dynamic live Ads insertion.</span><span class="sxs-lookup"><span data-stu-id="9d886-257">One example of this is dynamic live Ads insertion.</span></span> <span data-ttu-id="9d886-258">This type of event signaling is different from regular audio/video streaming because of its sparse nature.</span><span class="sxs-lookup"><span data-stu-id="9d886-258">This type of event signaling is different from regular audio/video streaming because of its sparse nature.</span></span> <span data-ttu-id="9d886-259">In other words, the signaling data usually does not happen continuously and the interval can be hard to predict.</span><span class="sxs-lookup"><span data-stu-id="9d886-259">In other words, the signaling data usually does not happen continuously and the interval can be hard to predict.</span></span> <span data-ttu-id="9d886-260">The concept of Sparse Track was specifically designed to ingest and broadcast in-band signaling data.</span><span class="sxs-lookup"><span data-stu-id="9d886-260">The concept of Sparse Track was specifically designed to ingest and broadcast in-band signaling data.</span></span>

<span data-ttu-id="9d886-261">Below is a recommended implementation for ingesting sparse track:</span><span class="sxs-lookup"><span data-stu-id="9d886-261">Below is a recommended implementation for ingesting sparse track:</span></span>

1. <span data-ttu-id="9d886-262">Create a separate Fragmented MP4 bit-stream which just contains sparse track(s) without audio/video tracks.</span><span class="sxs-lookup"><span data-stu-id="9d886-262">Create a separate Fragmented MP4 bit-stream which just contains sparse track(s) without audio/video tracks.</span></span>
2. <span data-ttu-id="9d886-263">In the “Live Server Manifest Box” as defined in Section 6 in [1], use “parentTrackName” parameter to specify the name of the parent track. Please refer to section 4.2.1.2.1.2 in [1] for more details.</span><span class="sxs-lookup"><span data-stu-id="9d886-263">In the “Live Server Manifest Box” as defined in Section 6 in [1], use “parentTrackName” parameter to specify the name of the parent track. Please refer to section 4.2.1.2.1.2 in [1] for more details.</span></span>
3. <span data-ttu-id="9d886-264">In the “Live Server Manifest Box”, manifestOutput MUST be set to “true”.</span><span class="sxs-lookup"><span data-stu-id="9d886-264">In the “Live Server Manifest Box”, manifestOutput MUST be set to “true”.</span></span>
4. <span data-ttu-id="9d886-265">Given the sparse nature of the signaling event, it is recommended that:</span><span class="sxs-lookup"><span data-stu-id="9d886-265">Given the sparse nature of the signaling event, it is recommended that:</span></span>
   1. <span data-ttu-id="9d886-266">At the beginning of the live event, encoder sends the initial header boxes to the service which would allow the service to register the sparse track in the client manifest.</span><span class="sxs-lookup"><span data-stu-id="9d886-266">At the beginning of the live event, encoder sends the initial header boxes to the service which would allow the service to register the sparse track in the client manifest.</span></span>
   2. <span data-ttu-id="9d886-267">The encoder SHOULD terminate the HTTP POST request when data is not being sent.</span><span class="sxs-lookup"><span data-stu-id="9d886-267">The encoder SHOULD terminate the HTTP POST request when data is not being sent.</span></span>  <span data-ttu-id="9d886-268">A long running HTTP POST that does not send data can prevent Azure Media Services from quickly disconnecting from the encoder in the event of a service update or server reboot, as the media server will be temporarily blocked in a receive operation on the socket.</span><span class="sxs-lookup"><span data-stu-id="9d886-268">A long running HTTP POST that does not send data can prevent Azure Media Services from quickly disconnecting from the encoder in the event of a service update or server reboot, as the media server will be temporarily blocked in a receive operation on the socket.</span></span> 
   3. <span data-ttu-id="9d886-269">During the time when signaling data is not available, the encoder SHOULD close the HTTP POST request.</span><span class="sxs-lookup"><span data-stu-id="9d886-269">During the time when signaling data is not available, the encoder SHOULD close the HTTP POST request.</span></span>  <span data-ttu-id="9d886-270">While the POST request is active, the encoder SHOULD send data</span><span class="sxs-lookup"><span data-stu-id="9d886-270">While the POST request is active, the encoder SHOULD send data</span></span> 
   4. <span data-ttu-id="9d886-271">When sending sparse fragments, encoder can set explicit Content-Length header if it’s available.</span><span class="sxs-lookup"><span data-stu-id="9d886-271">When sending sparse fragments, encoder can set explicit Content-Length header if it’s available.</span></span>
   5. <span data-ttu-id="9d886-272">When sending sparse fragment with a new connection, encoder SHOULD start sending from the header boxes followed by the new fragments.</span><span class="sxs-lookup"><span data-stu-id="9d886-272">When sending sparse fragment with a new connection, encoder SHOULD start sending from the header boxes followed by the new fragments.</span></span> <span data-ttu-id="9d886-273">This is to handle the case where failover happened in between and the new sparse connection is being established to a new server which has not seen the sparse track before.</span><span class="sxs-lookup"><span data-stu-id="9d886-273">This is to handle the case where failover happened in between and the new sparse connection is being established to a new server which has not seen the sparse track before.</span></span>
   6. <span data-ttu-id="9d886-274">The sparse track fragment will be made available to the client when the corresponding parent track fragment that has equal or bigger timestamp value is made available to the client.</span><span class="sxs-lookup"><span data-stu-id="9d886-274">The sparse track fragment will be made available to the client when the corresponding parent track fragment that has equal or bigger timestamp value is made available to the client.</span></span> <span data-ttu-id="9d886-275">For example, if the sparse fragment has a timestamp of t=1000, it is expected after the client sees video (assuming the parent track name is video) fragment timestamp 1000 or beyond, it can download the sparse fragment t=1000.</span><span class="sxs-lookup"><span data-stu-id="9d886-275">For example, if the sparse fragment has a timestamp of t=1000, it is expected after the client sees video (assuming the parent track name is video) fragment timestamp 1000 or beyond, it can download the sparse fragment t=1000.</span></span> <span data-ttu-id="9d886-276">Please note that the actual signal could very well be used for a different position in the presentation timeline for its designated purpose.</span><span class="sxs-lookup"><span data-stu-id="9d886-276">Please note that the actual signal could very well be used for a different position in the presentation timeline for its designated purpose.</span></span> <span data-ttu-id="9d886-277">In the example above, it’s possible that the sparse fragment of t=1000 has a XML payload which is for inserting an Ad in a position that’s a few seconds later.</span><span class="sxs-lookup"><span data-stu-id="9d886-277">In the example above, it’s possible that the sparse fragment of t=1000 has a XML payload which is for inserting an Ad in a position that’s a few seconds later.</span></span>
   7. <span data-ttu-id="9d886-278">The payload of sparse track fragment can be in various different formats (e.g. XML or text or binary, etc.) depending on different scenarios.</span><span class="sxs-lookup"><span data-stu-id="9d886-278">The payload of sparse track fragment can be in various different formats (e.g. XML or text or binary, etc.) depending on different scenarios.</span></span> 

### <a name="redundant-audio-track"></a><span data-ttu-id="9d886-279">Redundant Audio Track</span><span class="sxs-lookup"><span data-stu-id="9d886-279">Redundant Audio Track</span></span>
<span data-ttu-id="9d886-280">In a typical HTTP Adaptive Streaming scenario (e.g. Smooth Streaming or DASH), there is often only one audio track in the entire presentation.</span><span class="sxs-lookup"><span data-stu-id="9d886-280">In a typical HTTP Adaptive Streaming scenario (e.g. Smooth Streaming or DASH), there is often only one audio track in the entire presentation.</span></span> <span data-ttu-id="9d886-281">Unlike video tracks which have multiple quality levels for the client to choose from in error conditions, the audio track can be a single point of failure if the ingestion of the stream that contains the audio track is broken.</span><span class="sxs-lookup"><span data-stu-id="9d886-281">Unlike video tracks which have multiple quality levels for the client to choose from in error conditions, the audio track can be a single point of failure if the ingestion of the stream that contains the audio track is broken.</span></span> 

<span data-ttu-id="9d886-282">To solve this problem, Microsoft Azure Media Services supports live ingestion of redundant audio tracks.</span><span class="sxs-lookup"><span data-stu-id="9d886-282">To solve this problem, Microsoft Azure Media Services supports live ingestion of redundant audio tracks.</span></span> <span data-ttu-id="9d886-283">The idea is that the same audio track can be sent multiple times in different streams.</span><span class="sxs-lookup"><span data-stu-id="9d886-283">The idea is that the same audio track can be sent multiple times in different streams.</span></span> <span data-ttu-id="9d886-284">While the service will only register the audio track once in the client manifest, it is able to use redundant audio tracks as backups for retrieving audio fragments if the primary audio track is having issues.</span><span class="sxs-lookup"><span data-stu-id="9d886-284">While the service will only register the audio track once in the client manifest, it is able to use redundant audio tracks as backups for retrieving audio fragments if the primary audio track is having issues.</span></span> <span data-ttu-id="9d886-285">In order to ingest redundant audio tracks, the encoder needs to:</span><span class="sxs-lookup"><span data-stu-id="9d886-285">In order to ingest redundant audio tracks, the encoder needs to:</span></span>

1. <span data-ttu-id="9d886-286">Create the same audio track in multiple Fragment MP4 bit-streams.</span><span class="sxs-lookup"><span data-stu-id="9d886-286">Create the same audio track in multiple Fragment MP4 bit-streams.</span></span> <span data-ttu-id="9d886-287">The redundant audio tracks MUST be semantically equivalent with exactly the same fragment timestamps and interchangeable at header and fragment level.</span><span class="sxs-lookup"><span data-stu-id="9d886-287">The redundant audio tracks MUST be semantically equivalent with exactly the same fragment timestamps and interchangeable at header and fragment level.</span></span>
2. <span data-ttu-id="9d886-288">Ensure that the “audio” entry in the Live Server Manifest (Section 6 in [1]) be the same for all redundant audio tracks.</span><span class="sxs-lookup"><span data-stu-id="9d886-288">Ensure that the “audio” entry in the Live Server Manifest (Section 6 in [1]) be the same for all redundant audio tracks.</span></span>

<span data-ttu-id="9d886-289">Below is a recommended implementation for redundant audio tracks:</span><span class="sxs-lookup"><span data-stu-id="9d886-289">Below is a recommended implementation for redundant audio tracks:</span></span>

1. <span data-ttu-id="9d886-290">Send each unique audio track in a stream by itself.</span><span class="sxs-lookup"><span data-stu-id="9d886-290">Send each unique audio track in a stream by itself.</span></span>  <span data-ttu-id="9d886-291">Also send a redundant stream for each of these audio track streams, where the 2nd stream differs from the 1st only by the identifier in the HTTP POST URL:  {protocol}://{server address}/{publishing point path}/Streams({identifier}).</span><span class="sxs-lookup"><span data-stu-id="9d886-291">Also send a redundant stream for each of these audio track streams, where the 2nd stream differs from the 1st only by the identifier in the HTTP POST URL:  {protocol}://{server address}/{publishing point path}/Streams({identifier}).</span></span>
2. <span data-ttu-id="9d886-292">Use separate streams to send the two lowest video bitrates.</span><span class="sxs-lookup"><span data-stu-id="9d886-292">Use separate streams to send the two lowest video bitrates.</span></span> <span data-ttu-id="9d886-293">Each of these streams SHOULD also contain a copy of each unique audio track.  For example, when multiple languages are supported, these streams SHOULD contain audio tracks for each language.</span><span class="sxs-lookup"><span data-stu-id="9d886-293">Each of these streams SHOULD also contain a copy of each unique audio track.  For example, when multiple languages are supported, these streams SHOULD contain audio tracks for each language.</span></span>
3. <span data-ttu-id="9d886-294">Use separate server (encoder) instances to encode and send the redundant streams mentioned in (1) and (2).</span><span class="sxs-lookup"><span data-stu-id="9d886-294">Use separate server (encoder) instances to encode and send the redundant streams mentioned in (1) and (2).</span></span> 

## <a name="media-services-learning-paths"></a><span data-ttu-id="9d886-295">Media Services learning paths</span><span class="sxs-lookup"><span data-stu-id="9d886-295">Media Services learning paths</span></span>
[!INCLUDE [media-services-learning-paths-include](../../includes/media-services-learning-paths-include.md)]

## <a name="provide-feedback"></a><span data-ttu-id="9d886-296">Provide feedback</span><span class="sxs-lookup"><span data-stu-id="9d886-296">Provide feedback</span></span>
[!INCLUDE [media-services-user-voice-include](../../includes/media-services-user-voice-include.md)]

[image1]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image1.png
[image2]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image2.png
[image3]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image3.png
[image4]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image4.png
[image5]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image5.png
[image6]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image6.png
[image7]: https://docstestmedia1.blob.core.windows.net/azure-media/articles/media-services/media/media-services-fmp4-live-ingest-overview/media-services-image7.png








