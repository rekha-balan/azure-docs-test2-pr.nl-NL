---
title: Bing Speech Recognition API in Java on Android | Microsoft Docs
description: Use Bing Speech API to develop Android applications that convert spoken audio to text.
services: cognitive-services
author: priyaravi20
manager: yanbo
ms.service: cognitive-services
ms.technology: speech
ms.topic: article
ms.date: 12/09/2016
ms.author: prrajan
ms.openlocfilehash: 4b76e18dd34f02ae76ae636c0b9901e480aeb5ba
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44662706"
---
# <a name="get-started-with-bing-speech-recognition-in-java-on-android"></a><span data-ttu-id="5088a-103">Get Started with Bing Speech Recognition in Java on Android</span><span class="sxs-lookup"><span data-stu-id="5088a-103">Get Started with Bing Speech Recognition in Java on Android</span></span>
<span data-ttu-id="5088a-104">With Bing Speech Recognition API you can develop Android applications that leverage Microsoft cloud servers to convert spoken audio to text.</span><span class="sxs-lookup"><span data-stu-id="5088a-104">With Bing Speech Recognition API you can develop Android applications that leverage Microsoft cloud servers to convert spoken audio to text.</span></span> <span data-ttu-id="5088a-105">The API supports real-time streaming, so your application can simultaneously and asynchronously receive partial recognition results at the same time it is sending audio to the service</span><span class="sxs-lookup"><span data-stu-id="5088a-105">The API supports real-time streaming, so your application can simultaneously and asynchronously receive partial recognition results at the same time it is sending audio to the service</span></span>

<span data-ttu-id="5088a-106">This article uses a sample application to demonstrate how to use the Bing Speech Recognition API Client Library for Android to develop speech to text applications in Java for Android devices.</span><span class="sxs-lookup"><span data-stu-id="5088a-106">This article uses a sample application to demonstrate how to use the Bing Speech Recognition API Client Library for Android to develop speech to text applications in Java for Android devices.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="5088a-107">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="5088a-107">Prerequisites</span></span>

#### <a name="platform-requirements"></a><span data-ttu-id="5088a-108">Platform Requirements</span><span class="sxs-lookup"><span data-stu-id="5088a-108">Platform Requirements</span></span>
<span data-ttu-id="5088a-109">The below example has been developed for [Android Studio](http://developer.android.com/sdk/index.html) for Windows in Java.</span><span class="sxs-lookup"><span data-stu-id="5088a-109">The below example has been developed for [Android Studio](http://developer.android.com/sdk/index.html) for Windows in Java.</span></span>

#### <a name="get-the-client-library-and-example-application"></a><span data-ttu-id="5088a-110">Get the Client Library and Example Application</span><span class="sxs-lookup"><span data-stu-id="5088a-110">Get the Client Library and Example Application</span></span>
<span data-ttu-id="5088a-111">Download Speech Recognition API Client Library for Android from [this link](https://github.com/microsoft/cognitive-speech-stt-android).</span><span class="sxs-lookup"><span data-stu-id="5088a-111">Download Speech Recognition API Client Library for Android from [this link](https://github.com/microsoft/cognitive-speech-stt-android).</span></span> <span data-ttu-id="5088a-112">The downloaded files need to be saved to a folder of your choice.</span><span class="sxs-lookup"><span data-stu-id="5088a-112">The downloaded files need to be saved to a folder of your choice.</span></span> <span data-ttu-id="5088a-113">Inside there is both a fully buildable example and the SDK library.</span><span class="sxs-lookup"><span data-stu-id="5088a-113">Inside there is both a fully buildable example and the SDK library.</span></span> <span data-ttu-id="5088a-114">The buildable example can be found under **samples** in the **SpeechRecoExample** directory.</span><span class="sxs-lookup"><span data-stu-id="5088a-114">The buildable example can be found under **samples** in the **SpeechRecoExample** directory.</span></span> <span data-ttu-id="5088a-115">The two libraries you need to use in your own apps can be found in the **SpeechSDK** folder under **libs** in the **armeabi** and the **x86** folder.</span><span class="sxs-lookup"><span data-stu-id="5088a-115">The two libraries you need to use in your own apps can be found in the **SpeechSDK** folder under **libs** in the **armeabi** and the **x86** folder.</span></span> <span data-ttu-id="5088a-116">The size of **libandroid_platform.so** file is 22 MB but gets reduced to 4MB at deploy time.</span><span class="sxs-lookup"><span data-stu-id="5088a-116">The size of **libandroid_platform.so** file is 22 MB but gets reduced to 4MB at deploy time.</span></span> 

#### <a name="subscribe-to-speech-api-and-get-a-free-trial-subscription-key"></a><span data-ttu-id="5088a-117">Subscribe to Speech API and Get a Free Trial Subscription Key</span><span class="sxs-lookup"><span data-stu-id="5088a-117">Subscribe to Speech API and Get a Free Trial Subscription Key</span></span> 
<span data-ttu-id="5088a-118">Before creating the example, you must subscribe to Speech API which is part of Cognitive Services.</span><span class="sxs-lookup"><span data-stu-id="5088a-118">Before creating the example, you must subscribe to Speech API which is part of Cognitive Services.</span></span> <span data-ttu-id="5088a-119">Click the yellow **"Try for free"** button on one of the offered services, in this case Speech API, and follow the directions.</span><span class="sxs-lookup"><span data-stu-id="5088a-119">Click the yellow **"Try for free"** button on one of the offered services, in this case Speech API, and follow the directions.</span></span> <span data-ttu-id="5088a-120">For subscription and key management details, see [Subscriptions](https://www.microsoft.com/cognitive-services/en-us/sign-up).</span><span class="sxs-lookup"><span data-stu-id="5088a-120">For subscription and key management details, see [Subscriptions](https://www.microsoft.com/cognitive-services/en-us/sign-up).</span></span> <span data-ttu-id="5088a-121">Both the primary and secondary key can be used in this tutorial.</span><span class="sxs-lookup"><span data-stu-id="5088a-121">Both the primary and secondary key can be used in this tutorial.</span></span> 

## <a name="step-1-install-the-example-application-and-create-the-application-framework"></a><span data-ttu-id="5088a-122">Step 1: Install the Example Application and Create the Application Framework</span><span class="sxs-lookup"><span data-stu-id="5088a-122">Step 1: Install the Example Application and Create the Application Framework</span></span>

<span data-ttu-id="5088a-123">Create an Android application project to implement use of the Speech Recognition API</span><span class="sxs-lookup"><span data-stu-id="5088a-123">Create an Android application project to implement use of the Speech Recognition API</span></span>

1.  <span data-ttu-id="5088a-124">Open Android Studio.</span><span class="sxs-lookup"><span data-stu-id="5088a-124">Open Android Studio.</span></span>
2.  <span data-ttu-id="5088a-125">Paste your subscription key into the **primaryKey** string in the **..\samples\SpeechRecoExample\res\values** folder.</span><span class="sxs-lookup"><span data-stu-id="5088a-125">Paste your subscription key into the **primaryKey** string in the **..\samples\SpeechRecoExample\res\values** folder.</span></span> 
    
    >[!NOTE]
    ><span data-ttu-id="5088a-126">You don’t have to worry about the LUIS values if you don’t want to use Intent at this point.)</span><span class="sxs-lookup"><span data-stu-id="5088a-126">You don’t have to worry about the LUIS values if you don’t want to use Intent at this point.)</span></span>

3.  <span data-ttu-id="5088a-127">Create a new application project.</span><span class="sxs-lookup"><span data-stu-id="5088a-127">Create a new application project.</span></span>
4.  <span data-ttu-id="5088a-128">Using files downloaded from the **speech_SpeechToText-SDK-Android** zip package, do the following:</span><span class="sxs-lookup"><span data-stu-id="5088a-128">Using files downloaded from the **speech_SpeechToText-SDK-Android** zip package, do the following:</span></span> 
    1. <span data-ttu-id="5088a-129">Copy the **speechsdk.jar** file, found in the **SpeechSDK** folder inside the **Bin** folder, to the “**your-application\app\libs**” folder.</span><span class="sxs-lookup"><span data-stu-id="5088a-129">Copy the **speechsdk.jar** file, found in the **SpeechSDK** folder inside the **Bin** folder, to the “**your-application\app\libs**” folder.</span></span>
    2. <span data-ttu-id="5088a-130">Right click "**app**" in the project tree, select "**Open module settings**", select the "**Dependencies**" tab, and click "**+**" to add a "**File dependency**".</span><span class="sxs-lookup"><span data-stu-id="5088a-130">Right click "**app**" in the project tree, select "**Open module settings**", select the "**Dependencies**" tab, and click "**+**" to add a "**File dependency**".</span></span> 
    3. <span data-ttu-id="5088a-131">Select the **libs\speechsdk.jar** in the "**Select Path**" dialog box.</span><span class="sxs-lookup"><span data-stu-id="5088a-131">Select the **libs\speechsdk.jar** in the "**Select Path**" dialog box.</span></span>
    4. <span data-ttu-id="5088a-132">Copy the **libandroid_platform.so** file to the “**your-application\app\src\main\jniLibs\armeabi**” folder.</span><span class="sxs-lookup"><span data-stu-id="5088a-132">Copy the **libandroid_platform.so** file to the “**your-application\app\src\main\jniLibs\armeabi**” folder.</span></span>

<span data-ttu-id="5088a-133">**You can now run the example application or continue with thes following instructions to build your own application.**</span><span class="sxs-lookup"><span data-stu-id="5088a-133">**You can now run the example application or continue with thes following instructions to build your own application.**</span></span>

## <a name="step-2-build-the-example-application"></a><span data-ttu-id="5088a-134">Step 2: Build the Example Application</span><span class="sxs-lookup"><span data-stu-id="5088a-134">Step 2: Build the Example Application</span></span>
<span data-ttu-id="5088a-135">Open [MainActivity.java](https://oxfordportal.blob.core.windows.net/example-speech/MainActivity.java) or locate the **MainActivity.java** file within the **samples**, **SpeechRecoExample**, **src**, **com**, **microsoft**, **AzureIntelligentServicesExample** folder from the downloaded **speech_SpeechToText-SDK-Android** zip package.</span><span class="sxs-lookup"><span data-stu-id="5088a-135">Open [MainActivity.java](https://oxfordportal.blob.core.windows.net/example-speech/MainActivity.java) or locate the **MainActivity.java** file within the **samples**, **SpeechRecoExample**, **src**, **com**, **microsoft**, **AzureIntelligentServicesExample** folder from the downloaded **speech_SpeechToText-SDK-Android** zip package.</span></span> <span data-ttu-id="5088a-136">You will need the subscription key you generated above.</span><span class="sxs-lookup"><span data-stu-id="5088a-136">You will need the subscription key you generated above.</span></span> <span data-ttu-id="5088a-137">Once you have added your subscription key to the application, notice that you use the **SpeechRecognitionServiceFactory** to create a client of your liking.</span><span class="sxs-lookup"><span data-stu-id="5088a-137">Once you have added your subscription key to the application, notice that you use the **SpeechRecognitionServiceFactory** to create a client of your liking.</span></span> 

```
void initializeRecoClient()
    {
        String language = "en-us";
        
        String subscriptionKey = this.getString(R.string.subscription_key);
        String luisAppID = this.getString(R.string.luisAppID);
        String luisSubscriptionID = this.getString(R.string.luisSubscriptionID);

        if (m_isMicrophoneReco && null == m_micClient) {
            if (!m_isIntent) {
                m_micClient = SpeechRecognitionServiceFactory.createMicrophoneClient(this,
                                                                                     m_recoMode, 
                                                                                     language,
                                                                                     this,
                                                                                     subscriptionKey);
            }
            else {
                MicrophoneRecognitionClientWithIntent intentMicClient;
                intentMicClient = SpeechRecognitionServiceFactory.createMicrophoneClientWithIntent(this,
                                                                                                   language,
                                                                                                   this,
                                                                                                   subscriptionKey,
                                                                                                   luisAppID,
                                                                                                   luisSubscriptionID);
                m_micClient = intentMicClient;

            }
        }
        else if (!m_isMicrophoneReco && null == m_dataClient) {
            if (!m_isIntent) {
                m_dataClient = SpeechRecognitionServiceFactory.createDataClient(this,
                                                                                m_recoMode, 
                                                                                language,
                                                                                this,
                                                                                subscriptionKey);
            }
            else {
                DataRecognitionClientWithIntent intentDataClient;
                intentDataClient = SpeechRecognitionServiceFactory.createDataClientWithIntent(this, 
                                                                                              language,
                                                                                              this,
                                                                                              subscriptionKey,
                                                                                              luisAppID,
                                                                                              luisSubscriptionID);
                m_dataClient = intentDataClient;
            }
        }
    }

```
#### <a name="create-a-client"></a><span data-ttu-id="5088a-138">Create a Client:</span><span class="sxs-lookup"><span data-stu-id="5088a-138">Create a Client:</span></span>
<span data-ttu-id="5088a-139">Create one of the following clients</span><span class="sxs-lookup"><span data-stu-id="5088a-139">Create one of the following clients</span></span>

* <span data-ttu-id="5088a-140">**DataRecognitionClient:** Speech recognition with PCM data, for example from a file or audio source.</span><span class="sxs-lookup"><span data-stu-id="5088a-140">**DataRecognitionClient:** Speech recognition with PCM data, for example from a file or audio source.</span></span> 
    <span data-ttu-id="5088a-141">The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.</span><span class="sxs-lookup"><span data-stu-id="5088a-141">The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.</span></span> <span data-ttu-id="5088a-142">No modification is done to the buffers, so the user can apply their own Silence Detection if desired.</span><span class="sxs-lookup"><span data-stu-id="5088a-142">No modification is done to the buffers, so the user can apply their own Silence Detection if desired.</span></span> <span data-ttu-id="5088a-143">If the data is provided from wave files, you can send data from the file directly to the server.</span><span class="sxs-lookup"><span data-stu-id="5088a-143">If the data is provided from wave files, you can send data from the file directly to the server.</span></span> <span data-ttu-id="5088a-144">If you have raw data, for example audio coming over Bluetooth, then you first send a format header to the server followed by the data.</span><span class="sxs-lookup"><span data-stu-id="5088a-144">If you have raw data, for example audio coming over Bluetooth, then you first send a format header to the server followed by the data.</span></span>

* <span data-ttu-id="5088a-145">**MicrophoneRecognitionClient:** Speech recognition with audio coming from the microphone.</span><span class="sxs-lookup"><span data-stu-id="5088a-145">**MicrophoneRecognitionClient:** Speech recognition with audio coming from the microphone.</span></span> 
    <span data-ttu-id="5088a-146">Make sure the microphone is turned on and data from the microphone is sent to the Speech Recognition Service.</span><span class="sxs-lookup"><span data-stu-id="5088a-146">Make sure the microphone is turned on and data from the microphone is sent to the Speech Recognition Service.</span></span> <span data-ttu-id="5088a-147">A built-in Silence Detector is applied to the microphone data before it is sent to the recognition service.</span><span class="sxs-lookup"><span data-stu-id="5088a-147">A built-in Silence Detector is applied to the microphone data before it is sent to the recognition service.</span></span>

* <span data-ttu-id="5088a-148">**“WithIntent” clients:** Use “WithIntent” if you want the server to return additional structured information about the speech to be used by apps to parse the intent of the speaker and drive further actions by the app.</span><span class="sxs-lookup"><span data-stu-id="5088a-148">**“WithIntent” clients:** Use “WithIntent” if you want the server to return additional structured information about the speech to be used by apps to parse the intent of the speaker and drive further actions by the app.</span></span> <span data-ttu-id="5088a-149">To use Intent, you will need to train a model and get an AppID and a Secret.</span><span class="sxs-lookup"><span data-stu-id="5088a-149">To use Intent, you will need to train a model and get an AppID and a Secret.</span></span> <span data-ttu-id="5088a-150">See project [LUIS](https://www.luis.ai/) for details.</span><span class="sxs-lookup"><span data-stu-id="5088a-150">See project [LUIS](https://www.luis.ai/) for details.</span></span>

#### <a name="select-a-locale"></a><span data-ttu-id="5088a-151">Select a Locale</span><span class="sxs-lookup"><span data-stu-id="5088a-151">Select a Locale</span></span>
<span data-ttu-id="5088a-152">When you use the SpeechRecognitionServiceFactory to create the Client, you must select a language.</span><span class="sxs-lookup"><span data-stu-id="5088a-152">When you use the SpeechRecognitionServiceFactory to create the Client, you must select a language.</span></span>

<span data-ttu-id="5088a-153">Supported locales include:</span><span class="sxs-lookup"><span data-stu-id="5088a-153">Supported locales include:</span></span>

<span data-ttu-id="5088a-154">language-Country</span><span class="sxs-lookup"><span data-stu-id="5088a-154">language-Country</span></span> |<span data-ttu-id="5088a-155">language-Country</span><span class="sxs-lookup"><span data-stu-id="5088a-155">language-Country</span></span> | <span data-ttu-id="5088a-156">language-Country</span><span class="sxs-lookup"><span data-stu-id="5088a-156">language-Country</span></span> |<span data-ttu-id="5088a-157">language-Country</span><span class="sxs-lookup"><span data-stu-id="5088a-157">language-Country</span></span> 
---------|----------|--------|------------------
<span data-ttu-id="5088a-158">de-DE</span><span class="sxs-lookup"><span data-stu-id="5088a-158">de-DE</span></span>    |   <span data-ttu-id="5088a-159">zh-TW</span><span class="sxs-lookup"><span data-stu-id="5088a-159">zh-TW</span></span>  | <span data-ttu-id="5088a-160">zh-HK</span><span class="sxs-lookup"><span data-stu-id="5088a-160">zh-HK</span></span>  |    <span data-ttu-id="5088a-161">ru-RU</span><span class="sxs-lookup"><span data-stu-id="5088a-161">ru-RU</span></span> 
<span data-ttu-id="5088a-162">es-ES</span><span class="sxs-lookup"><span data-stu-id="5088a-162">es-ES</span></span>    |   <span data-ttu-id="5088a-163">ja-JP</span><span class="sxs-lookup"><span data-stu-id="5088a-163">ja-JP</span></span>  | <span data-ttu-id="5088a-164">ar-EG\*</span><span class="sxs-lookup"><span data-stu-id="5088a-164">ar-EG\*</span></span> |    <span data-ttu-id="5088a-165">da-DK</span><span class="sxs-lookup"><span data-stu-id="5088a-165">da-DK</span></span> 
<span data-ttu-id="5088a-166">en-GB</span><span class="sxs-lookup"><span data-stu-id="5088a-166">en-GB</span></span>    |   <span data-ttu-id="5088a-167">en-IN</span><span class="sxs-lookup"><span data-stu-id="5088a-167">en-IN</span></span>  | <span data-ttu-id="5088a-168">fi-FI</span><span class="sxs-lookup"><span data-stu-id="5088a-168">fi-FI</span></span>  |    <span data-ttu-id="5088a-169">nl-NL</span><span class="sxs-lookup"><span data-stu-id="5088a-169">nl-NL</span></span> 
<span data-ttu-id="5088a-170">en-US</span><span class="sxs-lookup"><span data-stu-id="5088a-170">en-US</span></span>    |   <span data-ttu-id="5088a-171">pt-BR</span><span class="sxs-lookup"><span data-stu-id="5088a-171">pt-BR</span></span>  | <span data-ttu-id="5088a-172">pt-PT</span><span class="sxs-lookup"><span data-stu-id="5088a-172">pt-PT</span></span>  |    <span data-ttu-id="5088a-173">ca-ES</span><span class="sxs-lookup"><span data-stu-id="5088a-173">ca-ES</span></span>
<span data-ttu-id="5088a-174">fr-FR</span><span class="sxs-lookup"><span data-stu-id="5088a-174">fr-FR</span></span>    |   <span data-ttu-id="5088a-175">ko-KR</span><span class="sxs-lookup"><span data-stu-id="5088a-175">ko-KR</span></span>  | <span data-ttu-id="5088a-176">en-NZ</span><span class="sxs-lookup"><span data-stu-id="5088a-176">en-NZ</span></span>  |    <span data-ttu-id="5088a-177">nb-NO</span><span class="sxs-lookup"><span data-stu-id="5088a-177">nb-NO</span></span>
<span data-ttu-id="5088a-178">it-IT</span><span class="sxs-lookup"><span data-stu-id="5088a-178">it-IT</span></span>    |   <span data-ttu-id="5088a-179">fr-CA</span><span class="sxs-lookup"><span data-stu-id="5088a-179">fr-CA</span></span>  | <span data-ttu-id="5088a-180">pl-PL</span><span class="sxs-lookup"><span data-stu-id="5088a-180">pl-PL</span></span>  |    <span data-ttu-id="5088a-181">es-MX</span><span class="sxs-lookup"><span data-stu-id="5088a-181">es-MX</span></span>
<span data-ttu-id="5088a-182">zh-CN</span><span class="sxs-lookup"><span data-stu-id="5088a-182">zh-CN</span></span>    |   <span data-ttu-id="5088a-183">en-AU</span><span class="sxs-lookup"><span data-stu-id="5088a-183">en-AU</span></span>  | <span data-ttu-id="5088a-184">en-CA</span><span class="sxs-lookup"><span data-stu-id="5088a-184">en-CA</span></span>  |    <span data-ttu-id="5088a-185">sv-SE</span><span class="sxs-lookup"><span data-stu-id="5088a-185">sv-SE</span></span>  
<span data-ttu-id="5088a-186">\*ar-EG supports Modern Standard Arabic (MSA)</span><span class="sxs-lookup"><span data-stu-id="5088a-186">\*ar-EG supports Modern Standard Arabic (MSA)</span></span>

#### <a name="select-a-recognition-mode"></a><span data-ttu-id="5088a-187">Select a Recognition Mode</span><span class="sxs-lookup"><span data-stu-id="5088a-187">Select a Recognition Mode</span></span>
<span data-ttu-id="5088a-188">You also need to provide the recognition mode.</span><span class="sxs-lookup"><span data-stu-id="5088a-188">You also need to provide the recognition mode.</span></span> 

* <span data-ttu-id="5088a-189">**ShortPhrase mode:** An utterance up to 15 seconds long.</span><span class="sxs-lookup"><span data-stu-id="5088a-189">**ShortPhrase mode:** An utterance up to 15 seconds long.</span></span> <span data-ttu-id="5088a-190">As data is sent to the service, the client will receive multiple partial results and one final multiple n-best choice result.</span><span class="sxs-lookup"><span data-stu-id="5088a-190">As data is sent to the service, the client will receive multiple partial results and one final multiple n-best choice result.</span></span>
* <span data-ttu-id="5088a-191">**LongDictation mode:** An utterance up to 2 minutes long.</span><span class="sxs-lookup"><span data-stu-id="5088a-191">**LongDictation mode:** An utterance up to 2 minutes long.</span></span> <span data-ttu-id="5088a-192">As data is sent to the service, the client will receive multiple partial results and multiple final results, based on where the server identifies sentence pauses.</span><span class="sxs-lookup"><span data-stu-id="5088a-192">As data is sent to the service, the client will receive multiple partial results and multiple final results, based on where the server identifies sentence pauses.</span></span>

#### <a name="attach-an-event-handler"></a><span data-ttu-id="5088a-193">Attach an Event Handler</span><span class="sxs-lookup"><span data-stu-id="5088a-193">Attach an Event Handler</span></span>
<span data-ttu-id="5088a-194">From the created client, you can attach various event handlers.</span><span class="sxs-lookup"><span data-stu-id="5088a-194">From the created client, you can attach various event handlers.</span></span>

* <span data-ttu-id="5088a-195">**Partial Results Events:** This event gets called every time the Speech Recognition Server has an idea of what you might be saying – even before you finish speaking (if you are using the Microphone Client) or have finished sending up data (if you are using the Data Client).</span><span class="sxs-lookup"><span data-stu-id="5088a-195">**Partial Results Events:** This event gets called every time the Speech Recognition Server has an idea of what you might be saying – even before you finish speaking (if you are using the Microphone Client) or have finished sending up data (if you are using the Data Client).</span></span>
* <span data-ttu-id="5088a-196">**Error Events:** Called when the Server Detects Error</span><span class="sxs-lookup"><span data-stu-id="5088a-196">**Error Events:** Called when the Server Detects Error</span></span>
* <span data-ttu-id="5088a-197">**Intent Events:** Called on WithIntent clients (only in ShortPhrase mode) after the final reco result has been parsed into a structured JSON intent.</span><span class="sxs-lookup"><span data-stu-id="5088a-197">**Intent Events:** Called on WithIntent clients (only in ShortPhrase mode) after the final reco result has been parsed into a structured JSON intent.</span></span>
* <span data-ttu-id="5088a-198">**Result Events:** When you have finished speaking (in ShortPhrase mode), this event is called.</span><span class="sxs-lookup"><span data-stu-id="5088a-198">**Result Events:** When you have finished speaking (in ShortPhrase mode), this event is called.</span></span> <span data-ttu-id="5088a-199">You will be provided with n-best choices for the result.</span><span class="sxs-lookup"><span data-stu-id="5088a-199">You will be provided with n-best choices for the result.</span></span> <span data-ttu-id="5088a-200">In LongDictation mode, he handler's associated with this event will be called multiple times, based on where the server thinks sentence pauses are.</span><span class="sxs-lookup"><span data-stu-id="5088a-200">In LongDictation mode, he handler's associated with this event will be called multiple times, based on where the server thinks sentence pauses are.</span></span>

#### <a name="select-confidence-value-and-text-form"></a><span data-ttu-id="5088a-201">Select Confidence Value and Text Form</span><span class="sxs-lookup"><span data-stu-id="5088a-201">Select Confidence Value and Text Form</span></span>
<span data-ttu-id="5088a-202">For each if the n-best choices, you get a confidence value and few different forms of the recognized text:</span><span class="sxs-lookup"><span data-stu-id="5088a-202">For each if the n-best choices, you get a confidence value and few different forms of the recognized text:</span></span>

* <span data-ttu-id="5088a-203">**LexicalForm:** This form is optimal for use by applications that need the raw, unprocessed speech recognition result.</span><span class="sxs-lookup"><span data-stu-id="5088a-203">**LexicalForm:** This form is optimal for use by applications that need the raw, unprocessed speech recognition result.</span></span>
* <span data-ttu-id="5088a-204">**DisplayText:** The recognized phrase with inverse text normalization, capitalization, punctuation and profanity masking applied.</span><span class="sxs-lookup"><span data-stu-id="5088a-204">**DisplayText:** The recognized phrase with inverse text normalization, capitalization, punctuation and profanity masking applied.</span></span> <span data-ttu-id="5088a-205">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span><span class="sxs-lookup"><span data-stu-id="5088a-205">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span></span> <span data-ttu-id="5088a-206">This form is optimal for use by applications that display the speech recognition results to a user.</span><span class="sxs-lookup"><span data-stu-id="5088a-206">This form is optimal for use by applications that display the speech recognition results to a user.</span></span>
* <span data-ttu-id="5088a-207">**Inverse Text Normalization (ITN):** has also been applied.</span><span class="sxs-lookup"><span data-stu-id="5088a-207">**Inverse Text Normalization (ITN):** has also been applied.</span></span> <span data-ttu-id="5088a-208">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span><span class="sxs-lookup"><span data-stu-id="5088a-208">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span></span> <span data-ttu-id="5088a-209">This form is optimal for use by applications that display the speech recognition results to a user.</span><span class="sxs-lookup"><span data-stu-id="5088a-209">This form is optimal for use by applications that display the speech recognition results to a user.</span></span>
* <span data-ttu-id="5088a-210">**InverseTextNormalizationResult:** Inverse text normalization (ITN) converts phrases like "one two three four" to a normalized form such as "1234".</span><span class="sxs-lookup"><span data-stu-id="5088a-210">**InverseTextNormalizationResult:** Inverse text normalization (ITN) converts phrases like "one two three four" to a normalized form such as "1234".</span></span> <span data-ttu-id="5088a-211">Another example is converting result text from "go to fourth street" to "go to 4th st".</span><span class="sxs-lookup"><span data-stu-id="5088a-211">Another example is converting result text from "go to fourth street" to "go to 4th st".</span></span> <span data-ttu-id="5088a-212">This form is optimal for use by applications that interpret the speech recognition results as commands or which perform queries based on the recognized text.</span><span class="sxs-lookup"><span data-stu-id="5088a-212">This form is optimal for use by applications that interpret the speech recognition results as commands or which perform queries based on the recognized text.</span></span>
* <span data-ttu-id="5088a-213">**MaskedInverseTextNormalizationResult:** The recognized phrase with inverse text normalization and profanity masking applied, but not capitalization or punctuation.</span><span class="sxs-lookup"><span data-stu-id="5088a-213">**MaskedInverseTextNormalizationResult:** The recognized phrase with inverse text normalization and profanity masking applied, but not capitalization or punctuation.</span></span> <span data-ttu-id="5088a-214">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span><span class="sxs-lookup"><span data-stu-id="5088a-214">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span></span> <span data-ttu-id="5088a-215">This form is optimal for use by applications that display the speech recognition results to a user.</span><span class="sxs-lookup"><span data-stu-id="5088a-215">This form is optimal for use by applications that display the speech recognition results to a user.</span></span> <span data-ttu-id="5088a-216">Inverse Text Normalization (ITN) has also been applied.</span><span class="sxs-lookup"><span data-stu-id="5088a-216">Inverse Text Normalization (ITN) has also been applied.</span></span> <span data-ttu-id="5088a-217">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span><span class="sxs-lookup"><span data-stu-id="5088a-217">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span></span> <span data-ttu-id="5088a-218">This form is optimal for use by applications that use the unmasked ITN results but also need to display the command or query to the user.</span><span class="sxs-lookup"><span data-stu-id="5088a-218">This form is optimal for use by applications that use the unmasked ITN results but also need to display the command or query to the user.</span></span>

## <a name="step-3-run-the-example-application"></a><span data-ttu-id="5088a-219">Step 3: Run the Example Application</span><span class="sxs-lookup"><span data-stu-id="5088a-219">Step 3: Run the Example Application</span></span>
<span data-ttu-id="5088a-220">Run the application with the chosen clients, recognition modes and event handlers.</span><span class="sxs-lookup"><span data-stu-id="5088a-220">Run the application with the chosen clients, recognition modes and event handlers.</span></span>

## <a name="related-topics"></a><span data-ttu-id="5088a-221">Related Topics</span><span class="sxs-lookup"><span data-stu-id="5088a-221">Related Topics</span></span>
* [<span data-ttu-id="5088a-222">Get Started with Bing Speech Recognition in C Sharp for Windows in .NET</span><span class="sxs-lookup"><span data-stu-id="5088a-222">Get Started with Bing Speech Recognition in C Sharp for Windows in .NET</span></span>](GetStartedCSharpDesktop.md)
* [<span data-ttu-id="5088a-223">Get Started with Bing Speech Recognition and/or intent in Objective C on iOS</span><span class="sxs-lookup"><span data-stu-id="5088a-223">Get Started with Bing Speech Recognition and/or intent in Objective C on iOS</span></span>](Get-Started-ObjectiveC-iOS.md)
* [<span data-ttu-id="5088a-224">Get Started with Bing Speech API in JavaScript</span><span class="sxs-lookup"><span data-stu-id="5088a-224">Get Started with Bing Speech API in JavaScript</span></span>](GetStartedJS.md)
