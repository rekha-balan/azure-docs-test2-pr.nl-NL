---
title: Get started with Bing Speech Recognition API in Objective C on iOS | Microsoft Docs
description: Use Bing Speech Recognition API to develop iOS applications applications that convert spoken audio to text.
services: cognitive-services
author: priyaravi20
manager: yanbo
ms.service: cognitive-services
ms.technology: speech
ms.topic: article
ms.date: 03/16/2017
ms.author: prrajan
ms.openlocfilehash: 32b864d092ef5baa294ad77ba9db634fc3023ea4
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44556513"
---
# <a name="get-started-with-bing-speech-recognition-api-in-objective-c-on-ios"></a><span data-ttu-id="b6d53-103">Get Started with Bing Speech Recognition API in Objective C on iOS</span><span class="sxs-lookup"><span data-stu-id="b6d53-103">Get Started with Bing Speech Recognition API in Objective C on iOS</span></span>

<span data-ttu-id="b6d53-104">With Bing Speech Recognition API you can develop iOS applications that leverage Microsoft cloud servers to convert spoken audio to text.</span><span class="sxs-lookup"><span data-stu-id="b6d53-104">With Bing Speech Recognition API you can develop iOS applications that leverage Microsoft cloud servers to convert spoken audio to text.</span></span> <span data-ttu-id="b6d53-105">The API supports real-time streaming, so your application can simultaneously and asynchronously receive partial recognition results at the same time it is sending audio to the service</span><span class="sxs-lookup"><span data-stu-id="b6d53-105">The API supports real-time streaming, so your application can simultaneously and asynchronously receive partial recognition results at the same time it is sending audio to the service</span></span> 

<span data-ttu-id="b6d53-106">This article uses a sample application to demonstrate the basics of getting started with the Bing Speech Recognition API to develop an iOS application.</span><span class="sxs-lookup"><span data-stu-id="b6d53-106">This article uses a sample application to demonstrate the basics of getting started with the Bing Speech Recognition API to develop an iOS application.</span></span> <span data-ttu-id="b6d53-107">For a complete API reference, see [Speech SDK Client Library Reference](https://cdn.rawgit.com/Microsoft/Cognitive-Speech-STT-iOS/master/com.Microsoft.SpeechSDK-1_0-for-iOS.docset/Contents/Resources/Documents/index.html).</span><span class="sxs-lookup"><span data-stu-id="b6d53-107">For a complete API reference, see [Speech SDK Client Library Reference](https://cdn.rawgit.com/Microsoft/Cognitive-Speech-STT-iOS/master/com.Microsoft.SpeechSDK-1_0-for-iOS.docset/Contents/Resources/Documents/index.html).</span></span>

<span data-ttu-id="b6d53-108"><a name="Prereqs"> </a></span><span class="sxs-lookup"><span data-stu-id="b6d53-108"><a name="Prereqs"> </a></span></span>
## <a name="prerequisites"></a><span data-ttu-id="b6d53-109">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="b6d53-109">Prerequisites</span></span>

#### <a name="platform-requirements"></a><span data-ttu-id="b6d53-110">Platform requirements</span><span class="sxs-lookup"><span data-stu-id="b6d53-110">Platform requirements</span></span>

<span data-ttu-id="b6d53-111">Make sure Mac XCode IDE is installed.</span><span class="sxs-lookup"><span data-stu-id="b6d53-111">Make sure Mac XCode IDE is installed.</span></span>

#### <a name="get-the-client-library-and-example"></a><span data-ttu-id="b6d53-112">Get the client library and example</span><span class="sxs-lookup"><span data-stu-id="b6d53-112">Get the client library and example</span></span>

<span data-ttu-id="b6d53-113">You may download the Speech API client library and example for iOS through https [SDK](https://github.com/microsoft/cognitive-speech-stt-ios).</span><span class="sxs-lookup"><span data-stu-id="b6d53-113">You may download the Speech API client library and example for iOS through https [SDK](https://github.com/microsoft/cognitive-speech-stt-ios).</span></span> <span data-ttu-id="b6d53-114">The downloaded zip file needs to be extracted to a folder of your choice.</span><span class="sxs-lookup"><span data-stu-id="b6d53-114">The downloaded zip file needs to be extracted to a folder of your choice.</span></span>
<span data-ttu-id="b6d53-115">Install the .pkg file on your Mac.</span><span class="sxs-lookup"><span data-stu-id="b6d53-115">Install the .pkg file on your Mac.</span></span> <span data-ttu-id="b6d53-116">The .pkg file will install onto your Mac hard drive in the root (or personal) Documents directory under **SpeechSDK**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-116">The .pkg file will install onto your Mac hard drive in the root (or personal) Documents directory under **SpeechSDK**.</span></span> <span data-ttu-id="b6d53-117">Inside the folder there is both a fully buildable example and an SDK library.</span><span class="sxs-lookup"><span data-stu-id="b6d53-117">Inside the folder there is both a fully buildable example and an SDK library.</span></span> <span data-ttu-id="b6d53-118">The buildable example can be found in the **samples\SpeechRecognitionServerExample** directory and the library can be found at the **SpeechSDK\SpeechSDK.framework**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-118">The buildable example can be found in the **samples\SpeechRecognitionServerExample** directory and the library can be found at the **SpeechSDK\SpeechSDK.framework**.</span></span>

#### <a name="subscribe-to-speech-api-and-get-a-free-trial-subscription-key"></a><span data-ttu-id="b6d53-119">Subscribe to Speech API and get a free trial subscription key</span><span class="sxs-lookup"><span data-stu-id="b6d53-119">Subscribe to Speech API and get a free trial subscription key</span></span>

<span data-ttu-id="b6d53-120">Before creating the example, you must subscribe to Speech API which is part of Cognitive Services.</span><span class="sxs-lookup"><span data-stu-id="b6d53-120">Before creating the example, you must subscribe to Speech API which is part of Cognitive Services.</span></span> <span data-ttu-id="b6d53-121">For subscription and key management details, see [Subscriptions](https://www.microsoft.com/cognitive-services/en-us/sign-up).</span><span class="sxs-lookup"><span data-stu-id="b6d53-121">For subscription and key management details, see [Subscriptions](https://www.microsoft.com/cognitive-services/en-us/sign-up).</span></span> <span data-ttu-id="b6d53-122">Both the primary and secondary key can be used in this tutorial.</span><span class="sxs-lookup"><span data-stu-id="b6d53-122">Both the primary and secondary key can be used in this tutorial.</span></span>

<span data-ttu-id="b6d53-123"><a name="Step1"> </a></span><span class="sxs-lookup"><span data-stu-id="b6d53-123"><a name="Step1"> </a></span></span>
## <a name="step-1-install-the-example-application-and-create-the-application-framework"></a><span data-ttu-id="b6d53-124">Step 1: Install the Example Application and Create the Application Framework</span><span class="sxs-lookup"><span data-stu-id="b6d53-124">Step 1: Install the Example Application and Create the Application Framework</span></span>

<span data-ttu-id="b6d53-125">Open Xcode IDE.</span><span class="sxs-lookup"><span data-stu-id="b6d53-125">Open Xcode IDE.</span></span> <span data-ttu-id="b6d53-126">You have two options, building the example application or building your own application.</span><span class="sxs-lookup"><span data-stu-id="b6d53-126">You have two options, building the example application or building your own application.</span></span>

<span data-ttu-id="b6d53-127">If you want build and run the **example application**, the project is embedded [here](https://www.projectoxford.ai/SDK/GetFile?path=speech/SpeechToText-SDK-iOS.zip) at **samples\SpeechRecognitionServerExample** and can be opened in XCode.</span><span class="sxs-lookup"><span data-stu-id="b6d53-127">If you want build and run the **example application**, the project is embedded [here](https://www.projectoxford.ai/SDK/GetFile?path=speech/SpeechToText-SDK-iOS.zip) at **samples\SpeechRecognitionServerExample** and can be opened in XCode.</span></span>
  * <span data-ttu-id="b6d53-128">You will need to paste your subscription key into the file “**settings.plist**” which can be found in the **samples** folder under **SpeechRecognitionServerExample**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-128">You will need to paste your subscription key into the file “**settings.plist**” which can be found in the **samples** folder under **SpeechRecognitionServerExample**.</span></span> <span data-ttu-id="b6d53-129">(You may ignore the LUIS values if you don’t want to use “Intent” right now.)</span><span class="sxs-lookup"><span data-stu-id="b6d53-129">(You may ignore the LUIS values if you don’t want to use “Intent” right now.)</span></span>

<span data-ttu-id="b6d53-130">If you want to **build your own application**, continue on with these instructions.</span><span class="sxs-lookup"><span data-stu-id="b6d53-130">If you want to **build your own application**, continue on with these instructions.</span></span>

1.  <span data-ttu-id="b6d53-131">Create a new application project.</span><span class="sxs-lookup"><span data-stu-id="b6d53-131">Create a new application project.</span></span>
2.  <span data-ttu-id="b6d53-132">With the items you downloaded from the SDK, do the following:</span><span class="sxs-lookup"><span data-stu-id="b6d53-132">With the items you downloaded from the SDK, do the following:</span></span>

 <span data-ttu-id="b6d53-133">**a)** Click on the project in the file navigator on the left.</span><span class="sxs-lookup"><span data-stu-id="b6d53-133">**a)** Click on the project in the file navigator on the left.</span></span> <span data-ttu-id="b6d53-134">Then click on the project or target in the editor that appears.</span><span class="sxs-lookup"><span data-stu-id="b6d53-134">Then click on the project or target in the editor that appears.</span></span> <span data-ttu-id="b6d53-135">Click on "**Build Settings**", then change from "**Basic**" to "**All**".</span><span class="sxs-lookup"><span data-stu-id="b6d53-135">Click on "**Build Settings**", then change from "**Basic**" to "**All**".</span></span>

 <span data-ttu-id="b6d53-136">**b)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK/SpeechSDK.framework/Headers**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-136">**b)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK/SpeechSDK.framework/Headers**.</span></span> <span data-ttu-id="b6d53-137">Add an “**Include Search Path**” to include the **Headers** directory.</span><span class="sxs-lookup"><span data-stu-id="b6d53-137">Add an “**Include Search Path**” to include the **Headers** directory.</span></span>

 <span data-ttu-id="b6d53-138">**c)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-138">**c)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK**.</span></span> <span data-ttu-id="b6d53-139">Add a “**Framework Search Path**” to include the **SpeechSDK** directory.</span><span class="sxs-lookup"><span data-stu-id="b6d53-139">Add a “**Framework Search Path**” to include the **SpeechSDK** directory.</span></span>

 <span data-ttu-id="b6d53-140">**d)** Click on the project in the file navigator on the left.</span><span class="sxs-lookup"><span data-stu-id="b6d53-140">**d)** Click on the project in the file navigator on the left.</span></span> <span data-ttu-id="b6d53-141">Then click on the project or target in the editor that appears.</span><span class="sxs-lookup"><span data-stu-id="b6d53-141">Then click on the project or target in the editor that appears.</span></span> <span data-ttu-id="b6d53-142">Click on “**General**”.</span><span class="sxs-lookup"><span data-stu-id="b6d53-142">Click on “**General**”.</span></span>

 <span data-ttu-id="b6d53-143">**e)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK/SpeechSDK.framework**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-143">**e)** Inside the directory to which you unpacked the SDK, you will see the directory, **SpeechSDK/SpeechSDK.framework**.</span></span> <span data-ttu-id="b6d53-144">Add **SpeechSDK/SpeechSDK.framework** as a “**Linked Frameworks and Libraries**” via the “**Add Other…**”</span><span class="sxs-lookup"><span data-stu-id="b6d53-144">Add **SpeechSDK/SpeechSDK.framework** as a “**Linked Frameworks and Libraries**” via the “**Add Other…**”</span></span> <span data-ttu-id="b6d53-145">button found after you click on “**+**”.</span><span class="sxs-lookup"><span data-stu-id="b6d53-145">button found after you click on “**+**”.</span></span>

 <span data-ttu-id="b6d53-146">**f)** Also add **SpeechSDK.framework** as an “**Embedded Binary**” framework.</span><span class="sxs-lookup"><span data-stu-id="b6d53-146">**f)** Also add **SpeechSDK.framework** as an “**Embedded Binary**” framework.</span></span>

 <span data-ttu-id="b6d53-147">**g)** Note that inside the directory to which you unpacked the SDK in directory **SpeechSDK\Samples\SpeechRecognitionServerExample** there is a XCode buildable example so you can see these settings in action.</span><span class="sxs-lookup"><span data-stu-id="b6d53-147">**g)** Note that inside the directory to which you unpacked the SDK in directory **SpeechSDK\Samples\SpeechRecognitionServerExample** there is a XCode buildable example so you can see these settings in action.</span></span>

<span data-ttu-id="b6d53-148"><a name="Step2"> </a></span><span class="sxs-lookup"><span data-stu-id="b6d53-148"><a name="Step2"> </a></span></span>
## <a name="step-2-build-the-application--example-code"></a><span data-ttu-id="b6d53-149">Step 2: Build the Application / Example Code</span><span class="sxs-lookup"><span data-stu-id="b6d53-149">Step 2: Build the Application / Example Code</span></span>

<span data-ttu-id="b6d53-150">Open [ViewController.mm](https://oxfordportal.blob.core.windows.net/example-speech/ViewController.mm) in a new window or find **ViewController.mm** in the downloaded file under **samples\SpeechRecognitionServiceExample**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-150">Open [ViewController.mm](https://oxfordportal.blob.core.windows.net/example-speech/ViewController.mm) in a new window or find **ViewController.mm** in the downloaded file under **samples\SpeechRecognitionServiceExample**.</span></span> <span data-ttu-id="b6d53-151">You will need the **Speech API primary subscription key**.</span><span class="sxs-lookup"><span data-stu-id="b6d53-151">You will need the **Speech API primary subscription key**.</span></span> <span data-ttu-id="b6d53-152">The below code snippet shows where to use the key.</span><span class="sxs-lookup"><span data-stu-id="b6d53-152">The below code snippet shows where to use the key.</span></span> <span data-ttu-id="b6d53-153">(You may ignore the LUIS values if you don’t want to use “Intent” right now.)</span><span class="sxs-lookup"><span data-stu-id="b6d53-153">(You may ignore the LUIS values if you don’t want to use “Intent” right now.)</span></span>

```
{
    NSString* language = @"en-us";

    NSString* path = [[NSBundle mainBundle] pathForResource:@"settings" ofType:@"plist"];
    NSDictionary* settings = [[NSDictionary alloc] initWithContentsOfFile:path];

    NSString* primaryOrSecondaryKey = [settings objectForKey:(@"primaryKey")];
    NSString* luisAppID = [settings objectForKey:(@"luisAppID")];
    NSString* luisSubscriptionID = [settings objectForKey:(@"luisSubscriptionID")];

    if (isMicrophoneReco) {
        if (!isIntent) {
            micClient = [SpeechRecognitionServiceFactory createMicrophoneClient:(recoMode)
                                                                   withLanguage:(language)
                                                                        withKey:(primaryOrSecondaryKey)
                                                                   withProtocol:(self)];
        }
        else {
            MicrophoneRecognitionClientWithIntent* micIntentClient;
            micIntentClient = [SpeechRecognitionServiceFactory createMicrophoneClientWithIntent:(language)
                                                                                        withKey:(primaryOrSecondaryKey)
                                                                                  withLUISAppID:(luisAppID)
                                                                                 withLUISSecret:(luisSubscriptionID)
                                                                                   withProtocol:(self)];
            micClient = micIntentClient;
        }
    }
    else {
        if (!isIntent) {
            dataClient = [SpeechRecognitionServiceFactory createDataClient:(recoMode)
                                                              withLanguage:(language)
                                                                   withKey:(primaryOrSecondaryKey)
                                                              withProtocol:(self)];
        }
        else {
            DataRecognitionClientWithIntent* dataIntentClient;
            dataIntentClient = [SpeechRecognitionServiceFactory createDataClientWithIntent:(language)
                                                                                   withKey:(primaryOrSecondaryKey)
                                                                             withLUISAppID:(luisAppID)
                                                                            withLUISSecret:(luisSubscriptionID)
                                                                              withProtocol:(self)];
            dataClient = dataIntentClient;
        }
    }
}

```
 
#### <a name="create-a-client"></a><span data-ttu-id="b6d53-154">Create a Client</span><span class="sxs-lookup"><span data-stu-id="b6d53-154">Create a Client</span></span>
<span data-ttu-id="b6d53-155">Once your **primaryKey** has been pasted into the example, you can use the **SpeechRecognitionServiceFactory** to create a client of your liking.</span><span class="sxs-lookup"><span data-stu-id="b6d53-155">Once your **primaryKey** has been pasted into the example, you can use the **SpeechRecognitionServiceFactory** to create a client of your liking.</span></span> <span data-ttu-id="b6d53-156">For example, you can create a client consisting of:</span><span class="sxs-lookup"><span data-stu-id="b6d53-156">For example, you can create a client consisting of:</span></span>

* <span data-ttu-id="b6d53-157">**DataRecognitionClient:** Speech recognition with PCM data (for example from a file or audio source).</span><span class="sxs-lookup"><span data-stu-id="b6d53-157">**DataRecognitionClient:** Speech recognition with PCM data (for example from a file or audio source).</span></span> <span data-ttu-id="b6d53-158">The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.</span><span class="sxs-lookup"><span data-stu-id="b6d53-158">The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.</span></span> <span data-ttu-id="b6d53-159">No modification is done to the buffers, so the user can apply their own Silence Detection if desired.</span><span class="sxs-lookup"><span data-stu-id="b6d53-159">No modification is done to the buffers, so the user can apply their own Silence Detection if desired.</span></span> <span data-ttu-id="b6d53-160">If the data is provided from wave files, you can send data from the file right to the server.</span><span class="sxs-lookup"><span data-stu-id="b6d53-160">If the data is provided from wave files, you can send data from the file right to the server.</span></span> <span data-ttu-id="b6d53-161">If you have raw data, for example audio coming over Bluetooth, then you first send a format header to the server followed by the data.</span><span class="sxs-lookup"><span data-stu-id="b6d53-161">If you have raw data, for example audio coming over Bluetooth, then you first send a format header to the server followed by the data.</span></span>

* <span data-ttu-id="b6d53-162">**MicrophoneRecognitionClient:** Speech recognition with audio coming from the microphone.</span><span class="sxs-lookup"><span data-stu-id="b6d53-162">**MicrophoneRecognitionClient:** Speech recognition with audio coming from the microphone.</span></span> <span data-ttu-id="b6d53-163">Make sure the microphone is turned on and data from the microphone is sent to the Speech Recognition Service.</span><span class="sxs-lookup"><span data-stu-id="b6d53-163">Make sure the microphone is turned on and data from the microphone is sent to the Speech Recognition Service.</span></span> <span data-ttu-id="b6d53-164">A built-in “Silence Detector” is applied to the microphone data before it is sent to the recognition service.</span><span class="sxs-lookup"><span data-stu-id="b6d53-164">A built-in “Silence Detector” is applied to the microphone data before it is sent to the recognition service.</span></span>

* <span data-ttu-id="b6d53-165">**“WithIntent” Clients:** Use “WithIntent” if you want the server to return additional structured information about the speech to be used by apps to parse the intent of the speaker and drive further actions by the app.</span><span class="sxs-lookup"><span data-stu-id="b6d53-165">**“WithIntent” Clients:** Use “WithIntent” if you want the server to return additional structured information about the speech to be used by apps to parse the intent of the speaker and drive further actions by the app.</span></span> <span data-ttu-id="b6d53-166">To use Intent, you will need to train a model and get an AppID and a Secret.</span><span class="sxs-lookup"><span data-stu-id="b6d53-166">To use Intent, you will need to train a model and get an AppID and a Secret.</span></span> <span data-ttu-id="b6d53-167">See project [LUIS](https://www.luis.ai) for details.</span><span class="sxs-lookup"><span data-stu-id="b6d53-167">See project [LUIS](https://www.luis.ai) for details.</span></span>

#### <a name="select-a-language"></a><span data-ttu-id="b6d53-168">Select a Language</span><span class="sxs-lookup"><span data-stu-id="b6d53-168">Select a Language</span></span>
<span data-ttu-id="b6d53-169">When you use the SpeechRecognitionServiceFactory to create the Client, you must select a language.</span><span class="sxs-lookup"><span data-stu-id="b6d53-169">When you use the SpeechRecognitionServiceFactory to create the Client, you must select a language.</span></span>

<span data-ttu-id="b6d53-170">Supported locales include:</span><span class="sxs-lookup"><span data-stu-id="b6d53-170">Supported locales include:</span></span>

<span data-ttu-id="b6d53-171">language-Country</span><span class="sxs-lookup"><span data-stu-id="b6d53-171">language-Country</span></span> |<span data-ttu-id="b6d53-172">language-Country</span><span class="sxs-lookup"><span data-stu-id="b6d53-172">language-Country</span></span> | <span data-ttu-id="b6d53-173">language-Country</span><span class="sxs-lookup"><span data-stu-id="b6d53-173">language-Country</span></span> |<span data-ttu-id="b6d53-174">language-Country</span><span class="sxs-lookup"><span data-stu-id="b6d53-174">language-Country</span></span>
---------|----------|--------|------------------
<span data-ttu-id="b6d53-175">de-DE</span><span class="sxs-lookup"><span data-stu-id="b6d53-175">de-DE</span></span>    |   <span data-ttu-id="b6d53-176">zh-TW</span><span class="sxs-lookup"><span data-stu-id="b6d53-176">zh-TW</span></span>  | <span data-ttu-id="b6d53-177">zh-HK</span><span class="sxs-lookup"><span data-stu-id="b6d53-177">zh-HK</span></span>  |    <span data-ttu-id="b6d53-178">ru-RU</span><span class="sxs-lookup"><span data-stu-id="b6d53-178">ru-RU</span></span>
<span data-ttu-id="b6d53-179">es-ES</span><span class="sxs-lookup"><span data-stu-id="b6d53-179">es-ES</span></span>    |   <span data-ttu-id="b6d53-180">ja-JP</span><span class="sxs-lookup"><span data-stu-id="b6d53-180">ja-JP</span></span>  | <span data-ttu-id="b6d53-181">ar-EG\*</span><span class="sxs-lookup"><span data-stu-id="b6d53-181">ar-EG\*</span></span> |    <span data-ttu-id="b6d53-182">da-DK</span><span class="sxs-lookup"><span data-stu-id="b6d53-182">da-DK</span></span>
<span data-ttu-id="b6d53-183">en-GB</span><span class="sxs-lookup"><span data-stu-id="b6d53-183">en-GB</span></span>    |   <span data-ttu-id="b6d53-184">en-IN</span><span class="sxs-lookup"><span data-stu-id="b6d53-184">en-IN</span></span>  | <span data-ttu-id="b6d53-185">fi-FI</span><span class="sxs-lookup"><span data-stu-id="b6d53-185">fi-FI</span></span>  |    <span data-ttu-id="b6d53-186">nl-NL</span><span class="sxs-lookup"><span data-stu-id="b6d53-186">nl-NL</span></span>
<span data-ttu-id="b6d53-187">en-US</span><span class="sxs-lookup"><span data-stu-id="b6d53-187">en-US</span></span>    |   <span data-ttu-id="b6d53-188">pt-BR</span><span class="sxs-lookup"><span data-stu-id="b6d53-188">pt-BR</span></span>  | <span data-ttu-id="b6d53-189">pt-PT</span><span class="sxs-lookup"><span data-stu-id="b6d53-189">pt-PT</span></span>  |    <span data-ttu-id="b6d53-190">ca-ES</span><span class="sxs-lookup"><span data-stu-id="b6d53-190">ca-ES</span></span>
<span data-ttu-id="b6d53-191">fr-FR</span><span class="sxs-lookup"><span data-stu-id="b6d53-191">fr-FR</span></span>    |   <span data-ttu-id="b6d53-192">ko-KR</span><span class="sxs-lookup"><span data-stu-id="b6d53-192">ko-KR</span></span>  | <span data-ttu-id="b6d53-193">en-NZ</span><span class="sxs-lookup"><span data-stu-id="b6d53-193">en-NZ</span></span>  |    <span data-ttu-id="b6d53-194">nb-NO</span><span class="sxs-lookup"><span data-stu-id="b6d53-194">nb-NO</span></span>
<span data-ttu-id="b6d53-195">it-IT</span><span class="sxs-lookup"><span data-stu-id="b6d53-195">it-IT</span></span>    |   <span data-ttu-id="b6d53-196">fr-CA</span><span class="sxs-lookup"><span data-stu-id="b6d53-196">fr-CA</span></span>  | <span data-ttu-id="b6d53-197">pl-PL</span><span class="sxs-lookup"><span data-stu-id="b6d53-197">pl-PL</span></span>  |    <span data-ttu-id="b6d53-198">es-MX</span><span class="sxs-lookup"><span data-stu-id="b6d53-198">es-MX</span></span>
<span data-ttu-id="b6d53-199">zh-CN</span><span class="sxs-lookup"><span data-stu-id="b6d53-199">zh-CN</span></span>    |   <span data-ttu-id="b6d53-200">en-AU</span><span class="sxs-lookup"><span data-stu-id="b6d53-200">en-AU</span></span>  | <span data-ttu-id="b6d53-201">en-CA</span><span class="sxs-lookup"><span data-stu-id="b6d53-201">en-CA</span></span>  |    <span data-ttu-id="b6d53-202">sv-SE</span><span class="sxs-lookup"><span data-stu-id="b6d53-202">sv-SE</span></span>
<span data-ttu-id="b6d53-203">\*ar-EG supports Modern Standard Arabic (MSA)</span><span class="sxs-lookup"><span data-stu-id="b6d53-203">\*ar-EG supports Modern Standard Arabic (MSA)</span></span>

#### <a name="select-a-recognition-mode"></a><span data-ttu-id="b6d53-204">Select a Recognition Mode</span><span class="sxs-lookup"><span data-stu-id="b6d53-204">Select a Recognition Mode</span></span>
<span data-ttu-id="b6d53-205">You also need to provide the recognition mode.</span><span class="sxs-lookup"><span data-stu-id="b6d53-205">You also need to provide the recognition mode.</span></span>

* <span data-ttu-id="b6d53-206">**ShortPhrase mode:** An utterance up to 15 seconds long.</span><span class="sxs-lookup"><span data-stu-id="b6d53-206">**ShortPhrase mode:** An utterance up to 15 seconds long.</span></span>
<span data-ttu-id="b6d53-207">As data is sent to the service, the client will receive multiple partial results and one final multiple n-best choice result.</span><span class="sxs-lookup"><span data-stu-id="b6d53-207">As data is sent to the service, the client will receive multiple partial results and one final multiple n-best choice result.</span></span>

* <span data-ttu-id="b6d53-208">**LongDictation mode:** An utterance up to 2 minutes long.</span><span class="sxs-lookup"><span data-stu-id="b6d53-208">**LongDictation mode:** An utterance up to 2 minutes long.</span></span>
<span data-ttu-id="b6d53-209">As data is sent to the service, the client will receive multiple partial results and multiple final results, based on where the server identifies sentence pauses.</span><span class="sxs-lookup"><span data-stu-id="b6d53-209">As data is sent to the service, the client will receive multiple partial results and multiple final results, based on where the server identifies sentence pauses.</span></span>

#### <a name="attach-event-handlers"></a><span data-ttu-id="b6d53-210">Attach Event Handlers</span><span class="sxs-lookup"><span data-stu-id="b6d53-210">Attach Event Handlers</span></span>
<span data-ttu-id="b6d53-211">You can attach various event handlers to the client you created.</span><span class="sxs-lookup"><span data-stu-id="b6d53-211">You can attach various event handlers to the client you created.</span></span>

* <span data-ttu-id="b6d53-212">**Partial Results Events:** This event gets called every time the Speech Recognition Service predicts what you might be saying – even before you finish speaking (if you are using the Microphone Client) or have finished sending data (if you are using the Data Client).</span><span class="sxs-lookup"><span data-stu-id="b6d53-212">**Partial Results Events:** This event gets called every time the Speech Recognition Service predicts what you might be saying – even before you finish speaking (if you are using the Microphone Client) or have finished sending data (if you are using the Data Client).</span></span>

* <span data-ttu-id="b6d53-213">**Error Events:** Called when the service detects an Error.</span><span class="sxs-lookup"><span data-stu-id="b6d53-213">**Error Events:** Called when the service detects an Error.</span></span>

* <span data-ttu-id="b6d53-214">**Intent Events:** Called on “WithIntent” clients (only in ShortPhrase mode) after the final reco result has been parsed into a structured JSON intent.</span><span class="sxs-lookup"><span data-stu-id="b6d53-214">**Intent Events:** Called on “WithIntent” clients (only in ShortPhrase mode) after the final reco result has been parsed into a structured JSON intent.</span></span>

* <span data-ttu-id="b6d53-215">**Result Events:**</span><span class="sxs-lookup"><span data-stu-id="b6d53-215">**Result Events:**</span></span>
  * <span data-ttu-id="b6d53-216">**In ShortPhrase mode**, this event is called and returns n-best results after you finish speaking.</span><span class="sxs-lookup"><span data-stu-id="b6d53-216">**In ShortPhrase mode**, this event is called and returns n-best results after you finish speaking.</span></span>
  * <span data-ttu-id="b6d53-217">**In LongDictation mode**, the event handler is called multiple times, based on where the service identifies sentence pauses.</span><span class="sxs-lookup"><span data-stu-id="b6d53-217">**In LongDictation mode**, the event handler is called multiple times, based on where the service identifies sentence pauses.</span></span>
  * <span data-ttu-id="b6d53-218">**For each of the n-best choices**, a confidence value and a few different forms of the recognized text are returned:</span><span class="sxs-lookup"><span data-stu-id="b6d53-218">**For each of the n-best choices**, a confidence value and a few different forms of the recognized text are returned:</span></span>

      * <span data-ttu-id="b6d53-219">**LexicalForm:** This form is optimal for use by applications that need the raw, unprocessed speech recognition result.</span><span class="sxs-lookup"><span data-stu-id="b6d53-219">**LexicalForm:** This form is optimal for use by applications that need the raw, unprocessed speech recognition result.</span></span>

      * <span data-ttu-id="b6d53-220">**DisplayText:** The recognized phrase with inverse text normalization, capitalization, punctuation and profanity masking applied.</span><span class="sxs-lookup"><span data-stu-id="b6d53-220">**DisplayText:** The recognized phrase with inverse text normalization, capitalization, punctuation and profanity masking applied.</span></span> <span data-ttu-id="b6d53-221">Profanity is masked with asterisks after the initial character, for example "d\*\*\*".</span><span class="sxs-lookup"><span data-stu-id="b6d53-221">Profanity is masked with asterisks after the initial character, for example "d\*\*\*".</span></span> <span data-ttu-id="b6d53-222">This form is optimal for use by applications that display the speech recognition results to users.</span><span class="sxs-lookup"><span data-stu-id="b6d53-222">This form is optimal for use by applications that display the speech recognition results to users.</span></span>

      * <span data-ttu-id="b6d53-223">**Inverse Text Normalization (ITN):** An example of ITN is converting result text from "go to fourth street" to "go to 4th St".</span><span class="sxs-lookup"><span data-stu-id="b6d53-223">**Inverse Text Normalization (ITN):** An example of ITN is converting result text from "go to fourth street" to "go to 4th St".</span></span> <span data-ttu-id="b6d53-224">This form is optimal for use by applications that display the speech recognition results to users.</span><span class="sxs-lookup"><span data-stu-id="b6d53-224">This form is optimal for use by applications that display the speech recognition results to users.</span></span>

      * <span data-ttu-id="b6d53-225">**InverseTextNormalizationResult:** Inverse text normalization (ITN) converts phrases like "one two three four" to a normalized form such as "1234".</span><span class="sxs-lookup"><span data-stu-id="b6d53-225">**InverseTextNormalizationResult:** Inverse text normalization (ITN) converts phrases like "one two three four" to a normalized form such as "1234".</span></span> <span data-ttu-id="b6d53-226">Another example is converting result text from "go to fourth street" to "go to 4th St".</span><span class="sxs-lookup"><span data-stu-id="b6d53-226">Another example is converting result text from "go to fourth street" to "go to 4th St".</span></span> <span data-ttu-id="b6d53-227">This form is optimal for use by applications that interpret the speech recognition results as commands or perform queries based on the recognized text.</span><span class="sxs-lookup"><span data-stu-id="b6d53-227">This form is optimal for use by applications that interpret the speech recognition results as commands or perform queries based on the recognized text.</span></span>

      * <span data-ttu-id="b6d53-228">**MaskedInverseTextNormalizationResult:** The recognized phrase with inverse text normalization and profanity masking applied, but no capitalization or punctuation.</span><span class="sxs-lookup"><span data-stu-id="b6d53-228">**MaskedInverseTextNormalizationResult:** The recognized phrase with inverse text normalization and profanity masking applied, but no capitalization or punctuation.</span></span> <span data-ttu-id="b6d53-229">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span><span class="sxs-lookup"><span data-stu-id="b6d53-229">Profanity is masked with asterisks after the initial character, e.g. "d\*\*\*".</span></span> <span data-ttu-id="b6d53-230">This form is optimal for use by applications that display the speech recognition results to users.</span><span class="sxs-lookup"><span data-stu-id="b6d53-230">This form is optimal for use by applications that display the speech recognition results to users.</span></span> <span data-ttu-id="b6d53-231">Inverse Text Normalization (ITN) has also been applied.</span><span class="sxs-lookup"><span data-stu-id="b6d53-231">Inverse Text Normalization (ITN) has also been applied.</span></span> <span data-ttu-id="b6d53-232">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span><span class="sxs-lookup"><span data-stu-id="b6d53-232">An example of ITN is converting result text from "go to fourth street" to "go to 4th st".</span></span> <span data-ttu-id="b6d53-233">This form is optimal for use by applications that use the unmasked ITN results, but also need to display the command or query to users.</span><span class="sxs-lookup"><span data-stu-id="b6d53-233">This form is optimal for use by applications that use the unmasked ITN results, but also need to display the command or query to users.</span></span>

<span data-ttu-id="b6d53-234"><a name="Step3"> </a></span><span class="sxs-lookup"><span data-stu-id="b6d53-234"><a name="Step3"> </a></span></span>
## <a name="step-3-run-the-example-application"></a><span data-ttu-id="b6d53-235">Step 3: Run the Example Application</span><span class="sxs-lookup"><span data-stu-id="b6d53-235">Step 3: Run the Example Application</span></span>

<span data-ttu-id="b6d53-236">Run the application with the chosen clients, recognition modes and event handlers.</span><span class="sxs-lookup"><span data-stu-id="b6d53-236">Run the application with the chosen clients, recognition modes and event handlers.</span></span>

<span data-ttu-id="b6d53-237"><a name="Related"> </a></span><span class="sxs-lookup"><span data-stu-id="b6d53-237"><a name="Related"> </a></span></span>
## <a name="related-topics"></a><span data-ttu-id="b6d53-238">Related Topics</span><span class="sxs-lookup"><span data-stu-id="b6d53-238">Related Topics</span></span>

 * [<span data-ttu-id="b6d53-239">Get started with Bing Speech Recognition and/or intent in Java on Android</span><span class="sxs-lookup"><span data-stu-id="b6d53-239">Get started with Bing Speech Recognition and/or intent in Java on Android</span></span>](GetStartedJavaAndroid.md)
 * [<span data-ttu-id="b6d53-240">Get started with Bing Speech API in JavaScript</span><span class="sxs-lookup"><span data-stu-id="b6d53-240">Get started with Bing Speech API in JavaScript</span></span>](GetStartedJS.md)
 * [<span data-ttu-id="b6d53-241">Get started with Bing Speech API in cURL</span><span class="sxs-lookup"><span data-stu-id="b6d53-241">Get started with Bing Speech API in cURL</span></span>](GetStarted-cURL.md)

