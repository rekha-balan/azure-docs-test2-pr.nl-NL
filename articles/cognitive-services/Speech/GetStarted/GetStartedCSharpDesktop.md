---
title: Get started with the Microsoft Speech Recognition API by using the C# desktop library | Microsoft Docs
description: Develop basic Windows applications that use the Microsoft Speech Recognition API to convert spoken audio to text.
services: cognitive-services
author: zhouwangzw
manager: wolfma
ms.service: cognitive-services
ms.component: bing-speech
ms.topic: article
ms.date: 09/27/2017
ms.author: zhouwang
ms.openlocfilehash: e59b0e25401fb5182edd52f82985ffed9052286d
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44827112"
---
# <a name="get-started-with-the-speech-recognition-api-in-c35-for-net-on-windows"></a><span data-ttu-id="a4b2a-103">Get started with the Speech Recognition API in C&#35; for .NET on Windows</span><span class="sxs-lookup"><span data-stu-id="a4b2a-103">Get started with the Speech Recognition API in C&#35; for .NET on Windows</span></span>

<span data-ttu-id="a4b2a-104">This page shows how to develop a basic Windows application that uses the Speech Recognition API to convert spoken audio to text.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-104">This page shows how to develop a basic Windows application that uses the Speech Recognition API to convert spoken audio to text.</span></span> <span data-ttu-id="a4b2a-105">Using the client library allows for real-time streaming, which means that when your client application sends audio to the service, it simultaneously and asynchronously receives partial recognition results back.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-105">Using the client library allows for real-time streaming, which means that when your client application sends audio to the service, it simultaneously and asynchronously receives partial recognition results back.</span></span>

<span data-ttu-id="a4b2a-106">Developers who want to use Speech Service from apps that run on any device can use the C# desktop library.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-106">Developers who want to use Speech Service from apps that run on any device can use the C# desktop library.</span></span> <span data-ttu-id="a4b2a-107">To use the library, install the [NuGet package Microsoft.ProjectOxford.SpeechRecognition-x86](https://www.nuget.org/packages/Microsoft.ProjectOxford.SpeechRecognition-x86/) for a 32-bit platform and the [NuGet package Microsoft.ProjectOxford.SpeechRecognition-x64](https://www.nuget.org/packages/Microsoft.ProjectOxford.SpeechRecognition-x64/) for a 64-bit platform.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-107">To use the library, install the [NuGet package Microsoft.ProjectOxford.SpeechRecognition-x86](https://www.nuget.org/packages/Microsoft.ProjectOxford.SpeechRecognition-x86/) for a 32-bit platform and the [NuGet package Microsoft.ProjectOxford.SpeechRecognition-x64](https://www.nuget.org/packages/Microsoft.ProjectOxford.SpeechRecognition-x64/) for a 64-bit platform.</span></span> <span data-ttu-id="a4b2a-108">For the client library API reference, see [Microsoft Speech C# desktop library](https://cdn.rawgit.com/Microsoft/Cognitive-Speech-STT-Windows/master/docs/SpeechSDK/index.html).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-108">For the client library API reference, see [Microsoft Speech C# desktop library](https://cdn.rawgit.com/Microsoft/Cognitive-Speech-STT-Windows/master/docs/SpeechSDK/index.html).</span></span>

<span data-ttu-id="a4b2a-109">The following sections describe how to install, build, and run the C# sample application by using the C# desktop library.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-109">The following sections describe how to install, build, and run the C# sample application by using the C# desktop library.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="a4b2a-110">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="a4b2a-110">Prerequisites</span></span>

### <a name="platform-requirements"></a><span data-ttu-id="a4b2a-111">Platform requirements</span><span class="sxs-lookup"><span data-stu-id="a4b2a-111">Platform requirements</span></span>

<span data-ttu-id="a4b2a-112">The following sample was developed for Windows 8+ and .NET Framework 4.5+ by using [Visual Studio 2015, Community Edition](https://www.visualstudio.com/products/visual-studio-community-vs).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-112">The following sample was developed for Windows 8+ and .NET Framework 4.5+ by using [Visual Studio 2015, Community Edition](https://www.visualstudio.com/products/visual-studio-community-vs).</span></span>

### <a name="get-the-sample-application"></a><span data-ttu-id="a4b2a-113">Get the sample application</span><span class="sxs-lookup"><span data-stu-id="a4b2a-113">Get the sample application</span></span>

<span data-ttu-id="a4b2a-114">Clone the sample from the [Speech C# desktop library sample](https://github.com/microsoft/cognitive-speech-stt-windows) repository.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-114">Clone the sample from the [Speech C# desktop library sample](https://github.com/microsoft/cognitive-speech-stt-windows) repository.</span></span>

### <a name="subscribe-to-the-speech-recognition-api-and-get-a-free-trial-subscription-key"></a><span data-ttu-id="a4b2a-115">Subscribe to the Speech Recognition API, and get a free trial subscription key</span><span class="sxs-lookup"><span data-stu-id="a4b2a-115">Subscribe to the Speech Recognition API, and get a free trial subscription key</span></span>

<span data-ttu-id="a4b2a-116">The Speech API is part of Cognitive Services (previously Project Oxford).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-116">The Speech API is part of Cognitive Services (previously Project Oxford).</span></span> <span data-ttu-id="a4b2a-117">You can get free trial subscription keys from the [Cognitive Services subscription](https://azure.microsoft.com/try/cognitive-services/) page.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-117">You can get free trial subscription keys from the [Cognitive Services subscription](https://azure.microsoft.com/try/cognitive-services/) page.</span></span> <span data-ttu-id="a4b2a-118">After you select the Speech API, select **Get API Key** to get the key.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-118">After you select the Speech API, select **Get API Key** to get the key.</span></span> <span data-ttu-id="a4b2a-119">It returns a primary and secondary key.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-119">It returns a primary and secondary key.</span></span> <span data-ttu-id="a4b2a-120">Both keys are tied to the same quota, so you can use either key.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-120">Both keys are tied to the same quota, so you can use either key.</span></span>

> [!IMPORTANT]
> * <span data-ttu-id="a4b2a-121">Get a subscription key.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-121">Get a subscription key.</span></span> <span data-ttu-id="a4b2a-122">Before you use the Speech client libraries, you must have a [subscription key](https://azure.microsoft.com/try/cognitive-services/).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-122">Before you use the Speech client libraries, you must have a [subscription key](https://azure.microsoft.com/try/cognitive-services/).</span></span>
>
> * <span data-ttu-id="a4b2a-123">Use your subscription key.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-123">Use your subscription key.</span></span> <span data-ttu-id="a4b2a-124">With the provided C# desktop sample application, paste your subscription key into the text box when you run the sample.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-124">With the provided C# desktop sample application, paste your subscription key into the text box when you run the sample.</span></span> <span data-ttu-id="a4b2a-125">For more information, see [Run the sample application](#step-3-run-the-sample-application).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-125">For more information, see [Run the sample application](#step-3-run-the-sample-application).</span></span>

## <a name="step-1-install-the-sample-application"></a><span data-ttu-id="a4b2a-126">Step 1: Install the sample application</span><span class="sxs-lookup"><span data-stu-id="a4b2a-126">Step 1: Install the sample application</span></span>

1. <span data-ttu-id="a4b2a-127">Start Visual Studio 2015, and select **File** > **Open** > **Project/Solution**.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-127">Start Visual Studio 2015, and select **File** > **Open** > **Project/Solution**.</span></span>

2. <span data-ttu-id="a4b2a-128">Browse to the folder where you saved the downloaded Speech Recognition API files.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-128">Browse to the folder where you saved the downloaded Speech Recognition API files.</span></span> <span data-ttu-id="a4b2a-129">Select **Speech** > **Windows**, and then select the Sample-WP folder.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-129">Select **Speech** > **Windows**, and then select the Sample-WP folder.</span></span>

3. <span data-ttu-id="a4b2a-130">Double-click to open the Visual Studio 2015 Solution (.sln) file named SpeechToText-WPF-Samples.sln.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-130">Double-click to open the Visual Studio 2015 Solution (.sln) file named SpeechToText-WPF-Samples.sln.</span></span> <span data-ttu-id="a4b2a-131">The solution opens in Visual Studio.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-131">The solution opens in Visual Studio.</span></span>

## <a name="step-2-build-the-sample-application"></a><span data-ttu-id="a4b2a-132">Step 2: Build the sample application</span><span class="sxs-lookup"><span data-stu-id="a4b2a-132">Step 2: Build the sample application</span></span>

1. <span data-ttu-id="a4b2a-133">If you want to use *recognition with intent*, you first need to sign up for the [Language Understanding Intelligent Service (LUIS)](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-133">If you want to use *recognition with intent*, you first need to sign up for the [Language Understanding Intelligent Service (LUIS)](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).</span></span> <span data-ttu-id="a4b2a-134">Then use the endpoint URL of your LUIS app to set the value of the key `LuisEndpointUrl` in the app.config file in the samples/SpeechRecognitionServiceExample folder.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-134">Then use the endpoint URL of your LUIS app to set the value of the key `LuisEndpointUrl` in the app.config file in the samples/SpeechRecognitionServiceExample folder.</span></span> <span data-ttu-id="a4b2a-135">For more information on the endpoint URL of the LUIS app, see [Publish your app](../../luis/luis-get-started-create-app.md#publish-your-app).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-135">For more information on the endpoint URL of the LUIS app, see [Publish your app](../../luis/luis-get-started-create-app.md#publish-your-app).</span></span>

   > [!TIP]
   > <span data-ttu-id="a4b2a-136">Replace the `&` character in the LUIS endpoint URL with `&amp;` to ensure that the URL is correctly interpreted by the XML parser.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-136">Replace the `&` character in the LUIS endpoint URL with `&amp;` to ensure that the URL is correctly interpreted by the XML parser.</span></span>

2. <span data-ttu-id="a4b2a-137">Press Ctrl+Shift+B, or select **Build** on the ribbon menu.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-137">Press Ctrl+Shift+B, or select **Build** on the ribbon menu.</span></span> <span data-ttu-id="a4b2a-138">Then select **Build Solution**.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-138">Then select **Build Solution**.</span></span>

## <a name="step-3-run-the-sample-application"></a><span data-ttu-id="a4b2a-139">Step 3: Run the sample application</span><span class="sxs-lookup"><span data-stu-id="a4b2a-139">Step 3: Run the sample application</span></span>

1. <span data-ttu-id="a4b2a-140">After the build is finished, press F5 or select **Start** on the ribbon menu to run the sample.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-140">After the build is finished, press F5 or select **Start** on the ribbon menu to run the sample.</span></span>

2. <span data-ttu-id="a4b2a-141">Go to the **Project Oxford Speech to Text Sample** window.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-141">Go to the **Project Oxford Speech to Text Sample** window.</span></span> <span data-ttu-id="a4b2a-142">Paste your subscription key into the **Paste your subscription key here to start** text box as shown.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-142">Paste your subscription key into the **Paste your subscription key here to start** text box as shown.</span></span> <span data-ttu-id="a4b2a-143">To persist your subscription key on your PC or laptop, select **Save Key**.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-143">To persist your subscription key on your PC or laptop, select **Save Key**.</span></span> <span data-ttu-id="a4b2a-144">To delete the subscription key from the system, select **Delete Key** to remove it from your PC or laptop.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-144">To delete the subscription key from the system, select **Delete Key** to remove it from your PC or laptop.</span></span>

   ![Speech recognition paste-in key](../Images/SpeechRecog_paste_key.PNG)

3. <span data-ttu-id="a4b2a-146">Under **Speech Recognition Source**, choose one of the six speech sources, which fall into two main input categories:</span><span class="sxs-lookup"><span data-stu-id="a4b2a-146">Under **Speech Recognition Source**, choose one of the six speech sources, which fall into two main input categories:</span></span>

   * <span data-ttu-id="a4b2a-147">Use your computer's microphone or an attached microphone to capture speech.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-147">Use your computer's microphone or an attached microphone to capture speech.</span></span>
   * <span data-ttu-id="a4b2a-148">Play an audio file.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-148">Play an audio file.</span></span>

   <span data-ttu-id="a4b2a-149">Each category has three recognition modes:</span><span class="sxs-lookup"><span data-stu-id="a4b2a-149">Each category has three recognition modes:</span></span>

    * <span data-ttu-id="a4b2a-150">**ShortPhrase mode**: An utterance up to 15 seconds long.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-150">**ShortPhrase mode**: An utterance up to 15 seconds long.</span></span> <span data-ttu-id="a4b2a-151">As data is sent to the server, the client receives multiple partial results and one final result with multiple n-best choices.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-151">As data is sent to the server, the client receives multiple partial results and one final result with multiple n-best choices.</span></span>
    * <span data-ttu-id="a4b2a-152">**LongDictation mode**: An utterance up to two minutes long.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-152">**LongDictation mode**: An utterance up to two minutes long.</span></span> <span data-ttu-id="a4b2a-153">As data is sent to the server, the client receives multiple partial results and multiple final results, based on where the server indicates sentence pauses.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-153">As data is sent to the server, the client receives multiple partial results and multiple final results, based on where the server indicates sentence pauses.</span></span>
    * <span data-ttu-id="a4b2a-154">**Intent detection**: The server returns additional structured information about the speech input.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-154">**Intent detection**: The server returns additional structured information about the speech input.</span></span> <span data-ttu-id="a4b2a-155">To use intent detection, you need to first train a model by using [LUIS](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-155">To use intent detection, you need to first train a model by using [LUIS](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).</span></span>

<span data-ttu-id="a4b2a-156">Use sample audio files with this sample application.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-156">Use sample audio files with this sample application.</span></span> <span data-ttu-id="a4b2a-157">Find the files in the repository you downloaded with this sample under the samples/SpeechRecognitionServiceExample folder.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-157">Find the files in the repository you downloaded with this sample under the samples/SpeechRecognitionServiceExample folder.</span></span> <span data-ttu-id="a4b2a-158">These sample audio files run automatically if no other files are chosen when you select **Use wav file for Shortphrase mode** or **Use wav file for Longdictation mode** as your speech input.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-158">These sample audio files run automatically if no other files are chosen when you select **Use wav file for Shortphrase mode** or **Use wav file for Longdictation mode** as your speech input.</span></span> <span data-ttu-id="a4b2a-159">Currently, only WAV audio format is supported.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-159">Currently, only WAV audio format is supported.</span></span>

![Speech to Text interface](../Images/HelloJones.PNG)

## <a name="samples-explained"></a><span data-ttu-id="a4b2a-161">Samples explained</span><span class="sxs-lookup"><span data-stu-id="a4b2a-161">Samples explained</span></span>

### <a name="recognition-events"></a><span data-ttu-id="a4b2a-162">Recognition events</span><span class="sxs-lookup"><span data-stu-id="a4b2a-162">Recognition events</span></span>

* <span data-ttu-id="a4b2a-163">**Partial Results events**: This event gets called every time Speech Service predicts what you might be saying, even before you finish speaking (if you use `MicrophoneRecognitionClient`) or finish sending data (if you use `DataRecognitionClient`).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-163">**Partial Results events**: This event gets called every time Speech Service predicts what you might be saying, even before you finish speaking (if you use `MicrophoneRecognitionClient`) or finish sending data (if you use `DataRecognitionClient`).</span></span>
* <span data-ttu-id="a4b2a-164">**Error events**: Called when the service detects an error.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-164">**Error events**: Called when the service detects an error.</span></span>
* <span data-ttu-id="a4b2a-165">**Intent events**: Called on "WithIntent" clients (only in ShortPhrase mode) after the final recognition result is parsed into a structured JSON intent.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-165">**Intent events**: Called on "WithIntent" clients (only in ShortPhrase mode) after the final recognition result is parsed into a structured JSON intent.</span></span>
* <span data-ttu-id="a4b2a-166">**Result events**:</span><span class="sxs-lookup"><span data-stu-id="a4b2a-166">**Result events**:</span></span>
  * <span data-ttu-id="a4b2a-167">In `ShortPhrase` mode, this event is called and returns the n-best results after you finish speaking.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-167">In `ShortPhrase` mode, this event is called and returns the n-best results after you finish speaking.</span></span>
  * <span data-ttu-id="a4b2a-168">In `LongDictation` mode, the event handler is called multiple times, based on where the service identifies sentence pauses.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-168">In `LongDictation` mode, the event handler is called multiple times, based on where the service identifies sentence pauses.</span></span>
  * <span data-ttu-id="a4b2a-169">**For each of the n-best choices**, a confidence value and a few different forms of the recognized text are returned.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-169">**For each of the n-best choices**, a confidence value and a few different forms of the recognized text are returned.</span></span> <span data-ttu-id="a4b2a-170">For more information, see [Output format](../Concepts.md#output-format).</span><span class="sxs-lookup"><span data-stu-id="a4b2a-170">For more information, see [Output format](../Concepts.md#output-format).</span></span>

<span data-ttu-id="a4b2a-171">Event handlers are already pointed out in the code in the form of code comments.</span><span class="sxs-lookup"><span data-stu-id="a4b2a-171">Event handlers are already pointed out in the code in the form of code comments.</span></span>

## <a name="related-topics"></a><span data-ttu-id="a4b2a-172">Related topics</span><span class="sxs-lookup"><span data-stu-id="a4b2a-172">Related topics</span></span>

* [<span data-ttu-id="a4b2a-173">Microsoft Speech desktop library reference</span><span class="sxs-lookup"><span data-stu-id="a4b2a-173">Microsoft Speech desktop library reference</span></span>](https://cdn.rawgit.com/Microsoft/Cognitive-Speech-STT-Windows/master/docs/SpeechSDK/index.html)
* [<span data-ttu-id="a4b2a-174">Get started with the Microsoft Speech Recognition API in Java on Android</span><span class="sxs-lookup"><span data-stu-id="a4b2a-174">Get started with the Microsoft Speech Recognition API in Java on Android</span></span>](GetStartedJavaAndroid.md)
* [<span data-ttu-id="a4b2a-175">Get started with the Microsoft Speech Recognition API in Objective-C on iOS</span><span class="sxs-lookup"><span data-stu-id="a4b2a-175">Get started with the Microsoft Speech Recognition API in Objective-C on iOS</span></span>](Get-Started-ObjectiveC-iOS.md)
* [<span data-ttu-id="a4b2a-176">Get started with the Microsoft Speech Recognition API in JavaScript</span><span class="sxs-lookup"><span data-stu-id="a4b2a-176">Get started with the Microsoft Speech Recognition API in JavaScript</span></span>](GetStartedJSWebsockets.md)
* [<span data-ttu-id="a4b2a-177">Get started with the Microsoft Speech Recognition API via REST</span><span class="sxs-lookup"><span data-stu-id="a4b2a-177">Get started with the Microsoft Speech Recognition API via REST</span></span>](GetStartedREST.md)
