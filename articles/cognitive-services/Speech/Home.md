---
title: Bing Speech API in Microsoft Cognitive Services | Microsoft Docs
description: Use the Bing Speech API to add speech-driven actions to your apps, including real-time interaction with users.
services: cognitive-services
author: priyaravi20
manager: yanbo
ms.service: cognitive-services
ms.technology: speech
ms.topic: article
ms.date: 02/28/2017
ms.author: prrajan
ms.openlocfilehash: a21677f8702ded942afbeb84e5fe428a1a5d8c5e
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: HT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44554262"
---
# <a name="bing-speech-api-overview"></a>Bing Speech API Overview

Welcome to Bing Speech API, a cloud-based API that provides advanced algorithms to process spoken language. With Bing Speech API you can add speech driven actions to your apps, including real-time interaction with the user.

Bing Speech API has two components:
* [Speech Recognition API, Client Library, Service Library](#SpeechRecognition):  For apps converting spoken words to text.
* [Text To Speech API](#TextToSpeech): For apps converting text into audio that can be played back to the user. 

Bing Speech APIs and libraries enables speech capabilities on all internet-connected devices. Every major platform including Android, iOS, Windows, and 3rd party IoT devices are supported. It offers industry-leading speech-to-text, text-to-speech, and language understanding capabilities delivered through the cloud.

Microsoft uses Bing Speech API for Windows applications like [Cortana](https://www.microsoft.com/en-us/mobile/experiences/cortana/) and [Skype Translator](https://www.skype.com/en/features/skype-translator/) as well as Android applications like [Bing Torque](https://play.google.com/store/apps/details?id=com.microsoft.bing.torque) for Android Wear and Android Phone.

<a name="SpeechRecognition"></a>
## <a name="speech-recognition-api"></a>Speech Recognition API
Bing Speech Recognition API provides the ability to convert spoken audio to text by sending audio to Microsoft’s servers in the cloud. Developers have a choice of using the REST API, Client Library or the Service Library. 

### <a name="speech-recognition---rest-api-versus-client-library-versus-service-library"></a>Speech Recognition - REST API versus Client Library versus Service Library
* Using the REST API means getting only one reco result back with no partial results. Documentation for the REST API can be found [here](API-Reference-REST/BingVoiceRecognition.md) and code samples [here](https://oxfordportal.blob.core.windows.net/speech/doc/recognition/Program.cs). 
*   Using the client library allows for real-time streaming, meaning that as audio is being sent or spoken to the server, partial recognition results are returned at the same time. Real-time streaming is supported on Android, iOS, and Windows. The client library also supports speech intent recognition in addition to returning recognized text from audio inputs.Structured information about the speech to apps that parse the intent of the speaker can also be retrieved to drive further actions. Models trained by [Project LUIS](https://www.luis.ai/) service are used to generate the intent. To use intent, you will need to train a model after getting an AppID and a Secret. Once you have a trained model, you can use the Speech Recognition API for intent parsing on reco results via the “WithIntent” clients.
* Using the service library allows for real-time streaming audio from a service to the speech cloud allowing for partial results. Service Library is supported for Windows.  

#### <a name="supported-languages"></a>Supported languages
Locales supported by the Speech Recognition API include:

language-Country |language-Country | language-Country |language-Country 
---------|----------|--------|------------------
ar-EG*   |  en-NZ  | it-IT  |  ru-RU
ca-ES    |  en-US  | ja-JP  |  sv-SE
da-DK    |  es-ES  | ko-KR  |  zh-CN
de-DE    |  es-MX  | nb-NO  |  zh-HK
en-AU    |  fi-FI  | nl-NL  |  zh-TW
en-CA    |  fr-CA  | pl-PL  |    
en-GB    |  fr-FR  | pt-BR  |      
en-IN    |  hi-IN  | pt-PT  |
*ar-EG supports Modern Standard Arabic (MSA)

<a name="TextToSpeech"></a>
## <a name="text-to-speech-api"></a>Text To Speech API
When applications need to “talk” back to their users, this API can be used to convert text generated by the app into audio that can played back to the user. Text to speech conversion (TTS) is done via a REST API. The TTS demo can be found on the [Speech landing page](https://www.microsoft.com/cognitive-services/en-us/speech-api), documentation for the REST API can be found [here](API-Reference-REST/BingVoiceOutput.md), and code samples [here](https://github.com/Microsoft/Cognitive-Speech-TTS/tree/master/Samples-Http/CSharp/TTSProgram.cs).

#### <a name="supported-languages"></a>Supported languages
Locales supported by Text to Speech API include:

language-Country |language-Country | language-Country 
---------|----------|------------
ar-EG*   |   es-ES  | ko-KR    
de-DE    |   es-MX  | pt-BR 
en-AU    |   fr-CA  | ru-RU   
en-CA    |   fr-FR  | zh-CN    
en-GB    |   hi-IN  | zh-HK    
en-IN    |   it-IT  |  zh-TW 
en-US    |   ja-JP  |      
*ar-EG supports Modern Standard Arabic (MSA)
