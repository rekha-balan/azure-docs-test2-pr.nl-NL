---
title: 'Azure Data Factory: Frequently asked questions | Microsoft Docs'
description: Get answers to frequently asked questions about Azure Data Factory.
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.assetid: 532dec5a-7261-4770-8f54-bfe527918058
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 06/27/2018
ms.author: shlo
ms.openlocfilehash: ebe8745db06113d0508d86554bf031a4235c8e44
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44968373"
---
# <a name="azure-data-factory-faq"></a><span data-ttu-id="8aac2-103">Azure Data Factory FAQ</span><span class="sxs-lookup"><span data-stu-id="8aac2-103">Azure Data Factory FAQ</span></span>
<span data-ttu-id="8aac2-104">This article provides answers to frequently asked questions about Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8aac2-104">This article provides answers to frequently asked questions about Azure Data Factory.</span></span>  

## <a name="what-is-azure-data-factory"></a><span data-ttu-id="8aac2-105">What is Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="8aac2-105">What is Azure Data Factory?</span></span> 
<span data-ttu-id="8aac2-106">Data Factory is a fully managed, cloud-based, data-integration service that automates the movement and transformation of data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-106">Data Factory is a fully managed, cloud-based, data-integration service that automates the movement and transformation of data.</span></span> <span data-ttu-id="8aac2-107">Like a factory that runs equipment to transform raw materials into finished goods, Azure Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</span><span class="sxs-lookup"><span data-stu-id="8aac2-107">Like a factory that runs equipment to transform raw materials into finished goods, Azure Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</span></span> 

<span data-ttu-id="8aac2-108">By using Azure Data Factory, you can create data-driven workflows to move data between on-premises and cloud data stores.</span><span class="sxs-lookup"><span data-stu-id="8aac2-108">By using Azure Data Factory, you can create data-driven workflows to move data between on-premises and cloud data stores.</span></span> <span data-ttu-id="8aac2-109">And you can process and transform data by using compute services such as Azure HDInsight, Azure Data Lake Analytics, and SQL Server Integration Services (SSIS) integration runtime.</span><span class="sxs-lookup"><span data-stu-id="8aac2-109">And you can process and transform data by using compute services such as Azure HDInsight, Azure Data Lake Analytics, and SQL Server Integration Services (SSIS) integration runtime.</span></span> 

<span data-ttu-id="8aac2-110">With Data Factory, you can execute your data processing either on an Azure-based cloud service or in your own self-hosted compute environment, such as SSIS, SQL Server, or Oracle.</span><span class="sxs-lookup"><span data-stu-id="8aac2-110">With Data Factory, you can execute your data processing either on an Azure-based cloud service or in your own self-hosted compute environment, such as SSIS, SQL Server, or Oracle.</span></span> <span data-ttu-id="8aac2-111">After you create a pipeline that performs the action that you need, you can schedule it to run periodically (for example, hourly, daily, or weekly), time window scheduling or trigger the pipeline from an event occurrence.</span><span class="sxs-lookup"><span data-stu-id="8aac2-111">After you create a pipeline that performs the action that you need, you can schedule it to run periodically (for example, hourly, daily, or weekly), time window scheduling or trigger the pipeline from an event occurrence.</span></span> <span data-ttu-id="8aac2-112">For more information, see [Introduction to Azure Data Factory](introduction.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-112">For more information, see [Introduction to Azure Data Factory](introduction.md).</span></span>

### <a name="control-flows-and-scale"></a><span data-ttu-id="8aac2-113">Control flows and scale</span><span class="sxs-lookup"><span data-stu-id="8aac2-113">Control flows and scale</span></span> 
<span data-ttu-id="8aac2-114">To support the diverse integration flows and patterns in the modern data warehouse, Data Factory enables flexible data pipeline modeling that includes full control flow programming paradigms including conditional execution, branching in data pipelines, and explicitly pass parameters within and across these flows.</span><span class="sxs-lookup"><span data-stu-id="8aac2-114">To support the diverse integration flows and patterns in the modern data warehouse, Data Factory enables flexible data pipeline modeling that includes full control flow programming paradigms including conditional execution, branching in data pipelines, and explicitly pass parameters within and across these flows.</span></span> <span data-ttu-id="8aac2-115">Control Flow also encompasses transforming data through activity dispatch to external execution engines and data flow capabilities, including data movement at scale, via the Copy Activity.</span><span class="sxs-lookup"><span data-stu-id="8aac2-115">Control Flow also encompasses transforming data through activity dispatch to external execution engines and data flow capabilities, including data movement at scale, via the Copy Activity.</span></span>

<span data-ttu-id="8aac2-116">Data Factory provides freedom to model any flow style that's required for data integration and that can be dispatched on demand or repeatedly on a schedule.</span><span class="sxs-lookup"><span data-stu-id="8aac2-116">Data Factory provides freedom to model any flow style that's required for data integration and that can be dispatched on demand or repeatedly on a schedule.</span></span> <span data-ttu-id="8aac2-117">A few common flows that this model enables are:</span><span class="sxs-lookup"><span data-stu-id="8aac2-117">A few common flows that this model enables are:</span></span>   

- <span data-ttu-id="8aac2-118">Control flows:</span><span class="sxs-lookup"><span data-stu-id="8aac2-118">Control flows:</span></span>
    - <span data-ttu-id="8aac2-119">Chain activities in a sequence within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-119">Chain activities in a sequence within a pipeline.</span></span>
    - <span data-ttu-id="8aac2-120">Branch activities within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-120">Branch activities within a pipeline.</span></span>
    - <span data-ttu-id="8aac2-121">Parameters</span><span class="sxs-lookup"><span data-stu-id="8aac2-121">Parameters</span></span>
        - <span data-ttu-id="8aac2-122">Define parameters at the pipeline level, and pass arguments while you invoke the pipeline on demand or from a trigger.</span><span class="sxs-lookup"><span data-stu-id="8aac2-122">Define parameters at the pipeline level, and pass arguments while you invoke the pipeline on demand or from a trigger.</span></span>
        - <span data-ttu-id="8aac2-123">Activities can consume the arguments that are passed to the pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-123">Activities can consume the arguments that are passed to the pipeline.</span></span>
    - <span data-ttu-id="8aac2-124">Custom state passing</span><span class="sxs-lookup"><span data-stu-id="8aac2-124">Custom state passing</span></span>
        - <span data-ttu-id="8aac2-125">Activity outputs including state can be consumed by a subsequent activity in the pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-125">Activity outputs including state can be consumed by a subsequent activity in the pipeline.</span></span>
    - <span data-ttu-id="8aac2-126">Looping containers</span><span class="sxs-lookup"><span data-stu-id="8aac2-126">Looping containers</span></span>
        - <span data-ttu-id="8aac2-127">For-each</span><span class="sxs-lookup"><span data-stu-id="8aac2-127">For-each</span></span> 
- <span data-ttu-id="8aac2-128">Trigger-based flows:</span><span class="sxs-lookup"><span data-stu-id="8aac2-128">Trigger-based flows:</span></span>
    - <span data-ttu-id="8aac2-129">Pipelines can be triggered on demand or by wall-clock time.</span><span class="sxs-lookup"><span data-stu-id="8aac2-129">Pipelines can be triggered on demand or by wall-clock time.</span></span>
- <span data-ttu-id="8aac2-130">Delta flows:</span><span class="sxs-lookup"><span data-stu-id="8aac2-130">Delta flows:</span></span>
    - <span data-ttu-id="8aac2-131">Use parameters and define your high-water mark for delta copy while moving dimension or reference tables from a relational store, either on-premises or in the cloud, to load the data into the lake.</span><span class="sxs-lookup"><span data-stu-id="8aac2-131">Use parameters and define your high-water mark for delta copy while moving dimension or reference tables from a relational store, either on-premises or in the cloud, to load the data into the lake.</span></span> 

<span data-ttu-id="8aac2-132">For more information, see [Tutorial: Control flows](tutorial-control-flow.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-132">For more information, see [Tutorial: Control flows](tutorial-control-flow.md).</span></span>

### <a name="transform-your-data-at-scale-with-code-free-pipelines"></a><span data-ttu-id="8aac2-133">Transform your data at scale with code free pipelines</span><span class="sxs-lookup"><span data-stu-id="8aac2-133">Transform your data at scale with code free pipelines</span></span>
<span data-ttu-id="8aac2-134">The new browser-based tooling experience provides code-free pipeline authoring and deployment with a modern, interactive web-based experience.</span><span class="sxs-lookup"><span data-stu-id="8aac2-134">The new browser-based tooling experience provides code-free pipeline authoring and deployment with a modern, interactive web-based experience.</span></span>

<span data-ttu-id="8aac2-135">For visual data developers and data engineers, the ADF Web UI is the code-free design environment that you will use to build pipelines.</span><span class="sxs-lookup"><span data-stu-id="8aac2-135">For visual data developers and data engineers, the ADF Web UI is the code-free design environment that you will use to build pipelines.</span></span> <span data-ttu-id="8aac2-136">It is fully integrated with Visual Studio Online Git and provides integration for CI/CD and iterative development with debugging options.</span><span class="sxs-lookup"><span data-stu-id="8aac2-136">It is fully integrated with Visual Studio Online Git and provides integration for CI/CD and iterative development with debugging options.</span></span>

### <a name="rich-cross-platform-sdks-for-advanced-users"></a><span data-ttu-id="8aac2-137">Rich cross platform SDKs for advanced users</span><span class="sxs-lookup"><span data-stu-id="8aac2-137">Rich cross platform SDKs for advanced users</span></span>
<span data-ttu-id="8aac2-138">If you are an advanced user and looking for a programmatic interface, ADF V2 provides a rich set of SDKs that can be leveraged to author, manage, monitor pipelines using your favorite IDE</span><span class="sxs-lookup"><span data-stu-id="8aac2-138">If you are an advanced user and looking for a programmatic interface, ADF V2 provides a rich set of SDKs that can be leveraged to author, manage, monitor pipelines using your favorite IDE</span></span>
1.  <span data-ttu-id="8aac2-139">Python SDK</span><span class="sxs-lookup"><span data-stu-id="8aac2-139">Python SDK</span></span>
2.  <span data-ttu-id="8aac2-140">Powershell CLI</span><span class="sxs-lookup"><span data-stu-id="8aac2-140">Powershell CLI</span></span>
3.  <span data-ttu-id="8aac2-141">C# SDK Users can also leverage the documented REST APIs to interface with ADF V2</span><span class="sxs-lookup"><span data-stu-id="8aac2-141">C# SDK Users can also leverage the documented REST APIs to interface with ADF V2</span></span>

### <a name="iterative-development-and-debugging-using-visual-tools"></a><span data-ttu-id="8aac2-142">Iterative development and debugging using visual tools</span><span class="sxs-lookup"><span data-stu-id="8aac2-142">Iterative development and debugging using visual tools</span></span>
<span data-ttu-id="8aac2-143">Azure Data Factory (ADF) visual tools allow you to do iterative development and debugging.</span><span class="sxs-lookup"><span data-stu-id="8aac2-143">Azure Data Factory (ADF) visual tools allow you to do iterative development and debugging.</span></span> <span data-ttu-id="8aac2-144">You can create your pipelines and do test runs using the Debug capability in the pipeline canvas without writing a single line of code.</span><span class="sxs-lookup"><span data-stu-id="8aac2-144">You can create your pipelines and do test runs using the Debug capability in the pipeline canvas without writing a single line of code.</span></span> <span data-ttu-id="8aac2-145">You can view the results of your test runs in the Output window of your pipeline canvas.</span><span class="sxs-lookup"><span data-stu-id="8aac2-145">You can view the results of your test runs in the Output window of your pipeline canvas.</span></span> <span data-ttu-id="8aac2-146">Once your test run succeeds, you can add more activities to your pipeline and continue debugging in an iterative manner.</span><span class="sxs-lookup"><span data-stu-id="8aac2-146">Once your test run succeeds, you can add more activities to your pipeline and continue debugging in an iterative manner.</span></span> <span data-ttu-id="8aac2-147">You can also Cancel your test runs once they are in-progress.</span><span class="sxs-lookup"><span data-stu-id="8aac2-147">You can also Cancel your test runs once they are in-progress.</span></span> <span data-ttu-id="8aac2-148">You are not required to publish your changes to the data factory service before clicking Debug.</span><span class="sxs-lookup"><span data-stu-id="8aac2-148">You are not required to publish your changes to the data factory service before clicking Debug.</span></span> <span data-ttu-id="8aac2-149">This is helpful in scenarios where you want to make sure that the new additions or changes work as expected before you update your data factory workflows in dev, test, or prod environments.</span><span class="sxs-lookup"><span data-stu-id="8aac2-149">This is helpful in scenarios where you want to make sure that the new additions or changes work as expected before you update your data factory workflows in dev, test, or prod environments.</span></span> 

### <a name="deploy-ssis-packages-to-azure"></a><span data-ttu-id="8aac2-150">Deploy SSIS packages to Azure</span><span class="sxs-lookup"><span data-stu-id="8aac2-150">Deploy SSIS packages to Azure</span></span> 
<span data-ttu-id="8aac2-151">If you want to move your SSIS workloads, you can create a Data Factory and provision an Azure-SSIS integration runtime.</span><span class="sxs-lookup"><span data-stu-id="8aac2-151">If you want to move your SSIS workloads, you can create a Data Factory and provision an Azure-SSIS integration runtime.</span></span> <span data-ttu-id="8aac2-152">The Azure-SSIS integration runtime is a fully managed cluster of Azure VMs (nodes) that are dedicated to run your SSIS packages in the cloud.</span><span class="sxs-lookup"><span data-stu-id="8aac2-152">The Azure-SSIS integration runtime is a fully managed cluster of Azure VMs (nodes) that are dedicated to run your SSIS packages in the cloud.</span></span> <span data-ttu-id="8aac2-153">For step-by-step instructions, see the [Deploy SSIS packages to Azure](tutorial-create-azure-ssis-runtime-portal.md) tutorial.</span><span class="sxs-lookup"><span data-stu-id="8aac2-153">For step-by-step instructions, see the [Deploy SSIS packages to Azure](tutorial-create-azure-ssis-runtime-portal.md) tutorial.</span></span> 
 
### <a name="sdks"></a><span data-ttu-id="8aac2-154">SDKs</span><span class="sxs-lookup"><span data-stu-id="8aac2-154">SDKs</span></span>
<span data-ttu-id="8aac2-155">If you are an advanced user and looking for a programmatic interface, ADF provides a rich set of SDKs that you can use to author, manage, or monitor pipelines by using your favorite IDE.</span><span class="sxs-lookup"><span data-stu-id="8aac2-155">If you are an advanced user and looking for a programmatic interface, ADF provides a rich set of SDKs that you can use to author, manage, or monitor pipelines by using your favorite IDE.</span></span> <span data-ttu-id="8aac2-156">Language support includes .NET, PowerShell, Python, and REST.</span><span class="sxs-lookup"><span data-stu-id="8aac2-156">Language support includes .NET, PowerShell, Python, and REST.</span></span>

### <a name="monitoring"></a><span data-ttu-id="8aac2-157">Monitoring</span><span class="sxs-lookup"><span data-stu-id="8aac2-157">Monitoring</span></span>
<span data-ttu-id="8aac2-158">You can monitor your Data Factories via PowerShell, SDK, or the Visual Monitoring Tools in the browser user interface.</span><span class="sxs-lookup"><span data-stu-id="8aac2-158">You can monitor your Data Factories via PowerShell, SDK, or the Visual Monitoring Tools in the browser user interface.</span></span> <span data-ttu-id="8aac2-159">You can monitor and manage on demand, trigger based and clock driven custom flows in an efficient and effective manner.</span><span class="sxs-lookup"><span data-stu-id="8aac2-159">You can monitor and manage on demand, trigger based and clock driven custom flows in an efficient and effective manner.</span></span> <span data-ttu-id="8aac2-160">Cancel existing tasks, see failures at a glance, drill down to get detailed error messages, and debug the issues all from a single pane of glass without context switching or navigating back and forth between screens.</span><span class="sxs-lookup"><span data-stu-id="8aac2-160">Cancel existing tasks, see failures at a glance, drill down to get detailed error messages, and debug the issues all from a single pane of glass without context switching or navigating back and forth between screens.</span></span> 

### <a name="new-features-for-ssis-in-adf"></a><span data-ttu-id="8aac2-161">New features for SSIS in ADF</span><span class="sxs-lookup"><span data-stu-id="8aac2-161">New features for SSIS in ADF</span></span>
<span data-ttu-id="8aac2-162">Since the initial Public Preview release in 2017, Data Factory has added the following features for SSIS:</span><span class="sxs-lookup"><span data-stu-id="8aac2-162">Since the initial Public Preview release in 2017, Data Factory has added the following features for SSIS:</span></span>

-   <span data-ttu-id="8aac2-163">Support for three more configurations/variants of Azure SQL Database (DB) to host SSIS catalog of projects/packages (SSISDB):</span><span class="sxs-lookup"><span data-stu-id="8aac2-163">Support for three more configurations/variants of Azure SQL Database (DB) to host SSIS catalog of projects/packages (SSISDB):</span></span>
-   <span data-ttu-id="8aac2-164">Azure SQL DB with VNet service endpoints</span><span class="sxs-lookup"><span data-stu-id="8aac2-164">Azure SQL DB with VNet service endpoints</span></span>
-   <span data-ttu-id="8aac2-165">Managed Instance (MI)</span><span class="sxs-lookup"><span data-stu-id="8aac2-165">Managed Instance (MI)</span></span>
-   <span data-ttu-id="8aac2-166">Elastic Pool</span><span class="sxs-lookup"><span data-stu-id="8aac2-166">Elastic Pool</span></span>
-   <span data-ttu-id="8aac2-167">Support for Azure Resource Manager Virtual Network (VNet) on top of Classic VNet that will be deprecated in the future – This lets you inject/join your Azure-SSIS Integration Runtime (IR) to a VNet that is configured for Azure SQL DB with VNet service endpoints/MI/on-premises data access, see: https://docs.microsoft.com/en-us/azure/data-factory/join-azure-ssis-integration-runtime-virtual-network</span><span class="sxs-lookup"><span data-stu-id="8aac2-167">Support for Azure Resource Manager Virtual Network (VNet) on top of Classic VNet that will be deprecated in the future – This lets you inject/join your Azure-SSIS Integration Runtime (IR) to a VNet that is configured for Azure SQL DB with VNet service endpoints/MI/on-premises data access, see: https://docs.microsoft.com/en-us/azure/data-factory/join-azure-ssis-integration-runtime-virtual-network</span></span> 
-   <span data-ttu-id="8aac2-168">Support for Azure Active Directory (AAD) authentication on top of SQL authentication to connect to your SSISDB - This lets you use AAD authentication with your ADF Managed Service Identity (MSI)</span><span class="sxs-lookup"><span data-stu-id="8aac2-168">Support for Azure Active Directory (AAD) authentication on top of SQL authentication to connect to your SSISDB - This lets you use AAD authentication with your ADF Managed Service Identity (MSI)</span></span>
-   <span data-ttu-id="8aac2-169">Support for bringing your own on-premises SQL Server license to earn substantial cost savings from Azure Hybrid Benefit (AHB) option</span><span class="sxs-lookup"><span data-stu-id="8aac2-169">Support for bringing your own on-premises SQL Server license to earn substantial cost savings from Azure Hybrid Benefit (AHB) option</span></span>
-   <span data-ttu-id="8aac2-170">Support for Enterprise Edition of Azure-SSIS IR that lets you use advanced/premium features, custom setup to install additional components/extensions, and 3rd party ecosystem, see: https://blogs.msdn.microsoft.com/ssis/2018/04/27/enterprise-edition-custom-setup-and-3rd-party-extensibility-for-ssis-in-adf/</span><span class="sxs-lookup"><span data-stu-id="8aac2-170">Support for Enterprise Edition of Azure-SSIS IR that lets you use advanced/premium features, custom setup to install additional components/extensions, and 3rd party ecosystem, see: https://blogs.msdn.microsoft.com/ssis/2018/04/27/enterprise-edition-custom-setup-and-3rd-party-extensibility-for-ssis-in-adf/</span></span> 
-   <span data-ttu-id="8aac2-171">Deeper integration of SSIS in ADF that lets you invoke/trigger first-class Execute SSIS Package activities in ADF pipelines and schedule them via SSMS, see: https://blogs.msdn.microsoft.com/ssis/2018/05/23/modernize-and-extend-your-etlelt-workflows-with-ssis-activities-in-adf-pipelines/</span><span class="sxs-lookup"><span data-stu-id="8aac2-171">Deeper integration of SSIS in ADF that lets you invoke/trigger first-class Execute SSIS Package activities in ADF pipelines and schedule them via SSMS, see: https://blogs.msdn.microsoft.com/ssis/2018/05/23/modernize-and-extend-your-etlelt-workflows-with-ssis-activities-in-adf-pipelines/</span></span> 


## <a name="what-is-integration-runtime"></a><span data-ttu-id="8aac2-172">What is integration runtime?</span><span class="sxs-lookup"><span data-stu-id="8aac2-172">What is integration runtime?</span></span>
<span data-ttu-id="8aac2-173">Integration runtime is the compute infrastructure that's used by Azure Data Factory to provide the following data integration capabilities across various network environments:</span><span class="sxs-lookup"><span data-stu-id="8aac2-173">Integration runtime is the compute infrastructure that's used by Azure Data Factory to provide the following data integration capabilities across various network environments:</span></span>

- <span data-ttu-id="8aac2-174">**Data movement**: For data movement, Integration Runtime moves the data between the source and destination data stores, while providing support for built-in connectors, format conversion, column mapping, and performant and scalable data transfer.</span><span class="sxs-lookup"><span data-stu-id="8aac2-174">**Data movement**: For data movement, Integration Runtime moves the data between the source and destination data stores, while providing support for built-in connectors, format conversion, column mapping, and performant and scalable data transfer.</span></span>
- <span data-ttu-id="8aac2-175">**Dispatch activities**: For transformation, Integration Runtime provide capability to natively execute SSIS packages.</span><span class="sxs-lookup"><span data-stu-id="8aac2-175">**Dispatch activities**: For transformation, Integration Runtime provide capability to natively execute SSIS packages.</span></span>
- <span data-ttu-id="8aac2-176">**Execute SSIS packages**: Natively executes SSIS packages in a managed Azure compute environment.</span><span class="sxs-lookup"><span data-stu-id="8aac2-176">**Execute SSIS packages**: Natively executes SSIS packages in a managed Azure compute environment.</span></span> <span data-ttu-id="8aac2-177">Integration Runtime also supports dispatching and monitoring transformation activities running on a variety of compute services such as Azure HDInsight, Azure Machine Learning, Azure SQL Database, SQL Server, and more.</span><span class="sxs-lookup"><span data-stu-id="8aac2-177">Integration Runtime also supports dispatching and monitoring transformation activities running on a variety of compute services such as Azure HDInsight, Azure Machine Learning, Azure SQL Database, SQL Server, and more.</span></span>

<span data-ttu-id="8aac2-178">You can deploy one or many instances of integration runtime as required to move and transform data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-178">You can deploy one or many instances of integration runtime as required to move and transform data.</span></span> <span data-ttu-id="8aac2-179">Integration runtime can run on an Azure public network or on a private network (on-premises, Azure Virtual Network, or Amazon Web Services virtual private cloud [VPC]).</span><span class="sxs-lookup"><span data-stu-id="8aac2-179">Integration runtime can run on an Azure public network or on a private network (on-premises, Azure Virtual Network, or Amazon Web Services virtual private cloud [VPC]).</span></span> 

<span data-ttu-id="8aac2-180">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-180">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md).</span></span>

## <a name="what-is-the-limit-on-the-number-of-integration-runtimes"></a><span data-ttu-id="8aac2-181">What is the limit on the number of integration runtimes?</span><span class="sxs-lookup"><span data-stu-id="8aac2-181">What is the limit on the number of integration runtimes?</span></span>
<span data-ttu-id="8aac2-182">There is no hard limit on the number of integration runtime instances you can have in a data factory.</span><span class="sxs-lookup"><span data-stu-id="8aac2-182">There is no hard limit on the number of integration runtime instances you can have in a data factory.</span></span> <span data-ttu-id="8aac2-183">There is, however, a limit on the number of VM cores that the integration runtime can use per subscription for SSIS package execution.</span><span class="sxs-lookup"><span data-stu-id="8aac2-183">There is, however, a limit on the number of VM cores that the integration runtime can use per subscription for SSIS package execution.</span></span> <span data-ttu-id="8aac2-184">For more information, see [Data Factory limits](../azure-subscription-service-limits.md#data-factory-limits).</span><span class="sxs-lookup"><span data-stu-id="8aac2-184">For more information, see [Data Factory limits](../azure-subscription-service-limits.md#data-factory-limits).</span></span>

## <a name="what-are-the-top-level-concepts-of-azure-data-factory"></a><span data-ttu-id="8aac2-185">What are the top-level concepts of Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="8aac2-185">What are the top-level concepts of Azure Data Factory?</span></span>
<span data-ttu-id="8aac2-186">An Azure subscription can have one or more Azure Data Factory instances (or data factories).</span><span class="sxs-lookup"><span data-stu-id="8aac2-186">An Azure subscription can have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="8aac2-187">Azure Data Factory contains four key components that work together as a platform on which you can compose data-driven workflows with steps to move and transform data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-187">Azure Data Factory contains four key components that work together as a platform on which you can compose data-driven workflows with steps to move and transform data.</span></span>

### <a name="pipelines"></a><span data-ttu-id="8aac2-188">Pipelines</span><span class="sxs-lookup"><span data-stu-id="8aac2-188">Pipelines</span></span>
<span data-ttu-id="8aac2-189">A data factory can have one or more pipelines.</span><span class="sxs-lookup"><span data-stu-id="8aac2-189">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="8aac2-190">A pipeline is a logical grouping of activities to perform a unit of work.</span><span class="sxs-lookup"><span data-stu-id="8aac2-190">A pipeline is a logical grouping of activities to perform a unit of work.</span></span> <span data-ttu-id="8aac2-191">Together, the activities in a pipeline perform a task.</span><span class="sxs-lookup"><span data-stu-id="8aac2-191">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="8aac2-192">For example, a pipeline can contain a group of activities that ingest data from an Azure blob and then run a Hive query on an HDInsight cluster to partition the data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-192">For example, a pipeline can contain a group of activities that ingest data from an Azure blob and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="8aac2-193">The benefit is that you can use a pipeline to manage the activities as a set instead of having to manage each activity individually.</span><span class="sxs-lookup"><span data-stu-id="8aac2-193">The benefit is that you can use a pipeline to manage the activities as a set instead of having to manage each activity individually.</span></span> <span data-ttu-id="8aac2-194">You can chain together the activities in a pipeline to operate them sequentially, or you can operate them independently, in parallel.</span><span class="sxs-lookup"><span data-stu-id="8aac2-194">You can chain together the activities in a pipeline to operate them sequentially, or you can operate them independently, in parallel.</span></span>

### <a name="activity"></a><span data-ttu-id="8aac2-195">Activity</span><span class="sxs-lookup"><span data-stu-id="8aac2-195">Activity</span></span>
<span data-ttu-id="8aac2-196">Activities represent a processing step in a pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-196">Activities represent a processing step in a pipeline.</span></span> <span data-ttu-id="8aac2-197">For example, you can use a *Copy* activity to copy data from one data store to another data store.</span><span class="sxs-lookup"><span data-stu-id="8aac2-197">For example, you can use a *Copy* activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="8aac2-198">Similarly, you can use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-198">Similarly, you can use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="8aac2-199">Data Factory supports three types of activities: data movement activities, data transformation activities, and control activities.</span><span class="sxs-lookup"><span data-stu-id="8aac2-199">Data Factory supports three types of activities: data movement activities, data transformation activities, and control activities.</span></span>

### <a name="datasets"></a><span data-ttu-id="8aac2-200">Datasets</span><span class="sxs-lookup"><span data-stu-id="8aac2-200">Datasets</span></span>
<span data-ttu-id="8aac2-201">Datasets represent data structures within the data stores, which simply point to or reference the data you want to use in your activities as inputs or outputs.</span><span class="sxs-lookup"><span data-stu-id="8aac2-201">Datasets represent data structures within the data stores, which simply point to or reference the data you want to use in your activities as inputs or outputs.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="8aac2-202">Linked services</span><span class="sxs-lookup"><span data-stu-id="8aac2-202">Linked services</span></span>
<span data-ttu-id="8aac2-203">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span><span class="sxs-lookup"><span data-stu-id="8aac2-203">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="8aac2-204">Think of it this way: a linked service defines the connection to the data source, and a data set represents the structure of the data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-204">Think of it this way: a linked service defines the connection to the data source, and a data set represents the structure of the data.</span></span> <span data-ttu-id="8aac2-205">For example, an Azure Storage linked service specifies the connection string to connect to the Azure Storage account.</span><span class="sxs-lookup"><span data-stu-id="8aac2-205">For example, an Azure Storage linked service specifies the connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="8aac2-206">And an Azure Blob data set specifies the blob container and the folder that contains the data.</span><span class="sxs-lookup"><span data-stu-id="8aac2-206">And an Azure Blob data set specifies the blob container and the folder that contains the data.</span></span>

<span data-ttu-id="8aac2-207">Linked services have two purposes in Data Factory:</span><span class="sxs-lookup"><span data-stu-id="8aac2-207">Linked services have two purposes in Data Factory:</span></span>

- <span data-ttu-id="8aac2-208">To represent a *data store* that includes, but is not limited to, an on-premises SQL Server instance, an Oracle database instance, a file share, or an Azure Blob storage account.</span><span class="sxs-lookup"><span data-stu-id="8aac2-208">To represent a *data store* that includes, but is not limited to, an on-premises SQL Server instance, an Oracle database instance, a file share, or an Azure Blob storage account.</span></span> <span data-ttu-id="8aac2-209">For a list of supported data stores, see [Copy Activity in Azure Data Factory](copy-activity-overview.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-209">For a list of supported data stores, see [Copy Activity in Azure Data Factory](copy-activity-overview.md).</span></span>
- <span data-ttu-id="8aac2-210">To represent a *compute resource* that can host the execution of an activity.</span><span class="sxs-lookup"><span data-stu-id="8aac2-210">To represent a *compute resource* that can host the execution of an activity.</span></span> <span data-ttu-id="8aac2-211">For example, the HDInsight Hive activity runs on an HDInsight Hadoop cluster.</span><span class="sxs-lookup"><span data-stu-id="8aac2-211">For example, the HDInsight Hive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="8aac2-212">For a list of transformation activities and supported compute environments, see [Transform data in Azure Data Factory](transform-data.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-212">For a list of transformation activities and supported compute environments, see [Transform data in Azure Data Factory](transform-data.md).</span></span>

### <a name="triggers"></a><span data-ttu-id="8aac2-213">Triggers</span><span class="sxs-lookup"><span data-stu-id="8aac2-213">Triggers</span></span>
<span data-ttu-id="8aac2-214">Triggers represent units of processing that determine when a pipeline execution is kicked off.</span><span class="sxs-lookup"><span data-stu-id="8aac2-214">Triggers represent units of processing that determine when a pipeline execution is kicked off.</span></span> <span data-ttu-id="8aac2-215">There are different types of triggers for different types of events.</span><span class="sxs-lookup"><span data-stu-id="8aac2-215">There are different types of triggers for different types of events.</span></span> 

### <a name="pipeline-runs"></a><span data-ttu-id="8aac2-216">Pipeline runs</span><span class="sxs-lookup"><span data-stu-id="8aac2-216">Pipeline runs</span></span>
<span data-ttu-id="8aac2-217">A pipeline run is an instance of a pipeline execution.</span><span class="sxs-lookup"><span data-stu-id="8aac2-217">A pipeline run is an instance of a pipeline execution.</span></span> <span data-ttu-id="8aac2-218">You usually instantiate a pipeline run by passing arguments to the parameters that are defined in the pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-218">You usually instantiate a pipeline run by passing arguments to the parameters that are defined in the pipeline.</span></span> <span data-ttu-id="8aac2-219">You can pass the arguments manually or within the trigger definition.</span><span class="sxs-lookup"><span data-stu-id="8aac2-219">You can pass the arguments manually or within the trigger definition.</span></span>

### <a name="parameters"></a><span data-ttu-id="8aac2-220">Parameters</span><span class="sxs-lookup"><span data-stu-id="8aac2-220">Parameters</span></span>
<span data-ttu-id="8aac2-221">Parameters are key-value pairs in a read-only configuration.</span><span class="sxs-lookup"><span data-stu-id="8aac2-221">Parameters are key-value pairs in a read-only configuration.</span></span><span data-ttu-id="8aac2-222"> You define parameters in a pipeline, and you pass the arguments for the defined parameters during execution from a run context.</span><span class="sxs-lookup"><span data-stu-id="8aac2-222"> You define parameters in a pipeline, and you pass the arguments for the defined parameters during execution from a run context.</span></span> <span data-ttu-id="8aac2-223">The run context is created by a trigger or from a pipeline that you execute manually.</span><span class="sxs-lookup"><span data-stu-id="8aac2-223">The run context is created by a trigger or from a pipeline that you execute manually.</span></span> <span data-ttu-id="8aac2-224">Activities within the pipeline consume the parameter values.</span><span class="sxs-lookup"><span data-stu-id="8aac2-224">Activities within the pipeline consume the parameter values.</span></span>

<span data-ttu-id="8aac2-225">A data set is a strongly typed parameter and an entity that you can reuse or reference.</span><span class="sxs-lookup"><span data-stu-id="8aac2-225">A data set is a strongly typed parameter and an entity that you can reuse or reference.</span></span> <span data-ttu-id="8aac2-226">An activity can reference data sets, and it can consume the properties that are defined in the data-set definition.</span><span class="sxs-lookup"><span data-stu-id="8aac2-226">An activity can reference data sets, and it can consume the properties that are defined in the data-set definition.</span></span>

<span data-ttu-id="8aac2-227">A linked service is also a strongly typed parameter that contains connection information to either a data store or a compute environment.</span><span class="sxs-lookup"><span data-stu-id="8aac2-227">A linked service is also a strongly typed parameter that contains connection information to either a data store or a compute environment.</span></span> <span data-ttu-id="8aac2-228">It is also an entity that you can reuse or reference.</span><span class="sxs-lookup"><span data-stu-id="8aac2-228">It is also an entity that you can reuse or reference.</span></span>

### <a name="control-flows"></a><span data-ttu-id="8aac2-229">Control flows</span><span class="sxs-lookup"><span data-stu-id="8aac2-229">Control flows</span></span>
<span data-ttu-id="8aac2-230">Control flows orchestrate pipeline activities that include chaining activities in a sequence, branching, parameters that you define at the pipeline level, and arguments that you pass as you invoke the pipeline on demand or from a trigger.</span><span class="sxs-lookup"><span data-stu-id="8aac2-230">Control flows orchestrate pipeline activities that include chaining activities in a sequence, branching, parameters that you define at the pipeline level, and arguments that you pass as you invoke the pipeline on demand or from a trigger.</span></span> <span data-ttu-id="8aac2-231">Control flows also include custom-state passing and looping containers (that is, for-each iterators).</span><span class="sxs-lookup"><span data-stu-id="8aac2-231">Control flows also include custom-state passing and looping containers (that is, for-each iterators).</span></span>


<span data-ttu-id="8aac2-232">For more information about Data Factory concepts, see the following articles:</span><span class="sxs-lookup"><span data-stu-id="8aac2-232">For more information about Data Factory concepts, see the following articles:</span></span>

- [<span data-ttu-id="8aac2-233">Data set and linked services</span><span class="sxs-lookup"><span data-stu-id="8aac2-233">Data set and linked services</span></span>](concepts-datasets-linked-services.md)
- [<span data-ttu-id="8aac2-234">Pipelines and activities</span><span class="sxs-lookup"><span data-stu-id="8aac2-234">Pipelines and activities</span></span>](concepts-pipelines-activities.md)
- [<span data-ttu-id="8aac2-235">Integration runtime</span><span class="sxs-lookup"><span data-stu-id="8aac2-235">Integration runtime</span></span>](concepts-integration-runtime.md)

## <a name="what-is-the-pricing-model-for-data-factory"></a><span data-ttu-id="8aac2-236">What is the pricing model for Data Factory?</span><span class="sxs-lookup"><span data-stu-id="8aac2-236">What is the pricing model for Data Factory?</span></span>
<span data-ttu-id="8aac2-237">For Azure Data Factory pricing details, see [Data Factory pricing details](https://azure.microsoft.com/pricing/details/data-factory/).</span><span class="sxs-lookup"><span data-stu-id="8aac2-237">For Azure Data Factory pricing details, see [Data Factory pricing details](https://azure.microsoft.com/pricing/details/data-factory/).</span></span>

## <a name="how-can-i-stay-up-to-date-with-information-about-data-factory"></a><span data-ttu-id="8aac2-238">How can I stay up-to-date with information about Data Factory?</span><span class="sxs-lookup"><span data-stu-id="8aac2-238">How can I stay up-to-date with information about Data Factory?</span></span>
<span data-ttu-id="8aac2-239">For the most up-to-date information about Azure Data Factory, go to the following sites:</span><span class="sxs-lookup"><span data-stu-id="8aac2-239">For the most up-to-date information about Azure Data Factory, go to the following sites:</span></span>

- [<span data-ttu-id="8aac2-240">Blog</span><span class="sxs-lookup"><span data-stu-id="8aac2-240">Blog</span></span>](https://azure.microsoft.com/blog/tag/azure-data-factory/)
- [<span data-ttu-id="8aac2-241">Documentation home page</span><span class="sxs-lookup"><span data-stu-id="8aac2-241">Documentation home page</span></span>](/azure/data-factory)
- [<span data-ttu-id="8aac2-242">Product home page</span><span class="sxs-lookup"><span data-stu-id="8aac2-242">Product home page</span></span>](https://azure.microsoft.com/services/data-factory/)

## <a name="technical-deep-dive"></a><span data-ttu-id="8aac2-243">Technical deep dive</span><span class="sxs-lookup"><span data-stu-id="8aac2-243">Technical deep dive</span></span> 

### <a name="how-can-i-schedule-a-pipeline"></a><span data-ttu-id="8aac2-244">How can I schedule a pipeline?</span><span class="sxs-lookup"><span data-stu-id="8aac2-244">How can I schedule a pipeline?</span></span> 
<span data-ttu-id="8aac2-245">You can use the scheduler trigger or time window trigger to schedule a pipeline.</span><span class="sxs-lookup"><span data-stu-id="8aac2-245">You can use the scheduler trigger or time window trigger to schedule a pipeline.</span></span> <span data-ttu-id="8aac2-246">The trigger uses a wall-clock calendar schedule, and you can use it to schedule pipelines either periodically or by using calendar-based recurrent patterns (for example, weekly on Mondays at 6 PM and Thursdays at 9 PM).</span><span class="sxs-lookup"><span data-stu-id="8aac2-246">The trigger uses a wall-clock calendar schedule, and you can use it to schedule pipelines either periodically or by using calendar-based recurrent patterns (for example, weekly on Mondays at 6 PM and Thursdays at 9 PM).</span></span> <span data-ttu-id="8aac2-247">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span><span class="sxs-lookup"><span data-stu-id="8aac2-247">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span></span>

### <a name="can-i-pass-parameters-to-a-pipeline-run"></a><span data-ttu-id="8aac2-248">Can I pass parameters to a pipeline run?</span><span class="sxs-lookup"><span data-stu-id="8aac2-248">Can I pass parameters to a pipeline run?</span></span>
<span data-ttu-id="8aac2-249">Yes, parameters are a first-class, top-level concept in ADF.</span><span class="sxs-lookup"><span data-stu-id="8aac2-249">Yes, parameters are a first-class, top-level concept in ADF.</span></span> <span data-ttu-id="8aac2-250">You can define parameters at the pipeline level and pass arguments as you execute the pipeline run on demand or by using a trigger.</span><span class="sxs-lookup"><span data-stu-id="8aac2-250">You can define parameters at the pipeline level and pass arguments as you execute the pipeline run on demand or by using a trigger.</span></span>  

### <a name="can-i-define-default-values-for-the-pipeline-parameters"></a><span data-ttu-id="8aac2-251">Can I define default values for the pipeline parameters?</span><span class="sxs-lookup"><span data-stu-id="8aac2-251">Can I define default values for the pipeline parameters?</span></span> 
<span data-ttu-id="8aac2-252">Yes.</span><span class="sxs-lookup"><span data-stu-id="8aac2-252">Yes.</span></span> <span data-ttu-id="8aac2-253">You can define default values for the parameters in the pipelines.</span><span class="sxs-lookup"><span data-stu-id="8aac2-253">You can define default values for the parameters in the pipelines.</span></span> 

### <a name="can-an-activity-in-a-pipeline-consume-arguments-that-are-passed-to-a-pipeline-run"></a><span data-ttu-id="8aac2-254">Can an activity in a pipeline consume arguments that are passed to a pipeline run?</span><span class="sxs-lookup"><span data-stu-id="8aac2-254">Can an activity in a pipeline consume arguments that are passed to a pipeline run?</span></span> 
<span data-ttu-id="8aac2-255">Yes.</span><span class="sxs-lookup"><span data-stu-id="8aac2-255">Yes.</span></span> <span data-ttu-id="8aac2-256">Each activity within the pipeline can consume the parameter value that's passed to the pipeline and run with the `@parameter` construct.</span><span class="sxs-lookup"><span data-stu-id="8aac2-256">Each activity within the pipeline can consume the parameter value that's passed to the pipeline and run with the `@parameter` construct.</span></span> 

### <a name="can-an-activity-output-property-be-consumed-in-another-activity"></a><span data-ttu-id="8aac2-257">Can an activity output property be consumed in another activity?</span><span class="sxs-lookup"><span data-stu-id="8aac2-257">Can an activity output property be consumed in another activity?</span></span> 
<span data-ttu-id="8aac2-258">Yes.</span><span class="sxs-lookup"><span data-stu-id="8aac2-258">Yes.</span></span> <span data-ttu-id="8aac2-259">An activity output can be consumed in a subsequent activity with the `@activity` construct.</span><span class="sxs-lookup"><span data-stu-id="8aac2-259">An activity output can be consumed in a subsequent activity with the `@activity` construct.</span></span>
 
### <a name="how-do-i-gracefully-handle-null-values-in-an-activity-output"></a><span data-ttu-id="8aac2-260">How do I gracefully handle null values in an activity output?</span><span class="sxs-lookup"><span data-stu-id="8aac2-260">How do I gracefully handle null values in an activity output?</span></span> 
<span data-ttu-id="8aac2-261">You can use the `@coalesce` construct in the expressions to handle null values gracefully.</span><span class="sxs-lookup"><span data-stu-id="8aac2-261">You can use the `@coalesce` construct in the expressions to handle null values gracefully.</span></span> 

## <a name="next-steps"></a><span data-ttu-id="8aac2-262">Next steps</span><span class="sxs-lookup"><span data-stu-id="8aac2-262">Next steps</span></span>
<span data-ttu-id="8aac2-263">For step-by-step instructions to create a data factory, see the following tutorials:</span><span class="sxs-lookup"><span data-stu-id="8aac2-263">For step-by-step instructions to create a data factory, see the following tutorials:</span></span>

- [<span data-ttu-id="8aac2-264">Quickstart: Create a data factory</span><span class="sxs-lookup"><span data-stu-id="8aac2-264">Quickstart: Create a data factory</span></span>](quickstart-create-data-factory-dot-net.md)
- [<span data-ttu-id="8aac2-265">Tutorial: Copy data in the cloud</span><span class="sxs-lookup"><span data-stu-id="8aac2-265">Tutorial: Copy data in the cloud</span></span>](tutorial-copy-data-dot-net.md)
