---
title: Introduction to Azure Data Factory | Microsoft Docs
description: Learn about Azure Data Factory, a cloud data integration service that orchestrates and automates movement and transformation of data.
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: overview
ms.date: 01/11/2018
ms.author: shlo
ms.openlocfilehash: 87df752f62956cffd455358059a3ab7b275b6a5d
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44867515"
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="5ac3b-103">Introduction to Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5ac3b-103">Introduction to Azure Data Factory</span></span> 
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Version 1](v1/data-factory-introduction.md)
> * [Current version](introduction.md)

<span data-ttu-id="5ac3b-106">In the world of big data, raw, unorganized data is often stored in relational, non-relational, and other storage systems.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-106">In the world of big data, raw, unorganized data is often stored in relational, non-relational, and other storage systems.</span></span> <span data-ttu-id="5ac3b-107">However, on its own, raw data doesn't have the proper context or meaning to provide meaningful insights to analysts, data scientists, or business decision makers.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-107">However, on its own, raw data doesn't have the proper context or meaning to provide meaningful insights to analysts, data scientists, or business decision makers.</span></span> 

<span data-ttu-id="5ac3b-108">Big data requires service that can orchestrate and operationalize processes to refine these enormous stores of raw data into actionable business insights.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-108">Big data requires service that can orchestrate and operationalize processes to refine these enormous stores of raw data into actionable business insights.</span></span> <span data-ttu-id="5ac3b-109">Azure Data Factory is a managed cloud service that's built for these complex hybrid extract-transform-load (ETL), extract-load-transform (ELT), and data integration projects.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-109">Azure Data Factory is a managed cloud service that's built for these complex hybrid extract-transform-load (ETL), extract-load-transform (ELT), and data integration projects.</span></span>

<span data-ttu-id="5ac3b-110">For example, imagine a gaming company that collects petabytes of game logs that are produced by games in the cloud.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-110">For example, imagine a gaming company that collects petabytes of game logs that are produced by games in the cloud.</span></span> <span data-ttu-id="5ac3b-111">The company wants to analyze these logs to gain insights into customer preferences, demographics, and usage behavior.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-111">The company wants to analyze these logs to gain insights into customer preferences, demographics, and usage behavior.</span></span> <span data-ttu-id="5ac3b-112">It also wants to identify up-sell and cross-sell opportunities, develop compelling new features, drive business growth, and provide a better experience to its customers.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-112">It also wants to identify up-sell and cross-sell opportunities, develop compelling new features, drive business growth, and provide a better experience to its customers.</span></span>

<span data-ttu-id="5ac3b-113">To analyze these logs, the company needs to use reference data such as customer information, game information, and marketing campaign information that is in an on-premises data store.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-113">To analyze these logs, the company needs to use reference data such as customer information, game information, and marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="5ac3b-114">The company wants to utilize this data from the on-premises data store, combining it with additional log data that it has in a cloud data store.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-114">The company wants to utilize this data from the on-premises data store, combining it with additional log data that it has in a cloud data store.</span></span> 

<span data-ttu-id="5ac3b-115">To extract insights, it hopes to process the joined data by using a Spark cluster in the cloud (Azure HDInsight), and publish the transformed data into a cloud data warehouse such as Azure SQL Data Warehouse to easily build a report on top of it.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-115">To extract insights, it hopes to process the joined data by using a Spark cluster in the cloud (Azure HDInsight), and publish the transformed data into a cloud data warehouse such as Azure SQL Data Warehouse to easily build a report on top of it.</span></span> <span data-ttu-id="5ac3b-116">They want to automate this workflow, and monitor and manage it on a daily schedule.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-116">They want to automate this workflow, and monitor and manage it on a daily schedule.</span></span> <span data-ttu-id="5ac3b-117">They also want to execute it when files land in a blob store container.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-117">They also want to execute it when files land in a blob store container.</span></span>

<span data-ttu-id="5ac3b-118">Azure Data Factory is the platform that solves such data scenarios.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-118">Azure Data Factory is the platform that solves such data scenarios.</span></span> <span data-ttu-id="5ac3b-119">It is a *cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation*.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-119">It is a *cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation*.</span></span> <span data-ttu-id="5ac3b-120">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-120">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores.</span></span> <span data-ttu-id="5ac3b-121">It can process and transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-121">It can process and transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning.</span></span> 

<span data-ttu-id="5ac3b-122">Additionally, you can publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-122">Additionally, you can publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span> <span data-ttu-id="5ac3b-123">Ultimately, through Azure Data Factory, raw data can be organized into meaningful data stores and data lakes for better business decisions.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-123">Ultimately, through Azure Data Factory, raw data can be organized into meaningful data stores and data lakes for better business decisions.</span></span>

![Top-level view of Data Factory](media/introduction/big-picture.png)

## <a name="how-does-it-work"></a><span data-ttu-id="5ac3b-125">How does it work?</span><span class="sxs-lookup"><span data-stu-id="5ac3b-125">How does it work?</span></span>
<span data-ttu-id="5ac3b-126">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following four steps:</span><span class="sxs-lookup"><span data-stu-id="5ac3b-126">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following four steps:</span></span>

![Four steps of a data-driven workflow](media/introduction/four-steps-of-a-workflow.png)

### <a name="connect-and-collect"></a><span data-ttu-id="5ac3b-128">Connect and collect</span><span class="sxs-lookup"><span data-stu-id="5ac3b-128">Connect and collect</span></span>

<span data-ttu-id="5ac3b-129">Enterprises have data of various types that are located in disparate sources on-premises, in the cloud, structured, unstructured, and semi-structured, all arriving at different intervals and speeds.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-129">Enterprises have data of various types that are located in disparate sources on-premises, in the cloud, structured, unstructured, and semi-structured, all arriving at different intervals and speeds.</span></span> 

<span data-ttu-id="5ac3b-130">The first step in building an information production system is to connect to all the required sources of data and processing, such as software-as-a-service (SaaS) services, databases, file shares, and FTP web services.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-130">The first step in building an information production system is to connect to all the required sources of data and processing, such as software-as-a-service (SaaS) services, databases, file shares, and FTP web services.</span></span> <span data-ttu-id="5ac3b-131">The next step is to move the data as needed to a centralized location for subsequent processing.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-131">The next step is to move the data as needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="5ac3b-132">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-132">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="5ac3b-133">It's expensive and hard to integrate and maintain such systems.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-133">It's expensive and hard to integrate and maintain such systems.</span></span> <span data-ttu-id="5ac3b-134">In addition, they often lack the enterprise-grade monitoring, alerting, and the controls that a fully managed service can offer.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-134">In addition, they often lack the enterprise-grade monitoring, alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="5ac3b-135">With Data Factory, you can use the [Copy Activity](copy-activity-overview.md) in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-135">With Data Factory, you can use the [Copy Activity](copy-activity-overview.md) in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="5ac3b-136">For example, you can collect data in Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-136">For example, you can collect data in Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="5ac3b-137">You can also collect data in Azure Blob storage and transform it later by using an Azure HDInsight Hadoop cluster.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-137">You can also collect data in Azure Blob storage and transform it later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="5ac3b-138">Transform and enrich</span><span class="sxs-lookup"><span data-stu-id="5ac3b-138">Transform and enrich</span></span>
<span data-ttu-id="5ac3b-139">After data is present in a centralized data store in the cloud, process or transform the collected data by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-139">After data is present in a centralized data store in the cloud, process or transform the collected data by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="5ac3b-140">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-140">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span>

### <a name="publish"></a><span data-ttu-id="5ac3b-141">Publish</span><span class="sxs-lookup"><span data-stu-id="5ac3b-141">Publish</span></span>
<span data-ttu-id="5ac3b-142">After the raw data has been refined into a business-ready consumable form, load the data into Azure Data Warehouse, Azure SQL Database, Azure CosmosDB, or whichever analytics engine your business users can point to from their business intelligence tools.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-142">After the raw data has been refined into a business-ready consumable form, load the data into Azure Data Warehouse, Azure SQL Database, Azure CosmosDB, or whichever analytics engine your business users can point to from their business intelligence tools.</span></span>

### <a name="monitor"></a><span data-ttu-id="5ac3b-143">Monitor</span><span class="sxs-lookup"><span data-stu-id="5ac3b-143">Monitor</span></span>
<span data-ttu-id="5ac3b-144">After you have successfully built and deployed your data integration pipeline, providing business value from refined data, monitor the scheduled activities and pipelines for success and failure rates.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-144">After you have successfully built and deployed your data integration pipeline, providing business value from refined data, monitor the scheduled activities and pipelines for success and failure rates.</span></span> <span data-ttu-id="5ac3b-145">Azure Data Factory has built-in support for pipeline monitoring via Azure Monitor, API, PowerShell, Log Analytics, and health panels on the Azure portal.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-145">Azure Data Factory has built-in support for pipeline monitoring via Azure Monitor, API, PowerShell, Log Analytics, and health panels on the Azure portal.</span></span>

## <a name="top-level-concepts"></a><span data-ttu-id="5ac3b-146">Top-level concepts</span><span class="sxs-lookup"><span data-stu-id="5ac3b-146">Top-level concepts</span></span>
<span data-ttu-id="5ac3b-147">An Azure subscription might have one or more Azure Data Factory instances (or data factories).</span><span class="sxs-lookup"><span data-stu-id="5ac3b-147">An Azure subscription might have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="5ac3b-148">Azure Data Factory is composed of four key components.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-148">Azure Data Factory is composed of four key components.</span></span> <span data-ttu-id="5ac3b-149">These components work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-149">These components work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span>

### <a name="pipeline"></a><span data-ttu-id="5ac3b-150">Pipeline</span><span class="sxs-lookup"><span data-stu-id="5ac3b-150">Pipeline</span></span>
<span data-ttu-id="5ac3b-151">A data factory might have one or more pipelines.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-151">A data factory might have one or more pipelines.</span></span> <span data-ttu-id="5ac3b-152">A pipeline is a logical grouping of activities that performs a unit of work.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-152">A pipeline is a logical grouping of activities that performs a unit of work.</span></span> <span data-ttu-id="5ac3b-153">Together, the activities in a pipeline perform a task.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-153">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="5ac3b-154">For example, a pipeline can contain a group of activities that ingests data from an Azure blob, and then runs a Hive query on an HDInsight cluster to partition the data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-154">For example, a pipeline can contain a group of activities that ingests data from an Azure blob, and then runs a Hive query on an HDInsight cluster to partition the data.</span></span> 

<span data-ttu-id="5ac3b-155">The benefit of this is that the pipeline allows you to manage the activities as a set instead of managing each one individually.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-155">The benefit of this is that the pipeline allows you to manage the activities as a set instead of managing each one individually.</span></span> <span data-ttu-id="5ac3b-156">The activities in a pipeline can be chained together to operate sequentially, or they can operate independently in parallel.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-156">The activities in a pipeline can be chained together to operate sequentially, or they can operate independently in parallel.</span></span>

### <a name="activity"></a><span data-ttu-id="5ac3b-157">Activity</span><span class="sxs-lookup"><span data-stu-id="5ac3b-157">Activity</span></span>
<span data-ttu-id="5ac3b-158">Activities represent a processing step in a pipeline.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-158">Activities represent a processing step in a pipeline.</span></span> <span data-ttu-id="5ac3b-159">For example, you might use a copy activity to copy data from one data store to another data store.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-159">For example, you might use a copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="5ac3b-160">Similarly, you might use a Hive activity, which runs a Hive query on an Azure HDInsight cluster, to transform or analyze your data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-160">Similarly, you might use a Hive activity, which runs a Hive query on an Azure HDInsight cluster, to transform or analyze your data.</span></span> <span data-ttu-id="5ac3b-161">Data Factory supports three types of activities: data movement activities, data transformation activities, and control activities.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-161">Data Factory supports three types of activities: data movement activities, data transformation activities, and control activities.</span></span>

### <a name="datasets"></a><span data-ttu-id="5ac3b-162">Datasets</span><span class="sxs-lookup"><span data-stu-id="5ac3b-162">Datasets</span></span>
<span data-ttu-id="5ac3b-163">Datasets represent data structures within the data stores, which simply point to or reference the data you want to use in your activities as inputs or outputs.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-163">Datasets represent data structures within the data stores, which simply point to or reference the data you want to use in your activities as inputs or outputs.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="5ac3b-164">Linked services</span><span class="sxs-lookup"><span data-stu-id="5ac3b-164">Linked services</span></span>
<span data-ttu-id="5ac3b-165">Linked services are much like connection strings, which define the connection information that's needed for Data Factory to connect to external resources.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-165">Linked services are much like connection strings, which define the connection information that's needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="5ac3b-166">Think of it this way: a linked service defines the connection to the data source, and a dataset represents the structure of the data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-166">Think of it this way: a linked service defines the connection to the data source, and a dataset represents the structure of the data.</span></span> <span data-ttu-id="5ac3b-167">For example, an Azure Storage-linked service specifies a connection string to connect to the Azure Storage account.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-167">For example, an Azure Storage-linked service specifies a connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="5ac3b-168">Additionally, an Azure blob dataset specifies the blob container and the folder that contains the data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-168">Additionally, an Azure blob dataset specifies the blob container and the folder that contains the data.</span></span>

<span data-ttu-id="5ac3b-169">Linked services are used for two purposes in Data Factory:</span><span class="sxs-lookup"><span data-stu-id="5ac3b-169">Linked services are used for two purposes in Data Factory:</span></span>

- <span data-ttu-id="5ac3b-170">To represent a **data store** that includes, but isn't limited to, an on-premises SQL Server database, Oracle database, file share, or Azure blob storage account.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-170">To represent a **data store** that includes, but isn't limited to, an on-premises SQL Server database, Oracle database, file share, or Azure blob storage account.</span></span> <span data-ttu-id="5ac3b-171">For a list of supported data stores, see the [copy activity](copy-activity-overview.md) article.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-171">For a list of supported data stores, see the [copy activity](copy-activity-overview.md) article.</span></span>

- <span data-ttu-id="5ac3b-172">To represent a **compute resource** that can host the execution of an activity.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-172">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="5ac3b-173">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-173">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="5ac3b-174">For a list of transformation activities and supported compute environments, see the [transform data](transform-data.md) article.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-174">For a list of transformation activities and supported compute environments, see the [transform data](transform-data.md) article.</span></span>

### <a name="triggers"></a><span data-ttu-id="5ac3b-175">Triggers</span><span class="sxs-lookup"><span data-stu-id="5ac3b-175">Triggers</span></span>
<span data-ttu-id="5ac3b-176">Triggers represent the unit of processing that determines when a pipeline execution needs to be kicked off.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-176">Triggers represent the unit of processing that determines when a pipeline execution needs to be kicked off.</span></span> <span data-ttu-id="5ac3b-177">There are different types of triggers for different types of events.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-177">There are different types of triggers for different types of events.</span></span>

### <a name="pipeline-runs"></a><span data-ttu-id="5ac3b-178">Pipeline runs</span><span class="sxs-lookup"><span data-stu-id="5ac3b-178">Pipeline runs</span></span>
<span data-ttu-id="5ac3b-179">A pipeline run is an instance of the pipeline execution.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-179">A pipeline run is an instance of the pipeline execution.</span></span> <span data-ttu-id="5ac3b-180">Pipeline runs are typically instantiated by passing the arguments to the parameters that are defined in pipelines.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-180">Pipeline runs are typically instantiated by passing the arguments to the parameters that are defined in pipelines.</span></span> <span data-ttu-id="5ac3b-181">The arguments can be passed manually or within the trigger definition.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-181">The arguments can be passed manually or within the trigger definition.</span></span>

### <a name="parameters"></a><span data-ttu-id="5ac3b-182">Parameters</span><span class="sxs-lookup"><span data-stu-id="5ac3b-182">Parameters</span></span>
<span data-ttu-id="5ac3b-183">Parameters are key-value pairs of read-only configuration.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-183">Parameters are key-value pairs of read-only configuration.</span></span><span data-ttu-id="5ac3b-184">  Parameters are defined in the pipeline.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-184">  Parameters are defined in the pipeline.</span></span> <span data-ttu-id="5ac3b-185">The arguments for the defined parameters are passed during execution from the run context that was created by a trigger or a pipeline that was executed manually.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-185">The arguments for the defined parameters are passed during execution from the run context that was created by a trigger or a pipeline that was executed manually.</span></span> <span data-ttu-id="5ac3b-186">Activities within the pipeline consume the parameter values.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-186">Activities within the pipeline consume the parameter values.</span></span>

<span data-ttu-id="5ac3b-187">A dataset is a strongly typed parameter and a reusable/referenceable entity.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-187">A dataset is a strongly typed parameter and a reusable/referenceable entity.</span></span> <span data-ttu-id="5ac3b-188">An activity can reference datasets and can consume the properties that are defined in the dataset definition.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-188">An activity can reference datasets and can consume the properties that are defined in the dataset definition.</span></span>

<span data-ttu-id="5ac3b-189">A linked service is also a strongly typed parameter that contains the connection information to either a data store or a compute environment.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-189">A linked service is also a strongly typed parameter that contains the connection information to either a data store or a compute environment.</span></span> <span data-ttu-id="5ac3b-190">It is also a reusable/referenceable entity.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-190">It is also a reusable/referenceable entity.</span></span>

### <a name="control-flow"></a><span data-ttu-id="5ac3b-191">Control flow</span><span class="sxs-lookup"><span data-stu-id="5ac3b-191">Control flow</span></span>
<span data-ttu-id="5ac3b-192">Control flow is an orchestration of pipeline activities that includes chaining activities in a sequence, branching, defining parameters at the pipeline level, and passing arguments while invoking the pipeline on-demand or from a trigger.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-192">Control flow is an orchestration of pipeline activities that includes chaining activities in a sequence, branching, defining parameters at the pipeline level, and passing arguments while invoking the pipeline on-demand or from a trigger.</span></span> <span data-ttu-id="5ac3b-193">It also includes custom-state passing and looping containers, that is, For-each iterators.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-193">It also includes custom-state passing and looping containers, that is, For-each iterators.</span></span>


<span data-ttu-id="5ac3b-194">For more information about Data Factory concepts, see the following articles:</span><span class="sxs-lookup"><span data-stu-id="5ac3b-194">For more information about Data Factory concepts, see the following articles:</span></span>

- [<span data-ttu-id="5ac3b-195">Dataset and linked services</span><span class="sxs-lookup"><span data-stu-id="5ac3b-195">Dataset and linked services</span></span>](concepts-datasets-linked-services.md)
- [<span data-ttu-id="5ac3b-196">Pipelines and activities</span><span class="sxs-lookup"><span data-stu-id="5ac3b-196">Pipelines and activities</span></span>](concepts-pipelines-activities.md)
- [<span data-ttu-id="5ac3b-197">Integration runtime</span><span class="sxs-lookup"><span data-stu-id="5ac3b-197">Integration runtime</span></span>](concepts-integration-runtime.md)

## <a name="supported-regions"></a><span data-ttu-id="5ac3b-198">Supported regions</span><span class="sxs-lookup"><span data-stu-id="5ac3b-198">Supported regions</span></span>

<span data-ttu-id="5ac3b-199">For a list of Azure regions in which Data Factory is currently available, select the regions that interest you on the following page, and then expand **Analytics** to locate **Data Factory**: [Products available by region](https://azure.microsoft.com/global-infrastructure/services/).</span><span class="sxs-lookup"><span data-stu-id="5ac3b-199">For a list of Azure regions in which Data Factory is currently available, select the regions that interest you on the following page, and then expand **Analytics** to locate **Data Factory**: [Products available by region](https://azure.microsoft.com/global-infrastructure/services/).</span></span> <span data-ttu-id="5ac3b-200">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-200">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="5ac3b-201">Azure Data Factory itself does not store any data.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-201">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="5ac3b-202">It lets you create data-driven workflows to orchestrate the movement of data between supported data stores and the processing of data using compute services in other regions or in an on-premises environment.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-202">It lets you create data-driven workflows to orchestrate the movement of data between supported data stores and the processing of data using compute services in other regions or in an on-premises environment.</span></span> <span data-ttu-id="5ac3b-203">It also allows you to monitor and manage workflows by using both programmatic and UI mechanisms.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-203">It also allows you to monitor and manage workflows by using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="5ac3b-204">Although Data Factory is available only in certain regions, the service that powers the data movement in Data Factory is available globally in several regions.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-204">Although Data Factory is available only in certain regions, the service that powers the data movement in Data Factory is available globally in several regions.</span></span> <span data-ttu-id="5ac3b-205">If a data store is behind a firewall, then a Self-hosted Integration Runtime that's installed in your on-premises environment moves the data instead.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-205">If a data store is behind a firewall, then a Self-hosted Integration Runtime that's installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="5ac3b-206">For an example, let's assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of the West Europe region.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-206">For an example, let's assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of the West Europe region.</span></span> <span data-ttu-id="5ac3b-207">You can create and use an Azure Data Factory instance in East US or East US 2 and use it to schedule jobs on your compute environments in West Europe.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-207">You can create and use an Azure Data Factory instance in East US or East US 2 and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="5ac3b-208">It takes a few milliseconds for Data Factory to trigger the job on your compute environment, but the time for running the job on your computing environment does not change.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-208">It takes a few milliseconds for Data Factory to trigger the job on your compute environment, but the time for running the job on your computing environment does not change.</span></span>

## <a name="accessibility"></a><span data-ttu-id="5ac3b-209">Accessibility</span><span class="sxs-lookup"><span data-stu-id="5ac3b-209">Accessibility</span></span>

<span data-ttu-id="5ac3b-210">The Data Factory user experience in the Azure portal is accessible.</span><span class="sxs-lookup"><span data-stu-id="5ac3b-210">The Data Factory user experience in the Azure portal is accessible.</span></span>

## <a name="compare-with-version-1"></a><span data-ttu-id="5ac3b-211">Compare with version 1</span><span class="sxs-lookup"><span data-stu-id="5ac3b-211">Compare with version 1</span></span>
<span data-ttu-id="5ac3b-212">For a list of differences between version 1 and the current version of the Data Factory service, see [Compare with version 1](compare-versions.md).</span><span class="sxs-lookup"><span data-stu-id="5ac3b-212">For a list of differences between version 1 and the current version of the Data Factory service, see [Compare with version 1](compare-versions.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="5ac3b-213">Next steps</span><span class="sxs-lookup"><span data-stu-id="5ac3b-213">Next steps</span></span>
<span data-ttu-id="5ac3b-214">Get started with creating a Data Factory pipeline by using one of the following tools/SDKs:</span><span class="sxs-lookup"><span data-stu-id="5ac3b-214">Get started with creating a Data Factory pipeline by using one of the following tools/SDKs:</span></span> 

- [<span data-ttu-id="5ac3b-215">Data Factory UI in the Azure portal</span><span class="sxs-lookup"><span data-stu-id="5ac3b-215">Data Factory UI in the Azure portal</span></span>](quickstart-create-data-factory-portal.md)
- [<span data-ttu-id="5ac3b-216">Copy Data tool in the Azure portal</span><span class="sxs-lookup"><span data-stu-id="5ac3b-216">Copy Data tool in the Azure portal</span></span>](quickstart-create-data-factory-copy-data-tool.md)
- [<span data-ttu-id="5ac3b-217">PowerShell</span><span class="sxs-lookup"><span data-stu-id="5ac3b-217">PowerShell</span></span>](quickstart-create-data-factory-powershell.md)
- [<span data-ttu-id="5ac3b-218">.NET</span><span class="sxs-lookup"><span data-stu-id="5ac3b-218">.NET</span></span>](quickstart-create-data-factory-dot-net.md)
- [<span data-ttu-id="5ac3b-219">Python</span><span class="sxs-lookup"><span data-stu-id="5ac3b-219">Python</span></span>](quickstart-create-data-factory-python.md)
- [<span data-ttu-id="5ac3b-220">REST</span><span class="sxs-lookup"><span data-stu-id="5ac3b-220">REST</span></span>](quickstart-create-data-factory-rest-api.md)
- [<span data-ttu-id="5ac3b-221">Azure Resource Manager template</span><span class="sxs-lookup"><span data-stu-id="5ac3b-221">Azure Resource Manager template</span></span>](quickstart-create-data-factory-resource-manager-template.md)
 
