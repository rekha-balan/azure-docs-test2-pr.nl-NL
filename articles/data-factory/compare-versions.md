---
title: Compare Azure Data Factory with Data Factory version 1 | Microsoft Docs
description: This article compares Azure Data Factory with Azure Data Factory version 1.
services: data-factory
documentationcenter: ''
author: kromerm
manager: craigg
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: overview
ms.date: 04/09/2018
ms.author: makromer
ms.openlocfilehash: ca00a414402c1cfdef55cfbde9291688f091bf77
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44966353"
---
# <a name="compare-azure-data-factory-with-data-factory-version-1"></a><span data-ttu-id="67ba7-103">Compare Azure Data Factory with Data Factory version 1</span><span class="sxs-lookup"><span data-stu-id="67ba7-103">Compare Azure Data Factory with Data Factory version 1</span></span>
<span data-ttu-id="67ba7-104">This article compares Data Factory with Data Factory version 1.</span><span class="sxs-lookup"><span data-stu-id="67ba7-104">This article compares Data Factory with Data Factory version 1.</span></span> <span data-ttu-id="67ba7-105">For an introduction to Data Factory, see [Introduction to Data Factory](introduction.md).For an introduction to Data Factory version 1, see [Introduction to Azure Data Factory](v1/data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-105">For an introduction to Data Factory, see [Introduction to Data Factory](introduction.md).For an introduction to Data Factory version 1, see [Introduction to Azure Data Factory](v1/data-factory-introduction.md).</span></span> 

## <a name="feature-comparison"></a><span data-ttu-id="67ba7-106">Feature comparison</span><span class="sxs-lookup"><span data-stu-id="67ba7-106">Feature comparison</span></span>
<span data-ttu-id="67ba7-107">The following table compares the features of Data Factory with the features of Data Factory version 1.</span><span class="sxs-lookup"><span data-stu-id="67ba7-107">The following table compares the features of Data Factory with the features of Data Factory version 1.</span></span> 

| <span data-ttu-id="67ba7-108">Feature</span><span class="sxs-lookup"><span data-stu-id="67ba7-108">Feature</span></span> | <span data-ttu-id="67ba7-109">Version 1</span><span class="sxs-lookup"><span data-stu-id="67ba7-109">Version 1</span></span> | <span data-ttu-id="67ba7-110">Current version</span><span class="sxs-lookup"><span data-stu-id="67ba7-110">Current version</span></span> | 
| ------- | --------- | --------- | 
| <span data-ttu-id="67ba7-111">Datasets</span><span class="sxs-lookup"><span data-stu-id="67ba7-111">Datasets</span></span> | <span data-ttu-id="67ba7-112">A named view of data that references the data that you want to use in your activities as inputs and outputs.</span><span class="sxs-lookup"><span data-stu-id="67ba7-112">A named view of data that references the data that you want to use in your activities as inputs and outputs.</span></span> <span data-ttu-id="67ba7-113">Datasets identify data within different data stores, such as tables, files, folders, and documents.</span><span class="sxs-lookup"><span data-stu-id="67ba7-113">Datasets identify data within different data stores, such as tables, files, folders, and documents.</span></span> <span data-ttu-id="67ba7-114">For example, an Azure Blob dataset specifies the blob container and folder in Azure Blob storage from which the activity should read the data.</span><span class="sxs-lookup"><span data-stu-id="67ba7-114">For example, an Azure Blob dataset specifies the blob container and folder in Azure Blob storage from which the activity should read the data.</span></span><br/><br/><span data-ttu-id="67ba7-115">**Availability** defines the processing window slicing model for the dataset (for example, hourly, daily, and so on).</span><span class="sxs-lookup"><span data-stu-id="67ba7-115">**Availability** defines the processing window slicing model for the dataset (for example, hourly, daily, and so on).</span></span> | <span data-ttu-id="67ba7-116">Datasets are the same in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-116">Datasets are the same in the current version.</span></span> <span data-ttu-id="67ba7-117">However, you do not need to define **availability** schedules for datasets.</span><span class="sxs-lookup"><span data-stu-id="67ba7-117">However, you do not need to define **availability** schedules for datasets.</span></span> <span data-ttu-id="67ba7-118">You can define a trigger resource that can schedule pipelines from a clock scheduler paradigm.</span><span class="sxs-lookup"><span data-stu-id="67ba7-118">You can define a trigger resource that can schedule pipelines from a clock scheduler paradigm.</span></span> <span data-ttu-id="67ba7-119">For more information, see [Triggers](concepts-pipeline-execution-triggers.md#triggers) and [Datasets](concepts-datasets-linked-services.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-119">For more information, see [Triggers](concepts-pipeline-execution-triggers.md#triggers) and [Datasets](concepts-datasets-linked-services.md).</span></span> | 
| <span data-ttu-id="67ba7-120">Linked services</span><span class="sxs-lookup"><span data-stu-id="67ba7-120">Linked services</span></span> | <span data-ttu-id="67ba7-121">Linked services are much like connection strings, which define the connection information that's necessary for Data Factory to connect to external resources.</span><span class="sxs-lookup"><span data-stu-id="67ba7-121">Linked services are much like connection strings, which define the connection information that's necessary for Data Factory to connect to external resources.</span></span> | <span data-ttu-id="67ba7-122">Linked services are the same as in Data Factory V1, but with a new **connectVia** property to utilize the Integration Runtime compute environment of the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-122">Linked services are the same as in Data Factory V1, but with a new **connectVia** property to utilize the Integration Runtime compute environment of the current version of Data Factory.</span></span> <span data-ttu-id="67ba7-123">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md) and [Linked service properties for Azure Blob storage](connector-azure-blob-storage.md#linked-service-properties).</span><span class="sxs-lookup"><span data-stu-id="67ba7-123">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md) and [Linked service properties for Azure Blob storage](connector-azure-blob-storage.md#linked-service-properties).</span></span> |
| <span data-ttu-id="67ba7-124">Pipelines</span><span class="sxs-lookup"><span data-stu-id="67ba7-124">Pipelines</span></span> | <span data-ttu-id="67ba7-125">A data factory can have one or more pipelines.</span><span class="sxs-lookup"><span data-stu-id="67ba7-125">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="67ba7-126">A pipeline is a logical grouping of activities that together perform a task.</span><span class="sxs-lookup"><span data-stu-id="67ba7-126">A pipeline is a logical grouping of activities that together perform a task.</span></span> <span data-ttu-id="67ba7-127">You use startTime, endTime, and isPaused to schedule and run pipelines.</span><span class="sxs-lookup"><span data-stu-id="67ba7-127">You use startTime, endTime, and isPaused to schedule and run pipelines.</span></span> | <span data-ttu-id="67ba7-128">Pipelines are groups of activities that are performed on data.</span><span class="sxs-lookup"><span data-stu-id="67ba7-128">Pipelines are groups of activities that are performed on data.</span></span> <span data-ttu-id="67ba7-129">However, the scheduling of activities in the pipeline has been separated into new trigger resources.</span><span class="sxs-lookup"><span data-stu-id="67ba7-129">However, the scheduling of activities in the pipeline has been separated into new trigger resources.</span></span> <span data-ttu-id="67ba7-130">You can think of pipelines in the current version of Data Factory more as “workflow units” that you schedule separately via triggers.</span><span class="sxs-lookup"><span data-stu-id="67ba7-130">You can think of pipelines in the current version of Data Factory more as “workflow units” that you schedule separately via triggers.</span></span> <br/><br/><span data-ttu-id="67ba7-131">Pipelines do not have “windows” of time execution in the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-131">Pipelines do not have “windows” of time execution in the current version of Data Factory.</span></span> <span data-ttu-id="67ba7-132">The Data Factory V1 concepts of startTime, endTime, and isPaused are no longer present in the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-132">The Data Factory V1 concepts of startTime, endTime, and isPaused are no longer present in the current version of Data Factory.</span></span> <span data-ttu-id="67ba7-133">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md) and [Pipelines and activities](concepts-pipelines-activities.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-133">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md) and [Pipelines and activities](concepts-pipelines-activities.md).</span></span> |
| <span data-ttu-id="67ba7-134">Activities</span><span class="sxs-lookup"><span data-stu-id="67ba7-134">Activities</span></span> | <span data-ttu-id="67ba7-135">Activities define actions to perform on your data within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-135">Activities define actions to perform on your data within a pipeline.</span></span> <span data-ttu-id="67ba7-136">Data movement (copy activity) and data transformation activities (such as Hive, Pig, and MapReduce) are supported.</span><span class="sxs-lookup"><span data-stu-id="67ba7-136">Data movement (copy activity) and data transformation activities (such as Hive, Pig, and MapReduce) are supported.</span></span> | <span data-ttu-id="67ba7-137">In the current version of Data Factory, activities still are defined actions within a pipelineThe current version of Data Factory introduces new [control flow activities](concepts-pipelines-activities.md#control-activities).</span><span class="sxs-lookup"><span data-stu-id="67ba7-137">In the current version of Data Factory, activities still are defined actions within a pipelineThe current version of Data Factory introduces new [control flow activities](concepts-pipelines-activities.md#control-activities).</span></span> <span data-ttu-id="67ba7-138">You use these activities in a control flow (looping and branching).</span><span class="sxs-lookup"><span data-stu-id="67ba7-138">You use these activities in a control flow (looping and branching).</span></span> <span data-ttu-id="67ba7-139">Data movement and data transformation activities that were supported in V1 are supported in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-139">Data movement and data transformation activities that were supported in V1 are supported in the current version.</span></span> <span data-ttu-id="67ba7-140">You can define transformation activities without using datasets in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-140">You can define transformation activities without using datasets in the current version.</span></span> |
| <span data-ttu-id="67ba7-141">Hybrid data movement and activity dispatch</span><span class="sxs-lookup"><span data-stu-id="67ba7-141">Hybrid data movement and activity dispatch</span></span> | <span data-ttu-id="67ba7-142">Now called Integration Runtime, [Data Management Gateway](v1/data-factory-data-management-gateway.md) supported moving data between on-premises and cloud.</span><span class="sxs-lookup"><span data-stu-id="67ba7-142">Now called Integration Runtime, [Data Management Gateway](v1/data-factory-data-management-gateway.md) supported moving data between on-premises and cloud.</span></span>| <span data-ttu-id="67ba7-143">Data Management Gateway is now called Self-Hosted Integration Runtime.</span><span class="sxs-lookup"><span data-stu-id="67ba7-143">Data Management Gateway is now called Self-Hosted Integration Runtime.</span></span> <span data-ttu-id="67ba7-144">It provides the same capability as it did in V1.</span><span class="sxs-lookup"><span data-stu-id="67ba7-144">It provides the same capability as it did in V1.</span></span> <br/><br/> <span data-ttu-id="67ba7-145">The Azure-SSIS Integration Runtime in the current version of Data Factory also supports deploying and running SQL Server Integration Services (SSIS) packages in the cloud.</span><span class="sxs-lookup"><span data-stu-id="67ba7-145">The Azure-SSIS Integration Runtime in the current version of Data Factory also supports deploying and running SQL Server Integration Services (SSIS) packages in the cloud.</span></span> <span data-ttu-id="67ba7-146">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-146">For more information, see [Integration runtime in Azure Data Factory](concepts-integration-runtime.md).</span></span>|
| <span data-ttu-id="67ba7-147">Parameters</span><span class="sxs-lookup"><span data-stu-id="67ba7-147">Parameters</span></span> | <span data-ttu-id="67ba7-148">NA</span><span class="sxs-lookup"><span data-stu-id="67ba7-148">NA</span></span> | <span data-ttu-id="67ba7-149">Parameters are key-value pairs of read-only configuration settings that are defined in pipelines.</span><span class="sxs-lookup"><span data-stu-id="67ba7-149">Parameters are key-value pairs of read-only configuration settings that are defined in pipelines.</span></span> <span data-ttu-id="67ba7-150">You can pass arguments for the parameters when you are manually running the pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-150">You can pass arguments for the parameters when you are manually running the pipeline.</span></span> <span data-ttu-id="67ba7-151">If you are using a scheduler trigger, the trigger can pass values for the parameters too.</span><span class="sxs-lookup"><span data-stu-id="67ba7-151">If you are using a scheduler trigger, the trigger can pass values for the parameters too.</span></span> <span data-ttu-id="67ba7-152">Activities within the pipeline consume the parameter values.</span><span class="sxs-lookup"><span data-stu-id="67ba7-152">Activities within the pipeline consume the parameter values.</span></span>  |
| <span data-ttu-id="67ba7-153">Expressions</span><span class="sxs-lookup"><span data-stu-id="67ba7-153">Expressions</span></span> | <span data-ttu-id="67ba7-154">Data Factory V1 allows you to use functions and system variables in data selection queries and activity/dataset properties.</span><span class="sxs-lookup"><span data-stu-id="67ba7-154">Data Factory V1 allows you to use functions and system variables in data selection queries and activity/dataset properties.</span></span> | <span data-ttu-id="67ba7-155">In the current version of Data Factory, you can use expressions anywhere in a JSON string value.</span><span class="sxs-lookup"><span data-stu-id="67ba7-155">In the current version of Data Factory, you can use expressions anywhere in a JSON string value.</span></span> <span data-ttu-id="67ba7-156">For more information, see [Expressions and functions in the current version of Data Factory](control-flow-expression-language-functions.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-156">For more information, see [Expressions and functions in the current version of Data Factory](control-flow-expression-language-functions.md).</span></span>|
| <span data-ttu-id="67ba7-157">Pipeline runs</span><span class="sxs-lookup"><span data-stu-id="67ba7-157">Pipeline runs</span></span> | <span data-ttu-id="67ba7-158">NA</span><span class="sxs-lookup"><span data-stu-id="67ba7-158">NA</span></span> | <span data-ttu-id="67ba7-159">A single instance of a pipeline execution.</span><span class="sxs-lookup"><span data-stu-id="67ba7-159">A single instance of a pipeline execution.</span></span> <span data-ttu-id="67ba7-160">For example, say you have a pipeline that executes at 8 AM, 9 AM, and 10 AM.</span><span class="sxs-lookup"><span data-stu-id="67ba7-160">For example, say you have a pipeline that executes at 8 AM, 9 AM, and 10 AM.</span></span> <span data-ttu-id="67ba7-161">There would be three separate runs of the pipeline (pipeline runs) in this case.</span><span class="sxs-lookup"><span data-stu-id="67ba7-161">There would be three separate runs of the pipeline (pipeline runs) in this case.</span></span> <span data-ttu-id="67ba7-162">Each pipeline run has a unique pipeline run ID.</span><span class="sxs-lookup"><span data-stu-id="67ba7-162">Each pipeline run has a unique pipeline run ID.</span></span> <span data-ttu-id="67ba7-163">The pipeline run ID is a GUID that uniquely defines that particular pipeline run.</span><span class="sxs-lookup"><span data-stu-id="67ba7-163">The pipeline run ID is a GUID that uniquely defines that particular pipeline run.</span></span> <span data-ttu-id="67ba7-164">Pipeline runs are typically instantiated by passing arguments to parameters that are defined in the pipelines.</span><span class="sxs-lookup"><span data-stu-id="67ba7-164">Pipeline runs are typically instantiated by passing arguments to parameters that are defined in the pipelines.</span></span> |
| <span data-ttu-id="67ba7-165">Activity runs</span><span class="sxs-lookup"><span data-stu-id="67ba7-165">Activity runs</span></span> | <span data-ttu-id="67ba7-166">NA</span><span class="sxs-lookup"><span data-stu-id="67ba7-166">NA</span></span> | <span data-ttu-id="67ba7-167">An instance of an activity execution within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-167">An instance of an activity execution within a pipeline.</span></span> | 
| <span data-ttu-id="67ba7-168">Trigger runs</span><span class="sxs-lookup"><span data-stu-id="67ba7-168">Trigger runs</span></span> | <span data-ttu-id="67ba7-169">NA</span><span class="sxs-lookup"><span data-stu-id="67ba7-169">NA</span></span> | <span data-ttu-id="67ba7-170">An instance of a trigger execution.</span><span class="sxs-lookup"><span data-stu-id="67ba7-170">An instance of a trigger execution.</span></span> <span data-ttu-id="67ba7-171">For more information, see [Triggers](concepts-pipeline-execution-triggers.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-171">For more information, see [Triggers](concepts-pipeline-execution-triggers.md).</span></span> |
| <span data-ttu-id="67ba7-172">Scheduling</span><span class="sxs-lookup"><span data-stu-id="67ba7-172">Scheduling</span></span> | <span data-ttu-id="67ba7-173">Scheduling is based on pipeline start/end times and dataset availability.</span><span class="sxs-lookup"><span data-stu-id="67ba7-173">Scheduling is based on pipeline start/end times and dataset availability.</span></span> | <span data-ttu-id="67ba7-174">Scheduler trigger or execution via external scheduler.</span><span class="sxs-lookup"><span data-stu-id="67ba7-174">Scheduler trigger or execution via external scheduler.</span></span> <span data-ttu-id="67ba7-175">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-175">For more information, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span></span> |

<span data-ttu-id="67ba7-176">The following sections provide more information about the capabilities of the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-176">The following sections provide more information about the capabilities of the current version.</span></span> 

## <a name="control-flow"></a><span data-ttu-id="67ba7-177">Control flow</span><span class="sxs-lookup"><span data-stu-id="67ba7-177">Control flow</span></span>  
<span data-ttu-id="67ba7-178">To support diverse integration flows and patterns in the modern data warehouse, the current version of Data Factory has enabled a new flexible data pipeline model that is no longer tied to time-series data.</span><span class="sxs-lookup"><span data-stu-id="67ba7-178">To support diverse integration flows and patterns in the modern data warehouse, the current version of Data Factory has enabled a new flexible data pipeline model that is no longer tied to time-series data.</span></span> <span data-ttu-id="67ba7-179">A few common flows that were previously not possible are now enabled.</span><span class="sxs-lookup"><span data-stu-id="67ba7-179">A few common flows that were previously not possible are now enabled.</span></span> <span data-ttu-id="67ba7-180">They are described in the following sections.</span><span class="sxs-lookup"><span data-stu-id="67ba7-180">They are described in the following sections.</span></span>   

### <a name="chaining-activities"></a><span data-ttu-id="67ba7-181">Chaining activities</span><span class="sxs-lookup"><span data-stu-id="67ba7-181">Chaining activities</span></span>
<span data-ttu-id="67ba7-182">In V1, you had to configure the output of an activity as an input of another activity to chain them.</span><span class="sxs-lookup"><span data-stu-id="67ba7-182">In V1, you had to configure the output of an activity as an input of another activity to chain them.</span></span> <span data-ttu-id="67ba7-183">in the current version, you can chain activities in a sequence within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-183">in the current version, you can chain activities in a sequence within a pipeline.</span></span> <span data-ttu-id="67ba7-184">You can use the **dependsOn** property in an activity definition to chain it with an upstream activity.</span><span class="sxs-lookup"><span data-stu-id="67ba7-184">You can use the **dependsOn** property in an activity definition to chain it with an upstream activity.</span></span> <span data-ttu-id="67ba7-185">For more information and an example, see [Pipelines and activities](concepts-pipelines-activities.md#multiple-activities-in-a-pipeline) and [Branching and chaining activities](tutorial-control-flow.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-185">For more information and an example, see [Pipelines and activities](concepts-pipelines-activities.md#multiple-activities-in-a-pipeline) and [Branching and chaining activities](tutorial-control-flow.md).</span></span> 

### <a name="branching-activities"></a><span data-ttu-id="67ba7-186">Branching activities</span><span class="sxs-lookup"><span data-stu-id="67ba7-186">Branching activities</span></span>
<span data-ttu-id="67ba7-187">in the current version, you can branch activities within a pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-187">in the current version, you can branch activities within a pipeline.</span></span> <span data-ttu-id="67ba7-188">The [If-condition activity](control-flow-if-condition-activity.md) provides the same functionality that an `if` statement provides in programming languages.</span><span class="sxs-lookup"><span data-stu-id="67ba7-188">The [If-condition activity](control-flow-if-condition-activity.md) provides the same functionality that an `if` statement provides in programming languages.</span></span> <span data-ttu-id="67ba7-189">It evaluates a set of activities when the condition evaluates to `true` and another set of activities when the condition evaluates to `false`.</span><span class="sxs-lookup"><span data-stu-id="67ba7-189">It evaluates a set of activities when the condition evaluates to `true` and another set of activities when the condition evaluates to `false`.</span></span> <span data-ttu-id="67ba7-190">For examples of branching activities, see the [Branching and chaining activities](tutorial-control-flow.md) tutorial.</span><span class="sxs-lookup"><span data-stu-id="67ba7-190">For examples of branching activities, see the [Branching and chaining activities](tutorial-control-flow.md) tutorial.</span></span>

### <a name="parameters"></a><span data-ttu-id="67ba7-191">Parameters</span><span class="sxs-lookup"><span data-stu-id="67ba7-191">Parameters</span></span> 
<span data-ttu-id="67ba7-192">You can define parameters at the pipeline level and pass arguments while you're invoking the pipeline on-demand or from a trigger.</span><span class="sxs-lookup"><span data-stu-id="67ba7-192">You can define parameters at the pipeline level and pass arguments while you're invoking the pipeline on-demand or from a trigger.</span></span> <span data-ttu-id="67ba7-193">Activities can consume the arguments that are passed to the pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-193">Activities can consume the arguments that are passed to the pipeline.</span></span> <span data-ttu-id="67ba7-194">For more information, see [Pipelines and triggers](concepts-pipeline-execution-triggers.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-194">For more information, see [Pipelines and triggers](concepts-pipeline-execution-triggers.md).</span></span> 

### <a name="custom-state-passing"></a><span data-ttu-id="67ba7-195">Custom state passing</span><span class="sxs-lookup"><span data-stu-id="67ba7-195">Custom state passing</span></span>
<span data-ttu-id="67ba7-196">Activity outputs including state can be consumed by a subsequent activity in the pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-196">Activity outputs including state can be consumed by a subsequent activity in the pipeline.</span></span> <span data-ttu-id="67ba7-197">For example, in the JSON definition of an activity, you can access the output of the previous activity by using the following syntax: `@activity('NameofPreviousActivity').output.value`.</span><span class="sxs-lookup"><span data-stu-id="67ba7-197">For example, in the JSON definition of an activity, you can access the output of the previous activity by using the following syntax: `@activity('NameofPreviousActivity').output.value`.</span></span> <span data-ttu-id="67ba7-198">By using this feature, you can build workflows where values can pass through activities.</span><span class="sxs-lookup"><span data-stu-id="67ba7-198">By using this feature, you can build workflows where values can pass through activities.</span></span>

### <a name="looping-containers"></a><span data-ttu-id="67ba7-199">Looping containers</span><span class="sxs-lookup"><span data-stu-id="67ba7-199">Looping containers</span></span>
<span data-ttu-id="67ba7-200">The [ForEach activity](control-flow-for-each-activity.md) defines a repeating control flow in your pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-200">The [ForEach activity](control-flow-for-each-activity.md) defines a repeating control flow in your pipeline.</span></span> <span data-ttu-id="67ba7-201">This activity iterates over a collection and runs specified activities in a loop.</span><span class="sxs-lookup"><span data-stu-id="67ba7-201">This activity iterates over a collection and runs specified activities in a loop.</span></span> <span data-ttu-id="67ba7-202">The loop implementation of this activity is similar to the Foreach looping structure in programming languages.</span><span class="sxs-lookup"><span data-stu-id="67ba7-202">The loop implementation of this activity is similar to the Foreach looping structure in programming languages.</span></span> 

<span data-ttu-id="67ba7-203">The [Until](control-flow-until-activity.md) activity provides the same functionality that a do-until looping structure provides in programming languages.</span><span class="sxs-lookup"><span data-stu-id="67ba7-203">The [Until](control-flow-until-activity.md) activity provides the same functionality that a do-until looping structure provides in programming languages.</span></span> <span data-ttu-id="67ba7-204">It runs a set of activities in a loop until the condition that's associated with the activity evaluates to `true`.</span><span class="sxs-lookup"><span data-stu-id="67ba7-204">It runs a set of activities in a loop until the condition that's associated with the activity evaluates to `true`.</span></span> <span data-ttu-id="67ba7-205">You can specify a timeout value for the until activity in Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-205">You can specify a timeout value for the until activity in Data Factory.</span></span>  

### <a name="trigger-based-flows"></a><span data-ttu-id="67ba7-206">Trigger-based flows</span><span class="sxs-lookup"><span data-stu-id="67ba7-206">Trigger-based flows</span></span>
<span data-ttu-id="67ba7-207">Pipelines can be triggered by on-demand or wall-clock time.</span><span class="sxs-lookup"><span data-stu-id="67ba7-207">Pipelines can be triggered by on-demand or wall-clock time.</span></span> <span data-ttu-id="67ba7-208">The [pipelines and triggers](concepts-pipeline-execution-triggers.md) article has detailed information about triggers.</span><span class="sxs-lookup"><span data-stu-id="67ba7-208">The [pipelines and triggers](concepts-pipeline-execution-triggers.md) article has detailed information about triggers.</span></span> 

### <a name="invoking-a-pipeline-from-another-pipeline"></a><span data-ttu-id="67ba7-209">Invoking a pipeline from another pipeline</span><span class="sxs-lookup"><span data-stu-id="67ba7-209">Invoking a pipeline from another pipeline</span></span>
<span data-ttu-id="67ba7-210">The [Execute Pipeline activity](control-flow-execute-pipeline-activity.md) allows a Data Factory pipeline to invoke another pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-210">The [Execute Pipeline activity](control-flow-execute-pipeline-activity.md) allows a Data Factory pipeline to invoke another pipeline.</span></span>

### <a name="delta-flows"></a><span data-ttu-id="67ba7-211">Delta flows</span><span class="sxs-lookup"><span data-stu-id="67ba7-211">Delta flows</span></span>
<span data-ttu-id="67ba7-212">A key use case in ETL patterns is “delta loads,” in which only data that has changed since the last iteration of a pipeline is loaded.</span><span class="sxs-lookup"><span data-stu-id="67ba7-212">A key use case in ETL patterns is “delta loads,” in which only data that has changed since the last iteration of a pipeline is loaded.</span></span> <span data-ttu-id="67ba7-213">New capabilities in the current version, such as [lookup activity](control-flow-lookup-activity.md), flexible scheduling, and control flow, enable this use case in a natural way.</span><span class="sxs-lookup"><span data-stu-id="67ba7-213">New capabilities in the current version, such as [lookup activity](control-flow-lookup-activity.md), flexible scheduling, and control flow, enable this use case in a natural way.</span></span> <span data-ttu-id="67ba7-214">For a tutorial with step-by-step instructions, see [Tutorial: Incremental copy](tutorial-incremental-copy-powershell.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-214">For a tutorial with step-by-step instructions, see [Tutorial: Incremental copy](tutorial-incremental-copy-powershell.md).</span></span>

### <a name="other-control-flow-activities"></a><span data-ttu-id="67ba7-215">Other control flow activities</span><span class="sxs-lookup"><span data-stu-id="67ba7-215">Other control flow activities</span></span>
<span data-ttu-id="67ba7-216">Following are a few more control flow activities that are supported by the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-216">Following are a few more control flow activities that are supported by the current version of Data Factory.</span></span> 

<span data-ttu-id="67ba7-217">Control activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-217">Control activity</span></span> | <span data-ttu-id="67ba7-218">Description</span><span class="sxs-lookup"><span data-stu-id="67ba7-218">Description</span></span>
---------------- | -----------
[<span data-ttu-id="67ba7-219">ForEach activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-219">ForEach activity</span></span>](control-flow-for-each-activity.md) | <span data-ttu-id="67ba7-220">Defines a repeating control flow in your pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-220">Defines a repeating control flow in your pipeline.</span></span> <span data-ttu-id="67ba7-221">This activity is used to iterate over a collection and runs specified activities in a loop.</span><span class="sxs-lookup"><span data-stu-id="67ba7-221">This activity is used to iterate over a collection and runs specified activities in a loop.</span></span> <span data-ttu-id="67ba7-222">The loop implementation of this activity is similar to Foreach looping structure in programming languages.</span><span class="sxs-lookup"><span data-stu-id="67ba7-222">The loop implementation of this activity is similar to Foreach looping structure in programming languages.</span></span>
[<span data-ttu-id="67ba7-223">Web activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-223">Web activity</span></span>](control-flow-web-activity.md) | <span data-ttu-id="67ba7-224">Calls a custom REST endpoint from a Data Factory pipeline.</span><span class="sxs-lookup"><span data-stu-id="67ba7-224">Calls a custom REST endpoint from a Data Factory pipeline.</span></span> <span data-ttu-id="67ba7-225">You can pass datasets and linked services to be consumed and accessed by the activity.</span><span class="sxs-lookup"><span data-stu-id="67ba7-225">You can pass datasets and linked services to be consumed and accessed by the activity.</span></span> 
[<span data-ttu-id="67ba7-226">Lookup activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-226">Lookup activity</span></span>](control-flow-lookup-activity.md) | <span data-ttu-id="67ba7-227">Reads or looks up a record or table name value from any external source.</span><span class="sxs-lookup"><span data-stu-id="67ba7-227">Reads or looks up a record or table name value from any external source.</span></span> <span data-ttu-id="67ba7-228">This output can further be referenced by succeeding activities.</span><span class="sxs-lookup"><span data-stu-id="67ba7-228">This output can further be referenced by succeeding activities.</span></span> 
[<span data-ttu-id="67ba7-229">Get metadata activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-229">Get metadata activity</span></span>](control-flow-get-metadata-activity.md) | <span data-ttu-id="67ba7-230">Retrieves the metadata of any data in Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-230">Retrieves the metadata of any data in Azure Data Factory.</span></span> 
[<span data-ttu-id="67ba7-231">Wait activity</span><span class="sxs-lookup"><span data-stu-id="67ba7-231">Wait activity</span></span>](control-flow-wait-activity.md) | <span data-ttu-id="67ba7-232">Pauses the pipeline for a specified period of time.</span><span class="sxs-lookup"><span data-stu-id="67ba7-232">Pauses the pipeline for a specified period of time.</span></span>

## <a name="deploy-ssis-packages-to-azure"></a><span data-ttu-id="67ba7-233">Deploy SSIS packages to Azure</span><span class="sxs-lookup"><span data-stu-id="67ba7-233">Deploy SSIS packages to Azure</span></span> 
<span data-ttu-id="67ba7-234">You use Azure-SSIS if you want to move your SSIS workloads to the cloud, create a data factory by using the current version, and provision an Azure-SSIS Integration Runtime.</span><span class="sxs-lookup"><span data-stu-id="67ba7-234">You use Azure-SSIS if you want to move your SSIS workloads to the cloud, create a data factory by using the current version, and provision an Azure-SSIS Integration Runtime.</span></span>

<span data-ttu-id="67ba7-235">The Azure-SSIS Integration Runtime is a fully managed cluster of Azure VMs (nodes) that are dedicated to running your SSIS packages in the cloud.</span><span class="sxs-lookup"><span data-stu-id="67ba7-235">The Azure-SSIS Integration Runtime is a fully managed cluster of Azure VMs (nodes) that are dedicated to running your SSIS packages in the cloud.</span></span> <span data-ttu-id="67ba7-236">After you provision Azure-SSIS Integration Runtime, you can use the same tools that you have been using to deploy SSIS packages to an on-premises SSIS environment.</span><span class="sxs-lookup"><span data-stu-id="67ba7-236">After you provision Azure-SSIS Integration Runtime, you can use the same tools that you have been using to deploy SSIS packages to an on-premises SSIS environment.</span></span> 

<span data-ttu-id="67ba7-237">For example, you can use SQL Server Data Tools or SQL Server Management Studio to deploy SSIS packages to this runtime on Azure.</span><span class="sxs-lookup"><span data-stu-id="67ba7-237">For example, you can use SQL Server Data Tools or SQL Server Management Studio to deploy SSIS packages to this runtime on Azure.</span></span> <span data-ttu-id="67ba7-238">For step-by-step instructions, see the tutorial [Deploy SQL Server integration services packages to Azure](tutorial-create-azure-ssis-runtime-portal.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-238">For step-by-step instructions, see the tutorial [Deploy SQL Server integration services packages to Azure](tutorial-create-azure-ssis-runtime-portal.md).</span></span> 

## <a name="flexible-scheduling"></a><span data-ttu-id="67ba7-239">Flexible scheduling</span><span class="sxs-lookup"><span data-stu-id="67ba7-239">Flexible scheduling</span></span>
<span data-ttu-id="67ba7-240">In the current version of Data Factory, you do not need to define dataset availability schedules.</span><span class="sxs-lookup"><span data-stu-id="67ba7-240">In the current version of Data Factory, you do not need to define dataset availability schedules.</span></span> <span data-ttu-id="67ba7-241">You can define a trigger resource that can schedule pipelines from a clock scheduler paradigm.</span><span class="sxs-lookup"><span data-stu-id="67ba7-241">You can define a trigger resource that can schedule pipelines from a clock scheduler paradigm.</span></span> <span data-ttu-id="67ba7-242">You can also pass parameters to pipelines from a trigger for a flexible scheduling and execution model.</span><span class="sxs-lookup"><span data-stu-id="67ba7-242">You can also pass parameters to pipelines from a trigger for a flexible scheduling and execution model.</span></span> 

<span data-ttu-id="67ba7-243">Pipelines do not have “windows” of time execution in the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-243">Pipelines do not have “windows” of time execution in the current version of Data Factory.</span></span> <span data-ttu-id="67ba7-244">The Data Factory V1 concepts of startTime, endTime, and isPaused don't exist in the current version of Data Factory.</span><span class="sxs-lookup"><span data-stu-id="67ba7-244">The Data Factory V1 concepts of startTime, endTime, and isPaused don't exist in the current version of Data Factory.</span></span> <span data-ttu-id="67ba7-245">For more information about how to build and then schedule a pipeline in the current version of Data Factory, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-245">For more information about how to build and then schedule a pipeline in the current version of Data Factory, see [Pipeline execution and triggers](concepts-pipeline-execution-triggers.md).</span></span>

## <a name="support-for-more-data-stores"></a><span data-ttu-id="67ba7-246">Support for more data stores</span><span class="sxs-lookup"><span data-stu-id="67ba7-246">Support for more data stores</span></span>
<span data-ttu-id="67ba7-247">The current version supports the copying of data to and from more data stores than V1.</span><span class="sxs-lookup"><span data-stu-id="67ba7-247">The current version supports the copying of data to and from more data stores than V1.</span></span> <span data-ttu-id="67ba7-248">For a list of supported data stores, see the following articles:</span><span class="sxs-lookup"><span data-stu-id="67ba7-248">For a list of supported data stores, see the following articles:</span></span>

- [<span data-ttu-id="67ba7-249">Version 1 - supported data stores</span><span class="sxs-lookup"><span data-stu-id="67ba7-249">Version 1 - supported data stores</span></span>](v1/data-factory-data-movement-activities.md#supported-data-stores-and-formats)
- [<span data-ttu-id="67ba7-250">Current version - supported data stores</span><span class="sxs-lookup"><span data-stu-id="67ba7-250">Current version - supported data stores</span></span>](copy-activity-overview.md#supported-data-stores-and-formats)

## <a name="support-for-on-demand-spark-cluster"></a><span data-ttu-id="67ba7-251">Support for on-demand Spark cluster</span><span class="sxs-lookup"><span data-stu-id="67ba7-251">Support for on-demand Spark cluster</span></span>
<span data-ttu-id="67ba7-252">The current version supports the creation of an on-demand Azure HDInsight Spark cluster.</span><span class="sxs-lookup"><span data-stu-id="67ba7-252">The current version supports the creation of an on-demand Azure HDInsight Spark cluster.</span></span> <span data-ttu-id="67ba7-253">To create an on-demand Spark cluster, specify the cluster type as Spark in your on-demand, HDInsight linked service definition.</span><span class="sxs-lookup"><span data-stu-id="67ba7-253">To create an on-demand Spark cluster, specify the cluster type as Spark in your on-demand, HDInsight linked service definition.</span></span> <span data-ttu-id="67ba7-254">Then you can configure the Spark activity in your pipeline to use this linked service.</span><span class="sxs-lookup"><span data-stu-id="67ba7-254">Then you can configure the Spark activity in your pipeline to use this linked service.</span></span> 

<span data-ttu-id="67ba7-255">At runtime, when the activity is executed, the Data Factory service automatically creates the Spark cluster for you.</span><span class="sxs-lookup"><span data-stu-id="67ba7-255">At runtime, when the activity is executed, the Data Factory service automatically creates the Spark cluster for you.</span></span> <span data-ttu-id="67ba7-256">For more information, see the following articles:</span><span class="sxs-lookup"><span data-stu-id="67ba7-256">For more information, see the following articles:</span></span>

- [<span data-ttu-id="67ba7-257">Spark Activity in the current version of Data Factory</span><span class="sxs-lookup"><span data-stu-id="67ba7-257">Spark Activity in the current version of Data Factory</span></span>](transform-data-using-spark.md)
- [<span data-ttu-id="67ba7-258">Azure HDInsight on-demand linked service</span><span class="sxs-lookup"><span data-stu-id="67ba7-258">Azure HDInsight on-demand linked service</span></span>](compute-linked-services.md#azure-hdinsight-on-demand-linked-service)

## <a name="custom-activities"></a><span data-ttu-id="67ba7-259">Custom activities</span><span class="sxs-lookup"><span data-stu-id="67ba7-259">Custom activities</span></span>
<span data-ttu-id="67ba7-260">In V1, you implement (custom) DotNet activity code by creating a .NET class library project with a class that implements the Execute method of the IDotNetActivity interface.</span><span class="sxs-lookup"><span data-stu-id="67ba7-260">In V1, you implement (custom) DotNet activity code by creating a .NET class library project with a class that implements the Execute method of the IDotNetActivity interface.</span></span> <span data-ttu-id="67ba7-261">Therefore, you need to write your custom code in .NET Framework 4.5.2 and run it on Windows-based Azure Batch Pool nodes.</span><span class="sxs-lookup"><span data-stu-id="67ba7-261">Therefore, you need to write your custom code in .NET Framework 4.5.2 and run it on Windows-based Azure Batch Pool nodes.</span></span> 

<span data-ttu-id="67ba7-262">In a custom activity in the current version, you don't have to implement a .NET interface.</span><span class="sxs-lookup"><span data-stu-id="67ba7-262">In a custom activity in the current version, you don't have to implement a .NET interface.</span></span> <span data-ttu-id="67ba7-263">You can directly run commands, scripts, and your own custom code compiled as an executable.</span><span class="sxs-lookup"><span data-stu-id="67ba7-263">You can directly run commands, scripts, and your own custom code compiled as an executable.</span></span> 

<span data-ttu-id="67ba7-264">For more information, see [Difference between custom activity in Data Factory and version 1](transform-data-using-dotnet-custom-activity.md#compare-v2-v1).</span><span class="sxs-lookup"><span data-stu-id="67ba7-264">For more information, see [Difference between custom activity in Data Factory and version 1](transform-data-using-dotnet-custom-activity.md#compare-v2-v1).</span></span>

## <a name="sdks"></a><span data-ttu-id="67ba7-265">SDKs</span><span class="sxs-lookup"><span data-stu-id="67ba7-265">SDKs</span></span>
 <span data-ttu-id="67ba7-266">the current version of Data Factory provides a richer set of SDKs that can be used to author, manage, and monitor pipelines.</span><span class="sxs-lookup"><span data-stu-id="67ba7-266">the current version of Data Factory provides a richer set of SDKs that can be used to author, manage, and monitor pipelines.</span></span>

- <span data-ttu-id="67ba7-267">**.NET SDK**: The .NET SDK is updated in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-267">**.NET SDK**: The .NET SDK is updated in the current version.</span></span>

- <span data-ttu-id="67ba7-268">**PowerShell**: The PowerShell cmdlets are updated in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-268">**PowerShell**: The PowerShell cmdlets are updated in the current version.</span></span> <span data-ttu-id="67ba7-269">The cmdlets for the current version have **DataFactoryV2** in the name, for example: Get-AzureRmDataFactoryV2.</span><span class="sxs-lookup"><span data-stu-id="67ba7-269">The cmdlets for the current version have **DataFactoryV2** in the name, for example: Get-AzureRmDataFactoryV2.</span></span> 

- <span data-ttu-id="67ba7-270">**Python SDK**: This SDK is new in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-270">**Python SDK**: This SDK is new in the current version.</span></span>

- <span data-ttu-id="67ba7-271">**REST API**: The REST API is updated in the current version.</span><span class="sxs-lookup"><span data-stu-id="67ba7-271">**REST API**: The REST API is updated in the current version.</span></span> 

<span data-ttu-id="67ba7-272">The SDKs that are updated in the current version are not backward-compatible with V1 clients.</span><span class="sxs-lookup"><span data-stu-id="67ba7-272">The SDKs that are updated in the current version are not backward-compatible with V1 clients.</span></span> 

## <a name="authoring-experience"></a><span data-ttu-id="67ba7-273">Authoring experience</span><span class="sxs-lookup"><span data-stu-id="67ba7-273">Authoring experience</span></span>

| &nbsp; | <span data-ttu-id="67ba7-274">V2</span><span class="sxs-lookup"><span data-stu-id="67ba7-274">V2</span></span> | <span data-ttu-id="67ba7-275">V1</span><span class="sxs-lookup"><span data-stu-id="67ba7-275">V1</span></span> |
| ------ | -- | -- | 
| <span data-ttu-id="67ba7-276">Azure portal</span><span class="sxs-lookup"><span data-stu-id="67ba7-276">Azure portal</span></span> | [<span data-ttu-id="67ba7-277">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-277">Yes</span></span>](quickstart-create-data-factory-portal.md) | [<span data-ttu-id="67ba7-278">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-278">Yes</span></span>](data-factory-build-your-first-pipeline-using-editor.md) |
| <span data-ttu-id="67ba7-279">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="67ba7-279">Azure PowerShell</span></span> | [<span data-ttu-id="67ba7-280">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-280">Yes</span></span>](quickstart-create-data-factory-powershell.md) | [<span data-ttu-id="67ba7-281">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-281">Yes</span></span>](data-factory-build-your-first-pipeline-using-powershell.md) |
| <span data-ttu-id="67ba7-282">.NET SDK</span><span class="sxs-lookup"><span data-stu-id="67ba7-282">.NET SDK</span></span> | [<span data-ttu-id="67ba7-283">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-283">Yes</span></span>](quickstart-create-data-factory-dot-net.md) | [<span data-ttu-id="67ba7-284">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-284">Yes</span></span>](data-factory-build-your-first-pipeline-using-vs.md) |
| <span data-ttu-id="67ba7-285">REST API</span><span class="sxs-lookup"><span data-stu-id="67ba7-285">REST API</span></span> | [<span data-ttu-id="67ba7-286">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-286">Yes</span></span>](quickstart-create-data-factory-rest-api.md) | [<span data-ttu-id="67ba7-287">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-287">Yes</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md) |
| <span data-ttu-id="67ba7-288">Python SDK</span><span class="sxs-lookup"><span data-stu-id="67ba7-288">Python SDK</span></span> | [<span data-ttu-id="67ba7-289">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-289">Yes</span></span>](quickstart-create-data-factory-python.md) | <span data-ttu-id="67ba7-290">No</span><span class="sxs-lookup"><span data-stu-id="67ba7-290">No</span></span> |
| <span data-ttu-id="67ba7-291">Resource Manager template</span><span class="sxs-lookup"><span data-stu-id="67ba7-291">Resource Manager template</span></span> | [<span data-ttu-id="67ba7-292">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-292">Yes</span></span>](quickstart-create-data-factory-resource-manager-template.md) | [<span data-ttu-id="67ba7-293">Yes</span><span class="sxs-lookup"><span data-stu-id="67ba7-293">Yes</span></span>](data-factory-build-your-first-pipeline-using-arm.md) | 

## <a name="roles-and-permissions"></a><span data-ttu-id="67ba7-294">Roles and permissions</span><span class="sxs-lookup"><span data-stu-id="67ba7-294">Roles and permissions</span></span>

<span data-ttu-id="67ba7-295">The Data Factory version 1 Contributor role can be used to create and manage the current version of Data Factory resources.</span><span class="sxs-lookup"><span data-stu-id="67ba7-295">The Data Factory version 1 Contributor role can be used to create and manage the current version of Data Factory resources.</span></span> <span data-ttu-id="67ba7-296">For more info, see [Data Factory Contributor](../role-based-access-control/built-in-roles.md#data-factory-contributor).</span><span class="sxs-lookup"><span data-stu-id="67ba7-296">For more info, see [Data Factory Contributor](../role-based-access-control/built-in-roles.md#data-factory-contributor).</span></span>

## <a name="monitoring-experience"></a><span data-ttu-id="67ba7-297">Monitoring experience</span><span class="sxs-lookup"><span data-stu-id="67ba7-297">Monitoring experience</span></span>
<span data-ttu-id="67ba7-298">in the current version, you can also monitor data factories by using [Azure Monitor](monitor-using-azure-monitor.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-298">in the current version, you can also monitor data factories by using [Azure Monitor](monitor-using-azure-monitor.md).</span></span> <span data-ttu-id="67ba7-299">The new PowerShell cmdlets support monitoring of [integration runtimes](monitor-integration-runtime.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-299">The new PowerShell cmdlets support monitoring of [integration runtimes](monitor-integration-runtime.md).</span></span> <span data-ttu-id="67ba7-300">Both V1 and V2 support visual monitoring via a monitoring application that can be launched from the Azure portal.</span><span class="sxs-lookup"><span data-stu-id="67ba7-300">Both V1 and V2 support visual monitoring via a monitoring application that can be launched from the Azure portal.</span></span>


## <a name="next-steps"></a><span data-ttu-id="67ba7-301">Next steps</span><span class="sxs-lookup"><span data-stu-id="67ba7-301">Next steps</span></span>
<span data-ttu-id="67ba7-302">Learn how to create a data factory by following step-by-step instructions in the following quickstarts: [PowerShell](quickstart-create-data-factory-powershell.md), [.NET](quickstart-create-data-factory-dot-net.md), [Python](quickstart-create-data-factory-python.md), [REST API](quickstart-create-data-factory-rest-api.md).</span><span class="sxs-lookup"><span data-stu-id="67ba7-302">Learn how to create a data factory by following step-by-step instructions in the following quickstarts: [PowerShell](quickstart-create-data-factory-powershell.md), [.NET](quickstart-create-data-factory-dot-net.md), [Python](quickstart-create-data-factory-python.md), [REST API](quickstart-create-data-factory-rest-api.md).</span></span> 
