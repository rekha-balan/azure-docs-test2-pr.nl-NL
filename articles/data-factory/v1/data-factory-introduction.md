---
title: Introduction to Data Factory, a data integration service | Microsoft Docs
description: 'Learn what Azure Data Factory is: A cloud data integration service that orchestrates and automates movement and transformation of data.'
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: overview
ms.date: 01/22/2018
ms.author: shlo
robots: noindex
ms.openlocfilehash: 0cdf10f4898ba103f9b6f65179300a10c9e33cdf
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44966472"
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="b8940-103">Introduction to Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="b8940-103">Introduction to Azure Data Factory</span></span> 
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Version 1](data-factory-introduction.md)
> * [Version 2 (current version)](../introduction.md)

> [!NOTE]
> This article applies to version 1 of Azure Data Factory. If you are using the current version of the Data Factory service, see [Introduction to Data Factory V2](../introduction.md).


## <a name="what-is-azure-data-factory"></a><span data-ttu-id="b8940-108">What is Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="b8940-108">What is Azure Data Factory?</span></span>
<span data-ttu-id="b8940-109">In the world of big data, how is existing data leveraged in business?</span><span class="sxs-lookup"><span data-stu-id="b8940-109">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="b8940-110">Is it possible to enrich data that's generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span><span class="sxs-lookup"><span data-stu-id="b8940-110">Is it possible to enrich data that's generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> 

<span data-ttu-id="b8940-111">For example, a gaming company collects logs that are produced by games in the cloud.</span><span class="sxs-lookup"><span data-stu-id="b8940-111">For example, a gaming company collects logs that are produced by games in the cloud.</span></span> <span data-ttu-id="b8940-112">It wants to analyze these logs to gain insights into customer preferences, demographics, usage behavior, and so on.</span><span class="sxs-lookup"><span data-stu-id="b8940-112">It wants to analyze these logs to gain insights into customer preferences, demographics, usage behavior, and so on.</span></span> <span data-ttu-id="b8940-113">The company also wants to identify up-sell and cross-sell opportunities, develop compelling new features to drive business growth, and provide a better experience to customers.</span><span class="sxs-lookup"><span data-stu-id="b8940-113">The company also wants to identify up-sell and cross-sell opportunities, develop compelling new features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="b8940-114">To analyze these logs, the company needs to use the reference data such as customer information, game information, and marketing campaign information that is in an on-premises data store.</span><span class="sxs-lookup"><span data-stu-id="b8940-114">To analyze these logs, the company needs to use the reference data such as customer information, game information, and marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="b8940-115">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span><span class="sxs-lookup"><span data-stu-id="b8940-115">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> 

<span data-ttu-id="b8940-116">Next they want to process the data by using Hadoop in the cloud (Azure HDInsight).</span><span class="sxs-lookup"><span data-stu-id="b8940-116">Next they want to process the data by using Hadoop in the cloud (Azure HDInsight).</span></span> <span data-ttu-id="b8940-117">They want to publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span><span class="sxs-lookup"><span data-stu-id="b8940-117">They want to publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="b8940-118">The company wants this workflow to run once a week.</span><span class="sxs-lookup"><span data-stu-id="b8940-118">The company wants this workflow to run once a week.</span></span> 

<span data-ttu-id="b8940-119">The company needs a platform where they can create a workflow that can ingest data from both on-premises and cloud data stores.</span><span class="sxs-lookup"><span data-stu-id="b8940-119">The company needs a platform where they can create a workflow that can ingest data from both on-premises and cloud data stores.</span></span> <span data-ttu-id="b8940-120">The company also needs to be able to transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span><span class="sxs-lookup"><span data-stu-id="b8940-120">The company also needs to be able to transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Data Factory overview](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="b8940-122">Azure Data Factory is the platform for these kinds of scenarios.</span><span class="sxs-lookup"><span data-stu-id="b8940-122">Azure Data Factory is the platform for these kinds of scenarios.</span></span> <span data-ttu-id="b8940-123">It is a *cloud-based data integration service that allows you to create data-driven workflows in the cloud that orchestrate and automate data movement and data transformation*.</span><span class="sxs-lookup"><span data-stu-id="b8940-123">It is a *cloud-based data integration service that allows you to create data-driven workflows in the cloud that orchestrate and automate data movement and data transformation*.</span></span> <span data-ttu-id="b8940-124">Using Azure Data Factory, you can do the following tasks:</span><span class="sxs-lookup"><span data-stu-id="b8940-124">Using Azure Data Factory, you can do the following tasks:</span></span> 

- <span data-ttu-id="b8940-125">Create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores.</span><span class="sxs-lookup"><span data-stu-id="b8940-125">Create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores.</span></span>

- <span data-ttu-id="b8940-126">Process or transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="b8940-126">Process or transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning.</span></span>

-  <span data-ttu-id="b8940-127">Publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span><span class="sxs-lookup"><span data-stu-id="b8940-127">Publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="b8940-128">It's more of an Extract-and-Load (EL) and Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span><span class="sxs-lookup"><span data-stu-id="b8940-128">It's more of an Extract-and-Load (EL) and Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="b8940-129">The transformations process data by using compute services rather than by adding derived columns, counting the number of rows, sorting data, and so on.</span><span class="sxs-lookup"><span data-stu-id="b8940-129">The transformations process data by using compute services rather than by adding derived columns, counting the number of rows, sorting data, and so on.</span></span> 

<span data-ttu-id="b8940-130">Currently, in Azure Data Factory, the data that workflows consume and produce is *time-sliced data* (hourly, daily, weekly, and so on).</span><span class="sxs-lookup"><span data-stu-id="b8940-130">Currently, in Azure Data Factory, the data that workflows consume and produce is *time-sliced data* (hourly, daily, weekly, and so on).</span></span> <span data-ttu-id="b8940-131">For example, a pipeline might read input data, process data, and produce output data once a day.</span><span class="sxs-lookup"><span data-stu-id="b8940-131">For example, a pipeline might read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="b8940-132">You can also run a workflow just one time.</span><span class="sxs-lookup"><span data-stu-id="b8940-132">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="b8940-133">How does it work?</span><span class="sxs-lookup"><span data-stu-id="b8940-133">How does it work?</span></span> 
<span data-ttu-id="b8940-134">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span><span class="sxs-lookup"><span data-stu-id="b8940-134">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Three stages of Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="b8940-136">Connect and collect</span><span class="sxs-lookup"><span data-stu-id="b8940-136">Connect and collect</span></span>
<span data-ttu-id="b8940-137">Enterprises have data of various types that are located in disparate sources.</span><span class="sxs-lookup"><span data-stu-id="b8940-137">Enterprises have data of various types that are located in disparate sources.</span></span> <span data-ttu-id="b8940-138">The first step in building an information production system is to connect to all the required sources of data and processing.</span><span class="sxs-lookup"><span data-stu-id="b8940-138">The first step in building an information production system is to connect to all the required sources of data and processing.</span></span> <span data-ttu-id="b8940-139">These sources include SaaS services, file shares, FTP, and web services.</span><span class="sxs-lookup"><span data-stu-id="b8940-139">These sources include SaaS services, file shares, FTP, and web services.</span></span> <span data-ttu-id="b8940-140">Then move the data as-needed to a centralized location for subsequent processing.</span><span class="sxs-lookup"><span data-stu-id="b8940-140">Then move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="b8940-141">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span><span class="sxs-lookup"><span data-stu-id="b8940-141">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="b8940-142">It is expensive and hard to integrate and maintain such systems.</span><span class="sxs-lookup"><span data-stu-id="b8940-142">It is expensive and hard to integrate and maintain such systems.</span></span> <span data-ttu-id="b8940-143">These systems also often lack the enterprise grade monitoring, alerting, and controls that a fully managed service can offer.</span><span class="sxs-lookup"><span data-stu-id="b8940-143">These systems also often lack the enterprise grade monitoring, alerting, and controls that a fully managed service can offer.</span></span>

<span data-ttu-id="b8940-144">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span><span class="sxs-lookup"><span data-stu-id="b8940-144">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> 

<span data-ttu-id="b8940-145">For example, you can collect data in Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span><span class="sxs-lookup"><span data-stu-id="b8940-145">For example, you can collect data in Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="b8940-146">Or, collect data in Azure blob storage and transform it later by using an Azure HDInsight Hadoop cluster.</span><span class="sxs-lookup"><span data-stu-id="b8940-146">Or, collect data in Azure blob storage and transform it later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="b8940-147">Transform and enrich</span><span class="sxs-lookup"><span data-stu-id="b8940-147">Transform and enrich</span></span>
<span data-ttu-id="b8940-148">After data is present in a centralized data store in the cloud, process or transfer it by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, or Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="b8940-148">After data is present in a centralized data store in the cloud, process or transfer it by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, or Machine Learning.</span></span> <span data-ttu-id="b8940-149">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span><span class="sxs-lookup"><span data-stu-id="b8940-149">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="b8940-150">Publish</span><span class="sxs-lookup"><span data-stu-id="b8940-150">Publish</span></span> 
<span data-ttu-id="b8940-151">Deliver transformed data from the cloud to on-premises sources such as SQL Server.</span><span class="sxs-lookup"><span data-stu-id="b8940-151">Deliver transformed data from the cloud to on-premises sources such as SQL Server.</span></span> <span data-ttu-id="b8940-152">Alternatively,  keep it in your cloud storage sources for consumption by BI and analytics tools and other applications.</span><span class="sxs-lookup"><span data-stu-id="b8940-152">Alternatively,  keep it in your cloud storage sources for consumption by BI and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="b8940-153">Key components</span><span class="sxs-lookup"><span data-stu-id="b8940-153">Key components</span></span>
<span data-ttu-id="b8940-154">An Azure subscription can have one or more Azure Data Factory instances (or data factories).</span><span class="sxs-lookup"><span data-stu-id="b8940-154">An Azure subscription can have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="b8940-155">Azure Data Factory is composed of four key components.</span><span class="sxs-lookup"><span data-stu-id="b8940-155">Azure Data Factory is composed of four key components.</span></span> <span data-ttu-id="b8940-156">These components work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span><span class="sxs-lookup"><span data-stu-id="b8940-156">These components work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="b8940-157">Pipeline</span><span class="sxs-lookup"><span data-stu-id="b8940-157">Pipeline</span></span>
<span data-ttu-id="b8940-158">A data factory can have one or more pipelines.</span><span class="sxs-lookup"><span data-stu-id="b8940-158">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="b8940-159">A pipeline is a group of activities.</span><span class="sxs-lookup"><span data-stu-id="b8940-159">A pipeline is a group of activities.</span></span> <span data-ttu-id="b8940-160">Together, the activities in a pipeline perform a task.</span><span class="sxs-lookup"><span data-stu-id="b8940-160">Together, the activities in a pipeline perform a task.</span></span> 

<span data-ttu-id="b8940-161">For example, a pipeline can contain a group of activities that ingests data from an Azure blob, and then runs a Hive query on an HDInsight cluster to partition the data.</span><span class="sxs-lookup"><span data-stu-id="b8940-161">For example, a pipeline can contain a group of activities that ingests data from an Azure blob, and then runs a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="b8940-162">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span><span class="sxs-lookup"><span data-stu-id="b8940-162">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="b8940-163">For example, you can deploy and schedule the pipeline, instead of scheduling independent activities.</span><span class="sxs-lookup"><span data-stu-id="b8940-163">For example, you can deploy and schedule the pipeline, instead of scheduling independent activities.</span></span> 

### <a name="activity"></a><span data-ttu-id="b8940-164">Activity</span><span class="sxs-lookup"><span data-stu-id="b8940-164">Activity</span></span>
<span data-ttu-id="b8940-165">A pipeline can have one or more activities.</span><span class="sxs-lookup"><span data-stu-id="b8940-165">A pipeline can have one or more activities.</span></span> <span data-ttu-id="b8940-166">Activities define the actions to perform on your data.</span><span class="sxs-lookup"><span data-stu-id="b8940-166">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="b8940-167">For example, you can use a copy activity to copy data from one data store to another data store.</span><span class="sxs-lookup"><span data-stu-id="b8940-167">For example, you can use a copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="b8940-168">Similarly, you can use a Hive activity.</span><span class="sxs-lookup"><span data-stu-id="b8940-168">Similarly, you can use a Hive activity.</span></span> <span data-ttu-id="b8940-169">A Hive activity runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span><span class="sxs-lookup"><span data-stu-id="b8940-169">A Hive activity runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="b8940-170">Data Factory supports two types of activities: data movement activities and data transformation activities.</span><span class="sxs-lookup"><span data-stu-id="b8940-170">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="b8940-171">Data movement activities</span><span class="sxs-lookup"><span data-stu-id="b8940-171">Data movement activities</span></span>
<span data-ttu-id="b8940-172">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span><span class="sxs-lookup"><span data-stu-id="b8940-172">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="b8940-173">Data from any source can be written to any sink.</span><span class="sxs-lookup"><span data-stu-id="b8940-173">Data from any source can be written to any sink.</span></span> <span data-ttu-id="b8940-174">Select a data store to learn how to copy data to and from that store.</span><span class="sxs-lookup"><span data-stu-id="b8940-174">Select a data store to learn how to copy data to and from that store.</span></span> <span data-ttu-id="b8940-175">Data Factory supports the following data stores:</span><span class="sxs-lookup"><span data-stu-id="b8940-175">Data Factory supports the following data stores:</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="b8940-176">For more information, see [Move data by using Copy Activity](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="b8940-176">For more information, see [Move data by using Copy Activity](data-factory-data-movement-activities.md).</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="b8940-177">Data transformation activities</span><span class="sxs-lookup"><span data-stu-id="b8940-177">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="b8940-178">For more information, see [Move data by using Copy Activity](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="b8940-178">For more information, see [Move data by using Copy Activity](data-factory-data-transformation-activities.md).</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="b8940-179">Custom .NET activities</span><span class="sxs-lookup"><span data-stu-id="b8940-179">Custom .NET activities</span></span>
<span data-ttu-id="b8940-180">Create a custom .NET activity if you need to move data to or from a data store that Copy Activity doesn't support or if you need to transform data by using your own logic.</span><span class="sxs-lookup"><span data-stu-id="b8940-180">Create a custom .NET activity if you need to move data to or from a data store that Copy Activity doesn't support or if you need to transform data by using your own logic.</span></span> <span data-ttu-id="b8940-181">For details about how to create and use a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="b8940-181">For details about how to create and use a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="b8940-182">Datasets</span><span class="sxs-lookup"><span data-stu-id="b8940-182">Datasets</span></span>
<span data-ttu-id="b8940-183">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span><span class="sxs-lookup"><span data-stu-id="b8940-183">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="b8940-184">Datasets represent data structures within the data stores.</span><span class="sxs-lookup"><span data-stu-id="b8940-184">Datasets represent data structures within the data stores.</span></span> <span data-ttu-id="b8940-185">These structures point to or reference the data you want to use in your activities (such as inputs or outputs).</span><span class="sxs-lookup"><span data-stu-id="b8940-185">These structures point to or reference the data you want to use in your activities (such as inputs or outputs).</span></span> 

<span data-ttu-id="b8940-186">For example, an Azure blob dataset specifies the blob container and folder in the Azure blob storage from which the pipeline should read the data.</span><span class="sxs-lookup"><span data-stu-id="b8940-186">For example, an Azure blob dataset specifies the blob container and folder in the Azure blob storage from which the pipeline should read the data.</span></span> <span data-ttu-id="b8940-187">Or an Azure SQL table dataset specifies the table to which the output data is written by the activity.</span><span class="sxs-lookup"><span data-stu-id="b8940-187">Or an Azure SQL table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="b8940-188">Linked services</span><span class="sxs-lookup"><span data-stu-id="b8940-188">Linked services</span></span>
<span data-ttu-id="b8940-189">Linked services are much like connection strings, which define the connection information that's needed for Data Factory to connect to external resources.</span><span class="sxs-lookup"><span data-stu-id="b8940-189">Linked services are much like connection strings, which define the connection information that's needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="b8940-190">Think of it this way: a linked service defines the connection to the data source and a dataset represents the structure of the data.</span><span class="sxs-lookup"><span data-stu-id="b8940-190">Think of it this way: a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> 

<span data-ttu-id="b8940-191">For example, an Azure Storage-linked service specifies a connection string with which to connect to the Azure Storage account.</span><span class="sxs-lookup"><span data-stu-id="b8940-191">For example, an Azure Storage-linked service specifies a connection string with which to connect to the Azure Storage account.</span></span> <span data-ttu-id="b8940-192">An Azure blob dataset specifies the blob container and the folder that contains the data.</span><span class="sxs-lookup"><span data-stu-id="b8940-192">An Azure blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="b8940-193">Linked services are used for two reasons in Data Factory:</span><span class="sxs-lookup"><span data-stu-id="b8940-193">Linked services are used for two reasons in Data Factory:</span></span>

* <span data-ttu-id="b8940-194">To represent a *data store* that includes, but isn't limited to, an on-premises SQL Server database, Oracle database, file share, or Azure blob storage account.</span><span class="sxs-lookup"><span data-stu-id="b8940-194">To represent a *data store* that includes, but isn't limited to, an on-premises SQL Server database, Oracle database, file share, or Azure blob storage account.</span></span> <span data-ttu-id="b8940-195">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span><span class="sxs-lookup"><span data-stu-id="b8940-195">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>

* <span data-ttu-id="b8940-196">To represent a *compute resource* that can host the execution of an activity.</span><span class="sxs-lookup"><span data-stu-id="b8940-196">To represent a *compute resource* that can host the execution of an activity.</span></span> <span data-ttu-id="b8940-197">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span><span class="sxs-lookup"><span data-stu-id="b8940-197">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="b8940-198">See the [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span><span class="sxs-lookup"><span data-stu-id="b8940-198">See the [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="b8940-199">Relationship between Data Factory entities</span><span class="sxs-lookup"><span data-stu-id="b8940-199">Relationship between Data Factory entities</span></span>

![Diagram: Data Factory, a cloud data integration service - key concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)

## <a name="supported-regions"></a><span data-ttu-id="b8940-201">Supported regions</span><span class="sxs-lookup"><span data-stu-id="b8940-201">Supported regions</span></span>
<span data-ttu-id="b8940-202">Currently, you can create data factories in the West US, East US, and North Europe regions.</span><span class="sxs-lookup"><span data-stu-id="b8940-202">Currently, you can create data factories in the West US, East US, and North Europe regions.</span></span> <span data-ttu-id="b8940-203">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data by using compute services.</span><span class="sxs-lookup"><span data-stu-id="b8940-203">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data by using compute services.</span></span>

<span data-ttu-id="b8940-204">Azure Data Factory itself does not store any data.</span><span class="sxs-lookup"><span data-stu-id="b8940-204">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="b8940-205">It lets you create data-driven workflows to orchestrate the movement of data between [supported data stores](#data-movement-activities).</span><span class="sxs-lookup"><span data-stu-id="b8940-205">It lets you create data-driven workflows to orchestrate the movement of data between [supported data stores](#data-movement-activities).</span></span> <span data-ttu-id="b8940-206">It also lets you process data by using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span><span class="sxs-lookup"><span data-stu-id="b8940-206">It also lets you process data by using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="b8940-207">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) by using both programmatic and UI mechanisms.</span><span class="sxs-lookup"><span data-stu-id="b8940-207">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) by using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="b8940-208">Data Factory is available in only West US, East US, and North Europe regions.</span><span class="sxs-lookup"><span data-stu-id="b8940-208">Data Factory is available in only West US, East US, and North Europe regions.</span></span> <span data-ttu-id="b8940-209">However, the service that powers the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span><span class="sxs-lookup"><span data-stu-id="b8940-209">However, the service that powers the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="b8940-210">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) that's installed in your on-premises environment moves the data instead.</span><span class="sxs-lookup"><span data-stu-id="b8940-210">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) that's installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="b8940-211">For an example, let's assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are located in the West Europe region.</span><span class="sxs-lookup"><span data-stu-id="b8940-211">For an example, let's assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are located in the West Europe region.</span></span> <span data-ttu-id="b8940-212">You can create and use an Azure Data Factory instance in North Europe.</span><span class="sxs-lookup"><span data-stu-id="b8940-212">You can create and use an Azure Data Factory instance in North Europe.</span></span> <span data-ttu-id="b8940-213">Then you can use it to schedule jobs on your compute environments in West Europe.</span><span class="sxs-lookup"><span data-stu-id="b8940-213">Then you can use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="b8940-214">It takes a few milliseconds for Data Factory to trigger the job on your compute environment, but the time for running the job on your computing environment does not change.</span><span class="sxs-lookup"><span data-stu-id="b8940-214">It takes a few milliseconds for Data Factory to trigger the job on your compute environment, but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="b8940-215">Get started with creating a pipeline</span><span class="sxs-lookup"><span data-stu-id="b8940-215">Get started with creating a pipeline</span></span>
<span data-ttu-id="b8940-216">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="b8940-216">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="b8940-217">Azure portal</span><span class="sxs-lookup"><span data-stu-id="b8940-217">Azure portal</span></span>
- <span data-ttu-id="b8940-218">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="b8940-218">Visual Studio</span></span>
- <span data-ttu-id="b8940-219">PowerShell</span><span class="sxs-lookup"><span data-stu-id="b8940-219">PowerShell</span></span>
- <span data-ttu-id="b8940-220">.NET API</span><span class="sxs-lookup"><span data-stu-id="b8940-220">.NET API</span></span>
- <span data-ttu-id="b8940-221">REST API</span><span class="sxs-lookup"><span data-stu-id="b8940-221">REST API</span></span>
- <span data-ttu-id="b8940-222">Azure Resource Manager template</span><span class="sxs-lookup"><span data-stu-id="b8940-222">Azure Resource Manager template</span></span>

<span data-ttu-id="b8940-223">To learn how to build data factories with data pipelines, follow the step-by-step instructions in the following tutorials:</span><span class="sxs-lookup"><span data-stu-id="b8940-223">To learn how to build data factories with data pipelines, follow the step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="b8940-224">Tutorial</span><span class="sxs-lookup"><span data-stu-id="b8940-224">Tutorial</span></span> | <span data-ttu-id="b8940-225">Description</span><span class="sxs-lookup"><span data-stu-id="b8940-225">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="b8940-226">Move data between two cloud data stores</span><span class="sxs-lookup"><span data-stu-id="b8940-226">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="b8940-227">Create a data factory with a pipeline that moves data from blob storage to a SQL database.</span><span class="sxs-lookup"><span data-stu-id="b8940-227">Create a data factory with a pipeline that moves data from blob storage to a SQL database.</span></span> |
| [<span data-ttu-id="b8940-228">Transform data by using Hadoop cluster</span><span class="sxs-lookup"><span data-stu-id="b8940-228">Transform data by using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="b8940-229">Build your first Azure data factory with a data pipeline that processes data by running a Hive script on an Azure HDInsight (Hadoop) cluster.</span><span class="sxs-lookup"><span data-stu-id="b8940-229">Build your first Azure data factory with a data pipeline that processes data by running a Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="b8940-230">Move data between an on-premises data store and a cloud data store by using Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="b8940-230">Move data between an on-premises data store and a cloud data store by using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="b8940-231">Build a data factory with a pipeline that moves data from an on-premises SQL Server database to an Azure blob.</span><span class="sxs-lookup"><span data-stu-id="b8940-231">Build a data factory with a pipeline that moves data from an on-premises SQL Server database to an Azure blob.</span></span> <span data-ttu-id="b8940-232">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span><span class="sxs-lookup"><span data-stu-id="b8940-232">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
