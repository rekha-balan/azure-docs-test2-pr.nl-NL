---
title: Cluster Resource Manager Cluster Description | Microsoft Docs
description: Describing a Service Fabric cluster by specifying Fault Domains, Upgrade Domains, node properties, and node capacities for the Cluster Resource Manager.
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: ''
ms.assetid: 55f8ab37-9399-4c9a-9e6c-d2d859de6766
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: conceptual
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 8d594cf9af83b7557de39e64c1965239f000bbb6
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44783203"
---
# <a name="describing-a-service-fabric-cluster"></a><span data-ttu-id="11f13-103">Describing a service fabric cluster</span><span class="sxs-lookup"><span data-stu-id="11f13-103">Describing a service fabric cluster</span></span>
<span data-ttu-id="11f13-104">The Service Fabric Cluster Resource Manager provides several mechanisms for describing a cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-104">The Service Fabric Cluster Resource Manager provides several mechanisms for describing a cluster.</span></span> <span data-ttu-id="11f13-105">During runtime, the Cluster Resource Manager uses this information to ensure high availability of the services running in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-105">During runtime, the Cluster Resource Manager uses this information to ensure high availability of the services running in the cluster.</span></span> <span data-ttu-id="11f13-106">While enforcing these important rules, it also attempts to optimize the resource consumption within the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-106">While enforcing these important rules, it also attempts to optimize the resource consumption within the cluster.</span></span>

## <a name="key-concepts"></a><span data-ttu-id="11f13-107">Key concepts</span><span class="sxs-lookup"><span data-stu-id="11f13-107">Key concepts</span></span>
<span data-ttu-id="11f13-108">The Cluster Resource Manager supports several features that describe a cluster:</span><span class="sxs-lookup"><span data-stu-id="11f13-108">The Cluster Resource Manager supports several features that describe a cluster:</span></span>

* <span data-ttu-id="11f13-109">Fault Domains</span><span class="sxs-lookup"><span data-stu-id="11f13-109">Fault Domains</span></span>
* <span data-ttu-id="11f13-110">Upgrade Domains</span><span class="sxs-lookup"><span data-stu-id="11f13-110">Upgrade Domains</span></span>
* <span data-ttu-id="11f13-111">Node Properties</span><span class="sxs-lookup"><span data-stu-id="11f13-111">Node Properties</span></span>
* <span data-ttu-id="11f13-112">Node Capacities</span><span class="sxs-lookup"><span data-stu-id="11f13-112">Node Capacities</span></span>

## <a name="fault-domains"></a><span data-ttu-id="11f13-113">Fault domains</span><span class="sxs-lookup"><span data-stu-id="11f13-113">Fault domains</span></span>
<span data-ttu-id="11f13-114">A Fault Domain is any area of coordinated failure.</span><span class="sxs-lookup"><span data-stu-id="11f13-114">A Fault Domain is any area of coordinated failure.</span></span> <span data-ttu-id="11f13-115">A single machine is a Fault Domain (since it can fail on its own for various reasons, from power supply failures to drive failures to bad NIC firmware).</span><span class="sxs-lookup"><span data-stu-id="11f13-115">A single machine is a Fault Domain (since it can fail on its own for various reasons, from power supply failures to drive failures to bad NIC firmware).</span></span> <span data-ttu-id="11f13-116">Machines connected to the same Ethernet switch are in the same Fault Domain, as are machines sharing a single source of power or in a single location.</span><span class="sxs-lookup"><span data-stu-id="11f13-116">Machines connected to the same Ethernet switch are in the same Fault Domain, as are machines sharing a single source of power or in a single location.</span></span> <span data-ttu-id="11f13-117">Since it's natural for hardware faults to overlap, Fault Domains are inherently hierarchal and are represented as URIs in Service Fabric.</span><span class="sxs-lookup"><span data-stu-id="11f13-117">Since it's natural for hardware faults to overlap, Fault Domains are inherently hierarchal and are represented as URIs in Service Fabric.</span></span>

<span data-ttu-id="11f13-118">It is important that Fault Domains are set up correctly since Service Fabric uses this information to safely place services.</span><span class="sxs-lookup"><span data-stu-id="11f13-118">It is important that Fault Domains are set up correctly since Service Fabric uses this information to safely place services.</span></span> <span data-ttu-id="11f13-119">Service Fabric doesn't want to place services such that the loss of a Fault Domain (caused by the failure of some component) causes a service to go down.</span><span class="sxs-lookup"><span data-stu-id="11f13-119">Service Fabric doesn't want to place services such that the loss of a Fault Domain (caused by the failure of some component) causes a service to go down.</span></span> <span data-ttu-id="11f13-120">In the Azure environment Service Fabric uses the Fault Domain information provided by the environment to correctly configure the nodes in the cluster on your behalf.</span><span class="sxs-lookup"><span data-stu-id="11f13-120">In the Azure environment Service Fabric uses the Fault Domain information provided by the environment to correctly configure the nodes in the cluster on your behalf.</span></span> <span data-ttu-id="11f13-121">For Service Fabric Standalone, Fault Domains are defined at the time that the cluster is set up</span><span class="sxs-lookup"><span data-stu-id="11f13-121">For Service Fabric Standalone, Fault Domains are defined at the time that the cluster is set up</span></span> 

> [!WARNING]
> <span data-ttu-id="11f13-122">It is important that the Fault Domain information provided to Service Fabric is accurate.</span><span class="sxs-lookup"><span data-stu-id="11f13-122">It is important that the Fault Domain information provided to Service Fabric is accurate.</span></span> <span data-ttu-id="11f13-123">For example, let's say that your Service Fabric cluster's nodes are running inside 10 virtual machines, running on five physical hosts.</span><span class="sxs-lookup"><span data-stu-id="11f13-123">For example, let's say that your Service Fabric cluster's nodes are running inside 10 virtual machines, running on five physical hosts.</span></span> <span data-ttu-id="11f13-124">In this case, even though there are 10 virtual machines, there are only 5 different (top level) fault domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-124">In this case, even though there are 10 virtual machines, there are only 5 different (top level) fault domains.</span></span> <span data-ttu-id="11f13-125">Sharing the same physical host causes VMs to share the same root fault domain, since the VMs experience coordinated failure if their physical host fails.</span><span class="sxs-lookup"><span data-stu-id="11f13-125">Sharing the same physical host causes VMs to share the same root fault domain, since the VMs experience coordinated failure if their physical host fails.</span></span>  
>
> <span data-ttu-id="11f13-126">Service Fabric expects the Fault Domain of a node not to change.</span><span class="sxs-lookup"><span data-stu-id="11f13-126">Service Fabric expects the Fault Domain of a node not to change.</span></span> <span data-ttu-id="11f13-127">Other mechanisms of ensuring high availability of the VMs such as [HA-VMs](https://technet.microsoft.com/library/cc967323.aspx) may cause conflicts with Service Fabric, as they use transparent migration of VMs from one host to another.</span><span class="sxs-lookup"><span data-stu-id="11f13-127">Other mechanisms of ensuring high availability of the VMs such as [HA-VMs](https://technet.microsoft.com/library/cc967323.aspx) may cause conflicts with Service Fabric, as they use transparent migration of VMs from one host to another.</span></span> <span data-ttu-id="11f13-128">These mechanisms do not reconfigure or notify the running code inside the VM.</span><span class="sxs-lookup"><span data-stu-id="11f13-128">These mechanisms do not reconfigure or notify the running code inside the VM.</span></span> <span data-ttu-id="11f13-129">As such, they are **not supported** as environments for running Service Fabric clusters.</span><span class="sxs-lookup"><span data-stu-id="11f13-129">As such, they are **not supported** as environments for running Service Fabric clusters.</span></span> <span data-ttu-id="11f13-130">Service Fabric should be the only high-availability technology employed.</span><span class="sxs-lookup"><span data-stu-id="11f13-130">Service Fabric should be the only high-availability technology employed.</span></span> <span data-ttu-id="11f13-131">Mechanisms like live VM migration, SANs, or others are not necessary.</span><span class="sxs-lookup"><span data-stu-id="11f13-131">Mechanisms like live VM migration, SANs, or others are not necessary.</span></span> <span data-ttu-id="11f13-132">If used in conjunction with Service Fabric, these mechanisms _reduce_ application availability and reliability because they introduce additional complexity, add centralized sources of failure, and utilize reliability and availability strategies that conflict with those in Service Fabric.</span><span class="sxs-lookup"><span data-stu-id="11f13-132">If used in conjunction with Service Fabric, these mechanisms _reduce_ application availability and reliability because they introduce additional complexity, add centralized sources of failure, and utilize reliability and availability strategies that conflict with those in Service Fabric.</span></span> 
>
>

<span data-ttu-id="11f13-133">In the graphic below we color all the entities that contribute to Fault Domains and list all the different Fault Domains that result.</span><span class="sxs-lookup"><span data-stu-id="11f13-133">In the graphic below we color all the entities that contribute to Fault Domains and list all the different Fault Domains that result.</span></span> <span data-ttu-id="11f13-134">In this example, we have datacenters ("DC"), racks ("R"), and blades ("B").</span><span class="sxs-lookup"><span data-stu-id="11f13-134">In this example, we have datacenters ("DC"), racks ("R"), and blades ("B").</span></span> <span data-ttu-id="11f13-135">Conceivably, if each blade holds more than one virtual machine, there could be another layer in the Fault Domain hierarchy.</span><span class="sxs-lookup"><span data-stu-id="11f13-135">Conceivably, if each blade holds more than one virtual machine, there could be another layer in the Fault Domain hierarchy.</span></span>

<span data-ttu-id="11f13-136"><center>
![Nodes organized via Fault Domains][Image1]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-136"><center>
![Nodes organized via Fault Domains][Image1]
</center></span></span>

<span data-ttu-id="11f13-137">During runtime, the Service Fabric Cluster Resource Manager considers the Fault Domains in the cluster and plans layouts.</span><span class="sxs-lookup"><span data-stu-id="11f13-137">During runtime, the Service Fabric Cluster Resource Manager considers the Fault Domains in the cluster and plans layouts.</span></span> <span data-ttu-id="11f13-138">The stateful replicas or stateless instances for a given service are distributed so they are in separate Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-138">The stateful replicas or stateless instances for a given service are distributed so they are in separate Fault Domains.</span></span> <span data-ttu-id="11f13-139">Distributing the service across fault domains ensures the availability of the service is not compromised when a Fault Domain fails at any level of the hierarchy.</span><span class="sxs-lookup"><span data-stu-id="11f13-139">Distributing the service across fault domains ensures the availability of the service is not compromised when a Fault Domain fails at any level of the hierarchy.</span></span>

<span data-ttu-id="11f13-140">Service Fabric’s Cluster Resource Manager doesn’t care how many layers there are in the Fault Domain hierarchy.</span><span class="sxs-lookup"><span data-stu-id="11f13-140">Service Fabric’s Cluster Resource Manager doesn’t care how many layers there are in the Fault Domain hierarchy.</span></span> <span data-ttu-id="11f13-141">However, it tries to ensure that the loss of any one portion of the hierarchy doesn’t impact services running in it.</span><span class="sxs-lookup"><span data-stu-id="11f13-141">However, it tries to ensure that the loss of any one portion of the hierarchy doesn’t impact services running in it.</span></span> 

<span data-ttu-id="11f13-142">It is best if there are the same number of nodes at each level of depth in the Fault Domain hierarchy.</span><span class="sxs-lookup"><span data-stu-id="11f13-142">It is best if there are the same number of nodes at each level of depth in the Fault Domain hierarchy.</span></span> <span data-ttu-id="11f13-143">If the “tree” of Fault Domains is unbalanced in your cluster, it makes it harder for the Cluster Resource Manager to figure out the best allocation of services.</span><span class="sxs-lookup"><span data-stu-id="11f13-143">If the “tree” of Fault Domains is unbalanced in your cluster, it makes it harder for the Cluster Resource Manager to figure out the best allocation of services.</span></span> <span data-ttu-id="11f13-144">Imbalanced Fault Domains layouts mean that the loss of some domains impact the availability of services more than other domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-144">Imbalanced Fault Domains layouts mean that the loss of some domains impact the availability of services more than other domains.</span></span> <span data-ttu-id="11f13-145">As a result, the Cluster Resource Manager is torn between two goals: It wants to use the machines in that “heavy” domain by placing services on them, and it wants to place services in other domains so that the loss of a domain doesn’t cause problems.</span><span class="sxs-lookup"><span data-stu-id="11f13-145">As a result, the Cluster Resource Manager is torn between two goals: It wants to use the machines in that “heavy” domain by placing services on them, and it wants to place services in other domains so that the loss of a domain doesn’t cause problems.</span></span> 

<span data-ttu-id="11f13-146">What do imbalanced domains look like?</span><span class="sxs-lookup"><span data-stu-id="11f13-146">What do imbalanced domains look like?</span></span> <span data-ttu-id="11f13-147">In the diagram below, we show two different cluster layouts.</span><span class="sxs-lookup"><span data-stu-id="11f13-147">In the diagram below, we show two different cluster layouts.</span></span> <span data-ttu-id="11f13-148">In the first example, the nodes are distributed evenly across the Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-148">In the first example, the nodes are distributed evenly across the Fault Domains.</span></span> <span data-ttu-id="11f13-149">In the second example, one Fault Domain has many more nodes than the other Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-149">In the second example, one Fault Domain has many more nodes than the other Fault Domains.</span></span> 

<span data-ttu-id="11f13-150"><center>
![Two different cluster layouts][Image2]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-150"><center>
![Two different cluster layouts][Image2]
</center></span></span>

<span data-ttu-id="11f13-151">In Azure, the choice of which Fault Domain contains a node is managed for you.</span><span class="sxs-lookup"><span data-stu-id="11f13-151">In Azure, the choice of which Fault Domain contains a node is managed for you.</span></span> <span data-ttu-id="11f13-152">However, depending on the number of nodes that you provision you can still end up with Fault Domains with more nodes in them than others.</span><span class="sxs-lookup"><span data-stu-id="11f13-152">However, depending on the number of nodes that you provision you can still end up with Fault Domains with more nodes in them than others.</span></span> <span data-ttu-id="11f13-153">For example, say you have five Fault Domains in the cluster but provision seven nodes for a given NodeType.</span><span class="sxs-lookup"><span data-stu-id="11f13-153">For example, say you have five Fault Domains in the cluster but provision seven nodes for a given NodeType.</span></span> <span data-ttu-id="11f13-154">In this case, the first two Fault Domains end up with more nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-154">In this case, the first two Fault Domains end up with more nodes.</span></span> <span data-ttu-id="11f13-155">If you continue to deploy more NodeTypes with only a couple instances, the problem gets worse.</span><span class="sxs-lookup"><span data-stu-id="11f13-155">If you continue to deploy more NodeTypes with only a couple instances, the problem gets worse.</span></span> <span data-ttu-id="11f13-156">For this reason it's recommended that the number of nodes in each node type is a multiple of the number of Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-156">For this reason it's recommended that the number of nodes in each node type is a multiple of the number of Fault Domains.</span></span>

## <a name="upgrade-domains"></a><span data-ttu-id="11f13-157">Upgrade domains</span><span class="sxs-lookup"><span data-stu-id="11f13-157">Upgrade domains</span></span>
<span data-ttu-id="11f13-158">Upgrade Domains are another feature that helps the Service Fabric Cluster Resource Manager understand the layout of the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-158">Upgrade Domains are another feature that helps the Service Fabric Cluster Resource Manager understand the layout of the cluster.</span></span> <span data-ttu-id="11f13-159">Upgrade Domains define sets of nodes that are upgraded at the same time.</span><span class="sxs-lookup"><span data-stu-id="11f13-159">Upgrade Domains define sets of nodes that are upgraded at the same time.</span></span> <span data-ttu-id="11f13-160">Upgrade Domains help the Cluster Resource Manager understand and orchestrate management operations like upgrades.</span><span class="sxs-lookup"><span data-stu-id="11f13-160">Upgrade Domains help the Cluster Resource Manager understand and orchestrate management operations like upgrades.</span></span>

<span data-ttu-id="11f13-161">Upgrade Domains are a lot like Fault Domains, but with a couple key differences.</span><span class="sxs-lookup"><span data-stu-id="11f13-161">Upgrade Domains are a lot like Fault Domains, but with a couple key differences.</span></span> <span data-ttu-id="11f13-162">First, areas of coordinated hardware failures define Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-162">First, areas of coordinated hardware failures define Fault Domains.</span></span> <span data-ttu-id="11f13-163">Upgrade Domains, on the other hand, are defined by policy.</span><span class="sxs-lookup"><span data-stu-id="11f13-163">Upgrade Domains, on the other hand, are defined by policy.</span></span> <span data-ttu-id="11f13-164">You get to decide how many you want, rather than it being dictated by the environment.</span><span class="sxs-lookup"><span data-stu-id="11f13-164">You get to decide how many you want, rather than it being dictated by the environment.</span></span> <span data-ttu-id="11f13-165">You could have as many Upgrade Domains as you do nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-165">You could have as many Upgrade Domains as you do nodes.</span></span> <span data-ttu-id="11f13-166">Another difference between Fault Domains and Upgrade Domains is that Upgrade Domains are not hierarchical.</span><span class="sxs-lookup"><span data-stu-id="11f13-166">Another difference between Fault Domains and Upgrade Domains is that Upgrade Domains are not hierarchical.</span></span> <span data-ttu-id="11f13-167">Instead, they are more like a simple tag.</span><span class="sxs-lookup"><span data-stu-id="11f13-167">Instead, they are more like a simple tag.</span></span> 

<span data-ttu-id="11f13-168">The following diagram shows three Upgrade Domains are striped across three Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-168">The following diagram shows three Upgrade Domains are striped across three Fault Domains.</span></span> <span data-ttu-id="11f13-169">It also shows one possible placement for three different replicas of a stateful service, where each ends up in different Fault and Upgrade Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-169">It also shows one possible placement for three different replicas of a stateful service, where each ends up in different Fault and Upgrade Domains.</span></span> <span data-ttu-id="11f13-170">This placement allows the loss of a Fault Domain while in the middle of a service upgrade and still have one copy of the code and data.</span><span class="sxs-lookup"><span data-stu-id="11f13-170">This placement allows the loss of a Fault Domain while in the middle of a service upgrade and still have one copy of the code and data.</span></span>  

<span data-ttu-id="11f13-171"><center>
![Placement With Fault and Upgrade Domains][Image3]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-171"><center>
![Placement With Fault and Upgrade Domains][Image3]
</center></span></span>

<span data-ttu-id="11f13-172">There are pros and cons to having large numbers of Upgrade Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-172">There are pros and cons to having large numbers of Upgrade Domains.</span></span> <span data-ttu-id="11f13-173">More Upgrade Domains means each step of the upgrade is more granular and therefore affects a smaller number of nodes or services.</span><span class="sxs-lookup"><span data-stu-id="11f13-173">More Upgrade Domains means each step of the upgrade is more granular and therefore affects a smaller number of nodes or services.</span></span> <span data-ttu-id="11f13-174">As a result, fewer services have to move at a time, introducing less churn into the system.</span><span class="sxs-lookup"><span data-stu-id="11f13-174">As a result, fewer services have to move at a time, introducing less churn into the system.</span></span> <span data-ttu-id="11f13-175">This tends to improve reliability, since less of the service is impacted by any issue introduced during the upgrade.</span><span class="sxs-lookup"><span data-stu-id="11f13-175">This tends to improve reliability, since less of the service is impacted by any issue introduced during the upgrade.</span></span> <span data-ttu-id="11f13-176">More Upgrade Domains also means that you need less available buffer on other nodes to handle the impact of the upgrade.</span><span class="sxs-lookup"><span data-stu-id="11f13-176">More Upgrade Domains also means that you need less available buffer on other nodes to handle the impact of the upgrade.</span></span> <span data-ttu-id="11f13-177">For example, if you have five Upgrade Domains, the nodes in each are handling roughly 20% of your traffic.</span><span class="sxs-lookup"><span data-stu-id="11f13-177">For example, if you have five Upgrade Domains, the nodes in each are handling roughly 20% of your traffic.</span></span> <span data-ttu-id="11f13-178">If you need to take down that Upgrade Domain for an upgrade, that load usually needs to go somewhere.</span><span class="sxs-lookup"><span data-stu-id="11f13-178">If you need to take down that Upgrade Domain for an upgrade, that load usually needs to go somewhere.</span></span> <span data-ttu-id="11f13-179">Since you have four remaining Upgrade Domains, each must have room for about 5% of the total traffic.</span><span class="sxs-lookup"><span data-stu-id="11f13-179">Since you have four remaining Upgrade Domains, each must have room for about 5% of the total traffic.</span></span> <span data-ttu-id="11f13-180">More Upgrade Domains means you need less buffer on the nodes in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-180">More Upgrade Domains means you need less buffer on the nodes in the cluster.</span></span> <span data-ttu-id="11f13-181">For example, consider if you had 10 Upgrade Domains instead.</span><span class="sxs-lookup"><span data-stu-id="11f13-181">For example, consider if you had 10 Upgrade Domains instead.</span></span> <span data-ttu-id="11f13-182">In that case, each UD would only be handling about 10% of the total traffic.</span><span class="sxs-lookup"><span data-stu-id="11f13-182">In that case, each UD would only be handling about 10% of the total traffic.</span></span> <span data-ttu-id="11f13-183">When an upgrade steps through the cluster, each domain would only need to have room for about 1.1% of the total traffic.</span><span class="sxs-lookup"><span data-stu-id="11f13-183">When an upgrade steps through the cluster, each domain would only need to have room for about 1.1% of the total traffic.</span></span> <span data-ttu-id="11f13-184">More Upgrade Domains generally allow you to run your nodes at higher utilization, since you need less reserved capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-184">More Upgrade Domains generally allow you to run your nodes at higher utilization, since you need less reserved capacity.</span></span> <span data-ttu-id="11f13-185">The same is true for Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-185">The same is true for Fault Domains.</span></span>  

<span data-ttu-id="11f13-186">The downside of having many Upgrade Domains is that upgrades tend to take longer.</span><span class="sxs-lookup"><span data-stu-id="11f13-186">The downside of having many Upgrade Domains is that upgrades tend to take longer.</span></span> <span data-ttu-id="11f13-187">Service Fabric waits a short period of time after an Upgrade Domain is completed and performs checks before starting to upgrade the next one.</span><span class="sxs-lookup"><span data-stu-id="11f13-187">Service Fabric waits a short period of time after an Upgrade Domain is completed and performs checks before starting to upgrade the next one.</span></span> <span data-ttu-id="11f13-188">These delays enable detecting issues introduced by the upgrade before the upgrade proceeds.</span><span class="sxs-lookup"><span data-stu-id="11f13-188">These delays enable detecting issues introduced by the upgrade before the upgrade proceeds.</span></span> <span data-ttu-id="11f13-189">The tradeoff is acceptable because it prevents bad changes from affecting too much of the service at a time.</span><span class="sxs-lookup"><span data-stu-id="11f13-189">The tradeoff is acceptable because it prevents bad changes from affecting too much of the service at a time.</span></span>

<span data-ttu-id="11f13-190">Too few Upgrade Domains has many negative side effects – while each individual Upgrade Domain is down and being upgraded a large portion of your overall capacity is unavailable.</span><span class="sxs-lookup"><span data-stu-id="11f13-190">Too few Upgrade Domains has many negative side effects – while each individual Upgrade Domain is down and being upgraded a large portion of your overall capacity is unavailable.</span></span> <span data-ttu-id="11f13-191">For example, if you only have three Upgrade Domains you are taking down about 1/3 of your overall service or cluster capacity at a time.</span><span class="sxs-lookup"><span data-stu-id="11f13-191">For example, if you only have three Upgrade Domains you are taking down about 1/3 of your overall service or cluster capacity at a time.</span></span> <span data-ttu-id="11f13-192">Having so much of your service down at once isn’t desirable since you have to have enough capacity in the rest of your cluster to handle the workload.</span><span class="sxs-lookup"><span data-stu-id="11f13-192">Having so much of your service down at once isn’t desirable since you have to have enough capacity in the rest of your cluster to handle the workload.</span></span> <span data-ttu-id="11f13-193">Maintaining that buffer means that during normal operation those nodes are less loaded than they would be otherwise.</span><span class="sxs-lookup"><span data-stu-id="11f13-193">Maintaining that buffer means that during normal operation those nodes are less loaded than they would be otherwise.</span></span> <span data-ttu-id="11f13-194">This increases the cost of running your service.</span><span class="sxs-lookup"><span data-stu-id="11f13-194">This increases the cost of running your service.</span></span>

<span data-ttu-id="11f13-195">There’s no real limit to the total number of fault or Upgrade Domains in an environment, or constraints on how they overlap.</span><span class="sxs-lookup"><span data-stu-id="11f13-195">There’s no real limit to the total number of fault or Upgrade Domains in an environment, or constraints on how they overlap.</span></span> <span data-ttu-id="11f13-196">That said, there are several common patterns:</span><span class="sxs-lookup"><span data-stu-id="11f13-196">That said, there are several common patterns:</span></span>

- <span data-ttu-id="11f13-197">Fault Domains and Upgrade Domains mapped 1:1</span><span class="sxs-lookup"><span data-stu-id="11f13-197">Fault Domains and Upgrade Domains mapped 1:1</span></span>
- <span data-ttu-id="11f13-198">One Upgrade Domain per Node (physical or virtual OS instance)</span><span class="sxs-lookup"><span data-stu-id="11f13-198">One Upgrade Domain per Node (physical or virtual OS instance)</span></span>
- <span data-ttu-id="11f13-199">A “striped” or “matrix” model where the Fault Domains and Upgrade Domains form a matrix with machines usually running down the diagonals</span><span class="sxs-lookup"><span data-stu-id="11f13-199">A “striped” or “matrix” model where the Fault Domains and Upgrade Domains form a matrix with machines usually running down the diagonals</span></span>

<span data-ttu-id="11f13-200"><center>
![Fault and Upgrade Domain Layouts][Image4]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-200"><center>
![Fault and Upgrade Domain Layouts][Image4]
</center></span></span>

<span data-ttu-id="11f13-201">There’s no best answer which layout to choose, each has some pros and cons.</span><span class="sxs-lookup"><span data-stu-id="11f13-201">There’s no best answer which layout to choose, each has some pros and cons.</span></span> <span data-ttu-id="11f13-202">For example, the 1FD:1UD model is simple to set up.</span><span class="sxs-lookup"><span data-stu-id="11f13-202">For example, the 1FD:1UD model is simple to set up.</span></span> <span data-ttu-id="11f13-203">The 1 Upgrade Domain per Node model is most like what people are used to.</span><span class="sxs-lookup"><span data-stu-id="11f13-203">The 1 Upgrade Domain per Node model is most like what people are used to.</span></span> <span data-ttu-id="11f13-204">During upgrades each node is updated independently.</span><span class="sxs-lookup"><span data-stu-id="11f13-204">During upgrades each node is updated independently.</span></span> <span data-ttu-id="11f13-205">This is similar to how small sets of machines were upgraded manually in the past.</span><span class="sxs-lookup"><span data-stu-id="11f13-205">This is similar to how small sets of machines were upgraded manually in the past.</span></span> 

<span data-ttu-id="11f13-206">The most common model is the FD/UD matrix, where the FDs and UDs form a table and nodes are placed starting along the diagonal.</span><span class="sxs-lookup"><span data-stu-id="11f13-206">The most common model is the FD/UD matrix, where the FDs and UDs form a table and nodes are placed starting along the diagonal.</span></span> <span data-ttu-id="11f13-207">This is the model used by default in Service Fabric clusters in Azure.</span><span class="sxs-lookup"><span data-stu-id="11f13-207">This is the model used by default in Service Fabric clusters in Azure.</span></span> <span data-ttu-id="11f13-208">For clusters with many nodes everything ends up looking like the dense matrix pattern above.</span><span class="sxs-lookup"><span data-stu-id="11f13-208">For clusters with many nodes everything ends up looking like the dense matrix pattern above.</span></span>

## <a name="fault-and-upgrade-domain-constraints-and-resulting-behavior"></a><span data-ttu-id="11f13-209">Fault and Upgrade Domain constraints and resulting behavior</span><span class="sxs-lookup"><span data-stu-id="11f13-209">Fault and Upgrade Domain constraints and resulting behavior</span></span>
### <a name="default-approach"></a><span data-ttu-id="11f13-210">*Default approach*</span><span class="sxs-lookup"><span data-stu-id="11f13-210">*Default approach*</span></span>
<span data-ttu-id="11f13-211">By default, the Cluster Resource Manager keeps services balanced across Fault and Upgrade Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-211">By default, the Cluster Resource Manager keeps services balanced across Fault and Upgrade Domains.</span></span> <span data-ttu-id="11f13-212">This is modeled as a [constraint](service-fabric-cluster-resource-manager-management-integration.md).</span><span class="sxs-lookup"><span data-stu-id="11f13-212">This is modeled as a [constraint](service-fabric-cluster-resource-manager-management-integration.md).</span></span> <span data-ttu-id="11f13-213">The Fault and Upgrade Domain constraint states: “For a given service partition, there should never be a difference greater than one in the number of service objects (stateless service instances or stateful service replicas) between any two domains on the same level of hierarchy”.</span><span class="sxs-lookup"><span data-stu-id="11f13-213">The Fault and Upgrade Domain constraint states: “For a given service partition, there should never be a difference greater than one in the number of service objects (stateless service instances or stateful service replicas) between any two domains on the same level of hierarchy”.</span></span> <span data-ttu-id="11f13-214">Let’s say this constraint provides a “maximum difference” guarantee.</span><span class="sxs-lookup"><span data-stu-id="11f13-214">Let’s say this constraint provides a “maximum difference” guarantee.</span></span> <span data-ttu-id="11f13-215">The Fault and Upgrade Domain constraint prevents certain moves or arrangements that violate the rule stated above.</span><span class="sxs-lookup"><span data-stu-id="11f13-215">The Fault and Upgrade Domain constraint prevents certain moves or arrangements that violate the rule stated above.</span></span> 

<span data-ttu-id="11f13-216">Let's look at one example.</span><span class="sxs-lookup"><span data-stu-id="11f13-216">Let's look at one example.</span></span> <span data-ttu-id="11f13-217">Let's say that we have a cluster with six nodes, configured with five Fault Domains and five Upgrade Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-217">Let's say that we have a cluster with six nodes, configured with five Fault Domains and five Upgrade Domains.</span></span>

|  | <span data-ttu-id="11f13-218">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-218">FD0</span></span> | <span data-ttu-id="11f13-219">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-219">FD1</span></span> | <span data-ttu-id="11f13-220">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-220">FD2</span></span> | <span data-ttu-id="11f13-221">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-221">FD3</span></span> | <span data-ttu-id="11f13-222">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-222">FD4</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-223">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-223">**UD0**</span></span> |<span data-ttu-id="11f13-224">N1</span><span class="sxs-lookup"><span data-stu-id="11f13-224">N1</span></span> | | | | |
| <span data-ttu-id="11f13-225">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-225">**UD1**</span></span> |<span data-ttu-id="11f13-226">N6</span><span class="sxs-lookup"><span data-stu-id="11f13-226">N6</span></span> |<span data-ttu-id="11f13-227">N2</span><span class="sxs-lookup"><span data-stu-id="11f13-227">N2</span></span> | | | |
| <span data-ttu-id="11f13-228">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-228">**UD2**</span></span> | | |<span data-ttu-id="11f13-229">N3</span><span class="sxs-lookup"><span data-stu-id="11f13-229">N3</span></span> | | |
| <span data-ttu-id="11f13-230">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-230">**UD3**</span></span> | | | |<span data-ttu-id="11f13-231">N4</span><span class="sxs-lookup"><span data-stu-id="11f13-231">N4</span></span> | |
| <span data-ttu-id="11f13-232">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-232">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-233">N5</span><span class="sxs-lookup"><span data-stu-id="11f13-233">N5</span></span> |

<span data-ttu-id="11f13-234">*Configuration 1*</span><span class="sxs-lookup"><span data-stu-id="11f13-234">*Configuration 1*</span></span>

<span data-ttu-id="11f13-235">Now let's say that we create a service with a TargetReplicaSetSize (or, for a stateless service an InstanceCount) of five.</span><span class="sxs-lookup"><span data-stu-id="11f13-235">Now let's say that we create a service with a TargetReplicaSetSize (or, for a stateless service an InstanceCount) of five.</span></span> <span data-ttu-id="11f13-236">The replicas land on N1-N5.</span><span class="sxs-lookup"><span data-stu-id="11f13-236">The replicas land on N1-N5.</span></span> <span data-ttu-id="11f13-237">In fact, N6 is never used no matter how many services like this you create.</span><span class="sxs-lookup"><span data-stu-id="11f13-237">In fact, N6 is never used no matter how many services like this you create.</span></span> <span data-ttu-id="11f13-238">But why?</span><span class="sxs-lookup"><span data-stu-id="11f13-238">But why?</span></span> <span data-ttu-id="11f13-239">Let's look at the difference between the current layout and what would happen if N6 is chosen.</span><span class="sxs-lookup"><span data-stu-id="11f13-239">Let's look at the difference between the current layout and what would happen if N6 is chosen.</span></span>

<span data-ttu-id="11f13-240">Here's the layout we got and the total number of replicas per Fault and Upgrade Domain:</span><span class="sxs-lookup"><span data-stu-id="11f13-240">Here's the layout we got and the total number of replicas per Fault and Upgrade Domain:</span></span>

|  | <span data-ttu-id="11f13-241">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-241">FD0</span></span> | <span data-ttu-id="11f13-242">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-242">FD1</span></span> | <span data-ttu-id="11f13-243">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-243">FD2</span></span> | <span data-ttu-id="11f13-244">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-244">FD3</span></span> | <span data-ttu-id="11f13-245">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-245">FD4</span></span> | <span data-ttu-id="11f13-246">UDTotal</span><span class="sxs-lookup"><span data-stu-id="11f13-246">UDTotal</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-247">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-247">**UD0**</span></span> |<span data-ttu-id="11f13-248">R1</span><span class="sxs-lookup"><span data-stu-id="11f13-248">R1</span></span> | | | | |<span data-ttu-id="11f13-249">1</span><span class="sxs-lookup"><span data-stu-id="11f13-249">1</span></span> |
| <span data-ttu-id="11f13-250">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-250">**UD1**</span></span> | |<span data-ttu-id="11f13-251">R2</span><span class="sxs-lookup"><span data-stu-id="11f13-251">R2</span></span> | | | |<span data-ttu-id="11f13-252">1</span><span class="sxs-lookup"><span data-stu-id="11f13-252">1</span></span> |
| <span data-ttu-id="11f13-253">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-253">**UD2**</span></span> | | |<span data-ttu-id="11f13-254">R3</span><span class="sxs-lookup"><span data-stu-id="11f13-254">R3</span></span> | | |<span data-ttu-id="11f13-255">1</span><span class="sxs-lookup"><span data-stu-id="11f13-255">1</span></span> |
| <span data-ttu-id="11f13-256">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-256">**UD3**</span></span> | | | |<span data-ttu-id="11f13-257">R4</span><span class="sxs-lookup"><span data-stu-id="11f13-257">R4</span></span> | |<span data-ttu-id="11f13-258">1</span><span class="sxs-lookup"><span data-stu-id="11f13-258">1</span></span> |
| <span data-ttu-id="11f13-259">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-259">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-260">R5</span><span class="sxs-lookup"><span data-stu-id="11f13-260">R5</span></span> |<span data-ttu-id="11f13-261">1</span><span class="sxs-lookup"><span data-stu-id="11f13-261">1</span></span> |
| <span data-ttu-id="11f13-262">**FDTotal**</span><span class="sxs-lookup"><span data-stu-id="11f13-262">**FDTotal**</span></span> |<span data-ttu-id="11f13-263">1</span><span class="sxs-lookup"><span data-stu-id="11f13-263">1</span></span> |<span data-ttu-id="11f13-264">1</span><span class="sxs-lookup"><span data-stu-id="11f13-264">1</span></span> |<span data-ttu-id="11f13-265">1</span><span class="sxs-lookup"><span data-stu-id="11f13-265">1</span></span> |<span data-ttu-id="11f13-266">1</span><span class="sxs-lookup"><span data-stu-id="11f13-266">1</span></span> |<span data-ttu-id="11f13-267">1</span><span class="sxs-lookup"><span data-stu-id="11f13-267">1</span></span> |- |

<span data-ttu-id="11f13-268">*Layout 1*</span><span class="sxs-lookup"><span data-stu-id="11f13-268">*Layout 1*</span></span>


<span data-ttu-id="11f13-269">This layout is balanced in terms of nodes per Fault Domain and Upgrade Domain.</span><span class="sxs-lookup"><span data-stu-id="11f13-269">This layout is balanced in terms of nodes per Fault Domain and Upgrade Domain.</span></span> <span data-ttu-id="11f13-270">It is also balanced in terms of the number of replicas per Fault and Upgrade Domain.</span><span class="sxs-lookup"><span data-stu-id="11f13-270">It is also balanced in terms of the number of replicas per Fault and Upgrade Domain.</span></span> <span data-ttu-id="11f13-271">Each domain has the same number of nodes and the same number of replicas.</span><span class="sxs-lookup"><span data-stu-id="11f13-271">Each domain has the same number of nodes and the same number of replicas.</span></span>

<span data-ttu-id="11f13-272">Now, let's look at what would happen if we'd used N6 instead of N2.</span><span class="sxs-lookup"><span data-stu-id="11f13-272">Now, let's look at what would happen if we'd used N6 instead of N2.</span></span> <span data-ttu-id="11f13-273">How would the replicas be distributed then?</span><span class="sxs-lookup"><span data-stu-id="11f13-273">How would the replicas be distributed then?</span></span>

|  | <span data-ttu-id="11f13-274">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-274">FD0</span></span> | <span data-ttu-id="11f13-275">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-275">FD1</span></span> | <span data-ttu-id="11f13-276">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-276">FD2</span></span> | <span data-ttu-id="11f13-277">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-277">FD3</span></span> | <span data-ttu-id="11f13-278">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-278">FD4</span></span> | <span data-ttu-id="11f13-279">UDTotal</span><span class="sxs-lookup"><span data-stu-id="11f13-279">UDTotal</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-280">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-280">**UD0**</span></span> |<span data-ttu-id="11f13-281">R1</span><span class="sxs-lookup"><span data-stu-id="11f13-281">R1</span></span> | | | | |<span data-ttu-id="11f13-282">1</span><span class="sxs-lookup"><span data-stu-id="11f13-282">1</span></span> |
| <span data-ttu-id="11f13-283">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-283">**UD1**</span></span> |<span data-ttu-id="11f13-284">R5</span><span class="sxs-lookup"><span data-stu-id="11f13-284">R5</span></span> | | | | |<span data-ttu-id="11f13-285">1</span><span class="sxs-lookup"><span data-stu-id="11f13-285">1</span></span> |
| <span data-ttu-id="11f13-286">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-286">**UD2**</span></span> | | |<span data-ttu-id="11f13-287">R2</span><span class="sxs-lookup"><span data-stu-id="11f13-287">R2</span></span> | | |<span data-ttu-id="11f13-288">1</span><span class="sxs-lookup"><span data-stu-id="11f13-288">1</span></span> |
| <span data-ttu-id="11f13-289">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-289">**UD3**</span></span> | | | |<span data-ttu-id="11f13-290">R3</span><span class="sxs-lookup"><span data-stu-id="11f13-290">R3</span></span> | |<span data-ttu-id="11f13-291">1</span><span class="sxs-lookup"><span data-stu-id="11f13-291">1</span></span> |
| <span data-ttu-id="11f13-292">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-292">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-293">R4</span><span class="sxs-lookup"><span data-stu-id="11f13-293">R4</span></span> |<span data-ttu-id="11f13-294">1</span><span class="sxs-lookup"><span data-stu-id="11f13-294">1</span></span> |
| <span data-ttu-id="11f13-295">**FDTotal**</span><span class="sxs-lookup"><span data-stu-id="11f13-295">**FDTotal**</span></span> |<span data-ttu-id="11f13-296">2</span><span class="sxs-lookup"><span data-stu-id="11f13-296">2</span></span> |<span data-ttu-id="11f13-297">0</span><span class="sxs-lookup"><span data-stu-id="11f13-297">0</span></span> |<span data-ttu-id="11f13-298">1</span><span class="sxs-lookup"><span data-stu-id="11f13-298">1</span></span> |<span data-ttu-id="11f13-299">1</span><span class="sxs-lookup"><span data-stu-id="11f13-299">1</span></span> |<span data-ttu-id="11f13-300">1</span><span class="sxs-lookup"><span data-stu-id="11f13-300">1</span></span> |- |

<span data-ttu-id="11f13-301">*Layout 2*</span><span class="sxs-lookup"><span data-stu-id="11f13-301">*Layout 2*</span></span>


<span data-ttu-id="11f13-302">This layout violates our definition of the “maximum difference” guarantee for the Fault Domain constraint.</span><span class="sxs-lookup"><span data-stu-id="11f13-302">This layout violates our definition of the “maximum difference” guarantee for the Fault Domain constraint.</span></span> <span data-ttu-id="11f13-303">FD0 has two replicas, while FD1 has zero, making the difference between FD0 and FD1 a total of two, which is greater than the maximum difference of one.</span><span class="sxs-lookup"><span data-stu-id="11f13-303">FD0 has two replicas, while FD1 has zero, making the difference between FD0 and FD1 a total of two, which is greater than the maximum difference of one.</span></span> <span data-ttu-id="11f13-304">Since the constraint is violated, the Cluster Resource Manager does not allow this arrangement.</span><span class="sxs-lookup"><span data-stu-id="11f13-304">Since the constraint is violated, the Cluster Resource Manager does not allow this arrangement.</span></span> <span data-ttu-id="11f13-305">Similarly if we picked N2 and N6 (instead of N1 and N2) we'd get:</span><span class="sxs-lookup"><span data-stu-id="11f13-305">Similarly if we picked N2 and N6 (instead of N1 and N2) we'd get:</span></span>

|  | <span data-ttu-id="11f13-306">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-306">FD0</span></span> | <span data-ttu-id="11f13-307">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-307">FD1</span></span> | <span data-ttu-id="11f13-308">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-308">FD2</span></span> | <span data-ttu-id="11f13-309">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-309">FD3</span></span> | <span data-ttu-id="11f13-310">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-310">FD4</span></span> | <span data-ttu-id="11f13-311">UDTotal</span><span class="sxs-lookup"><span data-stu-id="11f13-311">UDTotal</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-312">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-312">**UD0**</span></span> | | | | | |<span data-ttu-id="11f13-313">0</span><span class="sxs-lookup"><span data-stu-id="11f13-313">0</span></span> |
| <span data-ttu-id="11f13-314">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-314">**UD1**</span></span> |<span data-ttu-id="11f13-315">R5</span><span class="sxs-lookup"><span data-stu-id="11f13-315">R5</span></span> |<span data-ttu-id="11f13-316">R1</span><span class="sxs-lookup"><span data-stu-id="11f13-316">R1</span></span> | | | |<span data-ttu-id="11f13-317">2</span><span class="sxs-lookup"><span data-stu-id="11f13-317">2</span></span> |
| <span data-ttu-id="11f13-318">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-318">**UD2**</span></span> | | |<span data-ttu-id="11f13-319">R2</span><span class="sxs-lookup"><span data-stu-id="11f13-319">R2</span></span> | | |<span data-ttu-id="11f13-320">1</span><span class="sxs-lookup"><span data-stu-id="11f13-320">1</span></span> |
| <span data-ttu-id="11f13-321">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-321">**UD3**</span></span> | | | |<span data-ttu-id="11f13-322">R3</span><span class="sxs-lookup"><span data-stu-id="11f13-322">R3</span></span> | |<span data-ttu-id="11f13-323">1</span><span class="sxs-lookup"><span data-stu-id="11f13-323">1</span></span> |
| <span data-ttu-id="11f13-324">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-324">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-325">R4</span><span class="sxs-lookup"><span data-stu-id="11f13-325">R4</span></span> |<span data-ttu-id="11f13-326">1</span><span class="sxs-lookup"><span data-stu-id="11f13-326">1</span></span> |
| <span data-ttu-id="11f13-327">**FDTotal**</span><span class="sxs-lookup"><span data-stu-id="11f13-327">**FDTotal**</span></span> |<span data-ttu-id="11f13-328">1</span><span class="sxs-lookup"><span data-stu-id="11f13-328">1</span></span> |<span data-ttu-id="11f13-329">1</span><span class="sxs-lookup"><span data-stu-id="11f13-329">1</span></span> |<span data-ttu-id="11f13-330">1</span><span class="sxs-lookup"><span data-stu-id="11f13-330">1</span></span> |<span data-ttu-id="11f13-331">1</span><span class="sxs-lookup"><span data-stu-id="11f13-331">1</span></span> |<span data-ttu-id="11f13-332">1</span><span class="sxs-lookup"><span data-stu-id="11f13-332">1</span></span> |- |

<span data-ttu-id="11f13-333">*Layout 3*</span><span class="sxs-lookup"><span data-stu-id="11f13-333">*Layout 3*</span></span>


<span data-ttu-id="11f13-334">This layout is balanced in terms of Fault Domains.</span><span class="sxs-lookup"><span data-stu-id="11f13-334">This layout is balanced in terms of Fault Domains.</span></span> <span data-ttu-id="11f13-335">However, now it's violating the Upgrade Domain constraint because UD0 has zero replicas while UD1 has two.</span><span class="sxs-lookup"><span data-stu-id="11f13-335">However, now it's violating the Upgrade Domain constraint because UD0 has zero replicas while UD1 has two.</span></span> <span data-ttu-id="11f13-336">Therefore, this layout is also invalid and won't be picked by the Cluster Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="11f13-336">Therefore, this layout is also invalid and won't be picked by the Cluster Resource Manager.</span></span>

<span data-ttu-id="11f13-337">This approach to the distribution of stateful replicas or stateless instances provides the best possible fault tolerance.</span><span class="sxs-lookup"><span data-stu-id="11f13-337">This approach to the distribution of stateful replicas or stateless instances provides the best possible fault tolerance.</span></span> <span data-ttu-id="11f13-338">In a situation when one domain goes down, the minimal number of replicas/instances is lost.</span><span class="sxs-lookup"><span data-stu-id="11f13-338">In a situation when one domain goes down, the minimal number of replicas/instances is lost.</span></span> 

<span data-ttu-id="11f13-339">On the other hand, this approach can be too strict and not allow the cluster to utilize all resources.</span><span class="sxs-lookup"><span data-stu-id="11f13-339">On the other hand, this approach can be too strict and not allow the cluster to utilize all resources.</span></span> <span data-ttu-id="11f13-340">For certain cluster configurations, certain nodes can't be used.</span><span class="sxs-lookup"><span data-stu-id="11f13-340">For certain cluster configurations, certain nodes can't be used.</span></span> <span data-ttu-id="11f13-341">This can lead to Service Fabric not placing your services, resulting in warning messages.</span><span class="sxs-lookup"><span data-stu-id="11f13-341">This can lead to Service Fabric not placing your services, resulting in warning messages.</span></span> <span data-ttu-id="11f13-342">In the previous example some of the cluster nodes can’t be used (N6 in the given example).</span><span class="sxs-lookup"><span data-stu-id="11f13-342">In the previous example some of the cluster nodes can’t be used (N6 in the given example).</span></span> <span data-ttu-id="11f13-343">Even if you would add nodes to that cluster (N7 – N10), replicas/instances would only be placed on N1 – N5 due to Fault and Upgrade Domain constraints.</span><span class="sxs-lookup"><span data-stu-id="11f13-343">Even if you would add nodes to that cluster (N7 – N10), replicas/instances would only be placed on N1 – N5 due to Fault and Upgrade Domain constraints.</span></span> 

|  | <span data-ttu-id="11f13-344">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-344">FD0</span></span> | <span data-ttu-id="11f13-345">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-345">FD1</span></span> | <span data-ttu-id="11f13-346">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-346">FD2</span></span> | <span data-ttu-id="11f13-347">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-347">FD3</span></span> | <span data-ttu-id="11f13-348">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-348">FD4</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-349">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-349">**UD0**</span></span> |<span data-ttu-id="11f13-350">N1</span><span class="sxs-lookup"><span data-stu-id="11f13-350">N1</span></span> | | | |<span data-ttu-id="11f13-351">N10</span><span class="sxs-lookup"><span data-stu-id="11f13-351">N10</span></span> |
| <span data-ttu-id="11f13-352">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-352">**UD1**</span></span> |<span data-ttu-id="11f13-353">N6</span><span class="sxs-lookup"><span data-stu-id="11f13-353">N6</span></span> |<span data-ttu-id="11f13-354">N2</span><span class="sxs-lookup"><span data-stu-id="11f13-354">N2</span></span> | | | |
| <span data-ttu-id="11f13-355">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-355">**UD2**</span></span> | |<span data-ttu-id="11f13-356">N7</span><span class="sxs-lookup"><span data-stu-id="11f13-356">N7</span></span> |<span data-ttu-id="11f13-357">N3</span><span class="sxs-lookup"><span data-stu-id="11f13-357">N3</span></span> | | |
| <span data-ttu-id="11f13-358">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-358">**UD3**</span></span> | | |<span data-ttu-id="11f13-359">N8</span><span class="sxs-lookup"><span data-stu-id="11f13-359">N8</span></span> |<span data-ttu-id="11f13-360">N4</span><span class="sxs-lookup"><span data-stu-id="11f13-360">N4</span></span> | |
| <span data-ttu-id="11f13-361">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-361">**UD4**</span></span> | | | |<span data-ttu-id="11f13-362">N9</span><span class="sxs-lookup"><span data-stu-id="11f13-362">N9</span></span> |<span data-ttu-id="11f13-363">N5</span><span class="sxs-lookup"><span data-stu-id="11f13-363">N5</span></span> |

<span data-ttu-id="11f13-364">*Configuration 2*</span><span class="sxs-lookup"><span data-stu-id="11f13-364">*Configuration 2*</span></span>


### <a name="alternative-approach"></a><span data-ttu-id="11f13-365">*Alternative approach*</span><span class="sxs-lookup"><span data-stu-id="11f13-365">*Alternative approach*</span></span>

<span data-ttu-id="11f13-366">The Cluster Resource Manager supports another version of the Fault and Upgrade Domain constraint which allows placement while still guaranteeing a minimum level of safety.</span><span class="sxs-lookup"><span data-stu-id="11f13-366">The Cluster Resource Manager supports another version of the Fault and Upgrade Domain constraint which allows placement while still guaranteeing a minimum level of safety.</span></span> <span data-ttu-id="11f13-367">The alternative Fault and Upgrade Domain constraint can be stated as follows: “For a given service partition, replica distribution across domains should ensure that the partition does not suffer a quorum loss”.</span><span class="sxs-lookup"><span data-stu-id="11f13-367">The alternative Fault and Upgrade Domain constraint can be stated as follows: “For a given service partition, replica distribution across domains should ensure that the partition does not suffer a quorum loss”.</span></span> <span data-ttu-id="11f13-368">Let’s say this constraint provides a “quorum safe” guarantee.</span><span class="sxs-lookup"><span data-stu-id="11f13-368">Let’s say this constraint provides a “quorum safe” guarantee.</span></span> 

> [!NOTE]
><span data-ttu-id="11f13-369">For a stateful service, we define *quorum loss* in a situation when a majority of the partition replicas are down at the same time.</span><span class="sxs-lookup"><span data-stu-id="11f13-369">For a stateful service, we define *quorum loss* in a situation when a majority of the partition replicas are down at the same time.</span></span> <span data-ttu-id="11f13-370">For example, if TargetReplicaSetSize is five, a set of any three replicas represents quorum.</span><span class="sxs-lookup"><span data-stu-id="11f13-370">For example, if TargetReplicaSetSize is five, a set of any three replicas represents quorum.</span></span> <span data-ttu-id="11f13-371">Similarly, if TargetReplicaSetSize is 6, four replicas are necessary for quorum.</span><span class="sxs-lookup"><span data-stu-id="11f13-371">Similarly, if TargetReplicaSetSize is 6, four replicas are necessary for quorum.</span></span> <span data-ttu-id="11f13-372">In both cases no more than two replicas can be down at the same time if the partition wants to continue functioning normally.</span><span class="sxs-lookup"><span data-stu-id="11f13-372">In both cases no more than two replicas can be down at the same time if the partition wants to continue functioning normally.</span></span> <span data-ttu-id="11f13-373">For a stateless service, there is no such thing as *quorum loss* as stateless services conitnue to functionate normally even if a majority of instances go down at the same time.</span><span class="sxs-lookup"><span data-stu-id="11f13-373">For a stateless service, there is no such thing as *quorum loss* as stateless services conitnue to functionate normally even if a majority of instances go down at the same time.</span></span> <span data-ttu-id="11f13-374">Hence, we will focus on stateful services in the rest of the text.</span><span class="sxs-lookup"><span data-stu-id="11f13-374">Hence, we will focus on stateful services in the rest of the text.</span></span>
>

<span data-ttu-id="11f13-375">Let’s go back to the previous example.</span><span class="sxs-lookup"><span data-stu-id="11f13-375">Let’s go back to the previous example.</span></span> <span data-ttu-id="11f13-376">With the “quorum safe” version of the constraint, all three given layouts would be valid.</span><span class="sxs-lookup"><span data-stu-id="11f13-376">With the “quorum safe” version of the constraint, all three given layouts would be valid.</span></span> <span data-ttu-id="11f13-377">This is because even if there would be failure of FD0 in the second layout or UD1 in the third layout, the partition would still have quorum (a majority of its replicas would still be up).</span><span class="sxs-lookup"><span data-stu-id="11f13-377">This is because even if there would be failure of FD0 in the second layout or UD1 in the third layout, the partition would still have quorum (a majority of its replicas would still be up).</span></span> <span data-ttu-id="11f13-378">With this version of the constraint N6 could almost always be utilized.</span><span class="sxs-lookup"><span data-stu-id="11f13-378">With this version of the constraint N6 could almost always be utilized.</span></span>

<span data-ttu-id="11f13-379">The “quorum safe” approach provides more flexibility than the “maximum difference” approach as it is easier to find replica distributions that are valid in almost any cluster topology.</span><span class="sxs-lookup"><span data-stu-id="11f13-379">The “quorum safe” approach provides more flexibility than the “maximum difference” approach as it is easier to find replica distributions that are valid in almost any cluster topology.</span></span> <span data-ttu-id="11f13-380">However, this approach can’t guarantee the best fault tolerance characteristics because some failures are worse than others.</span><span class="sxs-lookup"><span data-stu-id="11f13-380">However, this approach can’t guarantee the best fault tolerance characteristics because some failures are worse than others.</span></span> <span data-ttu-id="11f13-381">In the worst case scenario, a majority of the replicas could be lost with the failure of one domain and one additional replica.</span><span class="sxs-lookup"><span data-stu-id="11f13-381">In the worst case scenario, a majority of the replicas could be lost with the failure of one domain and one additional replica.</span></span> <span data-ttu-id="11f13-382">For example, instead of 3 failures being required to lose quorum with 5 replicas or instances, you could now lose a majority with just two failures.</span><span class="sxs-lookup"><span data-stu-id="11f13-382">For example, instead of 3 failures being required to lose quorum with 5 replicas or instances, you could now lose a majority with just two failures.</span></span> 

### <a name="adaptive-approach"></a><span data-ttu-id="11f13-383">*Adaptive approach*</span><span class="sxs-lookup"><span data-stu-id="11f13-383">*Adaptive approach*</span></span>
<span data-ttu-id="11f13-384">Because both of the approaches have strengths and weaknesses, we've introduced an adaptive approach that combines these two strategies.</span><span class="sxs-lookup"><span data-stu-id="11f13-384">Because both of the approaches have strengths and weaknesses, we've introduced an adaptive approach that combines these two strategies.</span></span>

> [!NOTE]
><span data-ttu-id="11f13-385">This will be the default behavior starting with Service Fabric Version 6.2.</span><span class="sxs-lookup"><span data-stu-id="11f13-385">This will be the default behavior starting with Service Fabric Version 6.2.</span></span> 
>
<span data-ttu-id="11f13-386">The adaptive approach uses the “maximum difference” logic by default and switches to the “quorum safe” logic only when necessary.</span><span class="sxs-lookup"><span data-stu-id="11f13-386">The adaptive approach uses the “maximum difference” logic by default and switches to the “quorum safe” logic only when necessary.</span></span> <span data-ttu-id="11f13-387">The Cluster Resource Manager automatically figures out which strategy is necessary by looking at how the cluster and services are configured.</span><span class="sxs-lookup"><span data-stu-id="11f13-387">The Cluster Resource Manager automatically figures out which strategy is necessary by looking at how the cluster and services are configured.</span></span> <span data-ttu-id="11f13-388">For a given service: *If the TargetReplicaSetSize is evenly divisible by the number of Fault Domains and the number of Upgrade Domains **and** the number of nodes is less than or equal to the (number of Fault Domains) \* (the number of Upgrade Domains), the Cluster Resource Manager should utilize the “quorum based” logic for that service.*</span><span class="sxs-lookup"><span data-stu-id="11f13-388">For a given service: *If the TargetReplicaSetSize is evenly divisible by the number of Fault Domains and the number of Upgrade Domains **and** the number of nodes is less than or equal to the (number of Fault Domains) \* (the number of Upgrade Domains), the Cluster Resource Manager should utilize the “quorum based” logic for that service.*</span></span> <span data-ttu-id="11f13-389">Bear in mind that the Cluster Resource Manager will use this approach for both stateless and stateful services, despite quorum loss not being relevant for stateless services.</span><span class="sxs-lookup"><span data-stu-id="11f13-389">Bear in mind that the Cluster Resource Manager will use this approach for both stateless and stateful services, despite quorum loss not being relevant for stateless services.</span></span>

<span data-ttu-id="11f13-390">Let’s go back to the previous example and assume that a cluster now has 8 nodes (the cluster is still configured with five Fault Domains and five Upgrade Domains and the TargetReplicaSetSize of a service hosted on that cluster remains five).</span><span class="sxs-lookup"><span data-stu-id="11f13-390">Let’s go back to the previous example and assume that a cluster now has 8 nodes (the cluster is still configured with five Fault Domains and five Upgrade Domains and the TargetReplicaSetSize of a service hosted on that cluster remains five).</span></span> 

|  | <span data-ttu-id="11f13-391">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-391">FD0</span></span> | <span data-ttu-id="11f13-392">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-392">FD1</span></span> | <span data-ttu-id="11f13-393">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-393">FD2</span></span> | <span data-ttu-id="11f13-394">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-394">FD3</span></span> | <span data-ttu-id="11f13-395">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-395">FD4</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-396">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-396">**UD0**</span></span> |<span data-ttu-id="11f13-397">N1</span><span class="sxs-lookup"><span data-stu-id="11f13-397">N1</span></span> | | | | |
| <span data-ttu-id="11f13-398">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-398">**UD1**</span></span> |<span data-ttu-id="11f13-399">N6</span><span class="sxs-lookup"><span data-stu-id="11f13-399">N6</span></span> |<span data-ttu-id="11f13-400">N2</span><span class="sxs-lookup"><span data-stu-id="11f13-400">N2</span></span> | | | |
| <span data-ttu-id="11f13-401">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-401">**UD2**</span></span> | |<span data-ttu-id="11f13-402">N7</span><span class="sxs-lookup"><span data-stu-id="11f13-402">N7</span></span> |<span data-ttu-id="11f13-403">N3</span><span class="sxs-lookup"><span data-stu-id="11f13-403">N3</span></span> | | |
| <span data-ttu-id="11f13-404">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-404">**UD3**</span></span> | | |<span data-ttu-id="11f13-405">N8</span><span class="sxs-lookup"><span data-stu-id="11f13-405">N8</span></span> |<span data-ttu-id="11f13-406">N4</span><span class="sxs-lookup"><span data-stu-id="11f13-406">N4</span></span> | |
| <span data-ttu-id="11f13-407">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-407">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-408">N5</span><span class="sxs-lookup"><span data-stu-id="11f13-408">N5</span></span> |

<span data-ttu-id="11f13-409">*Configuration 3*</span><span class="sxs-lookup"><span data-stu-id="11f13-409">*Configuration 3*</span></span>

<span data-ttu-id="11f13-410">Because all necessary conditions are satisfied, Cluster Resource Manager will utilize the “quorum based” logic in distributing the service.</span><span class="sxs-lookup"><span data-stu-id="11f13-410">Because all necessary conditions are satisfied, Cluster Resource Manager will utilize the “quorum based” logic in distributing the service.</span></span> <span data-ttu-id="11f13-411">This enables usage of N6 – N8.</span><span class="sxs-lookup"><span data-stu-id="11f13-411">This enables usage of N6 – N8.</span></span> <span data-ttu-id="11f13-412">One possible service distribution in this case could look like:</span><span class="sxs-lookup"><span data-stu-id="11f13-412">One possible service distribution in this case could look like:</span></span>

|  | <span data-ttu-id="11f13-413">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-413">FD0</span></span> | <span data-ttu-id="11f13-414">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-414">FD1</span></span> | <span data-ttu-id="11f13-415">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-415">FD2</span></span> | <span data-ttu-id="11f13-416">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-416">FD3</span></span> | <span data-ttu-id="11f13-417">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-417">FD4</span></span> | <span data-ttu-id="11f13-418">UDTotal</span><span class="sxs-lookup"><span data-stu-id="11f13-418">UDTotal</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-419">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-419">**UD0**</span></span> |<span data-ttu-id="11f13-420">R1</span><span class="sxs-lookup"><span data-stu-id="11f13-420">R1</span></span> | | | | |<span data-ttu-id="11f13-421">1</span><span class="sxs-lookup"><span data-stu-id="11f13-421">1</span></span> |
| <span data-ttu-id="11f13-422">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-422">**UD1**</span></span> |<span data-ttu-id="11f13-423">R2</span><span class="sxs-lookup"><span data-stu-id="11f13-423">R2</span></span> | | | | |<span data-ttu-id="11f13-424">1</span><span class="sxs-lookup"><span data-stu-id="11f13-424">1</span></span> |
| <span data-ttu-id="11f13-425">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-425">**UD2**</span></span> | |<span data-ttu-id="11f13-426">R3</span><span class="sxs-lookup"><span data-stu-id="11f13-426">R3</span></span> |<span data-ttu-id="11f13-427">R4</span><span class="sxs-lookup"><span data-stu-id="11f13-427">R4</span></span> | | |<span data-ttu-id="11f13-428">2</span><span class="sxs-lookup"><span data-stu-id="11f13-428">2</span></span> |
| <span data-ttu-id="11f13-429">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-429">**UD3**</span></span> | | | | | |<span data-ttu-id="11f13-430">0</span><span class="sxs-lookup"><span data-stu-id="11f13-430">0</span></span> |
| <span data-ttu-id="11f13-431">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-431">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-432">R5</span><span class="sxs-lookup"><span data-stu-id="11f13-432">R5</span></span> |<span data-ttu-id="11f13-433">1</span><span class="sxs-lookup"><span data-stu-id="11f13-433">1</span></span> |
| <span data-ttu-id="11f13-434">**FDTotal**</span><span class="sxs-lookup"><span data-stu-id="11f13-434">**FDTotal**</span></span> |<span data-ttu-id="11f13-435">2</span><span class="sxs-lookup"><span data-stu-id="11f13-435">2</span></span> |<span data-ttu-id="11f13-436">1</span><span class="sxs-lookup"><span data-stu-id="11f13-436">1</span></span> |<span data-ttu-id="11f13-437">1</span><span class="sxs-lookup"><span data-stu-id="11f13-437">1</span></span> |<span data-ttu-id="11f13-438">0</span><span class="sxs-lookup"><span data-stu-id="11f13-438">0</span></span> |<span data-ttu-id="11f13-439">1</span><span class="sxs-lookup"><span data-stu-id="11f13-439">1</span></span> |- |

<span data-ttu-id="11f13-440">*Layout 4*</span><span class="sxs-lookup"><span data-stu-id="11f13-440">*Layout 4*</span></span>

<span data-ttu-id="11f13-441">If your service’s TargetReplicaSetSize is reduced to four (for example), Cluster Resource Manager will notice that change and resume using the “maximum difference” logic because TargetReplicaSetSize isn’t dividable by the number of FDs and UDs anymore.</span><span class="sxs-lookup"><span data-stu-id="11f13-441">If your service’s TargetReplicaSetSize is reduced to four (for example), Cluster Resource Manager will notice that change and resume using the “maximum difference” logic because TargetReplicaSetSize isn’t dividable by the number of FDs and UDs anymore.</span></span> <span data-ttu-id="11f13-442">As a result, certain replica movements will occur in order to distribute remaining four replicas on nodes N1-N5 so that the “maximum difference” version of the Fault Domain and Upgrade domain logic is not violated.</span><span class="sxs-lookup"><span data-stu-id="11f13-442">As a result, certain replica movements will occur in order to distribute remaining four replicas on nodes N1-N5 so that the “maximum difference” version of the Fault Domain and Upgrade domain logic is not violated.</span></span> 

<span data-ttu-id="11f13-443">Looking back to the fourth layout and the TargetReplicaSetSize of five.</span><span class="sxs-lookup"><span data-stu-id="11f13-443">Looking back to the fourth layout and the TargetReplicaSetSize of five.</span></span> <span data-ttu-id="11f13-444">If N1 is removed from the cluster, the number of Upgrade Domains becomes equal to four.</span><span class="sxs-lookup"><span data-stu-id="11f13-444">If N1 is removed from the cluster, the number of Upgrade Domains becomes equal to four.</span></span> <span data-ttu-id="11f13-445">Again, the Cluster Resource Manager starts using “maximum difference” logic as the number of UDs doesn’t evenly divide the service’s TargetReplicaSetSize anymore.</span><span class="sxs-lookup"><span data-stu-id="11f13-445">Again, the Cluster Resource Manager starts using “maximum difference” logic as the number of UDs doesn’t evenly divide the service’s TargetReplicaSetSize anymore.</span></span> <span data-ttu-id="11f13-446">As a result, replica R1, when built again, has to land on N4 so that Fault and Upgrade Domain Constraint is not violated.</span><span class="sxs-lookup"><span data-stu-id="11f13-446">As a result, replica R1, when built again, has to land on N4 so that Fault and Upgrade Domain Constraint is not violated.</span></span>

|  | <span data-ttu-id="11f13-447">FD0</span><span class="sxs-lookup"><span data-stu-id="11f13-447">FD0</span></span> | <span data-ttu-id="11f13-448">FD1</span><span class="sxs-lookup"><span data-stu-id="11f13-448">FD1</span></span> | <span data-ttu-id="11f13-449">FD2</span><span class="sxs-lookup"><span data-stu-id="11f13-449">FD2</span></span> | <span data-ttu-id="11f13-450">FD3</span><span class="sxs-lookup"><span data-stu-id="11f13-450">FD3</span></span> | <span data-ttu-id="11f13-451">FD4</span><span class="sxs-lookup"><span data-stu-id="11f13-451">FD4</span></span> | <span data-ttu-id="11f13-452">UDTotal</span><span class="sxs-lookup"><span data-stu-id="11f13-452">UDTotal</span></span> |
| --- |:---:|:---:|:---:|:---:|:---:|:---:|
| <span data-ttu-id="11f13-453">**UD0**</span><span class="sxs-lookup"><span data-stu-id="11f13-453">**UD0**</span></span> |<span data-ttu-id="11f13-454">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-454">N/A</span></span> |<span data-ttu-id="11f13-455">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-455">N/A</span></span> |<span data-ttu-id="11f13-456">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-456">N/A</span></span> |<span data-ttu-id="11f13-457">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-457">N/A</span></span> |<span data-ttu-id="11f13-458">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-458">N/A</span></span> |<span data-ttu-id="11f13-459">N/A</span><span class="sxs-lookup"><span data-stu-id="11f13-459">N/A</span></span> |
| <span data-ttu-id="11f13-460">**UD1**</span><span class="sxs-lookup"><span data-stu-id="11f13-460">**UD1**</span></span> |<span data-ttu-id="11f13-461">R2</span><span class="sxs-lookup"><span data-stu-id="11f13-461">R2</span></span> | | | | |<span data-ttu-id="11f13-462">1</span><span class="sxs-lookup"><span data-stu-id="11f13-462">1</span></span> |
| <span data-ttu-id="11f13-463">**UD2**</span><span class="sxs-lookup"><span data-stu-id="11f13-463">**UD2**</span></span> | |<span data-ttu-id="11f13-464">R3</span><span class="sxs-lookup"><span data-stu-id="11f13-464">R3</span></span> |<span data-ttu-id="11f13-465">R4</span><span class="sxs-lookup"><span data-stu-id="11f13-465">R4</span></span> | | |<span data-ttu-id="11f13-466">2</span><span class="sxs-lookup"><span data-stu-id="11f13-466">2</span></span> |
| <span data-ttu-id="11f13-467">**UD3**</span><span class="sxs-lookup"><span data-stu-id="11f13-467">**UD3**</span></span> | | | |<span data-ttu-id="11f13-468">R1</span><span class="sxs-lookup"><span data-stu-id="11f13-468">R1</span></span> | |<span data-ttu-id="11f13-469">1</span><span class="sxs-lookup"><span data-stu-id="11f13-469">1</span></span> |
| <span data-ttu-id="11f13-470">**UD4**</span><span class="sxs-lookup"><span data-stu-id="11f13-470">**UD4**</span></span> | | | | |<span data-ttu-id="11f13-471">R5</span><span class="sxs-lookup"><span data-stu-id="11f13-471">R5</span></span> |<span data-ttu-id="11f13-472">1</span><span class="sxs-lookup"><span data-stu-id="11f13-472">1</span></span> |
| <span data-ttu-id="11f13-473">**FDTotal**</span><span class="sxs-lookup"><span data-stu-id="11f13-473">**FDTotal**</span></span> |<span data-ttu-id="11f13-474">1</span><span class="sxs-lookup"><span data-stu-id="11f13-474">1</span></span> |<span data-ttu-id="11f13-475">1</span><span class="sxs-lookup"><span data-stu-id="11f13-475">1</span></span> |<span data-ttu-id="11f13-476">1</span><span class="sxs-lookup"><span data-stu-id="11f13-476">1</span></span> |<span data-ttu-id="11f13-477">1</span><span class="sxs-lookup"><span data-stu-id="11f13-477">1</span></span> |<span data-ttu-id="11f13-478">1</span><span class="sxs-lookup"><span data-stu-id="11f13-478">1</span></span> |- |

<span data-ttu-id="11f13-479">*Layout 5*</span><span class="sxs-lookup"><span data-stu-id="11f13-479">*Layout 5*</span></span>

## <a name="configuring-fault-and-upgrade-domains"></a><span data-ttu-id="11f13-480">Configuring fault and Upgrade Domains</span><span class="sxs-lookup"><span data-stu-id="11f13-480">Configuring fault and Upgrade Domains</span></span>
<span data-ttu-id="11f13-481">Defining Fault Domains and Upgrade Domains is done automatically in Azure hosted Service Fabric deployments.</span><span class="sxs-lookup"><span data-stu-id="11f13-481">Defining Fault Domains and Upgrade Domains is done automatically in Azure hosted Service Fabric deployments.</span></span> <span data-ttu-id="11f13-482">Service Fabric picks up and uses the environment information from Azure.</span><span class="sxs-lookup"><span data-stu-id="11f13-482">Service Fabric picks up and uses the environment information from Azure.</span></span>

<span data-ttu-id="11f13-483">If you’re creating your own cluster (or want to run a particular topology in development), you can provide the Fault Domain and Upgrade Domain information yourself.</span><span class="sxs-lookup"><span data-stu-id="11f13-483">If you’re creating your own cluster (or want to run a particular topology in development), you can provide the Fault Domain and Upgrade Domain information yourself.</span></span> <span data-ttu-id="11f13-484">In this example, we define a nine node local development cluster that spans three “datacenters” (each with three racks).</span><span class="sxs-lookup"><span data-stu-id="11f13-484">In this example, we define a nine node local development cluster that spans three “datacenters” (each with three racks).</span></span> <span data-ttu-id="11f13-485">This cluster also has three Upgrade Domains striped across those three datacenters.</span><span class="sxs-lookup"><span data-stu-id="11f13-485">This cluster also has three Upgrade Domains striped across those three datacenters.</span></span> <span data-ttu-id="11f13-486">An example of the configuration is below:</span><span class="sxs-lookup"><span data-stu-id="11f13-486">An example of the configuration is below:</span></span> 

<span data-ttu-id="11f13-487">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="11f13-487">ClusterManifest.xml</span></span>

```xml
  <Infrastructure>
    <!-- IsScaleMin indicates that this cluster runs on one-box /one single server -->
    <WindowsServer IsScaleMin="true">
      <NodeList>
        <Node NodeName="Node01" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType01" FaultDomain="fd:/DC01/Rack01" UpgradeDomain="UpgradeDomain1" IsSeedNode="true" />
        <Node NodeName="Node02" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType02" FaultDomain="fd:/DC01/Rack02" UpgradeDomain="UpgradeDomain2" IsSeedNode="true" />
        <Node NodeName="Node03" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType03" FaultDomain="fd:/DC01/Rack03" UpgradeDomain="UpgradeDomain3" IsSeedNode="true" />
        <Node NodeName="Node04" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType04" FaultDomain="fd:/DC02/Rack01" UpgradeDomain="UpgradeDomain1" IsSeedNode="true" />
        <Node NodeName="Node05" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType05" FaultDomain="fd:/DC02/Rack02" UpgradeDomain="UpgradeDomain2" IsSeedNode="true" />
        <Node NodeName="Node06" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType06" FaultDomain="fd:/DC02/Rack03" UpgradeDomain="UpgradeDomain3" IsSeedNode="true" />
        <Node NodeName="Node07" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType07" FaultDomain="fd:/DC03/Rack01" UpgradeDomain="UpgradeDomain1" IsSeedNode="true" />
        <Node NodeName="Node08" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType08" FaultDomain="fd:/DC03/Rack02" UpgradeDomain="UpgradeDomain2" IsSeedNode="true" />
        <Node NodeName="Node09" IPAddressOrFQDN="localhost" NodeTypeRef="NodeType09" FaultDomain="fd:/DC03/Rack03" UpgradeDomain="UpgradeDomain3" IsSeedNode="true" />
      </NodeList>
    </WindowsServer>
  </Infrastructure>
```

<span data-ttu-id="11f13-488">via ClusterConfig.json for Standalone deployments</span><span class="sxs-lookup"><span data-stu-id="11f13-488">via ClusterConfig.json for Standalone deployments</span></span>

```json
"nodes": [
  {
    "nodeName": "vm1",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc1/r0",
    "upgradeDomain": "UD1"
  },
  {
    "nodeName": "vm2",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc1/r0",
    "upgradeDomain": "UD2"
  },
  {
    "nodeName": "vm3",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc1/r0",
    "upgradeDomain": "UD3"
  },
  {
    "nodeName": "vm4",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc2/r0",
    "upgradeDomain": "UD1"
  },
  {
    "nodeName": "vm5",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc2/r0",
    "upgradeDomain": "UD2"
  },
  {
    "nodeName": "vm6",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc2/r0",
    "upgradeDomain": "UD3"
  },
  {
    "nodeName": "vm7",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc3/r0",
    "upgradeDomain": "UD1"
  },
  {
    "nodeName": "vm8",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc3/r0",
    "upgradeDomain": "UD2"
  },
  {
    "nodeName": "vm9",
    "iPAddress": "localhost",
    "nodeTypeRef": "NodeType0",
    "faultDomain": "fd:/dc3/r0",
    "upgradeDomain": "UD3"
  }
],
```

> [!NOTE]
> <span data-ttu-id="11f13-489">When defining clusters via Azure Resource Manager, Fault Domains and Upgrade Domains are assigned by Azure.</span><span class="sxs-lookup"><span data-stu-id="11f13-489">When defining clusters via Azure Resource Manager, Fault Domains and Upgrade Domains are assigned by Azure.</span></span> <span data-ttu-id="11f13-490">Therefore, the definition of your Node Types and Virtual Machine Scale Sets in your Azure Resource Manager template does not include Fault Domain or Upgrade Domain information.</span><span class="sxs-lookup"><span data-stu-id="11f13-490">Therefore, the definition of your Node Types and Virtual Machine Scale Sets in your Azure Resource Manager template does not include Fault Domain or Upgrade Domain information.</span></span>
>

## <a name="node-properties-and-placement-constraints"></a><span data-ttu-id="11f13-491">Node properties and placement constraints</span><span class="sxs-lookup"><span data-stu-id="11f13-491">Node properties and placement constraints</span></span>
<span data-ttu-id="11f13-492">Sometimes (in fact, most of the time) you’re going to want to ensure that certain workloads run only on certain types of nodes in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-492">Sometimes (in fact, most of the time) you’re going to want to ensure that certain workloads run only on certain types of nodes in the cluster.</span></span> <span data-ttu-id="11f13-493">For example, some workload may require GPUs or SSDs while others may not.</span><span class="sxs-lookup"><span data-stu-id="11f13-493">For example, some workload may require GPUs or SSDs while others may not.</span></span> <span data-ttu-id="11f13-494">A great example of targeting hardware to particular workloads is almost every n-tier architecture out there.</span><span class="sxs-lookup"><span data-stu-id="11f13-494">A great example of targeting hardware to particular workloads is almost every n-tier architecture out there.</span></span> <span data-ttu-id="11f13-495">Certain machines serve as the front end or API serving side of the application and are exposed to the clients or the internet.</span><span class="sxs-lookup"><span data-stu-id="11f13-495">Certain machines serve as the front end or API serving side of the application and are exposed to the clients or the internet.</span></span> <span data-ttu-id="11f13-496">Different machines, often with different hardware resources, handle the work of the compute or storage layers.</span><span class="sxs-lookup"><span data-stu-id="11f13-496">Different machines, often with different hardware resources, handle the work of the compute or storage layers.</span></span> <span data-ttu-id="11f13-497">These are usually _not_ directly exposed to clients or the internet.</span><span class="sxs-lookup"><span data-stu-id="11f13-497">These are usually _not_ directly exposed to clients or the internet.</span></span> <span data-ttu-id="11f13-498">Service Fabric expects that there are cases where particular workloads need to run on particular hardware configurations.</span><span class="sxs-lookup"><span data-stu-id="11f13-498">Service Fabric expects that there are cases where particular workloads need to run on particular hardware configurations.</span></span> <span data-ttu-id="11f13-499">For example:</span><span class="sxs-lookup"><span data-stu-id="11f13-499">For example:</span></span>

* <span data-ttu-id="11f13-500">an existing n-tier application has been “lifted and shifted” into a Service Fabric environment</span><span class="sxs-lookup"><span data-stu-id="11f13-500">an existing n-tier application has been “lifted and shifted” into a Service Fabric environment</span></span>
* <span data-ttu-id="11f13-501">a workload wants to run on specific hardware for performance, scale, or security isolation reasons</span><span class="sxs-lookup"><span data-stu-id="11f13-501">a workload wants to run on specific hardware for performance, scale, or security isolation reasons</span></span>
* <span data-ttu-id="11f13-502">A workload should be isolated from other workloads for policy or resource consumption reasons</span><span class="sxs-lookup"><span data-stu-id="11f13-502">A workload should be isolated from other workloads for policy or resource consumption reasons</span></span>

<span data-ttu-id="11f13-503">To support these sorts of configurations, Service Fabric has a first class notion of tags that can be applied to nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-503">To support these sorts of configurations, Service Fabric has a first class notion of tags that can be applied to nodes.</span></span> <span data-ttu-id="11f13-504">These tags are called **node properties**.</span><span class="sxs-lookup"><span data-stu-id="11f13-504">These tags are called **node properties**.</span></span> <span data-ttu-id="11f13-505">**Placement constraints** are the statements attached to individual services that select for one or more node properties.</span><span class="sxs-lookup"><span data-stu-id="11f13-505">**Placement constraints** are the statements attached to individual services that select for one or more node properties.</span></span> <span data-ttu-id="11f13-506">Placement constraints define where services should run.</span><span class="sxs-lookup"><span data-stu-id="11f13-506">Placement constraints define where services should run.</span></span> <span data-ttu-id="11f13-507">The set of constraints is extensible - any key/value pair can work.</span><span class="sxs-lookup"><span data-stu-id="11f13-507">The set of constraints is extensible - any key/value pair can work.</span></span> 

<span data-ttu-id="11f13-508"><center>
![Cluster Layout Different Workloads][Image5]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-508"><center>
![Cluster Layout Different Workloads][Image5]
</center></span></span>

### <a name="built-in-node-properties"></a><span data-ttu-id="11f13-509">Built in node properties</span><span class="sxs-lookup"><span data-stu-id="11f13-509">Built in node properties</span></span>
<span data-ttu-id="11f13-510">Service Fabric defines some default node properties that can be used automatically without the user having to define them.</span><span class="sxs-lookup"><span data-stu-id="11f13-510">Service Fabric defines some default node properties that can be used automatically without the user having to define them.</span></span> <span data-ttu-id="11f13-511">The default properties defined at each node are the **NodeType** and the **NodeName**.</span><span class="sxs-lookup"><span data-stu-id="11f13-511">The default properties defined at each node are the **NodeType** and the **NodeName**.</span></span> <span data-ttu-id="11f13-512">So for example you could write a placement constraint as `"(NodeType == NodeType03)"`.</span><span class="sxs-lookup"><span data-stu-id="11f13-512">So for example you could write a placement constraint as `"(NodeType == NodeType03)"`.</span></span> <span data-ttu-id="11f13-513">Generally we have found NodeType to be one of the most commonly used properties.</span><span class="sxs-lookup"><span data-stu-id="11f13-513">Generally we have found NodeType to be one of the most commonly used properties.</span></span> <span data-ttu-id="11f13-514">It is useful since it corresponds 1:1 with a type of a machine.</span><span class="sxs-lookup"><span data-stu-id="11f13-514">It is useful since it corresponds 1:1 with a type of a machine.</span></span> <span data-ttu-id="11f13-515">Each type of machine corresponds to a type of workload in a traditional n-tier application.</span><span class="sxs-lookup"><span data-stu-id="11f13-515">Each type of machine corresponds to a type of workload in a traditional n-tier application.</span></span>

<span data-ttu-id="11f13-516"><center>
![Placement Constraints and Node Properties][Image6]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-516"><center>
![Placement Constraints and Node Properties][Image6]
</center></span></span>

## <a name="placement-constraint-and-node-property-syntax"></a><span data-ttu-id="11f13-517">Placement Constraint and Node Property Syntax</span><span class="sxs-lookup"><span data-stu-id="11f13-517">Placement Constraint and Node Property Syntax</span></span> 
<span data-ttu-id="11f13-518">The value specified in the node property can be a string, bool, or signed long.</span><span class="sxs-lookup"><span data-stu-id="11f13-518">The value specified in the node property can be a string, bool, or signed long.</span></span> <span data-ttu-id="11f13-519">The statement at the service is called a placement *constraint* since it constrains where the service can run in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-519">The statement at the service is called a placement *constraint* since it constrains where the service can run in the cluster.</span></span> <span data-ttu-id="11f13-520">The constraint can be any Boolean statement that operates on the different node properties in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-520">The constraint can be any Boolean statement that operates on the different node properties in the cluster.</span></span> <span data-ttu-id="11f13-521">The valid selectors in these boolean statements are:</span><span class="sxs-lookup"><span data-stu-id="11f13-521">The valid selectors in these boolean statements are:</span></span>

1) <span data-ttu-id="11f13-522">conditional checks for creating particular statements</span><span class="sxs-lookup"><span data-stu-id="11f13-522">conditional checks for creating particular statements</span></span>

| <span data-ttu-id="11f13-523">Statement</span><span class="sxs-lookup"><span data-stu-id="11f13-523">Statement</span></span> | <span data-ttu-id="11f13-524">Syntax</span><span class="sxs-lookup"><span data-stu-id="11f13-524">Syntax</span></span> |
| --- |:---:|
| <span data-ttu-id="11f13-525">"equal to"</span><span class="sxs-lookup"><span data-stu-id="11f13-525">"equal to"</span></span> | <span data-ttu-id="11f13-526">"=="</span><span class="sxs-lookup"><span data-stu-id="11f13-526">"=="</span></span> |
| <span data-ttu-id="11f13-527">"not equal to"</span><span class="sxs-lookup"><span data-stu-id="11f13-527">"not equal to"</span></span> | <span data-ttu-id="11f13-528">"!="</span><span class="sxs-lookup"><span data-stu-id="11f13-528">"!="</span></span> |
| <span data-ttu-id="11f13-529">"greater than"</span><span class="sxs-lookup"><span data-stu-id="11f13-529">"greater than"</span></span> | <span data-ttu-id="11f13-530">">"</span><span class="sxs-lookup"><span data-stu-id="11f13-530">">"</span></span> |
| <span data-ttu-id="11f13-531">"greater than or equal to"</span><span class="sxs-lookup"><span data-stu-id="11f13-531">"greater than or equal to"</span></span> | <span data-ttu-id="11f13-532">">="</span><span class="sxs-lookup"><span data-stu-id="11f13-532">">="</span></span> |
| <span data-ttu-id="11f13-533">"less than"</span><span class="sxs-lookup"><span data-stu-id="11f13-533">"less than"</span></span> | <span data-ttu-id="11f13-534">"<"</span><span class="sxs-lookup"><span data-stu-id="11f13-534">"<"</span></span> |
| <span data-ttu-id="11f13-535">"less than or equal to"</span><span class="sxs-lookup"><span data-stu-id="11f13-535">"less than or equal to"</span></span> | <span data-ttu-id="11f13-536">"<="</span><span class="sxs-lookup"><span data-stu-id="11f13-536">"<="</span></span> |

2) <span data-ttu-id="11f13-537">boolean statements for grouping and logical operations</span><span class="sxs-lookup"><span data-stu-id="11f13-537">boolean statements for grouping and logical operations</span></span>

| <span data-ttu-id="11f13-538">Statement</span><span class="sxs-lookup"><span data-stu-id="11f13-538">Statement</span></span> | <span data-ttu-id="11f13-539">Syntax</span><span class="sxs-lookup"><span data-stu-id="11f13-539">Syntax</span></span> |
| --- |:---:|
| <span data-ttu-id="11f13-540">"and"</span><span class="sxs-lookup"><span data-stu-id="11f13-540">"and"</span></span> | <span data-ttu-id="11f13-541">"&&"</span><span class="sxs-lookup"><span data-stu-id="11f13-541">"&&"</span></span> |
| <span data-ttu-id="11f13-542">"or"</span><span class="sxs-lookup"><span data-stu-id="11f13-542">"or"</span></span> | <span data-ttu-id="11f13-543">"&#124;&#124;"</span><span class="sxs-lookup"><span data-stu-id="11f13-543">"&#124;&#124;"</span></span> |
| <span data-ttu-id="11f13-544">"not"</span><span class="sxs-lookup"><span data-stu-id="11f13-544">"not"</span></span> | <span data-ttu-id="11f13-545">"!"</span><span class="sxs-lookup"><span data-stu-id="11f13-545">"!"</span></span> |
| <span data-ttu-id="11f13-546">"group as single statement"</span><span class="sxs-lookup"><span data-stu-id="11f13-546">"group as single statement"</span></span> | <span data-ttu-id="11f13-547">"()"</span><span class="sxs-lookup"><span data-stu-id="11f13-547">"()"</span></span> |

<span data-ttu-id="11f13-548">Here are some examples of basic constraint statements.</span><span class="sxs-lookup"><span data-stu-id="11f13-548">Here are some examples of basic constraint statements.</span></span>

  * `"Value >= 5"`
  * `"NodeColor != green"`
  * `"((OneProperty < 100) || ((AnotherProperty == false) && (OneProperty >= 100)))"`

<span data-ttu-id="11f13-549">Only nodes where the overall placement constraint statement evaluates to “True” can have the service placed on it.</span><span class="sxs-lookup"><span data-stu-id="11f13-549">Only nodes where the overall placement constraint statement evaluates to “True” can have the service placed on it.</span></span> <span data-ttu-id="11f13-550">Nodes that do not have a property defined do not match any placement constraint containing that property.</span><span class="sxs-lookup"><span data-stu-id="11f13-550">Nodes that do not have a property defined do not match any placement constraint containing that property.</span></span>

<span data-ttu-id="11f13-551">Let’s say that the following node properties were defined for a given node type:</span><span class="sxs-lookup"><span data-stu-id="11f13-551">Let’s say that the following node properties were defined for a given node type:</span></span>

<span data-ttu-id="11f13-552">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="11f13-552">ClusterManifest.xml</span></span>

```xml
    <NodeType Name="NodeType01">
      <PlacementProperties>
        <Property Name="HasSSD" Value="true"/>
        <Property Name="NodeColor" Value="green"/>
        <Property Name="SomeProperty" Value="5"/>
      </PlacementProperties>
    </NodeType>
```

<span data-ttu-id="11f13-553">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters.</span><span class="sxs-lookup"><span data-stu-id="11f13-553">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters.</span></span> 

> [!NOTE]
> <span data-ttu-id="11f13-554">In your Azure Resource Manager template the node type is usually parameterized.</span><span class="sxs-lookup"><span data-stu-id="11f13-554">In your Azure Resource Manager template the node type is usually parameterized.</span></span> <span data-ttu-id="11f13-555">It would look like "[parameters('vmNodeType1Name')]" rather than "NodeType01".</span><span class="sxs-lookup"><span data-stu-id="11f13-555">It would look like "[parameters('vmNodeType1Name')]" rather than "NodeType01".</span></span>
>

```json
"nodeTypes": [
    {
        "name": "NodeType01",
        "placementProperties": {
            "HasSSD": "true",
            "NodeColor": "green",
            "SomeProperty": "5"
        },
    }
],
```

<span data-ttu-id="11f13-556">You can create service placement *constraints* for a service like as follows:</span><span class="sxs-lookup"><span data-stu-id="11f13-556">You can create service placement *constraints* for a service like as follows:</span></span>

<span data-ttu-id="11f13-557">C#</span><span class="sxs-lookup"><span data-stu-id="11f13-557">C#</span></span>

```csharp
FabricClient fabricClient = new FabricClient();
StatefulServiceDescription serviceDescription = new StatefulServiceDescription();
serviceDescription.PlacementConstraints = "(HasSSD == true && SomeProperty >= 4)";
// add other required servicedescription fields
//...
await fabricClient.ServiceManager.CreateServiceAsync(serviceDescription);
```

<span data-ttu-id="11f13-558">Powershell:</span><span class="sxs-lookup"><span data-stu-id="11f13-558">Powershell:</span></span>

```posh
New-ServiceFabricService -ApplicationName $applicationName -ServiceName $serviceName -ServiceTypeName $serviceType -Stateful -MinReplicaSetSize 3 -TargetReplicaSetSize 3 -PartitionSchemeSingleton -PlacementConstraint "HasSSD == true && SomeProperty >= 4"
```

<span data-ttu-id="11f13-559">If all nodes of NodeType01 are valid, you can also select that node type with the constraint "(NodeType == NodeType01)".</span><span class="sxs-lookup"><span data-stu-id="11f13-559">If all nodes of NodeType01 are valid, you can also select that node type with the constraint "(NodeType == NodeType01)".</span></span>

<span data-ttu-id="11f13-560">One of the cool things about a service’s placement constraints is that they can be updated dynamically during runtime.</span><span class="sxs-lookup"><span data-stu-id="11f13-560">One of the cool things about a service’s placement constraints is that they can be updated dynamically during runtime.</span></span> <span data-ttu-id="11f13-561">So if you need to, you can move a service around in the cluster, add and remove requirements, etc. Service Fabric takes care of ensuring that the service stays up and available even when these types of changes are made.</span><span class="sxs-lookup"><span data-stu-id="11f13-561">So if you need to, you can move a service around in the cluster, add and remove requirements, etc. Service Fabric takes care of ensuring that the service stays up and available even when these types of changes are made.</span></span>

<span data-ttu-id="11f13-562">C#:</span><span class="sxs-lookup"><span data-stu-id="11f13-562">C#:</span></span>

```csharp
StatefulServiceUpdateDescription updateDescription = new StatefulServiceUpdateDescription();
updateDescription.PlacementConstraints = "NodeType == NodeType01";
await fabricClient.ServiceManager.UpdateServiceAsync(new Uri("fabric:/app/service"), updateDescription);
```

<span data-ttu-id="11f13-563">Powershell:</span><span class="sxs-lookup"><span data-stu-id="11f13-563">Powershell:</span></span>

```posh
Update-ServiceFabricService -Stateful -ServiceName $serviceName -PlacementConstraints "NodeType == NodeType01"
```

<span data-ttu-id="11f13-564">Placement constraints are specified for every different named service instance.</span><span class="sxs-lookup"><span data-stu-id="11f13-564">Placement constraints are specified for every different named service instance.</span></span> <span data-ttu-id="11f13-565">Updates always take the place of (overwrite) what was previously specified.</span><span class="sxs-lookup"><span data-stu-id="11f13-565">Updates always take the place of (overwrite) what was previously specified.</span></span>

<span data-ttu-id="11f13-566">The cluster definition defines the properties on a node.</span><span class="sxs-lookup"><span data-stu-id="11f13-566">The cluster definition defines the properties on a node.</span></span> <span data-ttu-id="11f13-567">Changing a node's properties requires a cluster configuration upgrade.</span><span class="sxs-lookup"><span data-stu-id="11f13-567">Changing a node's properties requires a cluster configuration upgrade.</span></span> <span data-ttu-id="11f13-568">Upgrading a node's properties requires each affected node to restart to report its new properties.</span><span class="sxs-lookup"><span data-stu-id="11f13-568">Upgrading a node's properties requires each affected node to restart to report its new properties.</span></span> <span data-ttu-id="11f13-569">These rolling upgrades are managed by Service Fabric.</span><span class="sxs-lookup"><span data-stu-id="11f13-569">These rolling upgrades are managed by Service Fabric.</span></span>

## <a name="describing-and-managing-cluster-resources"></a><span data-ttu-id="11f13-570">Describing and Managing Cluster Resources</span><span class="sxs-lookup"><span data-stu-id="11f13-570">Describing and Managing Cluster Resources</span></span>
<span data-ttu-id="11f13-571">One of the most important jobs of any orchestrator is to help manage resource consumption in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-571">One of the most important jobs of any orchestrator is to help manage resource consumption in the cluster.</span></span> <span data-ttu-id="11f13-572">Managing cluster resources can mean a couple of different things.</span><span class="sxs-lookup"><span data-stu-id="11f13-572">Managing cluster resources can mean a couple of different things.</span></span> <span data-ttu-id="11f13-573">First, there's ensuring that machines are not overloaded.</span><span class="sxs-lookup"><span data-stu-id="11f13-573">First, there's ensuring that machines are not overloaded.</span></span> <span data-ttu-id="11f13-574">This means making sure that machines aren't running more services than they can handle.</span><span class="sxs-lookup"><span data-stu-id="11f13-574">This means making sure that machines aren't running more services than they can handle.</span></span> <span data-ttu-id="11f13-575">Second, there's balancing and optimization which is critical to running services efficiently.</span><span class="sxs-lookup"><span data-stu-id="11f13-575">Second, there's balancing and optimization which is critical to running services efficiently.</span></span> <span data-ttu-id="11f13-576">Cost effective or performance sensitive service offerings can't allow some nodes to be hot while others are cold.</span><span class="sxs-lookup"><span data-stu-id="11f13-576">Cost effective or performance sensitive service offerings can't allow some nodes to be hot while others are cold.</span></span> <span data-ttu-id="11f13-577">Hot nodes lead to resource contention and poor performance, and cold nodes represent wasted resources and increased costs.</span><span class="sxs-lookup"><span data-stu-id="11f13-577">Hot nodes lead to resource contention and poor performance, and cold nodes represent wasted resources and increased costs.</span></span> 

<span data-ttu-id="11f13-578">Service Fabric represents resources as `Metrics`.</span><span class="sxs-lookup"><span data-stu-id="11f13-578">Service Fabric represents resources as `Metrics`.</span></span> <span data-ttu-id="11f13-579">Metrics are any logical or physical resource that you want to describe to Service Fabric.</span><span class="sxs-lookup"><span data-stu-id="11f13-579">Metrics are any logical or physical resource that you want to describe to Service Fabric.</span></span> <span data-ttu-id="11f13-580">Examples of metrics are things like “WorkQueueDepth” or “MemoryInMb”.</span><span class="sxs-lookup"><span data-stu-id="11f13-580">Examples of metrics are things like “WorkQueueDepth” or “MemoryInMb”.</span></span> <span data-ttu-id="11f13-581">For information about the physical resources that Service Fabric can govern on nodes, see [resource governance](service-fabric-resource-governance.md).</span><span class="sxs-lookup"><span data-stu-id="11f13-581">For information about the physical resources that Service Fabric can govern on nodes, see [resource governance](service-fabric-resource-governance.md).</span></span> <span data-ttu-id="11f13-582">For information on configuring custom metrics and their uses, see [this article](service-fabric-cluster-resource-manager-metrics.md)</span><span class="sxs-lookup"><span data-stu-id="11f13-582">For information on configuring custom metrics and their uses, see [this article](service-fabric-cluster-resource-manager-metrics.md)</span></span>

<span data-ttu-id="11f13-583">Metrics are different from placements constraints and node properties.</span><span class="sxs-lookup"><span data-stu-id="11f13-583">Metrics are different from placements constraints and node properties.</span></span> <span data-ttu-id="11f13-584">Node properties are static descriptors of the nodes themselves.</span><span class="sxs-lookup"><span data-stu-id="11f13-584">Node properties are static descriptors of the nodes themselves.</span></span> <span data-ttu-id="11f13-585">Metrics describe resources that nodes have and that services consume when they are run on a node.</span><span class="sxs-lookup"><span data-stu-id="11f13-585">Metrics describe resources that nodes have and that services consume when they are run on a node.</span></span> <span data-ttu-id="11f13-586">A node property could be "HasSSD" and could be set to true or false.</span><span class="sxs-lookup"><span data-stu-id="11f13-586">A node property could be "HasSSD" and could be set to true or false.</span></span> <span data-ttu-id="11f13-587">The amount of space available on that SSD and how much is consumed by services would be a metric like “DriveSpaceInMb”.</span><span class="sxs-lookup"><span data-stu-id="11f13-587">The amount of space available on that SSD and how much is consumed by services would be a metric like “DriveSpaceInMb”.</span></span> 

<span data-ttu-id="11f13-588">It is important to note that just like for placement constraints and node properties, the Service Fabric Cluster Resource Manager doesn't understand what the names of the metrics mean.</span><span class="sxs-lookup"><span data-stu-id="11f13-588">It is important to note that just like for placement constraints and node properties, the Service Fabric Cluster Resource Manager doesn't understand what the names of the metrics mean.</span></span> <span data-ttu-id="11f13-589">Metric names are just strings.</span><span class="sxs-lookup"><span data-stu-id="11f13-589">Metric names are just strings.</span></span> <span data-ttu-id="11f13-590">It is a good practice to declare units as a part of the metric names that you create when it could be ambiguous.</span><span class="sxs-lookup"><span data-stu-id="11f13-590">It is a good practice to declare units as a part of the metric names that you create when it could be ambiguous.</span></span>

## <a name="capacity"></a><span data-ttu-id="11f13-591">Capacity</span><span class="sxs-lookup"><span data-stu-id="11f13-591">Capacity</span></span>
<span data-ttu-id="11f13-592">If you turned off all resource *balancing*, Service Fabric’s Cluster Resource Manager would still ensure that no node ended up over its capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-592">If you turned off all resource *balancing*, Service Fabric’s Cluster Resource Manager would still ensure that no node ended up over its capacity.</span></span> <span data-ttu-id="11f13-593">Managing capacity overruns is possible unless the cluster is too full or the workload is larger than any node.</span><span class="sxs-lookup"><span data-stu-id="11f13-593">Managing capacity overruns is possible unless the cluster is too full or the workload is larger than any node.</span></span> <span data-ttu-id="11f13-594">Capacity is another *constraint* that the Cluster Resource Manager uses to understand how much of a resource a node has.</span><span class="sxs-lookup"><span data-stu-id="11f13-594">Capacity is another *constraint* that the Cluster Resource Manager uses to understand how much of a resource a node has.</span></span> <span data-ttu-id="11f13-595">Remaining capacity is also tracked for the cluster as a whole.</span><span class="sxs-lookup"><span data-stu-id="11f13-595">Remaining capacity is also tracked for the cluster as a whole.</span></span> <span data-ttu-id="11f13-596">Both the capacity and the consumption at the service level are expressed in terms of metrics.</span><span class="sxs-lookup"><span data-stu-id="11f13-596">Both the capacity and the consumption at the service level are expressed in terms of metrics.</span></span> <span data-ttu-id="11f13-597">So for example, the metric might be "ClientConnections" and a given Node may have a capacity for "ClientConnections" of 32768.</span><span class="sxs-lookup"><span data-stu-id="11f13-597">So for example, the metric might be "ClientConnections" and a given Node may have a capacity for "ClientConnections" of 32768.</span></span> <span data-ttu-id="11f13-598">Other nodes can have other limits Some service running on that node can say it is currently consuming 32256 of the metric "ClientConnections".</span><span class="sxs-lookup"><span data-stu-id="11f13-598">Other nodes can have other limits Some service running on that node can say it is currently consuming 32256 of the metric "ClientConnections".</span></span>

<span data-ttu-id="11f13-599">During runtime, the Cluster Resource Manager tracks remaining capacity in the cluster and on nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-599">During runtime, the Cluster Resource Manager tracks remaining capacity in the cluster and on nodes.</span></span> <span data-ttu-id="11f13-600">In order to track capacity the Cluster Resource Manager subtracts each service's usage from node's capacity where the service runs.</span><span class="sxs-lookup"><span data-stu-id="11f13-600">In order to track capacity the Cluster Resource Manager subtracts each service's usage from node's capacity where the service runs.</span></span> <span data-ttu-id="11f13-601">With this information, the Service Fabric Cluster Resource Manager can figure out where to place or move replicas so that nodes don’t go over capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-601">With this information, the Service Fabric Cluster Resource Manager can figure out where to place or move replicas so that nodes don’t go over capacity.</span></span>

<span data-ttu-id="11f13-602"><center>
![Cluster nodes and capacity][Image7]
</center></span><span class="sxs-lookup"><span data-stu-id="11f13-602"><center>
![Cluster nodes and capacity][Image7]
</center></span></span>

<span data-ttu-id="11f13-603">C#:</span><span class="sxs-lookup"><span data-stu-id="11f13-603">C#:</span></span>

```csharp
StatefulServiceDescription serviceDescription = new StatefulServiceDescription();
ServiceLoadMetricDescription metric = new ServiceLoadMetricDescription();
metric.Name = "ClientConnections";
metric.PrimaryDefaultLoad = 1024;
metric.SecondaryDefaultLoad = 0;
metric.Weight = ServiceLoadMetricWeight.High;
serviceDescription.Metrics.Add(metric);
await fabricClient.ServiceManager.CreateServiceAsync(serviceDescription);
```

<span data-ttu-id="11f13-604">Powershell:</span><span class="sxs-lookup"><span data-stu-id="11f13-604">Powershell:</span></span>

```posh
New-ServiceFabricService -ApplicationName $applicationName -ServiceName $serviceName -ServiceTypeName $serviceTypeName –Stateful -MinReplicaSetSize 3 -TargetReplicaSetSize 3 -PartitionSchemeSingleton –Metric @("ClientConnections,High,1024,0)
```

<span data-ttu-id="11f13-605">You can see capacities defined in the cluster manifest:</span><span class="sxs-lookup"><span data-stu-id="11f13-605">You can see capacities defined in the cluster manifest:</span></span>

<span data-ttu-id="11f13-606">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="11f13-606">ClusterManifest.xml</span></span>

```xml
    <NodeType Name="NodeType03">
      <Capacities>
        <Capacity Name="ClientConnections" Value="65536"/>
      </Capacities>
    </NodeType>
```

<span data-ttu-id="11f13-607">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters.</span><span class="sxs-lookup"><span data-stu-id="11f13-607">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters.</span></span> 

```json
"nodeTypes": [
    {
        "name": "NodeType03",
        "capacities": {
            "ClientConnections": "65536",
        }
    }
],
```

<span data-ttu-id="11f13-608">Commonly a service’s load changes dynamically.</span><span class="sxs-lookup"><span data-stu-id="11f13-608">Commonly a service’s load changes dynamically.</span></span> <span data-ttu-id="11f13-609">Say that a replica's load of "ClientConnections" changed from 1024 to 2048, but the node it was running on then only had 512 capacity remaining for that metric.</span><span class="sxs-lookup"><span data-stu-id="11f13-609">Say that a replica's load of "ClientConnections" changed from 1024 to 2048, but the node it was running on then only had 512 capacity remaining for that metric.</span></span> <span data-ttu-id="11f13-610">Now that replica or instance's placement is invalid, since there's not enough room on that node.</span><span class="sxs-lookup"><span data-stu-id="11f13-610">Now that replica or instance's placement is invalid, since there's not enough room on that node.</span></span> <span data-ttu-id="11f13-611">The Cluster Resource Manager has to kick in and get the node back below capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-611">The Cluster Resource Manager has to kick in and get the node back below capacity.</span></span> <span data-ttu-id="11f13-612">It reduces load on the node that is over capacity by moving one or more of the replicas or instances from that node to other nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-612">It reduces load on the node that is over capacity by moving one or more of the replicas or instances from that node to other nodes.</span></span> <span data-ttu-id="11f13-613">When moving replicas, the Cluster Resource Manager tries to minimize the cost of those movements.</span><span class="sxs-lookup"><span data-stu-id="11f13-613">When moving replicas, the Cluster Resource Manager tries to minimize the cost of those movements.</span></span> <span data-ttu-id="11f13-614">Movement cost is discussed in [this article](service-fabric-cluster-resource-manager-movement-cost.md) and more about the Cluster Resource Manager's rebalancing strategies and rules is described [here](service-fabric-cluster-resource-manager-metrics.md).</span><span class="sxs-lookup"><span data-stu-id="11f13-614">Movement cost is discussed in [this article](service-fabric-cluster-resource-manager-movement-cost.md) and more about the Cluster Resource Manager's rebalancing strategies and rules is described [here](service-fabric-cluster-resource-manager-metrics.md).</span></span>

## <a name="cluster-capacity"></a><span data-ttu-id="11f13-615">Cluster capacity</span><span class="sxs-lookup"><span data-stu-id="11f13-615">Cluster capacity</span></span>
<span data-ttu-id="11f13-616">So how does the Service Fabric Cluster Resource Manager keep the overall cluster from being too full?</span><span class="sxs-lookup"><span data-stu-id="11f13-616">So how does the Service Fabric Cluster Resource Manager keep the overall cluster from being too full?</span></span> <span data-ttu-id="11f13-617">Well, with dynamic load there’s not a lot it can do.</span><span class="sxs-lookup"><span data-stu-id="11f13-617">Well, with dynamic load there’s not a lot it can do.</span></span> <span data-ttu-id="11f13-618">Services can have their load spike independently of actions taken by the Cluster Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="11f13-618">Services can have their load spike independently of actions taken by the Cluster Resource Manager.</span></span> <span data-ttu-id="11f13-619">As a result, your cluster with plenty of headroom today may be underpowered when you become famous tomorrow.</span><span class="sxs-lookup"><span data-stu-id="11f13-619">As a result, your cluster with plenty of headroom today may be underpowered when you become famous tomorrow.</span></span> <span data-ttu-id="11f13-620">That said, there are some controls that are baked in to prevent problems.</span><span class="sxs-lookup"><span data-stu-id="11f13-620">That said, there are some controls that are baked in to prevent problems.</span></span> <span data-ttu-id="11f13-621">The first thing we can do is prevent the creation of new workloads that would cause the cluster to become full.</span><span class="sxs-lookup"><span data-stu-id="11f13-621">The first thing we can do is prevent the creation of new workloads that would cause the cluster to become full.</span></span>

<span data-ttu-id="11f13-622">Say that you create a stateless service and it has some load associated with it.</span><span class="sxs-lookup"><span data-stu-id="11f13-622">Say that you create a stateless service and it has some load associated with it.</span></span> <span data-ttu-id="11f13-623">Let’s say that the service cares about the "DiskSpaceInMb" metric.</span><span class="sxs-lookup"><span data-stu-id="11f13-623">Let’s say that the service cares about the "DiskSpaceInMb" metric.</span></span> <span data-ttu-id="11f13-624">Let's also say that it is going to consume five units of "DiskSpaceInMb" for every instance of the service.</span><span class="sxs-lookup"><span data-stu-id="11f13-624">Let's also say that it is going to consume five units of "DiskSpaceInMb" for every instance of the service.</span></span> <span data-ttu-id="11f13-625">You want to create three instances of the service.</span><span class="sxs-lookup"><span data-stu-id="11f13-625">You want to create three instances of the service.</span></span> <span data-ttu-id="11f13-626">Great!</span><span class="sxs-lookup"><span data-stu-id="11f13-626">Great!</span></span> <span data-ttu-id="11f13-627">So that means that we need 15 units of "DiskSpaceInMb" to be present in the cluster in order for us to even be able to create these service instances.</span><span class="sxs-lookup"><span data-stu-id="11f13-627">So that means that we need 15 units of "DiskSpaceInMb" to be present in the cluster in order for us to even be able to create these service instances.</span></span> <span data-ttu-id="11f13-628">The Cluster Resource Manager continually calculates the capacity and consumption of each metric so it can determine the remaining capacity in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-628">The Cluster Resource Manager continually calculates the capacity and consumption of each metric so it can determine the remaining capacity in the cluster.</span></span> <span data-ttu-id="11f13-629">If there isn't enough space, the Cluster Resource Manager rejects the create service call.</span><span class="sxs-lookup"><span data-stu-id="11f13-629">If there isn't enough space, the Cluster Resource Manager rejects the create service call.</span></span>

<span data-ttu-id="11f13-630">Since the requirement is only that there be 15 units available, this space could be allocated many different ways.</span><span class="sxs-lookup"><span data-stu-id="11f13-630">Since the requirement is only that there be 15 units available, this space could be allocated many different ways.</span></span> <span data-ttu-id="11f13-631">For example, there could be one remaining unit of capacity on 15 different nodes, or three remaining units of capacity on five different nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-631">For example, there could be one remaining unit of capacity on 15 different nodes, or three remaining units of capacity on five different nodes.</span></span> <span data-ttu-id="11f13-632">If the Cluster Resource Manager can rearrange things so there's five units available on three nodes, it places the service.</span><span class="sxs-lookup"><span data-stu-id="11f13-632">If the Cluster Resource Manager can rearrange things so there's five units available on three nodes, it places the service.</span></span> <span data-ttu-id="11f13-633">Rearranging the cluster is usually possible unless the cluster is almost full or the existing services can't be consolidated for some reason.</span><span class="sxs-lookup"><span data-stu-id="11f13-633">Rearranging the cluster is usually possible unless the cluster is almost full or the existing services can't be consolidated for some reason.</span></span>

## <a name="buffered-capacity"></a><span data-ttu-id="11f13-634">Buffered Capacity</span><span class="sxs-lookup"><span data-stu-id="11f13-634">Buffered Capacity</span></span>
<span data-ttu-id="11f13-635">Buffered capacity is another feature of the Cluster Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="11f13-635">Buffered capacity is another feature of the Cluster Resource Manager.</span></span> <span data-ttu-id="11f13-636">It allows reservation of some portion of the overall node capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-636">It allows reservation of some portion of the overall node capacity.</span></span> <span data-ttu-id="11f13-637">This capacity buffer is only used to place services during upgrades and node failures.</span><span class="sxs-lookup"><span data-stu-id="11f13-637">This capacity buffer is only used to place services during upgrades and node failures.</span></span> <span data-ttu-id="11f13-638">Buffered Capacity is specified globally per metric for all nodes.</span><span class="sxs-lookup"><span data-stu-id="11f13-638">Buffered Capacity is specified globally per metric for all nodes.</span></span> <span data-ttu-id="11f13-639">The value you pick for the reserved capacity is a function of the number of Fault and Upgrade Domains you have in the cluster.</span><span class="sxs-lookup"><span data-stu-id="11f13-639">The value you pick for the reserved capacity is a function of the number of Fault and Upgrade Domains you have in the cluster.</span></span> <span data-ttu-id="11f13-640">More Fault and Upgrade Domains means that you can pick a lower number for your buffered capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-640">More Fault and Upgrade Domains means that you can pick a lower number for your buffered capacity.</span></span> <span data-ttu-id="11f13-641">If you have more domains, you can expect smaller amounts of your cluster to be unavailable during upgrades and failures.</span><span class="sxs-lookup"><span data-stu-id="11f13-641">If you have more domains, you can expect smaller amounts of your cluster to be unavailable during upgrades and failures.</span></span> <span data-ttu-id="11f13-642">Specifying Buffered Capacity only makes sense if you have also specified the node capacity for a metric.</span><span class="sxs-lookup"><span data-stu-id="11f13-642">Specifying Buffered Capacity only makes sense if you have also specified the node capacity for a metric.</span></span>

<span data-ttu-id="11f13-643">Here's an example of how to specify buffered capacity:</span><span class="sxs-lookup"><span data-stu-id="11f13-643">Here's an example of how to specify buffered capacity:</span></span>

<span data-ttu-id="11f13-644">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="11f13-644">ClusterManifest.xml</span></span>

```xml
        <Section Name="NodeBufferPercentage">
            <Parameter Name="SomeMetric" Value="0.15" />
            <Parameter Name="SomeOtherMetric" Value="0.20" />
        </Section>
```

<span data-ttu-id="11f13-645">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters:</span><span class="sxs-lookup"><span data-stu-id="11f13-645">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters:</span></span>

```json
"fabricSettings": [
  {
    "name": "NodeBufferPercentage",
    "parameters": [
      {
          "name": "SomeMetric",
          "value": "0.15"
      },
      {
          "name": "SomeOtherMetric",
          "value": "0.20"
      }
    ]
  }
]
```

<span data-ttu-id="11f13-646">The creation of new services fails when the cluster is out of buffered capacity for a metric.</span><span class="sxs-lookup"><span data-stu-id="11f13-646">The creation of new services fails when the cluster is out of buffered capacity for a metric.</span></span> <span data-ttu-id="11f13-647">Preventing the creation of new services to preserve the buffer ensures that upgrades and failures don’t cause nodes to go over capacity.</span><span class="sxs-lookup"><span data-stu-id="11f13-647">Preventing the creation of new services to preserve the buffer ensures that upgrades and failures don’t cause nodes to go over capacity.</span></span> <span data-ttu-id="11f13-648">Buffered capacity is optional but is recommended in any cluster that defines a capacity for a metric.</span><span class="sxs-lookup"><span data-stu-id="11f13-648">Buffered capacity is optional but is recommended in any cluster that defines a capacity for a metric.</span></span>

<span data-ttu-id="11f13-649">The Cluster Resource Manager exposes this load information.</span><span class="sxs-lookup"><span data-stu-id="11f13-649">The Cluster Resource Manager exposes this load information.</span></span> <span data-ttu-id="11f13-650">For each metric, this information includes:</span><span class="sxs-lookup"><span data-stu-id="11f13-650">For each metric, this information includes:</span></span> 
  - <span data-ttu-id="11f13-651">the buffered capacity settings</span><span class="sxs-lookup"><span data-stu-id="11f13-651">the buffered capacity settings</span></span>
  - <span data-ttu-id="11f13-652">the total capacity</span><span class="sxs-lookup"><span data-stu-id="11f13-652">the total capacity</span></span>
  - <span data-ttu-id="11f13-653">the current consumption</span><span class="sxs-lookup"><span data-stu-id="11f13-653">the current consumption</span></span>
  - <span data-ttu-id="11f13-654">whether each metric is considered balanced or not</span><span class="sxs-lookup"><span data-stu-id="11f13-654">whether each metric is considered balanced or not</span></span>
  - <span data-ttu-id="11f13-655">statistics about the standard deviation</span><span class="sxs-lookup"><span data-stu-id="11f13-655">statistics about the standard deviation</span></span>
  - <span data-ttu-id="11f13-656">the nodes which have the most and least load</span><span class="sxs-lookup"><span data-stu-id="11f13-656">the nodes which have the most and least load</span></span>  
  
<span data-ttu-id="11f13-657">Below we see an example of that output:</span><span class="sxs-lookup"><span data-stu-id="11f13-657">Below we see an example of that output:</span></span>

```posh
PS C:\Users\user> Get-ServiceFabricClusterLoadInformation
LastBalancingStartTimeUtc : 9/1/2016 12:54:59 AM
LastBalancingEndTimeUtc   : 9/1/2016 12:54:59 AM
LoadMetricInformation     :
                            LoadMetricName        : Metric1
                            IsBalancedBefore      : False
                            IsBalancedAfter       : False
                            DeviationBefore       : 0.192450089729875
                            DeviationAfter        : 0.192450089729875
                            BalancingThreshold    : 1
                            Action                : NoActionNeeded
                            ActivityThreshold     : 0
                            ClusterCapacity       : 189
                            ClusterLoad           : 45
                            ClusterRemainingCapacity : 144
                            NodeBufferPercentage  : 10
                            ClusterBufferedCapacity : 170
                            ClusterRemainingBufferedCapacity : 125
                            ClusterCapacityViolation : False
                            MinNodeLoadValue      : 0
                            MinNodeLoadNodeId     : 3ea71e8e01f4b0999b121abcbf27d74d
                            MaxNodeLoadValue      : 15
                            MaxNodeLoadNodeId     : 2cc648b6770be1bc9824fa995d5b68b1
```

## <a name="next-steps"></a><span data-ttu-id="11f13-658">Next steps</span><span class="sxs-lookup"><span data-stu-id="11f13-658">Next steps</span></span>
* <span data-ttu-id="11f13-659">For information on the architecture and information flow within the Cluster Resource Manager, check out [this article ](service-fabric-cluster-resource-manager-architecture.md)</span><span class="sxs-lookup"><span data-stu-id="11f13-659">For information on the architecture and information flow within the Cluster Resource Manager, check out [this article ](service-fabric-cluster-resource-manager-architecture.md)</span></span>
* <span data-ttu-id="11f13-660">Defining Defragmentation Metrics is one way to consolidate load on nodes instead of spreading it out. To learn how to configure defragmentation, refer to [this article](service-fabric-cluster-resource-manager-defragmentation-metrics.md)</span><span class="sxs-lookup"><span data-stu-id="11f13-660">Defining Defragmentation Metrics is one way to consolidate load on nodes instead of spreading it out. To learn how to configure defragmentation, refer to [this article](service-fabric-cluster-resource-manager-defragmentation-metrics.md)</span></span>
* <span data-ttu-id="11f13-661">Start from the beginning and [get an Introduction to the Service Fabric Cluster Resource Manager](service-fabric-cluster-resource-manager-introduction.md)</span><span class="sxs-lookup"><span data-stu-id="11f13-661">Start from the beginning and [get an Introduction to the Service Fabric Cluster Resource Manager](service-fabric-cluster-resource-manager-introduction.md)</span></span>
* <span data-ttu-id="11f13-662">To find out about how the Cluster Resource Manager manages and balances load in the cluster, check out the article on [balancing load](service-fabric-cluster-resource-manager-balancing.md)</span><span class="sxs-lookup"><span data-stu-id="11f13-662">To find out about how the Cluster Resource Manager manages and balances load in the cluster, check out the article on [balancing load](service-fabric-cluster-resource-manager-balancing.md)</span></span>

[Image1]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-fault-domains.png
[Image2]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-uneven-fault-domain-layout.png
[Image3]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-fault-and-upgrade-domains-with-placement.png
[Image4]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-fault-and-upgrade-domain-layout-strategies.png
[Image5]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-layout-different-workloads.png
[Image6]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-placement-constraints-node-properties.png
[Image7]:./media/service-fabric-cluster-resource-manager-cluster-description/cluster-nodes-and-capacity.png
