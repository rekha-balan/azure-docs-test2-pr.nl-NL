---
title: Streaming at scale in Azure HDInsight
description: How to use data streaming with scalable HDInsight clusters.
services: hdinsight
author: jasonwhowell
ms.author: jasonh
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 01/19/2018
ms.openlocfilehash: 35304a51ff7fda8bbf7ef6ebb0366ebe740abfa6
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44855926"
---
# <a name="streaming-at-scale-in-hdinsight"></a><span data-ttu-id="bcc5f-103">Streaming at scale in HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcc5f-103">Streaming at scale in HDInsight</span></span>

<span data-ttu-id="bcc5f-104">Realtime big data solutions  act on data that is in motion.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-104">Realtime big data solutions  act on data that is in motion.</span></span> <span data-ttu-id="bcc5f-105">Typically, this data is most valuable at its time of arrival.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-105">Typically, this data is most valuable at its time of arrival.</span></span> <span data-ttu-id="bcc5f-106">If the incoming data stream becomes greater than can be handled at that moment, you may need to throttle down resources.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-106">If the incoming data stream becomes greater than can be handled at that moment, you may need to throttle down resources.</span></span> <span data-ttu-id="bcc5f-107">Alternatively, an HDInsight cluster can   scale up to meet your streaming solution by adding nodes on demand.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-107">Alternatively, an HDInsight cluster can   scale up to meet your streaming solution by adding nodes on demand.</span></span>

<span data-ttu-id="bcc5f-108">In a streaming application, one or more data sources are generating events (sometimes in the millions per second) that need to be ingested  quickly  without dropping any useful information.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-108">In a streaming application, one or more data sources are generating events (sometimes in the millions per second) that need to be ingested  quickly  without dropping any useful information.</span></span> <span data-ttu-id="bcc5f-109">The incoming events are handled with *stream buffering*, also called *event queuing*, by a service such as [Kafka](kafka/apache-kafka-introduction.md) or [Event Hubs](https://azure.microsoft.com/services/event-hubs/).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-109">The incoming events are handled with *stream buffering*, also called *event queuing*, by a service such as [Kafka](kafka/apache-kafka-introduction.md) or [Event Hubs](https://azure.microsoft.com/services/event-hubs/).</span></span> <span data-ttu-id="bcc5f-110">After you collect the events, you can then analyze the data using a real-time analytics system within the *stream processing* layer, such as [Storm](storm/apache-storm-overview.md) or [Spark Streaming](spark/apache-spark-streaming-overview.md).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-110">After you collect the events, you can then analyze the data using a real-time analytics system within the *stream processing* layer, such as [Storm](storm/apache-storm-overview.md) or [Spark Streaming](spark/apache-spark-streaming-overview.md).</span></span> <span data-ttu-id="bcc5f-111">The processed data can be stored in long-term storage systems, like [Azure Data Lake Store](https://azure.microsoft.com/services/data-lake-store/), and displayed in real time on a business intelligence dashboard, such as [Power BI](https://powerbi.microsoft.com), Tableau, or a custom web page.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-111">The processed data can be stored in long-term storage systems, like [Azure Data Lake Store](https://azure.microsoft.com/services/data-lake-store/), and displayed in real time on a business intelligence dashboard, such as [Power BI](https://powerbi.microsoft.com), Tableau, or a custom web page.</span></span>

![HDInsight Streaming Patterns](./media/hdinsight-streaming-at-scale-overview/HDInsight-streaming-patterns.png)

## <a name="apache-kafka"></a><span data-ttu-id="bcc5f-113">Apache Kafka</span><span class="sxs-lookup"><span data-stu-id="bcc5f-113">Apache Kafka</span></span>

<span data-ttu-id="bcc5f-114">Apache Kafka provides a high-throughput, low-latency message queueing service, and is now part of the Apache suite of Open Source Software (OSS).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-114">Apache Kafka provides a high-throughput, low-latency message queueing service, and is now part of the Apache suite of Open Source Software (OSS).</span></span> <span data-ttu-id="bcc5f-115">Kafka uses a publish and subscribe messaging model and stores streams of partitioned data safely in a distributed, replicated cluster.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-115">Kafka uses a publish and subscribe messaging model and stores streams of partitioned data safely in a distributed, replicated cluster.</span></span> <span data-ttu-id="bcc5f-116">Kafka  scales linearly as throughput increases.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-116">Kafka  scales linearly as throughput increases.</span></span>

<span data-ttu-id="bcc5f-117">For more information, see [Introducing Apache Kafka on HDInsight](kafka/apache-kafka-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-117">For more information, see [Introducing Apache Kafka on HDInsight](kafka/apache-kafka-introduction.md).</span></span>

## <a name="apache-storm"></a><span data-ttu-id="bcc5f-118">Apache Storm</span><span class="sxs-lookup"><span data-stu-id="bcc5f-118">Apache Storm</span></span>

<span data-ttu-id="bcc5f-119">Apache Storm is a distributed, fault-tolerant, open-source computation system that is optimized for processing streams of data in real time with Hadoop.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-119">Apache Storm is a distributed, fault-tolerant, open-source computation system that is optimized for processing streams of data in real time with Hadoop.</span></span> <span data-ttu-id="bcc5f-120">The core unit of data for an incoming event is  a Tuple, which is an immutable set of key/value pairs.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-120">The core unit of data for an incoming event is  a Tuple, which is an immutable set of key/value pairs.</span></span> <span data-ttu-id="bcc5f-121">An unbounded sequence of these Tuples forms a Stream, which is comes from a Spout.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-121">An unbounded sequence of these Tuples forms a Stream, which is comes from a Spout.</span></span> <span data-ttu-id="bcc5f-122">The Spout wraps a streaming data source (such as Kafka), and emits Tuples.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-122">The Spout wraps a streaming data source (such as Kafka), and emits Tuples.</span></span> <span data-ttu-id="bcc5f-123">A storm Topology is a sequence of transformations on these streams.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-123">A storm Topology is a sequence of transformations on these streams.</span></span>

<span data-ttu-id="bcc5f-124">For more information, see [What is Apache Storm on Azure HDInsight?](storm/apache-storm-overview.md).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-124">For more information, see [What is Apache Storm on Azure HDInsight?](storm/apache-storm-overview.md).</span></span>

## <a name="spark-streaming"></a><span data-ttu-id="bcc5f-125">Spark Streaming</span><span class="sxs-lookup"><span data-stu-id="bcc5f-125">Spark Streaming</span></span>

<span data-ttu-id="bcc5f-126">Spark Streaming  is an extension to Spark, which allows you to reuse the same code that you use for batch processing.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-126">Spark Streaming  is an extension to Spark, which allows you to reuse the same code that you use for batch processing.</span></span> <span data-ttu-id="bcc5f-127">You can  combine both batch and interactive queries in the same application.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-127">You can  combine both batch and interactive queries in the same application.</span></span> <span data-ttu-id="bcc5f-128">Unlike Storm, Spark Streaming provides stateful exactly-once processing semantics.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-128">Unlike Storm, Spark Streaming provides stateful exactly-once processing semantics.</span></span> <span data-ttu-id="bcc5f-129">When used in combination with the [Kafka Direct API](http://spark.apache.org/docs/latest/streaming-kafka-integration.html), which ensures that all Kafka data is received by Spark Streaming exactly once, it is possible to achieve end-to-end exactly-once guarantees.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-129">When used in combination with the [Kafka Direct API](http://spark.apache.org/docs/latest/streaming-kafka-integration.html), which ensures that all Kafka data is received by Spark Streaming exactly once, it is possible to achieve end-to-end exactly-once guarantees.</span></span> <span data-ttu-id="bcc5f-130">One of Spark Streaming's strengths is its fault-tolerant capabilities, recovering faulted nodes rapidly when multiple nodes are being used within the cluster.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-130">One of Spark Streaming's strengths is its fault-tolerant capabilities, recovering faulted nodes rapidly when multiple nodes are being used within the cluster.</span></span>

<span data-ttu-id="bcc5f-131">For more information, see [What is Spark Streaming?](hdinsight-spark-streaming-overview.md).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-131">For more information, see [What is Spark Streaming?](hdinsight-spark-streaming-overview.md).</span></span>

## <a name="scaling-a-cluster"></a><span data-ttu-id="bcc5f-132">Scaling a cluster</span><span class="sxs-lookup"><span data-stu-id="bcc5f-132">Scaling a cluster</span></span>

<span data-ttu-id="bcc5f-133">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match the workload.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-133">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match the workload.</span></span> <span data-ttu-id="bcc5f-134">All HDInsight clusters allow you to [change the number of nodes in the cluster](hdinsight-administer-use-management-portal.md#scale-clusters).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-134">All HDInsight clusters allow you to [change the number of nodes in the cluster](hdinsight-administer-use-management-portal.md#scale-clusters).</span></span> <span data-ttu-id="bcc5f-135">Spark clusters can be dropped with no loss of data, as all  data is stored in Azure Storage or Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-135">Spark clusters can be dropped with no loss of data, as all  data is stored in Azure Storage or Data Lake Store.</span></span>

<span data-ttu-id="bcc5f-136">There are advantages to decoupling technologies.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-136">There are advantages to decoupling technologies.</span></span> <span data-ttu-id="bcc5f-137">For instance, Kafka is an event buffering technology, so it is very IO intensive and does not need much processing power.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-137">For instance, Kafka is an event buffering technology, so it is very IO intensive and does not need much processing power.</span></span> <span data-ttu-id="bcc5f-138">In comparison, stream processors such as Spark Streaming are compute-intensive, requiring more powerful VMs.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-138">In comparison, stream processors such as Spark Streaming are compute-intensive, requiring more powerful VMs.</span></span> <span data-ttu-id="bcc5f-139">By having these technologies decoupled into different clusters, you can scale them independently while best utilizing the VMs.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-139">By having these technologies decoupled into different clusters, you can scale them independently while best utilizing the VMs.</span></span>

### <a name="scale-the-stream-buffering-layer"></a><span data-ttu-id="bcc5f-140">Scale the stream buffering layer</span><span class="sxs-lookup"><span data-stu-id="bcc5f-140">Scale the stream buffering layer</span></span>

<span data-ttu-id="bcc5f-141">The stream buffering technologies Event Hubs and Kafka both use partitions, and consumers read from those partitions.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-141">The stream buffering technologies Event Hubs and Kafka both use partitions, and consumers read from those partitions.</span></span> <span data-ttu-id="bcc5f-142">Scaling the input throughput requires scaling up the number of partitions, and adding partitions provides increasing parallelism.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-142">Scaling the input throughput requires scaling up the number of partitions, and adding partitions provides increasing parallelism.</span></span> <span data-ttu-id="bcc5f-143">In Event Hubs, the partition count cannot be changed after deployment so it is important to start with the target scale in mind.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-143">In Event Hubs, the partition count cannot be changed after deployment so it is important to start with the target scale in mind.</span></span> <span data-ttu-id="bcc5f-144">With Kafka, it is possible to [add partitions](https://kafka.apache.org/documentation.html#basic_ops_cluster_expansion), even while Kafka is processing data.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-144">With Kafka, it is possible to [add partitions](https://kafka.apache.org/documentation.html#basic_ops_cluster_expansion), even while Kafka is processing data.</span></span> <span data-ttu-id="bcc5f-145">Kafka provides a tool to reassign partitions,  `kafka-reassign-partitions.sh`.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-145">Kafka provides a tool to reassign partitions,  `kafka-reassign-partitions.sh`.</span></span> <span data-ttu-id="bcc5f-146">HDInsight provides a [partition replica rebalancing tool](https://github.com/hdinsight/hdinsight-kafka-tools),  `rebalance_rackaware.py`.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-146">HDInsight provides a [partition replica rebalancing tool](https://github.com/hdinsight/hdinsight-kafka-tools),  `rebalance_rackaware.py`.</span></span> <span data-ttu-id="bcc5f-147">This rebalancing tool calls the `kafka-reassign-partitions.sh` tool in such a way that each replica is in a separate fault domain and update domain, making Kafka rack aware and increasing fault tolerance.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-147">This rebalancing tool calls the `kafka-reassign-partitions.sh` tool in such a way that each replica is in a separate fault domain and update domain, making Kafka rack aware and increasing fault tolerance.</span></span>

### <a name="scale-the-stream-processing-layer"></a><span data-ttu-id="bcc5f-148">Scale the stream processing layer</span><span class="sxs-lookup"><span data-stu-id="bcc5f-148">Scale the stream processing layer</span></span>

<span data-ttu-id="bcc5f-149">Both Apache Storm and Spark Streaming support adding worker nodes to their clusters, even while data is being processed.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-149">Both Apache Storm and Spark Streaming support adding worker nodes to their clusters, even while data is being processed.</span></span>

<span data-ttu-id="bcc5f-150">To take advantage of new nodes added through scaling  Storm, you need to rebalance any Storm topologies started before the cluster size was increased.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-150">To take advantage of new nodes added through scaling  Storm, you need to rebalance any Storm topologies started before the cluster size was increased.</span></span> <span data-ttu-id="bcc5f-151">This rebalancing can be done using the Storm web UI or its CLI.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-151">This rebalancing can be done using the Storm web UI or its CLI.</span></span> <span data-ttu-id="bcc5f-152">For more information, see the [Apache Storm documentation](http://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-152">For more information, see the [Apache Storm documentation](http://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html).</span></span>

<span data-ttu-id="bcc5f-153">Apache Spark uses three key parameters for configuring its environment, depending on application requirements: `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-153">Apache Spark uses three key parameters for configuring its environment, depending on application requirements: `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="bcc5f-154">An *executor* is a process that is launched for a Spark application.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-154">An *executor* is a process that is launched for a Spark application.</span></span> <span data-ttu-id="bcc5f-155">An executor runs on the worker node and is responsible for carrying out the  application's tasks.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-155">An executor runs on the worker node and is responsible for carrying out the  application's tasks.</span></span> <span data-ttu-id="bcc5f-156">The default number of executors and the executor sizes for each cluster are calculated based on the number of worker nodes and the worker node size.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-156">The default number of executors and the executor sizes for each cluster are calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="bcc5f-157">These numbers are stored in the `spark-defaults.conf`file on each cluster head node.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-157">These numbers are stored in the `spark-defaults.conf`file on each cluster head node.</span></span>

<span data-ttu-id="bcc5f-158">These three  parameters can be configured at the cluster level, for all applications that run on the cluster, and can also  be specified for each individual application.</span><span class="sxs-lookup"><span data-stu-id="bcc5f-158">These three  parameters can be configured at the cluster level, for all applications that run on the cluster, and can also  be specified for each individual application.</span></span> <span data-ttu-id="bcc5f-159">For more information, see [Managing resources for Apache Spark clusters](spark/apache-spark-resource-manager.md).</span><span class="sxs-lookup"><span data-stu-id="bcc5f-159">For more information, see [Managing resources for Apache Spark clusters](spark/apache-spark-resource-manager.md).</span></span>

## <a name="next-steps"></a><span data-ttu-id="bcc5f-160">Next steps</span><span class="sxs-lookup"><span data-stu-id="bcc5f-160">Next steps</span></span>

* [<span data-ttu-id="bcc5f-161">Get started with Apache Storm on HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcc5f-161">Get started with Apache Storm on HDInsight</span></span>](storm/apache-storm-tutorial-get-started-linux.md)
* [<span data-ttu-id="bcc5f-162">Example topologies for Apache Storm on HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcc5f-162">Example topologies for Apache Storm on HDInsight</span></span>](storm/apache-storm-example-topology.md)
* [<span data-ttu-id="bcc5f-163">Introduction to Spark on HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcc5f-163">Introduction to Spark on HDInsight</span></span>](spark/apache-spark-overview.md)
* [<span data-ttu-id="bcc5f-164">Start with Apache Kafka on HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcc5f-164">Start with Apache Kafka on HDInsight</span></span>](kafka/apache-kafka-get-started.md)
