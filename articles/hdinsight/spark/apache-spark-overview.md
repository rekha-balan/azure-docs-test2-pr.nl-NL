---
title: What is Apache Spark in Azure HDInsight
description: This article provides an introduction to Spark in HDInsight and the different scenarios in which you can use Spark cluster in HDInsight.
services: hdinsight
author: jasonwhowell
ms.reviewer: jasonh
ms.service: hdinsight
ms.custom: hdinsightactive,mvc
ms.topic: overview
ms.date: 05/07/2018
ms.author: jasonh
ms.openlocfilehash: 9e4cb497a2dc81b9503b03fd2db27ff2538d424a
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44856045"
---
# <a name="what-is-apache-spark-in-azure-hdinsight"></a><span data-ttu-id="6d5bd-103">What is Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="6d5bd-103">What is Apache Spark in Azure HDInsight</span></span>

<span data-ttu-id="6d5bd-104">*Apache Spark* parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-104">*Apache Spark* parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="6d5bd-105">Apache Spark in Azure HDInsight is the Microsoft's implementation of Apache Hadoop in the cloud.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-105">Apache Spark in Azure HDInsight is the Microsoft's implementation of Apache Hadoop in the cloud.</span></span> <span data-ttu-id="6d5bd-106">HDInsight makes it easier to create and configure a Spark cluster in Azure.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-106">HDInsight makes it easier to create and configure a Spark cluster in Azure.</span></span> <span data-ttu-id="6d5bd-107">Spark clusters in HDInsight are compatible with Azure Storage and Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-107">Spark clusters in HDInsight are compatible with Azure Storage and Azure Data Lake Store.</span></span> <span data-ttu-id="6d5bd-108">So you can use HDInsight Spark clusters to process your data stored in Azure.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-108">So you can use HDInsight Spark clusters to process your data stored in Azure.</span></span> <span data-ttu-id="6d5bd-109">For the components and the versioning information, see [Hadoop components and versions in Azure HDInsight](../hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-109">For the components and the versioning information, see [Hadoop components and versions in Azure HDInsight](../hdinsight-component-versioning.md).</span></span>

![Spark: a unified framework](./media/apache-spark-overview/hdinsight-spark-overview.png)


## <a name="what-is-spark"></a><span data-ttu-id="6d5bd-111">What is Spark?</span><span class="sxs-lookup"><span data-stu-id="6d5bd-111">What is Spark?</span></span>

<span data-ttu-id="6d5bd-112">Spark provides primitives for in-memory cluster computing.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-112">Spark provides primitives for in-memory cluster computing.</span></span> <span data-ttu-id="6d5bd-113">A Spark job can load and cache data into memory and query it repeatedly.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-113">A Spark job can load and cache data into memory and query it repeatedly.</span></span> <span data-ttu-id="6d5bd-114">In-memory computing is much faster than disk-based applications, such as Hadoop, which shares data through HDFS.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-114">In-memory computing is much faster than disk-based applications, such as Hadoop, which shares data through HDFS.</span></span> <span data-ttu-id="6d5bd-115">Spark also integrates into the Scala programming language to let you manipulate distributed data sets like local collections.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-115">Spark also integrates into the Scala programming language to let you manipulate distributed data sets like local collections.</span></span> <span data-ttu-id="6d5bd-116">There's no need to structure everything as map and reduce operations.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-116">There's no need to structure everything as map and reduce operations.</span></span>

![Traditional MapReduce vs. Spark](./media/apache-spark-overview/mapreduce-vs-spark.png)

<span data-ttu-id="6d5bd-118">Spark clusters in HDInsight offer a fully managed Spark service.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-118">Spark clusters in HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="6d5bd-119">Benefits of creating a Spark cluster in HDInsight are listed here.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-119">Benefits of creating a Spark cluster in HDInsight are listed here.</span></span>

| <span data-ttu-id="6d5bd-120">Feature</span><span class="sxs-lookup"><span data-stu-id="6d5bd-120">Feature</span></span> | <span data-ttu-id="6d5bd-121">Description</span><span class="sxs-lookup"><span data-stu-id="6d5bd-121">Description</span></span> |
| --- | --- |
| <span data-ttu-id="6d5bd-122">Ease creation</span><span class="sxs-lookup"><span data-stu-id="6d5bd-122">Ease creation</span></span> |<span data-ttu-id="6d5bd-123">You can create a new Spark cluster in HDInsight in minutes using the Azure portal, Azure PowerShell, or the HDInsight .NET SDK.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-123">You can create a new Spark cluster in HDInsight in minutes using the Azure portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="6d5bd-124">See [Get started with Spark cluster in HDInsight](apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="6d5bd-124">See [Get started with Spark cluster in HDInsight](apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="6d5bd-125">Ease of use</span><span class="sxs-lookup"><span data-stu-id="6d5bd-125">Ease of use</span></span> |<span data-ttu-id="6d5bd-126">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-126">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="6d5bd-127">You can use these notebooks for interactive data processing and visualization.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-127">You can use these notebooks for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="6d5bd-128">REST APIs</span><span class="sxs-lookup"><span data-stu-id="6d5bd-128">REST APIs</span></span> |<span data-ttu-id="6d5bd-129">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-129">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="6d5bd-130">Support for Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="6d5bd-130">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="6d5bd-131">Spark clusters in HDInsight can use Azure Data Lake Store as both the primary storage or additional storage.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-131">Spark clusters in HDInsight can use Azure Data Lake Store as both the primary storage or additional storage.</span></span> <span data-ttu-id="6d5bd-132">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-132">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="6d5bd-133">Integration with Azure services</span><span class="sxs-lookup"><span data-stu-id="6d5bd-133">Integration with Azure services</span></span> |<span data-ttu-id="6d5bd-134">Spark cluster in HDInsight comes with a connector to Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-134">Spark cluster in HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="6d5bd-135">You can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-135">You can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="6d5bd-136">Support for ML Server</span><span class="sxs-lookup"><span data-stu-id="6d5bd-136">Support for ML Server</span></span> | <span data-ttu-id="6d5bd-137">Support for ML Server in HDInsight is provided as the **ML Services** cluster type.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-137">Support for ML Server in HDInsight is provided as the **ML Services** cluster type.</span></span> <span data-ttu-id="6d5bd-138">You can set up an ML Services cluster to run distributed R computations with the speeds promised with a Spark cluster.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-138">You can set up an ML Services cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="6d5bd-139">For more information, see [Get started using ML Server in HDInsight](../r-server/r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-139">For more information, see [Get started using ML Server in HDInsight](../r-server/r-server-get-started.md).</span></span> |
| <span data-ttu-id="6d5bd-140">Integration with third-party IDEs</span><span class="sxs-lookup"><span data-stu-id="6d5bd-140">Integration with third-party IDEs</span></span> | <span data-ttu-id="6d5bd-141">HDInsight provides several IDE plugins that are useful to create and submit applications to an HDInsight Spark cluster.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-141">HDInsight provides several IDE plugins that are useful to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="6d5bd-142">For more information, see [Use Azure Toolkit for IntelliJ IDEA](apache-spark-intellij-tool-plugin.md), [Use HDInsight for VSCode](../hdinsight-for-vscode.md) and [Use Azure Toolkit for Eclipse](apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-142">For more information, see [Use Azure Toolkit for IntelliJ IDEA](apache-spark-intellij-tool-plugin.md), [Use HDInsight for VSCode](../hdinsight-for-vscode.md) and [Use Azure Toolkit for Eclipse](apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="6d5bd-143">Concurrent Queries</span><span class="sxs-lookup"><span data-stu-id="6d5bd-143">Concurrent Queries</span></span> |<span data-ttu-id="6d5bd-144">Spark clusters in HDInsight support concurrent queries.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-144">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="6d5bd-145">This capability enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-145">This capability enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="6d5bd-146">Caching on SSDs</span><span class="sxs-lookup"><span data-stu-id="6d5bd-146">Caching on SSDs</span></span> |<span data-ttu-id="6d5bd-147">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-147">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="6d5bd-148">Caching in memory provides the best query performance but could be expensive.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-148">Caching in memory provides the best query performance but could be expensive.</span></span> <span data-ttu-id="6d5bd-149">Caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-149">Caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="6d5bd-150">Integration with BI Tools</span><span class="sxs-lookup"><span data-stu-id="6d5bd-150">Integration with BI Tools</span></span> |<span data-ttu-id="6d5bd-151">Spark clusters in HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) for data analytics.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-151">Spark clusters in HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) for data analytics.</span></span> |
| <span data-ttu-id="6d5bd-152">Pre-loaded Anaconda libraries</span><span class="sxs-lookup"><span data-stu-id="6d5bd-152">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="6d5bd-153">Spark clusters in HDInsight come with Anaconda libraries pre-installed.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-153">Spark clusters in HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="6d5bd-154">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-154">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="6d5bd-155">Scalability</span><span class="sxs-lookup"><span data-stu-id="6d5bd-155">Scalability</span></span> | <span data-ttu-id="6d5bd-156">HDInsight allow you to change the number of cluster nodes.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-156">HDInsight allow you to change the number of cluster nodes.</span></span> <span data-ttu-id="6d5bd-157">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-157">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="6d5bd-158">SLA</span><span class="sxs-lookup"><span data-stu-id="6d5bd-158">SLA</span></span> |<span data-ttu-id="6d5bd-159">Spark clusters in HDInsight come with 24/7 support and an SLA of 99.9% up-time.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-159">Spark clusters in HDInsight come with 24/7 support and an SLA of 99.9% up-time.</span></span> |

<span data-ttu-id="6d5bd-160">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-160">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="6d5bd-161">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-161">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="6d5bd-162">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-162">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="6d5bd-163">Anaconda</span><span class="sxs-lookup"><span data-stu-id="6d5bd-163">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="6d5bd-164">Livy</span><span class="sxs-lookup"><span data-stu-id="6d5bd-164">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="6d5bd-165">Jupyter notebook</span><span class="sxs-lookup"><span data-stu-id="6d5bd-165">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="6d5bd-166">Zeppelin notebook</span><span class="sxs-lookup"><span data-stu-id="6d5bd-166">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="6d5bd-167">Spark clusters in HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-167">Spark clusters in HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI.</span></span>

## <a name="spark-cluster-architecture"></a><span data-ttu-id="6d5bd-168">Spark cluster architecture</span><span class="sxs-lookup"><span data-stu-id="6d5bd-168">Spark cluster architecture</span></span>

![The architecture of HDInsight Spark](./media/apache-spark-overview/spark-architecture.png)

<span data-ttu-id="6d5bd-170">It is easy to understand the components of Spark by understanding how Spark runs on HDInsight clusters.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-170">It is easy to understand the components of Spark by understanding how Spark runs on HDInsight clusters.</span></span>

<span data-ttu-id="6d5bd-171">Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-171">Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program).</span></span>

<span data-ttu-id="6d5bd-172">The SparkContext can connect to several types of cluster managers, which allocate resources across applications.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-172">The SparkContext can connect to several types of cluster managers, which allocate resources across applications.</span></span> <span data-ttu-id="6d5bd-173">These cluster managers include Apache Mesos, Apache YARN, or the Spark cluster manager.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-173">These cluster managers include Apache Mesos, Apache YARN, or the Spark cluster manager.</span></span> <span data-ttu-id="6d5bd-174">In HDInsight, Spark runs using the YARN cluster manager.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-174">In HDInsight, Spark runs using the YARN cluster manager.</span></span> <span data-ttu-id="6d5bd-175">Once connected, Spark acquires executors on workers nodes in the cluster, which are processes that run computations and store data for your application.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-175">Once connected, Spark acquires executors on workers nodes in the cluster, which are processes that run computations and store data for your application.</span></span> <span data-ttu-id="6d5bd-176">Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-176">Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors.</span></span> <span data-ttu-id="6d5bd-177">Finally, SparkContext sends tasks to the executors to run.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-177">Finally, SparkContext sends tasks to the executors to run.</span></span>

<span data-ttu-id="6d5bd-178">The SparkContext runs the user's main function and executes the various parallel operations on the worker nodes.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-178">The SparkContext runs the user's main function and executes the various parallel operations on the worker nodes.</span></span> <span data-ttu-id="6d5bd-179">Then, the SparkContext collects the results of the operations.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-179">Then, the SparkContext collects the results of the operations.</span></span> <span data-ttu-id="6d5bd-180">The worker nodes read and write data from and to the Hadoop distributed file system (HDFS).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-180">The worker nodes read and write data from and to the Hadoop distributed file system (HDFS).</span></span> <span data-ttu-id="6d5bd-181">The worker nodes also cache transformed data in-memory as Resilient Distributed Datasets (RDDs).</span><span class="sxs-lookup"><span data-stu-id="6d5bd-181">The worker nodes also cache transformed data in-memory as Resilient Distributed Datasets (RDDs).</span></span>

<span data-ttu-id="6d5bd-182">The SparkContext connects to the Spark master and is responsible for converting an application to a directed graph (DAG) of individual tasks that get executed within an executor process on the worker nodes.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-182">The SparkContext connects to the Spark master and is responsible for converting an application to a directed graph (DAG) of individual tasks that get executed within an executor process on the worker nodes.</span></span> <span data-ttu-id="6d5bd-183">Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-183">Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads.</span></span>

## <a name="spark-in-hdinsight-use-cases"></a><span data-ttu-id="6d5bd-184">Spark in HDInsight use cases</span><span class="sxs-lookup"><span data-stu-id="6d5bd-184">Spark in HDInsight use cases</span></span>

<span data-ttu-id="6d5bd-185">Spark clusters in HDInsight enable the following key scenarios:</span><span class="sxs-lookup"><span data-stu-id="6d5bd-185">Spark clusters in HDInsight enable the following key scenarios:</span></span>

- <span data-ttu-id="6d5bd-186">Interactive data analysis and BI</span><span class="sxs-lookup"><span data-stu-id="6d5bd-186">Interactive data analysis and BI</span></span>

    <span data-ttu-id="6d5bd-187">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-187">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="6d5bd-188">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-188">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="6d5bd-189">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-189">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="6d5bd-190">Spark clusters in HDInsight also support a number of third-party BI tools such as Tableau making it easier for data analysts, business experts, and key decision makers.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-190">Spark clusters in HDInsight also support a number of third-party BI tools such as Tableau making it easier for data analysts, business experts, and key decision makers.</span></span>

    [<span data-ttu-id="6d5bd-191">Tutorial: Visualize Spark data using Power BI</span><span class="sxs-lookup"><span data-stu-id="6d5bd-191">Tutorial: Visualize Spark data using Power BI</span></span>](apache-spark-use-bi-tools.md)
- <span data-ttu-id="6d5bd-192">Spark Machine Learning</span><span class="sxs-lookup"><span data-stu-id="6d5bd-192">Spark Machine Learning</span></span>

    <span data-ttu-id="6d5bd-193">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-193">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="6d5bd-194">Spark cluster in HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-194">Spark cluster in HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="6d5bd-195">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have an environment for creating machine learning applications.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-195">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have an environment for creating machine learning applications.</span></span>

    <span data-ttu-id="6d5bd-196">[Tutorial: Predict building temperatures using HVAC data](apache-spark-ipython-notebook-machine-learning.md) [Tutorial: Predict food inspection results](apache-spark-machine-learning-mllib-ipython.md)</span><span class="sxs-lookup"><span data-stu-id="6d5bd-196">[Tutorial: Predict building temperatures using HVAC data](apache-spark-ipython-notebook-machine-learning.md) [Tutorial: Predict food inspection results](apache-spark-machine-learning-mllib-ipython.md)</span></span>    
- <span data-ttu-id="6d5bd-197">Spark streaming and real-time data analysis</span><span class="sxs-lookup"><span data-stu-id="6d5bd-197">Spark streaming and real-time data analysis</span></span>

    <span data-ttu-id="6d5bd-198">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-198">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="6d5bd-199">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-199">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="6d5bd-200">Event Hubs is the most widely used queuing service on Azure.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-200">Event Hubs is the most widely used queuing service on Azure.</span></span> <span data-ttu-id="6d5bd-201">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real-time analytics pipeline.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-201">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real-time analytics pipeline.</span></span>
    
## <a name="where-do-i-start"></a><span data-ttu-id="6d5bd-202">Where do I start?</span><span class="sxs-lookup"><span data-stu-id="6d5bd-202">Where do I start?</span></span>

<span data-ttu-id="6d5bd-203">You can use the following articles to learn more about Spark in HDInsight:</span><span class="sxs-lookup"><span data-stu-id="6d5bd-203">You can use the following articles to learn more about Spark in HDInsight:</span></span>

- [<span data-ttu-id="6d5bd-204">QuickStart: create a Spark cluster in HDInsight and run interactive query using Jupyter</span><span class="sxs-lookup"><span data-stu-id="6d5bd-204">QuickStart: create a Spark cluster in HDInsight and run interactive query using Jupyter</span></span>](./apache-spark-jupyter-spark-sql.md)
- [<span data-ttu-id="6d5bd-205">Tutorial: run a Spark job using Jupyter</span><span class="sxs-lookup"><span data-stu-id="6d5bd-205">Tutorial: run a Spark job using Jupyter</span></span>](./apache-spark-load-data-run-query.md)
- [<span data-ttu-id="6d5bd-206">Tutorial: analyze data using BI tools</span><span class="sxs-lookup"><span data-stu-id="6d5bd-206">Tutorial: analyze data using BI tools</span></span>](./apache-spark-use-bi-tools.md)
- [<span data-ttu-id="6d5bd-207">Tutorial: machine learning using Spark</span><span class="sxs-lookup"><span data-stu-id="6d5bd-207">Tutorial: machine learning using Spark</span></span>](./apache-spark-ipython-notebook-machine-learning.md)
- [<span data-ttu-id="6d5bd-208">Tutorial: create a Scala Maven application using IntelliJ</span><span class="sxs-lookup"><span data-stu-id="6d5bd-208">Tutorial: create a Scala Maven application using IntelliJ</span></span>](./apache-spark-create-standalone-application.md)

## <a name="next-steps"></a><span data-ttu-id="6d5bd-209">Next Steps</span><span class="sxs-lookup"><span data-stu-id="6d5bd-209">Next Steps</span></span>

<span data-ttu-id="6d5bd-210">In this overview, you get some basic understanding of Apache Spark in Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6d5bd-210">In this overview, you get some basic understanding of Apache Spark in Azure HDInsight.</span></span> <span data-ttu-id="6d5bd-211">Advance to the next article to learn how to create an HDInsight Spark cluster and run some Spark SQL queries:</span><span class="sxs-lookup"><span data-stu-id="6d5bd-211">Advance to the next article to learn how to create an HDInsight Spark cluster and run some Spark SQL queries:</span></span>

- [<span data-ttu-id="6d5bd-212">Create an Spark cluster in HDInsight</span><span class="sxs-lookup"><span data-stu-id="6d5bd-212">Create an Spark cluster in HDInsight</span></span>](./apache-spark-jupyter-spark-sql.md)

