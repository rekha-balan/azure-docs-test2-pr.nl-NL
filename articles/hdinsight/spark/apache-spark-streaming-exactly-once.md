---
title: Create Spark Streaming jobs with exactly-once event processing - Azure HDInsight
description: How to set up Spark Streaming to process an event once and only once.
services: hdinsight
ms.service: hdinsight
author: jasonwhowell
ms.author: jasonh
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 01/26/2018
ms.openlocfilehash: ae170e90cede26bd6a43fcc10b93fcd7490d838f
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44856630"
---
# <a name="create-spark-streaming-jobs-with-exactly-once-event-processing"></a><span data-ttu-id="d7739-103">Create Spark Streaming jobs with exactly-once event processing</span><span class="sxs-lookup"><span data-stu-id="d7739-103">Create Spark Streaming jobs with exactly-once event processing</span></span>

<span data-ttu-id="d7739-104">Stream processing applications take different approaches to how they handle re-processing messages after some failure in the system:</span><span class="sxs-lookup"><span data-stu-id="d7739-104">Stream processing applications take different approaches to how they handle re-processing messages after some failure in the system:</span></span>

* <span data-ttu-id="d7739-105">At least once: Each message is guaranteed to be processed, but it may get processed more than once.</span><span class="sxs-lookup"><span data-stu-id="d7739-105">At least once: Each message is guaranteed to be processed, but it may get processed more than once.</span></span>
* <span data-ttu-id="d7739-106">At most once: Each message may or may not be processed.</span><span class="sxs-lookup"><span data-stu-id="d7739-106">At most once: Each message may or may not be processed.</span></span> <span data-ttu-id="d7739-107">If a message is processed, it is only processed once.</span><span class="sxs-lookup"><span data-stu-id="d7739-107">If a message is processed, it is only processed once.</span></span>
* <span data-ttu-id="d7739-108">Exactly once: Each message is guaranteed to be processed once and only once.</span><span class="sxs-lookup"><span data-stu-id="d7739-108">Exactly once: Each message is guaranteed to be processed once and only once.</span></span>

<span data-ttu-id="d7739-109">This article shows you how to configure Spark Streaming to achieve exactly-once processing.</span><span class="sxs-lookup"><span data-stu-id="d7739-109">This article shows you how to configure Spark Streaming to achieve exactly-once processing.</span></span>

## <a name="exactly-once-semantics-with-spark-streaming"></a><span data-ttu-id="d7739-110">Exactly-once semantics with Spark Streaming</span><span class="sxs-lookup"><span data-stu-id="d7739-110">Exactly-once semantics with Spark Streaming</span></span>

<span data-ttu-id="d7739-111">First, consider how all system points of failure restart after having an issue, and how you can avoid data loss.</span><span class="sxs-lookup"><span data-stu-id="d7739-111">First, consider how all system points of failure restart after having an issue, and how you can avoid data loss.</span></span> <span data-ttu-id="d7739-112">A Spark Streaming application has:</span><span class="sxs-lookup"><span data-stu-id="d7739-112">A Spark Streaming application has:</span></span>

* <span data-ttu-id="d7739-113">An input source</span><span class="sxs-lookup"><span data-stu-id="d7739-113">An input source</span></span>
* <span data-ttu-id="d7739-114">One or more receiver processes that pull data from the input source</span><span class="sxs-lookup"><span data-stu-id="d7739-114">One or more receiver processes that pull data from the input source</span></span>
* <span data-ttu-id="d7739-115">Tasks that process the data</span><span class="sxs-lookup"><span data-stu-id="d7739-115">Tasks that process the data</span></span>
* <span data-ttu-id="d7739-116">An output sink</span><span class="sxs-lookup"><span data-stu-id="d7739-116">An output sink</span></span>
* <span data-ttu-id="d7739-117">A driver process that manages the long-running job</span><span class="sxs-lookup"><span data-stu-id="d7739-117">A driver process that manages the long-running job</span></span>

<span data-ttu-id="d7739-118">Exactly-once semantics require that no data is lost at any point, and that message processing is restartable, regardless of where the failure occurs.</span><span class="sxs-lookup"><span data-stu-id="d7739-118">Exactly-once semantics require that no data is lost at any point, and that message processing is restartable, regardless of where the failure occurs.</span></span>

### <a name="replayable-sources"></a><span data-ttu-id="d7739-119">Replayable sources</span><span class="sxs-lookup"><span data-stu-id="d7739-119">Replayable sources</span></span>

<span data-ttu-id="d7739-120">The source your Spark Streaming application is reading your events from must be *replayable*.</span><span class="sxs-lookup"><span data-stu-id="d7739-120">The source your Spark Streaming application is reading your events from must be *replayable*.</span></span> <span data-ttu-id="d7739-121">This means that in cases where the message was retrieved but then the system failed before the message could be persisted or processed, the source must provide the same message again.</span><span class="sxs-lookup"><span data-stu-id="d7739-121">This means that in cases where the message was retrieved but then the system failed before the message could be persisted or processed, the source must provide the same message again.</span></span>

<span data-ttu-id="d7739-122">In Azure, both Azure Event Hubs and Kafka on HDInsight provide replayable sources.</span><span class="sxs-lookup"><span data-stu-id="d7739-122">In Azure, both Azure Event Hubs and Kafka on HDInsight provide replayable sources.</span></span> <span data-ttu-id="d7739-123">Another example of a replayable source is a fault-tolerant file system like HDFS, Azure Storage blobs, or Azure Data Lake Store, where all data is kept forever and at any point you can re-read the data in its entirety.</span><span class="sxs-lookup"><span data-stu-id="d7739-123">Another example of a replayable source is a fault-tolerant file system like HDFS, Azure Storage blobs, or Azure Data Lake Store, where all data is kept forever and at any point you can re-read the data in its entirety.</span></span>

### <a name="reliable-receivers"></a><span data-ttu-id="d7739-124">Reliable receivers</span><span class="sxs-lookup"><span data-stu-id="d7739-124">Reliable receivers</span></span>

<span data-ttu-id="d7739-125">In Spark Streaming, sources like Event Hubs and Kafka have *reliable receivers*, where each receiver keeps track of its progress reading the source.</span><span class="sxs-lookup"><span data-stu-id="d7739-125">In Spark Streaming, sources like Event Hubs and Kafka have *reliable receivers*, where each receiver keeps track of its progress reading the source.</span></span> <span data-ttu-id="d7739-126">A reliable receiver persists its state into fault-tolerant storage, either within ZooKeeper or in Spark Streaming checkpoints written to HDFS.</span><span class="sxs-lookup"><span data-stu-id="d7739-126">A reliable receiver persists its state into fault-tolerant storage, either within ZooKeeper or in Spark Streaming checkpoints written to HDFS.</span></span> <span data-ttu-id="d7739-127">If such a receiver fails and is later restarted, it can pick up where it left off.</span><span class="sxs-lookup"><span data-stu-id="d7739-127">If such a receiver fails and is later restarted, it can pick up where it left off.</span></span>

### <a name="use-the-write-ahead-log"></a><span data-ttu-id="d7739-128">Use the Write-Ahead Log</span><span class="sxs-lookup"><span data-stu-id="d7739-128">Use the Write-Ahead Log</span></span>

<span data-ttu-id="d7739-129">Spark Streaming supports the use of a Write-Ahead Log, where each received event is first written to Spark's checkpoint directory in fault-tolerant storage and then stored in a Resilient Distributed Dataset (RDD).</span><span class="sxs-lookup"><span data-stu-id="d7739-129">Spark Streaming supports the use of a Write-Ahead Log, where each received event is first written to Spark's checkpoint directory in fault-tolerant storage and then stored in a Resilient Distributed Dataset (RDD).</span></span> <span data-ttu-id="d7739-130">In Azure, the fault-tolerant storage is HDFS backed by either Azure Storage or Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="d7739-130">In Azure, the fault-tolerant storage is HDFS backed by either Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="d7739-131">In your Spark Streaming application, the Write-Ahead Log is enabled for all receivers by setting the `spark.streaming.receiver.writeAheadLog.enable` configuration setting to `true`.</span><span class="sxs-lookup"><span data-stu-id="d7739-131">In your Spark Streaming application, the Write-Ahead Log is enabled for all receivers by setting the `spark.streaming.receiver.writeAheadLog.enable` configuration setting to `true`.</span></span> <span data-ttu-id="d7739-132">The Write-Ahead Log provides fault tolerance for failures of both the driver and the executors.</span><span class="sxs-lookup"><span data-stu-id="d7739-132">The Write-Ahead Log provides fault tolerance for failures of both the driver and the executors.</span></span>

<span data-ttu-id="d7739-133">For workers running tasks against the event data, each RDD is by definition both replicated and distributed across multiple workers.</span><span class="sxs-lookup"><span data-stu-id="d7739-133">For workers running tasks against the event data, each RDD is by definition both replicated and distributed across multiple workers.</span></span> <span data-ttu-id="d7739-134">If a task fails because the worker running it crashed, the task will be restarted on another worker that has a replica of the event data, so the event is not lost.</span><span class="sxs-lookup"><span data-stu-id="d7739-134">If a task fails because the worker running it crashed, the task will be restarted on another worker that has a replica of the event data, so the event is not lost.</span></span>

### <a name="use-checkpoints-for-drivers"></a><span data-ttu-id="d7739-135">Use checkpoints for drivers</span><span class="sxs-lookup"><span data-stu-id="d7739-135">Use checkpoints for drivers</span></span>

<span data-ttu-id="d7739-136">The job drivers need to be restartable.</span><span class="sxs-lookup"><span data-stu-id="d7739-136">The job drivers need to be restartable.</span></span> <span data-ttu-id="d7739-137">If the driver running your Spark Streaming application crashes, it takes down with it all running receivers, tasks, and any RDDs storing event data.</span><span class="sxs-lookup"><span data-stu-id="d7739-137">If the driver running your Spark Streaming application crashes, it takes down with it all running receivers, tasks, and any RDDs storing event data.</span></span> <span data-ttu-id="d7739-138">In this case, you need to be able to save the progress of the job so you can resume it later.</span><span class="sxs-lookup"><span data-stu-id="d7739-138">In this case, you need to be able to save the progress of the job so you can resume it later.</span></span> <span data-ttu-id="d7739-139">This is accomplished by checkpointing the Directed Acyclic Graph (DAG) of the DStream periodically to fault-tolerant storage.</span><span class="sxs-lookup"><span data-stu-id="d7739-139">This is accomplished by checkpointing the Directed Acyclic Graph (DAG) of the DStream periodically to fault-tolerant storage.</span></span> <span data-ttu-id="d7739-140">The DAG metadata includes the configuration used to create the streaming application, the operations that define the application, and any batches that are queued but not yet completed.</span><span class="sxs-lookup"><span data-stu-id="d7739-140">The DAG metadata includes the configuration used to create the streaming application, the operations that define the application, and any batches that are queued but not yet completed.</span></span> <span data-ttu-id="d7739-141">This metadata enables a failed driver to be restarted from the checkpoint information.</span><span class="sxs-lookup"><span data-stu-id="d7739-141">This metadata enables a failed driver to be restarted from the checkpoint information.</span></span> <span data-ttu-id="d7739-142">When the driver restarts, it will launch new receivers that themselves recover the event data back into RDDs from the Write-Ahead Log.</span><span class="sxs-lookup"><span data-stu-id="d7739-142">When the driver restarts, it will launch new receivers that themselves recover the event data back into RDDs from the Write-Ahead Log.</span></span>

<span data-ttu-id="d7739-143">Checkpoints are enabled in Spark Streaming in two steps.</span><span class="sxs-lookup"><span data-stu-id="d7739-143">Checkpoints are enabled in Spark Streaming in two steps.</span></span> 

1. <span data-ttu-id="d7739-144">In the StreamingContext object, configure the storage path for the checkpoints:</span><span class="sxs-lookup"><span data-stu-id="d7739-144">In the StreamingContext object, configure the storage path for the checkpoints:</span></span>

    <span data-ttu-id="d7739-145">val ssc = new StreamingContext(spark, Seconds(1))  ssc.checkpoint("/path/to/checkpoints")</span><span class="sxs-lookup"><span data-stu-id="d7739-145">val ssc = new StreamingContext(spark, Seconds(1))  ssc.checkpoint("/path/to/checkpoints")</span></span>

    <span data-ttu-id="d7739-146">In HDInsight, these checkpoints should be saved to the default storage attached to your cluster, either Azure Storage or Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="d7739-146">In HDInsight, these checkpoints should be saved to the default storage attached to your cluster, either Azure Storage or Azure Data Lake Store.</span></span>

2. <span data-ttu-id="d7739-147">Next, specify a checkpoint interval (in seconds) on the DStream.</span><span class="sxs-lookup"><span data-stu-id="d7739-147">Next, specify a checkpoint interval (in seconds) on the DStream.</span></span> <span data-ttu-id="d7739-148">At each interval, state data derived from the input event is persisted to storage.</span><span class="sxs-lookup"><span data-stu-id="d7739-148">At each interval, state data derived from the input event is persisted to storage.</span></span> <span data-ttu-id="d7739-149">Persisted state data can reduce the computation needed when rebuilding the state from the source event.</span><span class="sxs-lookup"><span data-stu-id="d7739-149">Persisted state data can reduce the computation needed when rebuilding the state from the source event.</span></span>

    <span data-ttu-id="d7739-150">val lines = ssc.socketTextStream("hostname", 9999)  lines.checkpoint(30)  ssc.start()  ssc.awaitTermination()</span><span class="sxs-lookup"><span data-stu-id="d7739-150">val lines = ssc.socketTextStream("hostname", 9999)  lines.checkpoint(30)  ssc.start()  ssc.awaitTermination()</span></span>

### <a name="use-idempotent-sinks"></a><span data-ttu-id="d7739-151">Use idempotent sinks</span><span class="sxs-lookup"><span data-stu-id="d7739-151">Use idempotent sinks</span></span>

<span data-ttu-id="d7739-152">The destination sink to which your job writes results must be able to handle the situation where it is given the same result more than once.</span><span class="sxs-lookup"><span data-stu-id="d7739-152">The destination sink to which your job writes results must be able to handle the situation where it is given the same result more than once.</span></span> <span data-ttu-id="d7739-153">The sink must be able to detect such duplicate results and ignore them.</span><span class="sxs-lookup"><span data-stu-id="d7739-153">The sink must be able to detect such duplicate results and ignore them.</span></span> <span data-ttu-id="d7739-154">An *idempotent* sink can be called multiple times with the same data with no change of state.</span><span class="sxs-lookup"><span data-stu-id="d7739-154">An *idempotent* sink can be called multiple times with the same data with no change of state.</span></span>

<span data-ttu-id="d7739-155">You can create idempotent sinks by implementing logic that first checks for the existence of the incoming result in the datastore.</span><span class="sxs-lookup"><span data-stu-id="d7739-155">You can create idempotent sinks by implementing logic that first checks for the existence of the incoming result in the datastore.</span></span> <span data-ttu-id="d7739-156">If the result already exists, the write should appear to succeed from the perspective of your Spark job, but in reality your data store ignored the duplicate data.</span><span class="sxs-lookup"><span data-stu-id="d7739-156">If the result already exists, the write should appear to succeed from the perspective of your Spark job, but in reality your data store ignored the duplicate data.</span></span> <span data-ttu-id="d7739-157">If the result does not exist, then the sink should insert this new result into its storage.</span><span class="sxs-lookup"><span data-stu-id="d7739-157">If the result does not exist, then the sink should insert this new result into its storage.</span></span> 

<span data-ttu-id="d7739-158">For example, you could use a stored procedure with Azure SQL Database that inserts events into a table.</span><span class="sxs-lookup"><span data-stu-id="d7739-158">For example, you could use a stored procedure with Azure SQL Database that inserts events into a table.</span></span> <span data-ttu-id="d7739-159">This stored procedure first looks up the event by key fields, and only when no matching event found is the record inserted into the table.</span><span class="sxs-lookup"><span data-stu-id="d7739-159">This stored procedure first looks up the event by key fields, and only when no matching event found is the record inserted into the table.</span></span>

<span data-ttu-id="d7739-160">Another example is to use a partitioned file system, like Azure Storage blobs or Azure Data Lake store.</span><span class="sxs-lookup"><span data-stu-id="d7739-160">Another example is to use a partitioned file system, like Azure Storage blobs or Azure Data Lake store.</span></span> <span data-ttu-id="d7739-161">In this case your sink logic does not need to check for the existence of a file.</span><span class="sxs-lookup"><span data-stu-id="d7739-161">In this case your sink logic does not need to check for the existence of a file.</span></span> <span data-ttu-id="d7739-162">If the file representing the event exists, it is simply overwritten with the same data.</span><span class="sxs-lookup"><span data-stu-id="d7739-162">If the file representing the event exists, it is simply overwritten with the same data.</span></span> <span data-ttu-id="d7739-163">Otherwise, a new file is created at the computed path.</span><span class="sxs-lookup"><span data-stu-id="d7739-163">Otherwise, a new file is created at the computed path.</span></span>

## <a name="next-steps"></a><span data-ttu-id="d7739-164">Next steps</span><span class="sxs-lookup"><span data-stu-id="d7739-164">Next steps</span></span>

* [<span data-ttu-id="d7739-165">Spark Streaming Overview</span><span class="sxs-lookup"><span data-stu-id="d7739-165">Spark Streaming Overview</span></span>](apache-spark-streaming-overview.md)
* [<span data-ttu-id="d7739-166">Creating highly available Spark Streaming jobs in YARN</span><span class="sxs-lookup"><span data-stu-id="d7739-166">Creating highly available Spark Streaming jobs in YARN</span></span>](apache-spark-streaming-high-availability.md)
