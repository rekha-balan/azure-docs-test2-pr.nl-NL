---
title: Compute context options for ML Services on HDInsight - Azure
description: Learn about the different compute context options available to users with ML Services on HDInsight
services: hdinsight
ms.service: hdinsight
author: jasonwhowell
ms.author: jasonh
ms.reviewer: jasonh
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 06/27/2018
ms.openlocfilehash: b956a641c6e6797efde98e7b613e6ce91023fc09
ms.sourcegitcommit: d1451406a010fd3aa854dc8e5b77dc5537d8050e
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/13/2018
ms.locfileid: "44864636"
---
# <a name="compute-context-options-for-ml-services-on-hdinsight"></a><span data-ttu-id="5c94c-103">Compute context options for ML Services on HDInsight</span><span class="sxs-lookup"><span data-stu-id="5c94c-103">Compute context options for ML Services on HDInsight</span></span>

<span data-ttu-id="5c94c-104">ML Services on Azure HDInsight controls how calls are executed by setting the compute context.</span><span class="sxs-lookup"><span data-stu-id="5c94c-104">ML Services on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="5c94c-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="5c94c-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="5c94c-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span><span class="sxs-lookup"><span data-stu-id="5c94c-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="5c94c-107">With an edge node, you have the option of running the parallelized distributed functions of RevoScaleR across the cores of the edge node server.</span><span class="sxs-lookup"><span data-stu-id="5c94c-107">With an edge node, you have the option of running the parallelized distributed functions of RevoScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="5c94c-108">You can also run them across the nodes of the cluster by using RevoScaleR’s Hadoop Map Reduce or Spark compute contexts.</span><span class="sxs-lookup"><span data-stu-id="5c94c-108">You can also run them across the nodes of the cluster by using RevoScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="ml-services-on-azure-hdinsight"></a><span data-ttu-id="5c94c-109">ML Services on Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="5c94c-109">ML Services on Azure HDInsight</span></span>
<span data-ttu-id="5c94c-110">[ML Services on Azure HDInsight](r-server-overview.md) provides the latest capabilities for R-based analytics.</span><span class="sxs-lookup"><span data-stu-id="5c94c-110">[ML Services on Azure HDInsight](r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="5c94c-111">It can use data that is stored in an HDFS container in your [Azure Blob](../../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span><span class="sxs-lookup"><span data-stu-id="5c94c-111">It can use data that is stored in an HDFS container in your [Azure Blob](../../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="5c94c-112">Since ML Services is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span><span class="sxs-lookup"><span data-stu-id="5c94c-112">Since ML Services is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="5c94c-113">They can also use the routines in [RevoScaleR](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/revoscaler), Microsoft’s big data analytics package that is included with ML Services.</span><span class="sxs-lookup"><span data-stu-id="5c94c-113">They can also use the routines in [RevoScaleR](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/revoscaler), Microsoft’s big data analytics package that is included with ML Services.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="5c94c-114">Compute contexts for an edge node</span><span class="sxs-lookup"><span data-stu-id="5c94c-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="5c94c-115">In general, an R script that's run in ML Services cluster on the edge node runs within the R interpreter on that node.</span><span class="sxs-lookup"><span data-stu-id="5c94c-115">In general, an R script that's run in ML Services cluster on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="5c94c-116">The exceptions are those steps that call a RevoScaleR function.</span><span class="sxs-lookup"><span data-stu-id="5c94c-116">The exceptions are those steps that call a RevoScaleR function.</span></span> <span data-ttu-id="5c94c-117">The RevoScaleR calls run in a compute environment that is determined by how you set the RevoScaleR compute context.</span><span class="sxs-lookup"><span data-stu-id="5c94c-117">The RevoScaleR calls run in a compute environment that is determined by how you set the RevoScaleR compute context.</span></span>  <span data-ttu-id="5c94c-118">When you run your R script from an edge node, the possible values of the compute context are:</span><span class="sxs-lookup"><span data-stu-id="5c94c-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="5c94c-119">local sequential (*local*)</span><span class="sxs-lookup"><span data-stu-id="5c94c-119">local sequential (*local*)</span></span>
- <span data-ttu-id="5c94c-120">local parallel (*localpar*)</span><span class="sxs-lookup"><span data-stu-id="5c94c-120">local parallel (*localpar*)</span></span>
- <span data-ttu-id="5c94c-121">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="5c94c-121">Map Reduce</span></span>
- <span data-ttu-id="5c94c-122">Spark</span><span class="sxs-lookup"><span data-stu-id="5c94c-122">Spark</span></span>

<span data-ttu-id="5c94c-123">The *local* and *localpar* options differ only in how **rxExec** calls are executed.</span><span class="sxs-lookup"><span data-stu-id="5c94c-123">The *local* and *localpar* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="5c94c-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the RevoScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="5c94c-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the RevoScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="5c94c-125">Parallel execution options offer optimal performance.</span><span class="sxs-lookup"><span data-stu-id="5c94c-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="5c94c-126">The following table summarizes the various compute context options to set how calls are executed:</span><span class="sxs-lookup"><span data-stu-id="5c94c-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="5c94c-127">Compute context</span><span class="sxs-lookup"><span data-stu-id="5c94c-127">Compute context</span></span>  | <span data-ttu-id="5c94c-128">How to set</span><span class="sxs-lookup"><span data-stu-id="5c94c-128">How to set</span></span>                      | <span data-ttu-id="5c94c-129">Execution context</span><span class="sxs-lookup"><span data-stu-id="5c94c-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="5c94c-130">Local sequential</span><span class="sxs-lookup"><span data-stu-id="5c94c-130">Local sequential</span></span> | <span data-ttu-id="5c94c-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="5c94c-131">rxSetComputeContext('local')</span></span>    | <span data-ttu-id="5c94c-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span><span class="sxs-lookup"><span data-stu-id="5c94c-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="5c94c-133">Local parallel</span><span class="sxs-lookup"><span data-stu-id="5c94c-133">Local parallel</span></span>   | <span data-ttu-id="5c94c-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="5c94c-134">rxSetComputeContext('localpar')</span></span> | <span data-ttu-id="5c94c-135">Parallelized execution across the cores of the edge node server</span><span class="sxs-lookup"><span data-stu-id="5c94c-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="5c94c-136">Spark</span><span class="sxs-lookup"><span data-stu-id="5c94c-136">Spark</span></span>            | <span data-ttu-id="5c94c-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="5c94c-137">RxSpark()</span></span>                       | <span data-ttu-id="5c94c-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span><span class="sxs-lookup"><span data-stu-id="5c94c-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="5c94c-139">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="5c94c-139">Map Reduce</span></span>       | <span data-ttu-id="5c94c-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="5c94c-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="5c94c-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span><span class="sxs-lookup"><span data-stu-id="5c94c-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="5c94c-142">Guidelines for deciding on a compute context</span><span class="sxs-lookup"><span data-stu-id="5c94c-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="5c94c-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span><span class="sxs-lookup"><span data-stu-id="5c94c-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="5c94c-144">There is no simple formula that tells you which compute context to use.</span><span class="sxs-lookup"><span data-stu-id="5c94c-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="5c94c-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span><span class="sxs-lookup"><span data-stu-id="5c94c-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="5c94c-146">These guiding principles include:</span><span class="sxs-lookup"><span data-stu-id="5c94c-146">These guiding principles include:</span></span>

- <span data-ttu-id="5c94c-147">The local Linux file system is faster than HDFS.</span><span class="sxs-lookup"><span data-stu-id="5c94c-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="5c94c-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span><span class="sxs-lookup"><span data-stu-id="5c94c-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="5c94c-149">It's preferable to stream small amounts of data from a text data source.</span><span class="sxs-lookup"><span data-stu-id="5c94c-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="5c94c-150">If the amount of data is larger, convert it to XDF before analysis.</span><span class="sxs-lookup"><span data-stu-id="5c94c-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="5c94c-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span><span class="sxs-lookup"><span data-stu-id="5c94c-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="5c94c-152">Spark is faster than Map Reduce for analysis in Hadoop.</span><span class="sxs-lookup"><span data-stu-id="5c94c-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="5c94c-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span><span class="sxs-lookup"><span data-stu-id="5c94c-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="5c94c-154">Local</span><span class="sxs-lookup"><span data-stu-id="5c94c-154">Local</span></span>
* <span data-ttu-id="5c94c-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *local* or *localpar*.</span><span class="sxs-lookup"><span data-stu-id="5c94c-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *local* or *localpar*.</span></span>
* <span data-ttu-id="5c94c-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *local* or *localpar*.</span><span class="sxs-lookup"><span data-stu-id="5c94c-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *local* or *localpar*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="5c94c-157">Hadoop Spark</span><span class="sxs-lookup"><span data-stu-id="5c94c-157">Hadoop Spark</span></span>
* <span data-ttu-id="5c94c-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span><span class="sxs-lookup"><span data-stu-id="5c94c-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="5c94c-159">Hadoop Map Reduce</span><span class="sxs-lookup"><span data-stu-id="5c94c-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="5c94c-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span><span class="sxs-lookup"><span data-stu-id="5c94c-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="5c94c-161">Inline help on rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="5c94c-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="5c94c-162">For more information and examples of RevoScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span><span class="sxs-lookup"><span data-stu-id="5c94c-162">For more information and examples of RevoScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="5c94c-163">You can also refer to the [Distributed computing overview](https://docs.microsoft.com/machine-learning-server/r/how-to-revoscaler-distributed-computing) in [Machine Learning Server documentation](https://docs.microsoft.com/machine-learning-server/).</span><span class="sxs-lookup"><span data-stu-id="5c94c-163">You can also refer to the [Distributed computing overview](https://docs.microsoft.com/machine-learning-server/r/how-to-revoscaler-distributed-computing) in [Machine Learning Server documentation](https://docs.microsoft.com/machine-learning-server/).</span></span>

## <a name="next-steps"></a><span data-ttu-id="5c94c-164">Next steps</span><span class="sxs-lookup"><span data-stu-id="5c94c-164">Next steps</span></span>
<span data-ttu-id="5c94c-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="5c94c-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="5c94c-166">To learn more about how to use ML Services with HDInsight clusters, see the following topics:</span><span class="sxs-lookup"><span data-stu-id="5c94c-166">To learn more about how to use ML Services with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="5c94c-167">Overview of ML Services for Hadoop</span><span class="sxs-lookup"><span data-stu-id="5c94c-167">Overview of ML Services for Hadoop</span></span>](r-server-overview.md)
* [<span data-ttu-id="5c94c-168">Get started with ML Services for Hadoop</span><span class="sxs-lookup"><span data-stu-id="5c94c-168">Get started with ML Services for Hadoop</span></span>](r-server-get-started.md)
* [<span data-ttu-id="5c94c-169">Azure Storage options for ML Services on HDInsight</span><span class="sxs-lookup"><span data-stu-id="5c94c-169">Azure Storage options for ML Services on HDInsight</span></span>](r-server-storage.md)

