---
title: Analyze Application Insight logs with Spark on HDInsight | Microsoft Docs
description: Learn how to export Application Insight logs to blob storage, and then analyze the logs with Spark on HDInsight.
services: hdinsight
documentationcenter: ''
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: 883beae6-9839-45b5-94f7-7eb0f4534ad5
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 02/10/2017
ms.author: larryfr
ms.openlocfilehash: 209649359af7a68806ee60f7f98017758ff39045
ms.sourcegitcommit: 5b9d839c0c0a94b293fdafe1d6e5429506c07e05
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 08/02/2018
ms.locfileid: "44552036"
---
# <a name="analyze-application-insights-telemetry-logs-with-spark-on-hdinsight"></a><span data-ttu-id="65e78-103">Analyze Application Insights telemetry logs with Spark on HDInsight</span><span class="sxs-lookup"><span data-stu-id="65e78-103">Analyze Application Insights telemetry logs with Spark on HDInsight</span></span>

<span data-ttu-id="65e78-104">Learn how to use Spark on HDInsight to analyze Application Insight telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-104">Learn how to use Spark on HDInsight to analyze Application Insight telemetry data.</span></span>

<span data-ttu-id="65e78-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) is an analytics service that monitors your web applications.</span><span class="sxs-lookup"><span data-stu-id="65e78-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) is an analytics service that monitors your web applications.</span></span> <span data-ttu-id="65e78-106">Telemetry data generated by Application Insights can be exported to Azure Storage, and from there it can be analyzed by HDInsight.</span><span class="sxs-lookup"><span data-stu-id="65e78-106">Telemetry data generated by Application Insights can be exported to Azure Storage, and from there it can be analyzed by HDInsight.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="65e78-107">Prerequisites</span><span class="sxs-lookup"><span data-stu-id="65e78-107">Prerequisites</span></span>

* <span data-ttu-id="65e78-108">An Azure subscription.</span><span class="sxs-lookup"><span data-stu-id="65e78-108">An Azure subscription.</span></span>

* <span data-ttu-id="65e78-109">An application that is configured to use Application Insights.</span><span class="sxs-lookup"><span data-stu-id="65e78-109">An application that is configured to use Application Insights.</span></span>

* <span data-ttu-id="65e78-110">Familiarity with creating a Linux-based HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-110">Familiarity with creating a Linux-based HDInsight cluster.</span></span> <span data-ttu-id="65e78-111">For more information, see [Create Spark on HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="65e78-111">For more information, see [Create Spark on HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

  > [!IMPORTANT]
  > <span data-ttu-id="65e78-112">The steps in this document require an HDInsight cluster that uses Linux.</span><span class="sxs-lookup"><span data-stu-id="65e78-112">The steps in this document require an HDInsight cluster that uses Linux.</span></span> <span data-ttu-id="65e78-113">Linux is the only operating system used on HDInsight version 3.4 or greater.</span><span class="sxs-lookup"><span data-stu-id="65e78-113">Linux is the only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="65e78-114">For more information, see [HDInsight Deprecation on Windows](hdinsight-component-versioning.md#hdi-version-33-nearing-deprecation-date).</span><span class="sxs-lookup"><span data-stu-id="65e78-114">For more information, see [HDInsight Deprecation on Windows](hdinsight-component-versioning.md#hdi-version-33-nearing-deprecation-date).</span></span>

* <span data-ttu-id="65e78-115">A web browser.</span><span class="sxs-lookup"><span data-stu-id="65e78-115">A web browser.</span></span>

<span data-ttu-id="65e78-116">The following resources were used in developing and testing this document:</span><span class="sxs-lookup"><span data-stu-id="65e78-116">The following resources were used in developing and testing this document:</span></span>

* <span data-ttu-id="65e78-117">Application Insights telemetry data was generated using a [Node.js web app configured to use Application Insights](../application-insights/app-insights-nodejs.md).</span><span class="sxs-lookup"><span data-stu-id="65e78-117">Application Insights telemetry data was generated using a [Node.js web app configured to use Application Insights](../application-insights/app-insights-nodejs.md).</span></span>

* <span data-ttu-id="65e78-118">A Linux-based Spark on HDInsight cluster version 3.5 was used to analyze the data.</span><span class="sxs-lookup"><span data-stu-id="65e78-118">A Linux-based Spark on HDInsight cluster version 3.5 was used to analyze the data.</span></span>

## <a name="architecture-and-planning"></a><span data-ttu-id="65e78-119">Architecture and planning</span><span class="sxs-lookup"><span data-stu-id="65e78-119">Architecture and planning</span></span>

<span data-ttu-id="65e78-120">The following diagram illustrates the service architecture of this example:</span><span class="sxs-lookup"><span data-stu-id="65e78-120">The following diagram illustrates the service architecture of this example:</span></span>

![diagram showing data flowing from Application Insights to blob storage, then being processed by Spark on HDInsight](https://docstestmedia1.blob.core.windows.net/azure-media/articles/hdinsight/media/hdinsight-spark-analyze-application-insight-logs/appinsightshdinsight.png)

### <a name="azure-storage"></a><span data-ttu-id="65e78-122">Azure storage</span><span class="sxs-lookup"><span data-stu-id="65e78-122">Azure storage</span></span>

<span data-ttu-id="65e78-123">Application Insights can be configured to continuously export telemetry information to blobs.</span><span class="sxs-lookup"><span data-stu-id="65e78-123">Application Insights can be configured to continuously export telemetry information to blobs.</span></span> <span data-ttu-id="65e78-124">HDInsight can then read data stored in the blobs.</span><span class="sxs-lookup"><span data-stu-id="65e78-124">HDInsight can then read data stored in the blobs.</span></span> <span data-ttu-id="65e78-125">However, there are some requirements that you must follow:</span><span class="sxs-lookup"><span data-stu-id="65e78-125">However, there are some requirements that you must follow:</span></span>

* <span data-ttu-id="65e78-126">**Location**: If the Storage Account and HDInsight are in different locations, it may increase latency.</span><span class="sxs-lookup"><span data-stu-id="65e78-126">**Location**: If the Storage Account and HDInsight are in different locations, it may increase latency.</span></span> <span data-ttu-id="65e78-127">It also increases cost, as egress charges are applied to data moving between regions.</span><span class="sxs-lookup"><span data-stu-id="65e78-127">It also increases cost, as egress charges are applied to data moving between regions.</span></span>
* <span data-ttu-id="65e78-128">**Blob type**: HDInsight only supports block blobs.</span><span class="sxs-lookup"><span data-stu-id="65e78-128">**Blob type**: HDInsight only supports block blobs.</span></span> <span data-ttu-id="65e78-129">Application Insights defaults to using block blobs, so should work by default with HDInsight.</span><span class="sxs-lookup"><span data-stu-id="65e78-129">Application Insights defaults to using block blobs, so should work by default with HDInsight.</span></span>
* <span data-ttu-id="65e78-130">**Access permissions**: If you use the same storage account for both Application Insights continuous export and HDInsight's default storage, HDInsight has full access to the Application Insight telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-130">**Access permissions**: If you use the same storage account for both Application Insights continuous export and HDInsight's default storage, HDInsight has full access to the Application Insight telemetry data.</span></span> <span data-ttu-id="65e78-131">This means that it is possible to delete the telemetry data from the HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-131">This means that it is possible to delete the telemetry data from the HDInsight cluster.</span></span>

    <span data-ttu-id="65e78-132">Instead, it is recommended that you use separate storage accounts for HDInsight and Application Insights telemetry, and [use Shared Access Signatures (SAS) to restrict access to the data from HDInsight](hdinsight-storage-sharedaccesssignature-permissions.md).</span><span class="sxs-lookup"><span data-stu-id="65e78-132">Instead, it is recommended that you use separate storage accounts for HDInsight and Application Insights telemetry, and [use Shared Access Signatures (SAS) to restrict access to the data from HDInsight](hdinsight-storage-sharedaccesssignature-permissions.md).</span></span> <span data-ttu-id="65e78-133">Using an SAS allows you to grant HDInsight read-only access to the telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-133">Using an SAS allows you to grant HDInsight read-only access to the telemetry data.</span></span>

### <a name="data-schema"></a><span data-ttu-id="65e78-134">Data schema</span><span class="sxs-lookup"><span data-stu-id="65e78-134">Data schema</span></span>

<span data-ttu-id="65e78-135">Application Insights provides [export data model](../application-insights/app-insights-export-data-model.md) information for the telemetry data format exported to blobs.</span><span class="sxs-lookup"><span data-stu-id="65e78-135">Application Insights provides [export data model](../application-insights/app-insights-export-data-model.md) information for the telemetry data format exported to blobs.</span></span> <span data-ttu-id="65e78-136">The steps in this document use Spark SQL to work with the data.</span><span class="sxs-lookup"><span data-stu-id="65e78-136">The steps in this document use Spark SQL to work with the data.</span></span> <span data-ttu-id="65e78-137">Spark SQL can automatically generate a schema for the JSON data structure logged by Application Insights, so you do not have to manually define the schema when performing analysis.</span><span class="sxs-lookup"><span data-stu-id="65e78-137">Spark SQL can automatically generate a schema for the JSON data structure logged by Application Insights, so you do not have to manually define the schema when performing analysis.</span></span>

## <a name="export-telemetry-data"></a><span data-ttu-id="65e78-138">Export telemetry data</span><span class="sxs-lookup"><span data-stu-id="65e78-138">Export telemetry data</span></span>
<span data-ttu-id="65e78-139">Follow the steps in [Configure Continuous Export](../application-insights/app-insights-export-telemetry.md) to configure your Application Insights to export telemetry information to an Azure storage blob.</span><span class="sxs-lookup"><span data-stu-id="65e78-139">Follow the steps in [Configure Continuous Export](../application-insights/app-insights-export-telemetry.md) to configure your Application Insights to export telemetry information to an Azure storage blob.</span></span>

## <a name="configure-hdinsight-to-access-the-data"></a><span data-ttu-id="65e78-140">Configure HDInsight to access the data</span><span class="sxs-lookup"><span data-stu-id="65e78-140">Configure HDInsight to access the data</span></span>
<span data-ttu-id="65e78-141">Use the information in [Use Shared Access Signatures (SAS) to restrict access to the data from HDInsight](hdinsight-storage-sharedaccesssignature-permissions.md) to create a SAS for the blob container that holds the exported telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-141">Use the information in [Use Shared Access Signatures (SAS) to restrict access to the data from HDInsight](hdinsight-storage-sharedaccesssignature-permissions.md) to create a SAS for the blob container that holds the exported telemetry data.</span></span> <span data-ttu-id="65e78-142">The SAS should provide read-only access to the data.</span><span class="sxs-lookup"><span data-stu-id="65e78-142">The SAS should provide read-only access to the data.</span></span>

<span data-ttu-id="65e78-143">The Shared Access Signature document provides information on how you can add the SAS storage to an existing Linux-based HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-143">The Shared Access Signature document provides information on how you can add the SAS storage to an existing Linux-based HDInsight cluster.</span></span> <span data-ttu-id="65e78-144">It also provides information on how to add it when creating a new HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-144">It also provides information on how to add it when creating a new HDInsight cluster.</span></span>

## <a name="analyze-the-data-using-python-pyspark"></a><span data-ttu-id="65e78-145">Analyze the data using Python (PySpark)</span><span class="sxs-lookup"><span data-stu-id="65e78-145">Analyze the data using Python (PySpark)</span></span>

1. <span data-ttu-id="65e78-146">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-146">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="65e78-147">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span><span class="sxs-lookup"><span data-stu-id="65e78-147">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span></span>

    ![The cluster dashboards](https://docstestmedia1.blob.core.windows.net/azure-media/articles/hdinsight/media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)

2. <span data-ttu-id="65e78-149">In the upper right corner of the Jupyter page, select **New**, and then **PySpark**.</span><span class="sxs-lookup"><span data-stu-id="65e78-149">In the upper right corner of the Jupyter page, select **New**, and then **PySpark**.</span></span> <span data-ttu-id="65e78-150">A new browser tab containing a Python-based Jupyter Notebook opens.</span><span class="sxs-lookup"><span data-stu-id="65e78-150">A new browser tab containing a Python-based Jupyter Notebook opens.</span></span>

3. <span data-ttu-id="65e78-151">In the first field (called a **cell**) on the page, enter the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-151">In the first field (called a **cell**) on the page, enter the following text:</span></span>

        sc._jsc.hadoopConfiguration().set('mapreduce.input.fileinputformat.input.dir.recursive', 'true')

    <span data-ttu-id="65e78-152">This code configures Spark to recursively access the directory structure for the input data.</span><span class="sxs-lookup"><span data-stu-id="65e78-152">This code configures Spark to recursively access the directory structure for the input data.</span></span> <span data-ttu-id="65e78-153">Application Insights telemetry is logged to a directory structure similar to the `/{telemetry type}/YYYY-MM-DD/{##}/`.</span><span class="sxs-lookup"><span data-stu-id="65e78-153">Application Insights telemetry is logged to a directory structure similar to the `/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="65e78-154">Use **SHIFT+ENTER** to run the code.</span><span class="sxs-lookup"><span data-stu-id="65e78-154">Use **SHIFT+ENTER** to run the code.</span></span> <span data-ttu-id="65e78-155">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span><span class="sxs-lookup"><span data-stu-id="65e78-155">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span></span> <span data-ttu-id="65e78-156">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span><span class="sxs-lookup"><span data-stu-id="65e78-156">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    pyspark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="65e78-157">A new cell is created below the first one.</span><span class="sxs-lookup"><span data-stu-id="65e78-157">A new cell is created below the first one.</span></span> <span data-ttu-id="65e78-158">Enter the following text in the new cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-158">Enter the following text in the new cell.</span></span> <span data-ttu-id="65e78-159">Replace **CONTAINER** and **STORAGEACCOUNT** with the Azure storage account name and blob container name that you used when configuring the Application Insights continuous export.</span><span class="sxs-lookup"><span data-stu-id="65e78-159">Replace **CONTAINER** and **STORAGEACCOUNT** with the Azure storage account name and blob container name that you used when configuring the Application Insights continuous export.</span></span>

        %%bash
        hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/

    <span data-ttu-id="65e78-160">Use **SHIFT+ENTER** to execute this cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-160">Use **SHIFT+ENTER** to execute this cell.</span></span> <span data-ttu-id="65e78-161">You see a result similar to the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-161">You see a result similar to the following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="65e78-162">The wasb path returned is the location of the Application Insights telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-162">The wasb path returned is the location of the Application Insights telemetry data.</span></span> <span data-ttu-id="65e78-163">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span><span class="sxs-lookup"><span data-stu-id="65e78-163">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span></span> <span data-ttu-id="65e78-164">This time, the results should display the directories that contain telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-164">This time, the results should display the directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="65e78-165">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span><span class="sxs-lookup"><span data-stu-id="65e78-165">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="65e78-166">Your directory structure may be different.</span><span class="sxs-lookup"><span data-stu-id="65e78-166">Your directory structure may be different.</span></span>

6. <span data-ttu-id="65e78-167">In the next cell, enter the following.</span><span class="sxs-lookup"><span data-stu-id="65e78-167">In the next cell, enter the following.</span></span> <span data-ttu-id="65e78-168">Replace **WASB\_PATH** with the path from the previous step.</span><span class="sxs-lookup"><span data-stu-id="65e78-168">Replace **WASB\_PATH** with the path from the previous step.</span></span>

        jsonFiles = sc.textFile('WASB_PATH')
        jsonData = sqlContext.read.json(jsonFiles)

    <span data-ttu-id="65e78-169">This code creates a dataframe from the JSON files exported by the continuous export process.</span><span class="sxs-lookup"><span data-stu-id="65e78-169">This code creates a dataframe from the JSON files exported by the continuous export process.</span></span> <span data-ttu-id="65e78-170">Use **SHIFT+ENTER** to run this cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-170">Use **SHIFT+ENTER** to run this cell.</span></span>
7. <span data-ttu-id="65e78-171">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span><span class="sxs-lookup"><span data-stu-id="65e78-171">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span></span>

        jsonData.printSchema()

    <span data-ttu-id="65e78-172">The schema for each type of telemetry is different.</span><span class="sxs-lookup"><span data-stu-id="65e78-172">The schema for each type of telemetry is different.</span></span> <span data-ttu-id="65e78-173">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span><span class="sxs-lookup"><span data-stu-id="65e78-173">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)
8. <span data-ttu-id="65e78-174">Use the following to register the dataframe as a temporary table and run a query against the data:</span><span class="sxs-lookup"><span data-stu-id="65e78-174">Use the following to register the dataframe as a temporary table and run a query against the data:</span></span>

        jsonData.registerTempTable("requests")
        sqlContext.sql("select context.location.city from requests where context.location.city is not null")

    <span data-ttu-id="65e78-175">This query returns the city information for the top 20 records where context.location.city is not null.</span><span class="sxs-lookup"><span data-stu-id="65e78-175">This query returns the city information for the top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="65e78-176">The context structure is present in all telemetry logged by Application Insights; however, the city element may not be populated in your logs.</span><span class="sxs-lookup"><span data-stu-id="65e78-176">The context structure is present in all telemetry logged by Application Insights; however, the city element may not be populated in your logs.</span></span> <span data-ttu-id="65e78-177">Use the schema to identify other elements that you can query that may contain data for your logs.</span><span class="sxs-lookup"><span data-stu-id="65e78-177">Use the schema to identify other elements that you can query that may contain data for your logs.</span></span>
   >
   >

    <span data-ttu-id="65e78-178">This query returns information similar to the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-178">This query returns information similar to the following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="analyze-the-data-using-scala"></a><span data-ttu-id="65e78-179">Analyze the data using Scala</span><span class="sxs-lookup"><span data-stu-id="65e78-179">Analyze the data using Scala</span></span>
1. <span data-ttu-id="65e78-180">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="65e78-180">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="65e78-181">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span><span class="sxs-lookup"><span data-stu-id="65e78-181">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span></span>

    ![The cluster dashboards](https://docstestmedia1.blob.core.windows.net/azure-media/articles/hdinsight/media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)
2. <span data-ttu-id="65e78-183">In the upper right corner of the Jupyter page, select **New**, and then **Scala**.</span><span class="sxs-lookup"><span data-stu-id="65e78-183">In the upper right corner of the Jupyter page, select **New**, and then **Scala**.</span></span> <span data-ttu-id="65e78-184">This opens a new browser tab containing a Scala-based Jupyter Notebook.</span><span class="sxs-lookup"><span data-stu-id="65e78-184">This opens a new browser tab containing a Scala-based Jupyter Notebook.</span></span>
3. <span data-ttu-id="65e78-185">In the first field (called a **cell**) on the page, enter the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-185">In the first field (called a **cell**) on the page, enter the following text:</span></span>

        sc.hadoopConfiguration.set("mapreduce.input.fileinputformat.input.dir.recursive", "true")

    <span data-ttu-id="65e78-186">This code configures Spark to recursively access the directory structure for the input data.</span><span class="sxs-lookup"><span data-stu-id="65e78-186">This code configures Spark to recursively access the directory structure for the input data.</span></span> <span data-ttu-id="65e78-187">Application Insights telemetry is logged to a directory structure similar to `/{telemetry type}/YYYY-MM-DD/{##}/`.</span><span class="sxs-lookup"><span data-stu-id="65e78-187">Application Insights telemetry is logged to a directory structure similar to `/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="65e78-188">Use **SHIFT+ENTER** to run the code.</span><span class="sxs-lookup"><span data-stu-id="65e78-188">Use **SHIFT+ENTER** to run the code.</span></span> <span data-ttu-id="65e78-189">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span><span class="sxs-lookup"><span data-stu-id="65e78-189">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span></span> <span data-ttu-id="65e78-190">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span><span class="sxs-lookup"><span data-stu-id="65e78-190">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    spark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="65e78-191">A new cell is created below the first one.</span><span class="sxs-lookup"><span data-stu-id="65e78-191">A new cell is created below the first one.</span></span> <span data-ttu-id="65e78-192">Enter the following text in the new cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-192">Enter the following text in the new cell.</span></span> <span data-ttu-id="65e78-193">Replace **CONTAINER** and **STORAGEACCOUNT** with the Azure storage account name and blob container name that you used when configuring the Application Insights continuous export.</span><span class="sxs-lookup"><span data-stu-id="65e78-193">Replace **CONTAINER** and **STORAGEACCOUNT** with the Azure storage account name and blob container name that you used when configuring the Application Insights continuous export.</span></span>

        %%bash
        hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/

    <span data-ttu-id="65e78-194">Use **SHIFT+ENTER** to execute this cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-194">Use **SHIFT+ENTER** to execute this cell.</span></span> <span data-ttu-id="65e78-195">You see a result similar to the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-195">You see a result similar to the following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="65e78-196">The wasb path returned is the location of the Application Insights telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-196">The wasb path returned is the location of the Application Insights telemetry data.</span></span> <span data-ttu-id="65e78-197">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span><span class="sxs-lookup"><span data-stu-id="65e78-197">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span></span> <span data-ttu-id="65e78-198">This time, the results should display the directories that contain telemetry data.</span><span class="sxs-lookup"><span data-stu-id="65e78-198">This time, the results should display the directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="65e78-199">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span><span class="sxs-lookup"><span data-stu-id="65e78-199">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="65e78-200">This directory may not exist unless your telemetry data is for a web app.</span><span class="sxs-lookup"><span data-stu-id="65e78-200">This directory may not exist unless your telemetry data is for a web app.</span></span> <span data-ttu-id="65e78-201">If you are using telemetry data that does not include a requests directory, pick another directory and adjust the rest of the steps to use that directory and the schema for the data stored within it.</span><span class="sxs-lookup"><span data-stu-id="65e78-201">If you are using telemetry data that does not include a requests directory, pick another directory and adjust the rest of the steps to use that directory and the schema for the data stored within it.</span></span>
   >
   >
6. <span data-ttu-id="65e78-202">In the next cell, enter the following.</span><span class="sxs-lookup"><span data-stu-id="65e78-202">In the next cell, enter the following.</span></span> <span data-ttu-id="65e78-203">Replace **WASB\_PATH** with the path from the previous step.</span><span class="sxs-lookup"><span data-stu-id="65e78-203">Replace **WASB\_PATH** with the path from the previous step.</span></span>

        jsonFiles = sc.textFile('WASB_PATH')
        jsonData = sqlContext.read.json(jsonFiles)

    <span data-ttu-id="65e78-204">This code creates a dataframe from the JSON files exported by the continuous export process.</span><span class="sxs-lookup"><span data-stu-id="65e78-204">This code creates a dataframe from the JSON files exported by the continuous export process.</span></span> <span data-ttu-id="65e78-205">Use **SHIFT+ENTER** to run this cell.</span><span class="sxs-lookup"><span data-stu-id="65e78-205">Use **SHIFT+ENTER** to run this cell.</span></span>
7. <span data-ttu-id="65e78-206">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span><span class="sxs-lookup"><span data-stu-id="65e78-206">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span></span>

        jsonData.printSchema

    <span data-ttu-id="65e78-207">The schema for each type of telemetry is different.</span><span class="sxs-lookup"><span data-stu-id="65e78-207">The schema for each type of telemetry is different.</span></span> <span data-ttu-id="65e78-208">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span><span class="sxs-lookup"><span data-stu-id="65e78-208">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)
8. <span data-ttu-id="65e78-209">Use the following to register the dataframe as a temporary table and run a query against the data:</span><span class="sxs-lookup"><span data-stu-id="65e78-209">Use the following to register the dataframe as a temporary table and run a query against the data:</span></span>

        jsonData.registerTempTable("requests")
        var city = sqlContext.sql("select context.location.city from requests where context.location.city is not null limit 10").show()

    <span data-ttu-id="65e78-210">This query returns the city information for the top 20 records where context.location.city is not null.</span><span class="sxs-lookup"><span data-stu-id="65e78-210">This query returns the city information for the top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="65e78-211">The context structure is present in all telemetry logged by Application Insights; however, the city element may not be populated in your logs.</span><span class="sxs-lookup"><span data-stu-id="65e78-211">The context structure is present in all telemetry logged by Application Insights; however, the city element may not be populated in your logs.</span></span> <span data-ttu-id="65e78-212">Use the schema to identify other elements that you can query that may contain data for your logs.</span><span class="sxs-lookup"><span data-stu-id="65e78-212">Use the schema to identify other elements that you can query that may contain data for your logs.</span></span>
   >
   >

    <span data-ttu-id="65e78-213">This query returns information similar to the following text:</span><span class="sxs-lookup"><span data-stu-id="65e78-213">This query returns information similar to the following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="next-steps"></a><span data-ttu-id="65e78-214">Next steps</span><span class="sxs-lookup"><span data-stu-id="65e78-214">Next steps</span></span>
<span data-ttu-id="65e78-215">For more examples of using Spark to work with data and services in Azure, see the following documents:</span><span class="sxs-lookup"><span data-stu-id="65e78-215">For more examples of using Spark to work with data and services in Azure, see the following documents:</span></span>

* [<span data-ttu-id="65e78-216">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span><span class="sxs-lookup"><span data-stu-id="65e78-216">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="65e78-217">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span><span class="sxs-lookup"><span data-stu-id="65e78-217">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="65e78-218">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span><span class="sxs-lookup"><span data-stu-id="65e78-218">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="65e78-219">Spark Streaming: Use Spark in HDInsight for building streaming applications</span><span class="sxs-lookup"><span data-stu-id="65e78-219">Spark Streaming: Use Spark in HDInsight for building streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="65e78-220">Website log analysis using Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="65e78-220">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

<span data-ttu-id="65e78-221">For information on creating and running Spark applications, see the following documents:</span><span class="sxs-lookup"><span data-stu-id="65e78-221">For information on creating and running Spark applications, see the following documents:</span></span>

* [<span data-ttu-id="65e78-222">Create a standalone application using Scala</span><span class="sxs-lookup"><span data-stu-id="65e78-222">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="65e78-223">Run jobs remotely on a Spark cluster using Livy</span><span class="sxs-lookup"><span data-stu-id="65e78-223">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)



